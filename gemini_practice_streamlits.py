# ========================================
# streamlit_app_last_correction.py
# ë¡œì»¬ ì „ìš©: RAG + ì‹œë®¬ë ˆì´í„° + ìŒì„± ê¸°ë¡ + LSTM + ì½˜í…ì¸ 
# Firebase/GCS ì œê±°, local_db(JSON/íŒŒì¼)ë§Œ ì‚¬ìš©
# Python 3.9 / langchain>=1.0 / streamlit-mic-recorder 0.0.8 ê¸°ì¤€
# ========================================

import os
import io
import json
import time
import uuid
import base64
import tempfile
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any
import google.generativeai as genai
import numpy as np
import streamlit as st
from matplotlib import pyplot as plt

from openai import OpenAI

# mic_recorder (0.0.8) - returns dict with key "bytes"
from streamlit_mic_recorder import mic_recorder

# LangChain / RAG ê´€ë ¨
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, TextLoader

# ========================================
# 0. ê¸°ë³¸ ê²½ë¡œ/ë¡œì»¬ DB ì„¤ì •
# ========================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "local_db")
AUDIO_DIR = os.path.join(DATA_DIR, "audio")
RAG_INDEX_DIR = os.path.join(DATA_DIR, "rag_index")

VOICE_META_FILE = os.path.join(DATA_DIR, "voice_records.json")
SIM_META_FILE = os.path.join(DATA_DIR, "simulation_histories.json")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(RAG_INDEX_DIR, exist_ok=True)


# ----------------------------------------
# JSON Helper
# ----------------------------------------
def _load_json(path: str, default: Any):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return default


def _save_json(path: str, data: Any):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# ========================================
# 1. ë‹¤êµ­ì–´ ì„¤ì •
# ========================================
DEFAULT_LANG = "ko"

LANG: Dict[str, Dict[str, str]] = {
    "ko": {
        "title": "ê°œì¸ ë§ì¶¤í˜• AI í•™ìŠµ ì½”ì¹˜ (ìŒì„± ë° DB í†µí•©)",
        "sidebar_title": "ğŸ“š AI Study Coach ì„¤ì •",
        "file_uploader": "í•™ìŠµ ìë£Œ ì—…ë¡œë“œ (PDF, TXT, HTML)",
        "button_start_analysis": "ìë£Œ ë¶„ì„ ì‹œì‘ (RAG Indexing)",
        "rag_tab": "RAG ì§€ì‹ ì±—ë´‡",
        "content_tab": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "lstm_tab": "LSTM ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "simulator_tab": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°",
        "rag_header": "RAG ì§€ì‹ ì±—ë´‡ (ë¬¸ì„œ ê¸°ë°˜ Q&A)",
        "rag_desc": "ì—…ë¡œë“œëœ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ã€‚",
        "rag_input_placeholder": "í•™ìŠµ ìë£Œì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”",
        "llm_error_key": "âš ï¸ ê²½ê³ : GEMINI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì— 'GEMINI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”ã€‚",
        "llm_error_init": "LLM ì´ˆê¸°í™” ì˜¤ë¥˜: API í‚¤ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”ã€‚",
        "content_header": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "content_desc": "í•™ìŠµ ì£¼ì œì™€ ë‚œì´ë„ì— ë§ì¶° ì½˜í…ì¸  ìƒì„±",
        "topic_label": "í•™ìŠµ ì£¼ì œ",
        "level_label": "ë‚œì´ë„",
        "content_type_label": "ì½˜í…ì¸  í˜•ì‹",
        "level_options": ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"],
        "content_options": ["í•µì‹¬ ìš”ì•½ ë…¸íŠ¸", "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­", "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´"],
        "button_generate": "ì½˜í…ì¸  ìƒì„±",
        "warning_topic": "í•™ìŠµ ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚",
        "lstm_header": "LSTM ê¸°ë°˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "lstm_desc": "ê°€ìƒì˜ ê³¼ê±° í€´ì¦ˆ ì ìˆ˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ LSTM ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë¯¸ë˜ ì„±ì·¨ë„ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤ã€‚",
        "lang_select": "ì–¸ì–´ ì„ íƒ",
        "embed_success": "ì´ {count}ê°œ ì²­í¬ë¡œ í•™ìŠµ DB êµ¬ì¶• ì™„ë£Œ!",
        "embed_fail": "ì„ë² ë”© ì‹¤íŒ¨: ë¬´ë£Œ í‹°ì–´ í•œë„ ì´ˆê³¼ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œã€‚",
        "warning_no_files": "ë¨¼ì € í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
        "warning_rag_not_ready": "RAGê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•˜ì„¸ìš”ã€‚",
        "quiz_fail_structure": "í€´ì¦ˆ ë°ì´í„° êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚",
        "select_answer": "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”",
        "check_answer": "ì •ë‹µ í™•ì¸",
        "next_question": "ë‹¤ìŒ ë¬¸í•­",
        "correct_answer": "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰",
        "incorrect_answer": "ì˜¤ë‹µì…ë‹ˆë‹¤. ğŸ˜",
        "correct_is": "ì •ë‹µ",
        "explanation": "í•´ì„¤",
        "quiz_complete": "í€´ì¦ˆ ì™„ë£Œ!",
        "score": "ì ìˆ˜",
        "retake_quiz": "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°",
        "quiz_error_llm": "í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: LLMì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ã€‚",
        "quiz_original_response": "LLM ì›ë³¸ ì‘ë‹µ",
        "firestore_loading": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...",
        "firestore_no_index": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ RAG ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìƒˆë¡œ ë§Œë“œì„¸ìš”ã€‚",
        "db_save_complete": "(DB ì €ì¥ ì™„ë£Œ)",
        "data_analysis_progress": "ìë£Œ ë¶„ì„ ë° í•™ìŠµ DB êµ¬ì¶• ì¤‘...",
        "response_generating": "ë‹µë³€ ìƒì„± ì¤‘...",
        "lstm_result_header": "í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ ê²°ê³¼",
        "lstm_score_metric": "í˜„ì¬ ì˜ˆì¸¡ ì„±ì·¨ë„",
        "lstm_score_info": "ë‹¤ìŒ í€´ì¦ˆ ì˜ˆìƒ ì ìˆ˜ëŠ” ì•½ **{predicted_score:.1f}ì **ì…ë‹ˆë‹¤. í•™ìŠµ ì„±ê³¼ë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ê°œì„ í•˜ì„¸ìš”!",
        "lstm_rerun_button": "ìƒˆë¡œìš´ ê°€ìƒ ë°ì´í„°ë¡œ ì˜ˆì¸¡",

        # --- ì‹œë®¬ë ˆì´í„° ---
        "simulator_header": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°",
        "simulator_desc": "ê¹Œë‹¤ë¡œìš´ ê³ ê° ë¬¸ì˜ì— AIì˜ ì‘ëŒ€ ì´ˆì•ˆ ë° ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤ã€‚",
        "customer_query_label": "ê³ ê° ë¬¸ì˜ ë‚´ìš© (ë§í¬ í¬í•¨ ê°€ëŠ¥)",
        "customer_type_label": "ê³ ê° ì„±í–¥",
        "customer_type_options": ["ì¼ë°˜ì ì¸ ë¬¸ì˜", "ê¹Œë‹¤ë¡œìš´ ê³ ê°", "ë§¤ìš° ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ìš´ ê³ ê°"],
        "button_simulate": "ì‘ëŒ€ ì¡°ì–¸ ìš”ì²­",
        "customer_generate_response_button": "ê³ ê° ë°˜ì‘ ìƒì„±",
        "send_closing_confirm_button": "ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸°",
        "simulation_warning_query": "ê³ ê° ë¬¸ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚",
        "simulation_no_key_warning": "âš ï¸ API Keyê°€ ì—†ê¸° ë•Œë¬¸ì— ì‘ë‹µ ìƒì„±ì€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚",
        "simulation_advice_header": "AIì˜ ì‘ëŒ€ ê°€ì´ë“œë¼ì¸",
        "simulation_draft_header": "ì¶”ì²œ ì‘ëŒ€ ì´ˆì•ˆ",
        "button_listen_audio": "ìŒì„±ìœ¼ë¡œ ë“£ê¸°",
        "tts_status_ready": "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨",
        "tts_status_generating": "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...",
        "tts_status_success": "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!",
        "tts_status_error": "âŒ TTS ì˜¤ë¥˜ ë°œìƒ",
        "history_expander_title": "ğŸ“ ì´ì „ ìƒë‹´ ì´ë ¥ ë¡œë“œ (ìµœê·¼ 10ê°œ)",
        "initial_query_sample": "í”„ë‘ìŠ¤ íŒŒë¦¬ì— ë„ì°©í–ˆëŠ”ë°, í´ë£©ì—ì„œ êµ¬ë§¤í•œ eSIMì´ í™œì„±í™”ê°€ ì•ˆ ë©ë‹ˆë‹¤...",
        "button_mic_input": "ğŸ™ ìŒì„± ì…ë ¥",
        "prompt_customer_end": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ì„ ì¢…ë£Œí•©ë‹ˆë‹¤ã€‚",
        "prompt_survey": "ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› 000ì˜€ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì‹œê¸° ë°”ëë‹ˆë‹¤. [ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬]",
        "customer_closing_confirm": "ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹­ë‹ˆê¹Œ?",
        "customer_positive_response": "ì•Œê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤ã€‚",
        "button_end_chat": "ì‘ëŒ€ ì¢…ë£Œ (ì„¤ë¬¸ ìš”ì²­)",
        "survey_sent_confirm": "ğŸ“¨ ì„¤ë¬¸ì¡°ì‚¬ ë§í¬ê°€ ì „ì†¡ë˜ì—ˆìœ¼ë©°, ì´ ìƒë‹´ì€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ã€‚",
        "new_simulation_ready": "ìƒˆ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ã€‚",
        "agent_response_header": "âœï¸ ì—ì´ì „íŠ¸ ì‘ë‹µ",
        "agent_response_placeholder": "ê³ ê°ì—ê²Œ ì‘ë‹µí•˜ì„¸ìš”...",
        "send_response_button": "ì‘ë‹µ ì „ì†¡",
        "request_rebuttal_button": "ê³ ê°ì˜ ë‹¤ìŒ ë°˜ì‘ ìš”ì²­",
        "new_simulation_button": "ìƒˆ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘",
        "history_selectbox_label": "ë¡œë“œí•  ì´ë ¥ì„ ì„ íƒí•˜ì„¸ìš”:",
        "history_load_button": "ì„ íƒëœ ì´ë ¥ ë¡œë“œ",
        "delete_history_button": "âŒ ëª¨ë“  ì´ë ¥ ì‚­ì œ",
        "delete_confirm_message": "ì •ë§ë¡œ ëª¨ë“  ìƒë‹´ ì´ë ¥ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "delete_confirm_yes": "ì˜ˆ, ì‚­ì œí•©ë‹ˆë‹¤",
        "delete_confirm_no": "ì•„ë‹ˆì˜¤, ìœ ì§€í•©ë‹ˆë‹¤",
        "delete_success": "âœ… ì‚­ì œ ì™„ë£Œ!",
        "deleting_history_progress": "ì´ë ¥ ì‚­ì œ ì¤‘...",
        "search_history_label": "ì´ë ¥ ê²€ìƒ‰",
        "date_range_label": "ë‚ ì§œ ë²”ìœ„ í•„í„°",
        "no_history_found": "ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "customer_email_label": "ê³ ê° ì´ë©”ì¼ (ì„ íƒ)",
        "customer_phone_label": "ê³ ê° ì—°ë½ì²˜ / ì „í™”ë²ˆí˜¸ (ì„ íƒ)",
        "transfer_header": "ì–¸ì–´ ì´ê´€ ìš”ì²­ (ë‹¤ë¥¸ íŒ€)",
        "transfer_to_en": "ğŸ‡ºğŸ‡¸ ì˜ì–´ íŒ€ìœ¼ë¡œ ì´ê´€",
        "transfer_to_ja": "ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´ íŒ€ìœ¼ë¡œ ì´ê´€",
        "transfer_to_ko": "ğŸ‡°ğŸ‡· í•œêµ­ì–´ íŒ€ìœ¼ë¡œ ì´ê´€",
        "transfer_system_msg": "ğŸ“Œ ì‹œìŠ¤í…œ ë©”ì‹œì§€: ê³ ê° ìš”ì²­ì— ë”°ë¼ ìƒë‹´ ì–¸ì–´ê°€ {target_lang} íŒ€ìœ¼ë¡œ ì´ê´€ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ìƒë‹´ì›(AI)ì´ ì‘ëŒ€í•©ë‹ˆë‹¤ã€‚",
        "transfer_loading": "ì´ê´€ ì²˜ë¦¬ ì¤‘: ì´ì „ ëŒ€í™” ì´ë ¥ ë²ˆì—­ ë° ê²€í†  (ê³ ê°ë‹˜ê»˜ 3~10ë¶„ ì–‘í•´ ìš”ì²­)",
        "transfer_summary_header": "ğŸ” ì´ê´€ëœ ìƒë‹´ì›ì„ ìœ„í•œ ìš”ì•½ (ë²ˆì—­ë¨)",
        "transfer_summary_intro": "ê³ ê°ë‹˜ê³¼ì˜ ì´ì „ ëŒ€í™” ì´ë ¥ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ëŒ€ë¥¼ ì´ì–´ë‚˜ê°€ì„¸ìš”ã€‚",
        "llm_translation_error": "âŒ ë²ˆì—­ ì‹¤íŒ¨: LLM ì‘ë‹µ ì˜¤ë¥˜",
        "timer_metric": "ìƒë‹´ ê²½ê³¼ ì‹œê°„",
        "timer_info_ok": "AHT (15ë¶„ ê¸°ì¤€)",
        "timer_info_warn": "AHT (10ë¶„ ì´ˆê³¼)",
        "timer_info_risk": "ğŸš¨ 15ë¶„ ì´ˆê³¼: ë†’ì€ ë¦¬ìŠ¤í¬",
        "solution_check_label": "âœ… ì´ ì‘ë‹µì— ì†”ë£¨ì…˜/í•´ê²°ì±…ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",

        # --- ìŒì„± ê¸°ë¡ ---
        "voice_rec_header": "ìŒì„± ê¸°ë¡ & ê´€ë¦¬",
        "record_help": "ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒí•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
        "uploaded_file": "ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ",
        "rec_list_title": "ì €ì¥ëœ ìŒì„± ê¸°ë¡",
        "transcribe_btn": "ì „ì‚¬(Whisper)",
        "save_btn": "ìŒì„± ê¸°ë¡ ì €ì¥",
        "transcribing": "ìŒì„± ì „ì‚¬ ì¤‘...",
        "transcript_result": "ì „ì‚¬ ê²°ê³¼:",
        "transcript_text": "ì „ì‚¬ í…ìŠ¤íŠ¸",
        "openai_missing": "OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "whisper_client_error": "âŒ Whisper API Client ì´ˆê¸°í™” ì‹¤íŒ¨",
        "whisper_auth_error": "âŒ Whisper API ì¸ì¦ ì‹¤íŒ¨",
        "whisper_format_error": "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤ã€‚",
        "whisper_success": "âœ… ìŒì„± ì „ì‚¬ ì™„ë£Œ!",
        "playback": "ë…¹ìŒ ì¬ìƒ",
        "retranscribe": "ì¬ì „ì‚¬",
        "delete": "ì‚­ì œ",
        "no_records": "ì €ì¥ëœ ìŒì„± ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "saved_success": "ì €ì¥ ì™„ë£Œ!",
        "delete_confirm_rec": "ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "gcs_not_conf": "GCS ë¯¸ì„¤ì •",
        "gcs_playback_fail": "ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨",
        "gcs_no_audio": "ì˜¤ë””ì˜¤ ì—†ìŒ",
        "error": "ì˜¤ë¥˜:",
        "firestore_no_db_connect": "DB ì—°ê²° ì‹¤íŒ¨",
        "save_history_success": "ìƒë‹´ ì´ë ¥ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ã€‚",
        "save_history_fail": "ìƒë‹´ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨",
        "delete_fail": "ì‚­ì œ ì‹¤íŒ¨",
        "rec_header": "ìŒì„± ì…ë ¥ ë° ì „ì‚¬",
        "whisper_processing": "ìŒì„± ì „ì‚¬ ì²˜ë¦¬ ì¤‘",
        "empty_response_warning": "ì‘ë‹µì„ ì…ë ¥í•˜ì„¸ìš”ã€‚",
        "customer_no_more_inquiries": "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤ã€‚",
        "customer_has_additional_inquiries": "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ë„ ìˆìŠµë‹ˆë‹¤ã€‚",
        "sim_end_chat_button": "ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë° ì±„íŒ… ì¢…ë£Œ",
    },

    # --- â­ ì˜ì–´ ë²„ì „ (í•œêµ­ì–´ 100% ë§¤ì¹­) ---
    "en": {
        "title": "Personalized AI Study Coach (Voice & Local DB)",
        "sidebar_title": "ğŸ“š AI Study Coach Settings",
        "file_uploader": "Upload Study Materials (PDF, TXT, HTML)",
        "button_start_analysis": "Start Analysis (RAG Indexing)",
        "rag_tab": "RAG Knowledge Chatbot",
        "content_tab": "Custom Content Generation",
        "lstm_tab": "LSTM Achievement Prediction Dashboard",
        "simulator_tab": "AI Customer Support Simulator",
        "rag_header": "RAG Knowledge Chatbot (Document Q&A)",
        "rag_desc": "Answer questions based on uploaded documents.",
        "rag_input_placeholder": "Ask a question about your study materials",
        "llm_error_key": "âš ï¸ Warning: GEMINI_API_KEY is not set.",
        "llm_error_init": "LLM initialization error. Please check your API key.",
        "content_header": "Custom Learning Content Generation",
        "content_desc": "Generate content based on the topic and difficulty.",
        "topic_label": "Learning Topic",
        "level_label": "Difficulty",
        "content_type_label": "Content Type",
        "level_options": ["Beginner", "Intermediate", "Advanced"],
        "content_options": ["Key Summary Note", "10 MCQ Questions", "Practical Example Idea"],
        "button_generate": "Generate Content",
        "warning_topic": "Please enter a learning topic.",
        "lstm_header": "LSTM Achievement Prediction Dashboard",
        "lstm_desc": "Train an LSTM model on hypothetical quiz scores and predict performance.",
        "lang_select": "Select Language",
        "embed_success": "Learning DB built with {count} chunks!",
        "embed_fail": "Embedding failed: quota exceeded or network issue.",
        "warning_no_files": "Please upload study materials first.",
        "warning_rag_not_ready": "RAG is not ready. Upload materials and analyze.",
        "quiz_fail_structure": "Quiz data structure is invalid.",
        "select_answer": "Select answer",
        "check_answer": "Check answer",
        "next_question": "Next question",
        "correct_answer": "Correct! ğŸ‰",
        "incorrect_answer": "Incorrect ğŸ˜",
        "correct_is": "Correct answer",
        "explanation": "Explanation",
        "quiz_complete": "Quiz Complete!",
        "score": "Score",
        "retake_quiz": "Retake Quiz",
        "quiz_error_llm": "Quiz generation failed: invalid JSON.",
        "quiz_original_response": "Original LLM Response",
        "firestore_loading": "Loading RAG index...",
        "firestore_no_index": "No existing RAG index found.",
        "db_save_complete": "(DB Save Complete)",
        "data_analysis_progress": "Analyzing materials and building DB...",
        "response_generating": "Generating response...",
        "lstm_result_header": "Achievement Prediction",
        "lstm_score_metric": "Predicted Achievement",
        "lstm_score_info": "Estimated next quiz score: **{predicted_score:.1f}**.",
        "lstm_rerun_button": "Predict with New Data",

        # Simulator
        "simulator_header": "AI Customer Response Simulator",
        "simulator_desc": "AI generates draft responses and guidelines for customer inquiries.",
        "customer_query_label": "Customer Message (links allowed)",
        "customer_type_label": "Customer Type",
        "customer_type_options": ["General Inquiry", "Difficult Customer", "Highly Dissatisfied Customer"],
        "button_simulate": "Generate Response",
        "customer_generate_response_button": "Generate Customer Response",
        "send_closing_confirm_button": "Send Closing Confirmation",
        "simulation_warning_query": "Please enter the customerâ€™s message.",
        "simulation_no_key_warning": "âš ï¸ API Key missing. Simulation cannot proceed.",
        "simulation_advice_header": "AI Response Guidelines",
        "simulation_draft_header": "Recommended Response Draft",
        "button_listen_audio": "Play as Audio",
        "tts_status_ready": "Ready to generate audio",
        "tts_status_generating": "Generating audio...",
        "tts_status_success": "Audio ready!",
        "tts_status_error": "TTS error occurred",
        "history_expander_title": "ğŸ“ Load Previous Sessions (Last 10)",
        "initial_query_sample": "I arrived in Paris but my Klook eSIM won't activateâ€¦",
        "button_mic_input": "ğŸ™ Voice Input",
        "prompt_customer_end": "No further inquiries. Ending chat.",
        "prompt_survey": "This was Agent 000. Have a nice day. [Survey Link]",
        "customer_closing_confirm": "Is there anything else we can assist you with?",
        "customer_positive_response": "Noted with thanks.",
        "button_end_chat": "End Chat (Survey Request)",
        "survey_sent_confirm": "ğŸ“¨ The survey link has been sent. This chat session is now closed.",
        "new_simulation_ready": "You can now start a new simulation.",
        "agent_response_header": "âœï¸ Agent Response",
        "agent_response_placeholder": "Write a response...",
        "send_response_button": "Send Response",
        "request_rebuttal_button": "Request Customer Reaction",
        "new_simulation_button": "Start New Simulation",
        "history_selectbox_label": "Choose a record to load:",
        "history_load_button": "Load Selected Record",
        "delete_history_button": "âŒ Delete All History",
        "delete_confirm_message": "Are you sure you want to delete all records?",
        "delete_confirm_yes": "Yes, Delete",
        "delete_confirm_no": "Cancel",
        "delete_success": "Deleted successfully!",
        "deleting_history_progress": "Deleting history...",
        "search_history_label": "Search History",
        "date_range_label": "Date Filter",
        "no_history_found": "No matching history found.",
        "customer_email_label": "Customer Email (optional)",
        "customer_phone_label": "Customer Phone / WhatsApp (optional)",
        "transfer_header": "Language Transfer Request (To Other Teams)",
        "transfer_to_en": "ğŸ‡°ğŸ‡· Korean Team Transfer",
        "transfer_to_ja": "ğŸ‡¯ğŸ‡µ Japanese Team Transfer",
        "transfer_to_ko": "ğŸ‡ºğŸ‡¸ English Team Transfer",
        "transfer_system_msg": "ğŸ“Œ System Message: The session language has been transferred to the {target_lang} team per customer request. A new agent (AI) will now respond.",
        "transfer_loading": "Transferring: Translating and reviewing chat history (3-10 minute wait requested from customer)",
        "transfer_summary_header": "ğŸ” Summary for Transferred Agent (Translated)",
        "transfer_summary_intro": "This is the previous chat history. Please continue the support based on this summary.",
        "llm_translation_error": "âŒ Translation failed: LLM response error",
        "timer_metric": "Elapsed Time",
        "timer_info_ok": "AHT (15 min standard)",
        "timer_info_warn": "AHT (Over 10 min)",
        "timer_info_risk": "ğŸš¨ Over 15 min: High Risk",
        "solution_check_label": "âœ… This response includes a solution/fix.",

        # Voice
        "voice_rec_header": "Voice Record & Management",
        "record_help": "Record using the microphone or upload a file.",
        "uploaded_file": "Upload Audio File",
        "rec_list_title": "Saved Voice Records",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Record",
        "transcribing": "Transcribing...",
        "transcript_result": "Transcription:",
        "transcript_text": "Transcribed Text",
        "openai_missing": "Missing OPENAI_API_KEY",
        "whisper_client_error": "Whisper client initialization failed.",
        "whisper_auth_error": "Whisper authentication failed.",
        "whisper_format_error": "Unsupported audio format.",
        "whisper_success": "Transcription complete!",
        "playback": "Play Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Voice Record",
        "transcribing": "Transcribing voice...",
        "transcript_result": "Transcription Result:",
        "transcript_text": "Transcribed Text",
        "whisper_processing": "Processing voice transcription...",
        "whisper_success": "âœ… Transcription complete! Please check the text below.",
        "openai_missing": "OpenAI API Key is missing. Please set OPENAI_API_KEY.",
        "whisper_client_error": "âŒ Error: Whisper API client not initialized.",
        "whisper_auth_error": "âŒ Whisper API authentication failed. Check your API Key.",
        "whisper_format_error": "âŒ Error: Unsupported audio format.",
        "playback": "Playback Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "no_records": "No saved voice records.",
        "saved_success": "Saved successfully!",
        "delete_confirm_rec": "Are you sure you want to delete this voice record?",
        "gcs_not_conf": "GCS not configured or no audio available",
        "gcs_playback_fail": "Failed to play audio",
        "gcs_no_audio": "No audio file found",
        "error": "Error:",
        "firestore_no_db_connect": "DB connection failed",
        "save_history_success": "Saved successfully.",
        "save_history_fail": "Save failed.",
        "delete_fail": "Delete failed",
        "rec_header": "Voice Input & Transcription",
        "whisper_processing": "Processing...",
        "empty_response_warning": "Please enter a response.",
        "customer_no_more_inquiries": "No, that will be all, thank you.",
        "customer_has_additional_inquiries": "Yes, I have an additional question.",
        "sim_end_chat_button": "Send Survey Link and End Chat",
    },

    # --- â­ ì¼ë³¸ì–´ ë²„ì „ (í•œêµ­ì–´ 100% ë§¤ì¹­) ---
    "ja": {
        "title": "ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºAIå­¦ç¿’ã‚³ãƒ¼ãƒ (éŸ³å£°ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«DB)",
        "sidebar_title": "ğŸ“š AIå­¦ç¿’ã‚³ãƒ¼ãƒè¨­å®š",
        "file_uploader": "å­¦ç¿’è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PDF, TXT, HTML)",
        "button_start_analysis": "è³‡æ–™åˆ†æé–‹å§‹ (RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ)",
        "rag_tab": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
        "content_tab": "ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "lstm_tab": "LSTMé”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "simulator_tab": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
        "rag_header": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆQ&A)",
        "rag_desc": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè³‡æ–™ã«åŸºã¥ã„ã¦è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚",
        "rag_input_placeholder": "è³‡æ–™ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
        "llm_error_key": "âš ï¸ æ³¨æ„: GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "llm_error_init": "LLM åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ï¼šAPIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        "content_header": "ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "content_desc": "å­¦ç¿’ãƒ†ãƒ¼ãƒã¨é›£æ˜“åº¦ã«å¿œã˜ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "topic_label": "å­¦ç¿’ãƒ†ãƒ¼ãƒ",
        "level_label": "é›£æ˜“åº¦",
        "content_type_label": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç¨®é¡",
        "level_options": ["åˆç´š", "ä¸­ç´š", "ä¸Šç´š"],
        "content_options": ["è¦ç‚¹ã‚µãƒãƒªãƒ¼", "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•", "å®Ÿè·µä¾‹ã‚¢ã‚¤ãƒ‡ã‚¢"],
        "button_generate": "ç”Ÿæˆã™ã‚‹",
        "warning_topic": "å­¦ç¿’ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "lstm_header": "LSTMé”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "lstm_desc": "ä»®æƒ³ã‚¯ã‚¤ã‚ºã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã—ã¦é”æˆåº¦ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚",
        "lang_select": "è¨€èªé¸æŠ",
        "embed_success": "{count}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã§DBæ§‹ç¯‰å®Œäº†!",
        "embed_fail": "åŸ‹ã‚è¾¼ã¿å¤±æ•—ï¼šã‚¯ã‚©ãƒ¼ã‚¿è¶…éã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã€‚",
        "warning_no_files": "è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
        "warning_rag_not_ready": "RAGãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“ã€‚",
        "quiz_fail_structure": "ã‚¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚",
        "select_answer": "å›ç­”ã‚’é¸æŠã—ã¦ãã ã•ã„",
        "check_answer": "å›ç­”ã‚’ç¢ºèª",
        "next_question": "æ¬¡ã®è³ªå•",
        "correct_answer": "æ­£è§£ï¼ ğŸ‰",
        "incorrect_answer": "ä¸æ­£è§£ ğŸ˜",
        "correct_is": "æ­£è§£",
        "explanation": "è§£èª¬",
        "quiz_complete": "ã‚¯ã‚¤ã‚ºå®Œäº†!",
        "score": "ã‚¹ã‚³ã‚¢",
        "retake_quiz": "å†æŒ‘æˆ¦",
        "quiz_error_llm": "ã‚¯ã‚¤ã‚ºç”Ÿæˆå¤±æ•—ï¼šJSONå½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚",
        "quiz_original_response": "LLM åŸæœ¬å›ç­”",
        "firestore_loading": "RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ä¸­...",
        "firestore_no_index": "ä¿å­˜ã•ã‚ŒãŸRAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
        "db_save_complete": "(DBä¿å­˜å®Œäº†)",
        "data_analysis_progress": "è³‡æ–™åˆ†æä¸­...",
        "response_generating": "å¿œç­”ç”Ÿæˆä¸­...",
        "lstm_result_header": "é”æˆåº¦äºˆæ¸¬çµæœ",
        "lstm_score_metric": "äºˆæ¸¬é”æˆåº¦",
        "lstm_score_info": "æ¬¡ã®ã‚¹ã‚³ã‚¢äºˆæ¸¬: **{predicted_score:.1f}ç‚¹**",
        "lstm_rerun_button": "æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§å†äºˆæ¸¬",

        # --- Simulator ---
        "simulator_header": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
        "simulator_desc": "é›£ã—ã„é¡§å®¢å•ã„åˆã‚ã›ã«å¯¾ã™ã‚‹AIã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¨è‰æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "customer_query_label": "é¡§å®¢ã‹ã‚‰ã®å•ã„åˆã‚ã›å†…å®¹ (ãƒªãƒ³ã‚¯å¯)",
        "customer_type_label": "é¡§å®¢ã‚¿ã‚¤ãƒ—",
        "customer_type_options": ["ä¸€èˆ¬çš„ãªå•ã„åˆã‚ã›", "é›£ã—ã„é¡§å®¢", "éå¸¸ã«ä¸æº€ãªé¡§å®¢"],
        "button_simulate": "å¿œå¯¾ã‚¬ã‚¤ãƒ‰ç”Ÿæˆ",
        "customer_generate_response_button": "é¡§å®¢ã®è¿”ä¿¡ã‚’ç”Ÿæˆ",
        "send_closing_confirm_button": "è¿½åŠ ã®ã”è³ªå•æœ‰ç„¡ã‚’ç¢ºèªã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡",
        "simulation_warning_query": "ãŠå•ã„åˆã‚ã›å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "simulation_no_key_warning": "âš ï¸ APIã‚­ãƒ¼ä¸è¶³ã®ãŸã‚å¿œå¯¾ç”Ÿæˆä¸å¯ã€‚",
        "simulation_advice_header": "AIå¯¾å¿œã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
        "simulation_draft_header": "æ¨å¥¨å¿œå¯¾è‰æ¡ˆ",
        "button_listen_audio": "éŸ³å£°ã§èã",
        "tts_status_ready": "éŸ³å£°ç”Ÿæˆæº–å‚™å®Œäº†",
        "tts_status_generating": "éŸ³å£°ç”Ÿæˆä¸­...",
        "tts_status_success": "éŸ³å£°æº–å‚™å®Œäº†ï¼",
        "tts_status_error": "TTS ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
        "history_expander_title": "ğŸ“ éå»ã®å¯¾å¿œå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ (æœ€æ–°10ä»¶)",
        "initial_query_sample": "ãƒ‘ãƒªã«åˆ°ç€ã—ã¾ã—ãŸãŒã€Klookã®eSIMãŒä½¿ãˆã¾ã›ã‚“â€¦",
        "button_mic_input": "ğŸ™ éŸ³å£°å…¥åŠ›",
        "prompt_customer_end": "è¿½åŠ ã®è³ªå•ãŒãªã„ãŸã‚ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚",
        "prompt_survey": "æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ000ã§ã—ãŸã€‚è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚ [ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒªãƒ³ã‚¯]",
        "customer_closing_confirm": "ä»–ã®ãŠå•åˆã›ã¯ã”ã–ã„ã¾ã›ã‚“ã§ã—ã‚‡ã†ã‹ã€‚",
        "customer_positive_response": "ã¯ã„ã€æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",
        "button_end_chat": "ãƒãƒ£ãƒƒãƒˆçµ‚äº†ï¼ˆã‚¢ãƒ³ã‚±ãƒ¼ãƒˆï¼‰",
        "new_simulation_ready": "æ–°ã—ã„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã§ãã¾ã™ã€‚",
        "survey_sent_confirm": "ğŸ“¨ ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒªãƒ³ã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚ã“ã®ãƒãƒ£ãƒƒãƒˆã¯çµ‚äº†ã—ã¾ã—ãŸã€‚",
        "agent_response_header": "âœï¸ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”",
        "agent_response_placeholder": "é¡§å®¢ã¸è¿”ä¿¡å†…å®¹ã‚’å…¥åŠ›â€¦",
        "send_response_button": "è¿”ä¿¡é€ä¿¡",
        "request_rebuttal_button": "é¡§å®¢ã®åå¿œã‚’ç”Ÿæˆ",
        "new_simulation_button": "æ–°è¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
        "history_selectbox_label": "å±¥æ­´ã‚’é¸æŠ:",
        "history_load_button": "å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€",
        "delete_history_button": "âŒ å…¨å±¥æ­´å‰Šé™¤",
        "delete_confirm_message": "ã™ã¹ã¦ã®å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ",
        "delete_confirm_yes": "ã¯ã„ã€å‰Šé™¤ã—ã¾ã™ã€‚",
        "delete_confirm_no": "ã„ã„ãˆã€ç¶­æŒã—ã¾ã™ã€‚",
        "delete_success": "å‰Šé™¤å®Œäº†ï¼",
        "deleting_history_progress": "å‰Šé™¤ä¸­...",
        "search_history_label": "å±¥æ­´æ¤œç´¢",
        "date_range_label": "æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
        "no_history_found": "è©²å½“ã™ã‚‹å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        "customer_email_label": "é¡§å®¢ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆä»»æ„ï¼‰",
        "customer_phone_label": "é¡§å®¢é€£çµ¡å…ˆ / é›»è©±ç•ªå·ï¼ˆä»»æ„ï¼‰",
        "transfer_header": "è¨€èªåˆ‡ã‚Šæ›¿ãˆè¦è«‹ï¼ˆä»–ãƒãƒ¼ãƒ ã¸ï¼‰",
        "transfer_to_en": "ğŸ‡ºğŸ‡¸ è‹±èªãƒãƒ¼ãƒ ã¸è»¢é€",
        "transfer_to_ko": "ğŸ‡°ğŸ‡· éŸ“å›½èªãƒãƒ¼ãƒ ã¸è»¢é€",
        "transfer_system_msg": "ğŸ“Œ ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: é¡§å®¢ã®è¦è«‹ã«ã‚ˆã‚Šã€å¯¾å¿œè¨€èªãŒ {target_lang} ãƒãƒ¼ãƒ ã¸åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¾ã—ãŸã€‚æ–°ã—ã„æ‹…å½“è€…(AI)ãŒå¯¾å¿œã—ã¾ã™ã€‚",
        "transfer_loading": "è»¢é€ä¸­: éå»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ç¿»è¨³ãŠã‚ˆã³ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã„ã¾ã™ (ãŠå®¢æ§˜ã«ã¯3ã€œ10åˆ†ã®ãŠæ™‚é–“ã‚’ã„ãŸã ã„ã¦ã„ã¾ã™)",
        "transfer_summary_header": "ğŸ” è»¢é€ã•ã‚ŒãŸæ‹…å½“è€…å‘ã‘ã®è¦ç´„ (ç¿»è¨³æ¸ˆã¿)",
        "transfer_summary_intro": "ã“ã‚ŒãŒé¡§å®¢ã¨ã®éå»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã§ã™ã€‚ã“ã®è¦ç´„ã«åŸºã¥ã„ã¦ã‚µãƒãƒ¼ãƒˆã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚",
        "llm_translation_error": "âŒ ç¿»è¨³å¤±æ•—: LLMå¿œç­”ã‚¨ãƒ©ãƒ¼",
        "timer_metric": "çµŒéæ™‚é–“",
        "timer_info_ok": "AHT (15ë¶„ ê¸°ì¤€)",
        "timer_info_warn": "AHT (10ë¶„ ì´ˆê³¼)",
        "timer_info_risk": "ğŸš¨ 15ë¶„ ì´ˆê³¼: é«˜ã„ãƒªã‚¹ã‚¯",
        "solution_check_label": "âœ… ã“ã®å¿œç­”ã«è§£æ±ºç­–/å¯¾å¿œç­–ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",

        # --- Voice ---
        "voice_rec_header": "éŸ³å£°è¨˜éŒ²ï¼†ç®¡ç†",
        "record_help": "éŒ²éŸ³ã™ã‚‹ã‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚",
        "uploaded_file": "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "rec_list_title": "ä¿å­˜ã•ã‚ŒãŸéŸ³å£°è¨˜éŒ²",
        "transcribe_btn": "è»¢å†™ (Whisper)",
        "save_btn": "éŸ³å£°è¨˜éŒ²ã‚’ä¿å­˜",
        "transcribing": "éŸ³å£°ã‚’è»¢å†™ä¸­...",
        "transcript_result": "è»¢å†™çµæœ:",
        "transcript_text": "è»¢å†™ãƒ†ã‚­ã‚¹ãƒˆ",
        "whisper_processing": "éŸ³å£°è»¢å†™ã‚’å‡¦ç†ä¸­...",
        "whisper_success": "âœ… è»¢å†™ãŒå®Œäº†ã—ã¾ã—ãŸï¼ ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
        "openai_missing": "OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚",
        "whisper_client_error": "âŒ ã‚¨ãƒ©ãƒ¼: Whisper APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "whisper_auth_error": "âŒ Whisper APIèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
        "whisper_format_error": "âŒ ã‚¨ãƒ©ãƒ¼: ã“ã®éŸ³å£°å½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "playback": "éŒ²éŸ³å†ç”Ÿ",
        "retranscribe": "å†è»¢å†™",
        "delete": "å‰Šé™¤",
        "no_records": "ä¿å­˜ã•ã‚ŒãŸéŸ³å£°è¨˜éŒ²ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        "saved_success": "ä¿å­˜ã—ã¾ã—ãŸï¼",
        "delete_confirm_rec": "ã“ã®éŸ³å£°è¨˜éŒ²ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ",
        "gcs_not_conf": "GCSãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€éŸ³å£°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "gcs_playback_fail": "éŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
        "gcs_no_audio": "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "error": "ã‚¨ãƒ©ãƒ¼:",
        "firestore_no_db_connect": "DBæ¥ç¶šå¤±æ•—",
        "save_history_success": "ä¿å­˜å®Œäº†ã€‚",
        "save_history_fail": "ä¿å­˜å¤±æ•—ã€‚",
        "delete_fail": "å‰Šé™¤å¤±æ•—",
        "rec_header": "éŸ³å£°å…¥åŠ›ï¼†è»¢å†™",
        "whisper_processing": "å‡¦ç†ä¸­...",
        "empty_response_warning": "å¿œç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "customer_no_more_inquiries": "ã„ã„ãˆã€çµæ§‹ã§ã™ã€‚å¤§ä¸ˆå¤«ã§ã™ã€‚æœ‰é›£ã†å¾¡åº§ã„ã¾ã—ãŸã€‚",
        "customer_has_additional_inquiries": "ã¯ã„ã€è¿½åŠ ã®å•ã„åˆã‚ã›ãŒã‚ã‚Šã¾ã™ã€‚",
        "sim_end_chat_button": "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒªãƒ³ã‚¯ã‚’é€ä¿¡ã—ã¦ãƒãƒ£ãƒƒãƒˆçµ‚äº†",
    }
}

# ========================================
# 1-1. Session State ì´ˆê¸°í™” (ëˆ„ë½ëœ AHT/ì†”ë£¨ì…˜/ì´ê´€ ìƒíƒœ ì¶”ê°€)
# ========================================

if "language" not in st.session_state:
    st.session_state.language = DEFAULT_LANG
if "is_llm_ready" not in st.session_state:
    st.session_state.is_llm_ready = False
if "llm_init_error_msg" not in st.session_state:
    st.session_state.llm_init_error_msg = ""
if "uploaded_files_state" not in st.session_state:
    st.session_state.uploaded_files_state = None
if "is_rag_ready" not in st.session_state:
    st.session_state.is_rag_ready = False
if "rag_vectorstore" not in st.session_state:
    st.session_state.rag_vectorstore = None
if "rag_messages" not in st.session_state:
    st.session_state.rag_messages = []
if "agent_input" not in st.session_state:
    st.session_state.agent_input = ""
if "last_audio" not in st.session_state:
    st.session_state.last_audio = None
if "simulator_messages" not in st.session_state:
    st.session_state.simulator_messages = []
if "simulator_memory" not in st.session_state:
    st.session_state.simulator_memory = ConversationBufferMemory(memory_key="chat_history")
if "simulator_chain" not in st.session_state:
    st.session_state.simulator_chain = None
if "initial_advice_provided" not in st.session_state:
    st.session_state.initial_advice_provided = False
if "is_chat_ended" not in st.session_state:
    st.session_state.is_chat_ended = False
if "show_delete_confirm" not in st.session_state:
    st.session_state.show_delete_confirm = False
if "customer_query_text_area" not in st.session_state:
    st.session_state.customer_query_text_area = ""
if "agent_response_area_text" not in st.session_state:
    st.session_state.agent_response_area_text = ""
if "last_transcript" not in st.session_state:
    st.session_state.last_transcript = ""
if "sim_audio_bytes" not in st.session_state:
    st.session_state.sim_audio_bytes = None
if "chat_state" not in st.session_state:
    st.session_state.chat_state = "idle"
    # idle â†’ initial_customer â†’ supervisor_advice â†’ agent_turn â†’ customer_turn â†’ closing
if "openai_client" not in st.session_state:
    st.session_state.openai_client = None
if "openai_init_msg" not in st.session_state:
    st.session_state.openai_init_msg = ""
if "sim_stage" not in st.session_state:
    st.session_state.sim_stage = "WAIT_FIRST_QUERY"
    # WAIT_FIRST_QUERY (ì´ˆê¸° ë¬¸ì˜ ì…ë ¥)
    # AGENT_TURN (ì—ì´ì „íŠ¸ ì‘ë‹µ ì…ë ¥)
    # CUSTOMER_TURN (ê³ ê° ë°˜ì‘ ìƒì„± ìš”ì²­)
    # WAIT_CLOSING_CONFIRMATION_FROM_AGENT (ê³ ê°ì´ ê°ì‚¬, ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸° ëŒ€ê¸°)
    # WAIT_CUSTOMER_CLOSING_RESPONSE (ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ë³´ëƒ„, ê³ ê°ì˜ ë§ˆì§€ë§‰ ì‘ë‹µ ëŒ€ê¸°)
    # FINAL_CLOSING_ACTION (ìµœì¢… ì¢…ë£Œ ë²„íŠ¼ ëŒ€ê¸°)
    # CLOSING (ì±„íŒ… ì¢…ë£Œ)
if "start_time" not in st.session_state:  # AHT íƒ€ì´ë¨¸ ì‹œì‘ ì‹œê°„
    st.session_state.start_time = None
if "is_solution_provided" not in st.session_state:  # ì†”ë£¨ì…˜ ì œê³µ ì—¬ë¶€ í”Œë˜ê·¸
    st.session_state.is_solution_provided = False
if "transfer_summary_text" not in st.session_state:  # ì´ê´€ ì‹œ ë²ˆì—­ëœ ìš”ì•½
    st.session_state.transfer_summary_text = ""
if "language_transfer_requested" not in st.session_state:  # ê³ ê°ì˜ ì–¸ì–´ ì´ê´€ ìš”ì²­ ì—¬ë¶€
    st.session_state.language_transfer_requested = False

L = LANG[st.session_state.language]


# ========================================
# 2. LLM í´ë¼ì´ì–¸íŠ¸ ë¼ìš°íŒ… & ì‹¤í–‰
# ... (ìƒëµ)
# ========================================

# ... (Helper Functions - TTS, Whisper, RAG, etc. - are maintained)

# ========================================
# 8. LLM (ChatOpenAI) for Simulator / Content
# ... (get_chat_history_for_prompt, generate_customer_reaction, generate_customer_closing_response are maintained)
# ========================================

# ----------------------------------------
# LLM ë²ˆì—­ í•¨ìˆ˜ (Gemini í´ë¼ì´ì–¸íŠ¸ ì˜ì¡´ì„± ì œê±° ë° ê°•í™”)
# ----------------------------------------
def translate_text_with_llm(text_content: str, target_lang_code: str, source_lang_code: str) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ LLM(Gemini)ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ìƒ ì–¸ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
    """

    target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]

    prompt = f"""
    You are an AI educational content generator and helpful AI tutor.
    Generate the following content in {target_lang} ONLY.

    Topic: {topic}
    Difficulty: {level}
    Content Type: {content_type}
    """
    response = run_llm(prompt)

    # 1. Gemini API í‚¤ í™•ì¸ ë° ì„¤ì •
    gemini_key = get_api_key("gemini")
    target_lang = LANG.get(target_lang_code, {})

    if not gemini_key:
        return f"âŒ {target_lang.get('simulation_no_key_warning', 'API Key missing').replace('GEMINI_API_KEY', 'Translation API Key')}"

    try:
        # 2. Gemini í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (on-the-fly)
        client = genai
        client.configure(api_key=gemini_key)

        target_lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(target_lang_code, "English")
        source_lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(source_lang_code, "English")

        system_prompt = (
            f"You are a professional translation AI. Translate the following customer support chat history "
            f"from '{source_lang_name}' to '{target_lang_name}'. Preserve the original format, marking "
            f"each speaker (e.g., 'Customer:', 'Agent:'). Do not add any introductory or concluding remarks. "
            f"Translate the content accurately and neutrally."
        )

        prompt = f"Original Chat History:\n\n{text_content}"

        # 3. ë²ˆì—­ ì‹¤í–‰
        gen_model = client.GenerativeModel('gemini-2.5-flash')
        response = gen_model.generate_content(
            contents=prompt,
            config=genai.types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=0.2
            ),
        )
        return response.text.strip()
    except Exception as e:
        # LLM ì‘ë‹µ ì˜¤ë¥˜ ë˜ëŠ” ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
        st.error(f"{target_lang.get('llm_translation_error', 'Translation failed')}: {e}")
        return "âŒ LLM_TRANSLATION_ERROR"


# ... (generate_customer_reaction, generate_customer_closing_response ê·¸ëŒ€ë¡œ ìœ ì§€)

# ========================================
# 9. ì‚¬ì´ë“œë°”
# ... (ìƒëµ)
# ========================================

# ë©”ì¸ íƒ€ì´í‹€
st.title(L["title"])

# ========================================
# 10. ê¸°ëŠ¥ë³„ í˜ì´ì§€
# ... (RAG, Content, LSTM, Voice Tabs are maintained)
# -------------------- Simulator Tab --------------------
elif feature_selection == L["simulator_tab"]:
st.header(L["simulator_header"])
st.markdown(L["simulator_desc"])

current_lang = st.session_state.language
L = LANG[current_lang]  # ë‹¤ì‹œ L ì—…ë°ì´íŠ¸

# =========================
# 0. ì „ì²´ ì´ë ¥ ì‚­ì œ
# ... (ìƒëµ)

# =========================
# 1. ì´ì „ ì´ë ¥ ë¡œë“œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
# ... (ìƒëµ)

# =========================
# AHT íƒ€ì´ë¨¸ (í™”ë©´ ìµœìƒë‹¨)
# ** Fix 2: íƒ€ì´ë¨¸ ìœ„ì ¯ì„ ê³ ì •ëœ ì»¬ëŸ¼ì— ë°°ì¹˜í•˜ì—¬ ë¯¸í‘œì‹œ ì˜¤ë¥˜ í•´ê²° **
# =========================
if st.session_state.sim_stage not in ["WAIT_FIRST_QUERY", "CLOSING", "idle"]:
    col_timer, _ = st.columns([1, 4])

    # start_timeì´ ìˆì„ ë•Œë§Œ ê³„ì‚° ë° í‘œì‹œ
    if st.session_state.start_time is not None:
        # í˜„ì¬ ì‹œê°„ ê³„ì‚°
        elapsed_time = datetime.now() - st.session_state.start_time
        total_seconds = elapsed_time.total_seconds()

        # ì‹œê°„ í˜•ì‹ í¬ë§·íŒ…
        minutes = int(total_seconds // 60)
        seconds = int(total_seconds % 60)
        time_str = f"{minutes:02d}:{seconds:02d}"

        # ê²½ê³  ê¸°ì¤€
        if total_seconds > 900:  # 15ë¶„
            delta_str = L["timer_info_risk"]
            delta_color = "inverse"
        elif total_seconds > 600:  # 10ë¶„
            delta_str = L["timer_info_warn"]
            delta_color = "off"
        else:
            delta_str = L["timer_info_ok"]
            delta_color = "normal"

        with col_timer:
            st.metric(
                L["timer_metric"],
                time_str,
                delta=delta_str,
                delta_color=delta_color
            )

    st.markdown("---")

# =========================
# 2. LLM ì¤€ë¹„ ì²´í¬ & ì±„íŒ… ì¢…ë£Œ ìƒíƒœ
# ... (ìƒëµ)

# =========================
# 3. ì´ˆê¸° ë¬¸ì˜ ì…ë ¥ (WAIT_FIRST_QUERY)
# ... (ìƒëµ)

# =========================
# 4. ëŒ€í™” ë¡œê·¸ í‘œì‹œ (ê³µí†µ)
# ... (ìƒëµ)

# ì´ê´€ ìš”ì•½ í‘œì‹œ (ì´ê´€ í›„ì—ë§Œ)
if st.session_state.transfer_summary_text:
    st.markdown("---")
    st.markdown(f"**{L['transfer_summary_header']}**")
    st.info(L["transfer_summary_intro"])
    st.markdown(st.session_state.transfer_summary_text)
    st.markdown("---")

# =========================
# 5. ì—ì´ì „íŠ¸ ì…ë ¥ ë‹¨ê³„ (AGENT_TURN)
# =========================
if st.session_state.sim_stage == "AGENT_TURN":
    st.markdown(f"### {L['agent_response_header']}")

    # --- ì–¸ì–´ ì´ê´€ ìš”ì²­ ê°•ì¡° í‘œì‹œ ---
    if st.session_state.language_transfer_requested:
        st.error("ğŸš¨ ê³ ê°ì´ ì–¸ì–´ ì „í™˜(ì´ê´€)ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì‘ëŒ€í•˜ê±°ë‚˜ ì´ê´€ì„ ì§„í–‰í•˜ì„¸ìš”.")

    col_mic, col_text = st.columns([1, 2])


    # ... (ë§ˆì´í¬ ë…¹ìŒ ë° ì „ì‚¬ ë¡œì§)

    # --- í…ìŠ¤íŠ¸ ì…ë ¥ + ì „ì†¡ ë²„íŠ¼ ---

    # 1. í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ
    def update_agent_response():
        st.session_state.agent_response_area_text = st.session_state.agent_response_input_box_widget


    col_text, col_button = st.columns([4, 1])

    with col_text:
        st.text_area(
            L["agent_response_placeholder"],
            value=st.session_state.agent_response_area_text,
            key="agent_response_input_box_widget",
            on_change=update_agent_response,
        )

        # ì†”ë£¨ì…˜ ì œê³µ ì²´í¬ë°•ìŠ¤
        st.session_state.is_solution_provided = st.checkbox(
            L["solution_check_label"],
            value=st.session_state.is_solution_provided,
            key="solution_checkbox_widget",
        )

    with col_button:
        send_clicked = st.button(L["send_response_button"], key="send_agent_response_btn")

    if send_clicked:
        agent_response = st.session_state.agent_response_input_box_widget.strip()

        if not agent_response:
            st.warning(L["empty_response_warning"])
            st.stop()

        st.session_state.agent_response_area_text = agent_response  # ìµœì¢…ê°’ ë°˜ì˜

        # ë¡œê·¸ ì—…ë°ì´íŠ¸ (ì†”ë£¨ì…˜ ì œê³µ ì—¬ë¶€ëŠ” ì´ë¯¸ ì²´í¬ë°•ìŠ¤ì—ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸ë¨)
        st.session_state.simulator_messages.append(
            {"role": "agent_response", "content": agent_response}
        )

        # ì…ë ¥ì°½/ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
        st.session_state.agent_response_area_text = ""
        st.session_state.sim_audio_bytes = None
        st.session_state.language_transfer_requested = False  # ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ í”Œë˜ê·¸ ë¦¬ì…‹

        # ë‹¤ìŒ ë‹¨ê³„: ê³ ê° ë°˜ì‘ ìƒì„± ìš”ì²­
        st.session_state.sim_stage = "CUSTOMER_TURN"
        # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

    # --- ì–¸ì–´ ì´ê´€ ë²„íŠ¼ ---
    st.markdown("---")
    st.markdown(f"**{L['transfer_header']}**")
    transfer_cols = st.columns(len(LANG) - 1)

    languages = list(LANG.keys())
    languages.remove(current_lang)


    def transfer_session(target_lang: str, current_messages: List[Dict[str, str]]):
        """ì–¸ì–´ ì´ê´€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  ì„¸ì…˜ ì–¸ì–´ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤."""

        if not get_api_key("gemini"):
            st.error(LANG[current_lang]["simulation_no_key_warning"].replace('API Key', 'Gemini API Key'))
            st.stop()
            return

        # AHT íƒ€ì´ë¨¸ ì¤‘ì§€
        st.session_state.start_time = None

        # 1. ë¡œë”© ì‹œì‘ (ì‹œê°„ ì–‘í•´ ë©”ì‹œì§€ ì‹œë®¬ë ˆì´ì…˜)
        with st.spinner(L["transfer_loading"]):
            # ì‹¤ì œ ëŒ€ê¸° ì‹œê°„ 5~10ì´ˆ (3~10ë¶„ ì‹œë®¬ë ˆì´ì…˜)
            time.sleep(np.random.uniform(5, 10))

            # 2. ëŒ€í™” ê¸°ë¡ì„ ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¡œ ê°€ê³µ
            history_text = ""
            for msg in current_messages:
                role = "Customer" if msg["role"].startswith("customer") or msg["role"] == "initial_query" else "Agent"
                if msg["role"] in ["initial_query", "customer_rebuttal", "agent_response", "customer_closing_response"]:
                    history_text += f"{role}: {msg['content']}\n"

            # 3. LLM ë²ˆì—­ ì‹¤í–‰ (ìˆ˜ì •ëœ ë²ˆì—­ í•¨ìˆ˜ ì‚¬ìš©)
            translated_summary = translate_text_with_llm(history_text, target_lang, st.session_state.language)

            if translated_summary.startswith("âŒ"):
                st.session_state.transfer_summary_text = translated_summary
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€
                return

            # 4. ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.transfer_summary_text = translated_summary

            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€ (ì´ê´€ ì•Œë¦¼)
            target_lang_name = {"ko": "í•œêµ­ì–´", "en": "English", "ja": "æ—¥æœ¬èª"}.get(target_lang, target_lang.capitalize())
            system_msg = L["transfer_system_msg"].format(target_lang=target_lang_name)
            st.session_state.simulator_messages.append(
                {"role": "system_end", "content": system_msg}
            )

            st.session_state.language = target_lang  # ì–¸ì–´ ë³€ê²½
            st.session_state.is_solution_provided = False  # ìƒˆë¡œìš´ ì‘ëŒ€ë¥¼ ìœ„í•´ í”Œë˜ê·¸ ë¦¬ì…‹
            st.session_state.language_transfer_requested = False  # í”Œë˜ê·¸ ë¦¬ì…‹
            st.session_state.sim_stage = "AGENT_TURN"

            # 5. ì´ë ¥ ì €ì¥
            customer_type_display = st.session_state.get("customer_type_sim_select", "")
            save_simulation_history_local(
                st.session_state.customer_query_text_area,
                customer_type_display + f" (Transferred from {st.session_state.language} to {target_lang})",
                st.session_state.simulator_messages,
                is_chat_ended=False,
            )

        # 6. UI ì¬ì‹¤í–‰ (ì–¸ì–´ ë³€ê²½ ì ìš©)
        st.success(f"âœ… {LANG[target_lang]['transfer_summary_header']}ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì‘ëŒ€ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
        # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€


    for i, target_lang in enumerate(languages):
        button_label_key = f"transfer_to_{target_lang}"
        button_label = L.get(button_label_key, f"Transfer to {target_lang.capitalize()} Team")

        if transfer_cols[i].button(button_label, key=f"btn_transfer_{target_lang}"):
            transfer_session(target_lang, st.session_state.simulator_messages)

    st.markdown("---")
    # --- Language Transfer Buttons End ---

# =========================
# 6. ê³ ê° ë°˜ì‘ ìƒì„± ë‹¨ê³„ (CUSTOMER_TURN)
# =========================
if st.session_state.sim_stage == "CUSTOMER_TURN":
    st.info("ì—ì´ì „íŠ¸ ì‘ë‹µ ì „ì†¡ ì™„ë£Œ. ê³ ê° ë°˜ì‘ ìƒì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    if st.button(L["customer_generate_response_button"], key="sim_next_rebuttal_btn"):
        if not st.session_state.is_llm_ready:
            st.warning(L["simulation_no_key_warning"])
            st.stop()

        with st.spinner(L["response_generating"]):  # ë¡œë”© í‘œì‹œ
            reaction = generate_customer_reaction(st.session_state.language)

        if reaction.startswith("âŒ"):
            st.error(reaction)
            st.stop()

        st.session_state.simulator_messages.append(
            {"role": "customer_rebuttal", "content": reaction}
        )

        # --- AHT íƒ€ì´ë¨¸ ì‹œì‘ (ê³ ê° ë°˜ì‘ ìƒì„± í›„, ì¦‰ ì—ì´ì „íŠ¸ ì‘ëŒ€ê°€ ì‹œì‘ë˜ëŠ” ìˆœê°„) ---
        if st.session_state.start_time is None:
            st.session_state.start_time = datetime.now()

        # ì–¸ì–´ ì´ê´€ ìš”ì²­ í‚¤ì›Œë“œ í™•ì¸ (ìš”ì²­ 3 ë°˜ì˜)
        lang_request_keywords = ["english", "japanese", "í•œêµ­ì–´", "è‹±èª", "æ—¥æœ¬èª", "korean"]
        if any(k in reaction.lower() for k in lang_request_keywords):
            st.session_state.language_transfer_requested = True

        # ì¢…ë£Œ ì˜ì‚¬ íŒë³„ (ìš”ì²­ 7 ë°˜ì˜: ê°ì‚¬ ì¸ì‚¬ë¥¼ í–ˆëŠ”ì§€)
        reaction_lower = reaction.lower()
        appreciation_signals = ["ê°ì‚¬", "thank", "ã‚ã‚ŠãŒã¨ã†", "noted"]
        has_appreciation = any(k in reaction_lower for k in appreciation_signals)

        is_additional_inquiry_signal = L['customer_has_additional_inquiries'] in reaction

        customer_type_display = st.session_state.get("customer_type_sim_select", "")

        # --- í•µì‹¬ ë¡œì§ ìˆ˜ì • (ìš”ì²­ 1, 2 ë°˜ì˜) ---
        # 1. ì†”ë£¨ì…˜ ì œê³µ O, ê³ ê° ê°ì‚¬ O, ì¶”ê°€ ë¬¸ì˜ X -> ì¢…ë£Œ í™•ì¸ ë‹¨ê³„ë¡œ
        if st.session_state.is_solution_provided and has_appreciation and not is_additional_inquiry_signal:
            st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
            st.session_state.is_solution_provided = False  # ì¢…ë£Œ ë‹¨ê³„ ì§„ì… í›„ í”Œë˜ê·¸ ë¦¬ì…‹
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=False,
            )
        # 2. ì†”ë£¨ì…˜ ì œê³µ X, ê³ ê° ë°˜ì‘ O/ì¶”ê°€ ë¬¸ì˜ O -> ë¬´ì¡°ê±´ ì—ì´ì „íŠ¸ í„´ ìœ ì§€
        else:
            st.session_state.sim_stage = "AGENT_TURN"
            # ì†”ë£¨ì…˜ ì œê³µ X ì˜€ë”ë¼ë„, AGENT_TURNìœ¼ë¡œ ëŒì•„ê°€ë©´ ë‹¤ìŒ ì‘ë‹µ ì‹œ ì²´í¬ë°•ìŠ¤ ìƒíƒœë¥¼ ìœ ì§€í•´ì•¼ í•¨.
            # ë‹¨, is_solution_provided í”Œë˜ê·¸ëŠ” ì´ì „ í„´ì˜ ì²´í¬ë°•ìŠ¤ ìƒíƒœë¥¼ ë°˜ì˜í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œ ëª…ì‹œì ìœ¼ë¡œ ë³€ê²½í•  í•„ìš”ëŠ” ì—†ìŒ.
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=False,
            )

        # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

# =========================
# 7. ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ëŒ€ê¸° (WAIT_CLOSING_CONFIRMATION_FROM_AGENT)
# ** Fix 1: ì´ ìƒíƒœì—ì„œëŠ” ë²„íŠ¼ë§Œ í‘œì‹œí•˜ê³  ì…ë ¥ í•„ë“œëŠ” ìˆ¨ê¹€ **
# =========================
if st.session_state.sim_stage == "WAIT_CLOSING_CONFIRMATION_FROM_AGENT":
    st.success("ê³ ê°ì´ ì†”ë£¨ì…˜ì— ê¸ì •ì ìœ¼ë¡œ ë°˜ì‘í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

    # ì—ì´ì „íŠ¸ê°€ "ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë©”ì‹œì§€"ë¥¼ ë³´ë‚´ëŠ” ë²„íŠ¼ (ìš”ì²­ 1 ë°˜ì˜)
    if st.button(L["send_closing_confirm_button"], key="btn_send_closing_confirm"):
        closing_msg = L["customer_closing_confirm"]

        # ì—ì´ì „íŠ¸ ì‘ë‹µìœ¼ë¡œ ë¡œê·¸ ê¸°ë¡
        st.session_state.simulator_messages.append(
            {"role": "agent_response", "content": closing_msg}
        )

        # ë‹¤ìŒ ë‹¨ê³„: ê³ ê°ì˜ ìµœì¢… ë‹µë³€ ëŒ€ê¸°
        st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"

        customer_type_display = st.session_state.get("customer_type_sim_select", "")
        save_simulation_history_local(
            st.session_state.customer_query_text_area, customer_type_display,
            st.session_state.simulator_messages, is_chat_ended=False,
        )
        # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

# =========================
# 8. ê³ ê° ìµœì¢… ì‘ë‹µ ìƒì„± ë° ì²˜ë¦¬ (WAIT_CUSTOMER_CLOSING_RESPONSE)
# ... (ìƒëµ)

# =========================
# 9. ìµœì¢… ì¢…ë£Œ í–‰ë™ (FINAL_CLOSING_ACTION)
# ... (ìƒëµ)

# -------------------- RAG Tab --------------------
elif feature_selection == L["rag_tab"]:
    st.header(L["rag_header"])
    st.markdown(L["rag_desc"])

    if not st.session_state.is_rag_ready or st.session_state.rag_vectorstore is None:
        if st.session_state.is_llm_ready:
            with st.spinner(L["firestore_loading"]):
                vs = load_rag_index()
                if vs is not None:
                    st.session_state.rag_vectorstore = vs
                    st.session_state.is_rag_ready = True
                else:
                    st.info(L["firestore_no_index"])
        else:
            st.warning(L["warning_rag_not_ready"])

    if st.session_state.is_rag_ready and st.session_state.rag_vectorstore is not None:
        for m in st.session_state.rag_messages:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        user_q = st.chat_input(L["rag_input_placeholder"])
        if user_q:
            st.session_state.rag_messages.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)
            with st.chat_message("assistant"):
                with st.spinner(L["response_generating"]):
                    try:
                        ans = rag_answer(user_q, st.session_state.rag_vectorstore, st.session_state.language)
                        st.markdown(ans)
                        st.session_state.rag_messages.append({"role": "assistant", "content": ans})
                    except Exception as e:
                        st.error(f"ì±—ë´‡ ì˜¤ë¥˜: {e}")
                        msg = "ì˜¤ë¥˜ ë°œìƒ" if st.session_state.language == "ko" else "An error occurred"
                        st.session_state.rag_messages.append({"role": "assistant", "content": msg})
    else:
        st.warning(L["warning_rag_not_ready"])


# -------------------- LSTM Tab --------------------
elif feature_selection == L["lstm_tab"]:
    st.header(L["lstm_header"])
    st.markdown(L["lstm_desc"])

    if st.button(L["lstm_rerun_button"]):
        # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€
        pass

    try:
        data = load_or_train_lstm()
        predicted_score = float(np.clip(data[-1] + np.random.uniform(-3, 5), 50, 100))

        st.markdown("---")
        st.subheader(L["lstm_result_header"])

        col_score, col_chart = st.columns([1, 2])

        with col_score:
            suffix = "ì " if st.session_state.language == "ko" else ""
            st.metric(L["lstm_score_metric"], f"{predicted_score:.1f}{suffix}")
            st.info(L["lstm_score_info"].format(predicted_score=predicted_score))

        with col_chart:
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(data, label="Past Scores", marker="o")
            ax.plot(len(data), predicted_score, marker="*", markersize=10)
            ax.set_title(L["lstm_header"])
            ax.set_xlabel("Time (attempts)")
            ax.set_ylabel("Score (0-100)")
            ax.legend()
            st.pyplot(fig)
    except Exception as e:
        st.info(f"LSTM ê¸°ëŠ¥ ì—ëŸ¬: {e}")

# -------------------- Voice Record Tab --------------------
elif feature_selection == L["voice_rec_header"]:
    st.header(L["voice_rec_header"])
    st.caption(L["record_help"])

    col_rec, col_list = st.columns([1, 1])

    # ë…¹ìŒ/ì—…ë¡œë“œ + ì „ì‚¬ + ì €ì¥
    with col_rec:
        st.subheader(L["rec_header"])
        audio_file = st.file_uploader(
            L["uploaded_file"],
            type=["wav", "mp3", "m4a", "webm", "ogg"],
            key="voice_rec_uploader",
        )
        audio_bytes = None
        audio_mime = "audio/webm"

        if audio_file is not None:
            audio_bytes = audio_file.getvalue()
            audio_mime = audio_file.type or "audio/webm"

        # ì¬ìƒ
        if audio_bytes:
            st.audio(audio_bytes, format=audio_mime)

        # ì „ì‚¬ ë²„íŠ¼
        if audio_bytes and st.button(L["transcribe_btn"]):
            if st.session_state.openai_client is None:
                st.error(L["openai_missing"])
            else:
                with st.spinner(L["transcribing"]):
                    text = transcribe_bytes_with_whisper(
                        audio_bytes, audio_mime, lang_code=st.session_state.language
                    )
                    st.session_state.last_transcript = text
                    snippet = text[:50].replace("\n", " ")
                    if len(text) > 50:
                        snippet += "..."
                    if text.startswith("âŒ"):
                        st.error(text)
                    else:
                        st.success(f"{L['transcript_result']} **{snippet}**")

        st.text_area(
            L["transcript_text"],
            value=st.session_state.last_transcript,
            height=150,
            key="voice_rec_transcript_area",
        )

        if audio_bytes and st.button(L["save_btn"]):
            try:
                ext = audio_mime.split("/")[-1] if "/" in audio_mime else "webm"
                filename = f"record_{int(time.time())}.{ext}"
                save_audio_record_local(
                    audio_bytes,
                    filename,
                    st.session_state.last_transcript,
                    mime_type=audio_mime,
                )
                st.success(L["saved_success"])
                st.session_state.last_transcript = ""
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€
            except Exception as e:
                st.error(f"{L['error']} {e}")

    # ì €ì¥ëœ ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
    with col_list:
        st.subheader(L["rec_list_title"])
        try:
            records = load_voice_records()
        except Exception as e:
            st.error(f"read error: {e}")
            records = []

        if not records:
            st.info(L["no_records"])
        else:
            for rec in records:
                rec_id = rec["id"]
                created_at = rec.get("created_at")
                try:
                    dt = datetime.fromisoformat(created_at)
                    created_str = dt.strftime("%Y-%m-%d %H:%M")
                except Exception:
                    created_str = str(created_at)

                transcript_snippet = (rec.get("transcript") or "")[:50].replace("\n", " ")
                if len(rec.get("transcript") or "") > 50:
                    transcript_snippet += "..."

                with st.expander(f"[{created_str}] {transcript_snippet}"):
                    st.write(f"**{L['transcript_text']}:** {rec.get('transcript') or 'N/A'}")
                    st.caption(
                        f"**Size:** {rec.get('size')} bytes | **File:** {rec.get('audio_filename')}"
                    )

                    col_p, col_r, col_d = st.columns([2, 1, 1])

                    if col_p.button(L["playback"], key=f"play_{rec_id}"):
                        try:
                            b, info = get_audio_bytes_local(rec_id)
                            mime = info.get("mime_type", "audio/webm")
                            st.audio(b, format=mime)
                        except Exception as e:
                            st.error(f"{L['gcs_playback_fail']}: {e}")

                    if col_r.button(L["retranscribe"], key=f"re_{rec_id}"):
                        if st.session_state.openai_client is None:
                            st.error(L["openai_missing"])
                        else:
                            with st.spinner(L["transcribing"]):
                                try:
                                    b, info = get_audio_bytes_local(rec_id)
                                    mime = info.get("mime_type", "audio/webm")
                                    new_text = transcribe_bytes_with_whisper(
                                        b, mime, lang_code=st.session_state.language
                                    )
                                    records = load_voice_records()
                                    for r in records:
                                        if r["id"] == rec_id:
                                            r["transcript"] = new_text
                                            break
                                    save_voice_records(records)
                                    st.success(L["retranscribe"] + " " + L["saved_success"])
                                    # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€
                                except Exception as e:
                                    st.error(f"{L['error']} {e}")

                    if col_d.button(L["delete"], key=f"del_{rec_id}"):
                        if st.session_state.get(f"confirm_del_{rec_id}", False):
                            ok = delete_audio_record_local(rec_id)
                            if ok:
                                st.success(L["delete_success"])
                            else:
                                st.error(L["delete_fail"])
                            st.session_state[f"confirm_del_{rec_id}"] = False
                            # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€
                        else:
                            st.session_state[f"confirm_del_{rec_id}"] = True
                            st.warning(L["delete_confirm_rec"])

    # =========================
    # 7. ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ëŒ€ê¸° (WAIT_CLOSING_CONFIRMATION_FROM_AGENT)
    # ** Fix 1 & 2: ì±„íŒ…/ì´ë©”ì¼ ì¢…ë£Œ ë¶„ë¦¬ ë° ë²„íŠ¼ ë¶„ë¦¬ **
    # =========================
    if st.session_state.sim_stage == "WAIT_CLOSING_CONFIRMATION_FROM_AGENT":
        st.success("ê³ ê°ì´ ì†”ë£¨ì…˜ì— ê¸ì •ì ìœ¼ë¡œ ë°˜ì‘í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

        col_chat_end, col_email_end = st.columns(2) # ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜

        # [1] ì±„íŒ… - ì¶”ê°€ ë¬¸ì˜ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸° ë²„íŠ¼ (ê¸°ì¡´ ë¡œì§)
        with col_chat_end:
            if st.button(L["send_closing_confirm_button"], key="btn_send_closing_confirm"):
                # ... (ê¸°ì¡´ ì±„íŒ… ì¢…ë£Œ í™•ì¸ ë¡œì§ ìœ ì§€)
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

        # [2] ì´ë©”ì¼ - ìƒë‹´ ì¢…ë£Œ ë²„íŠ¼ (ìš”ì²­ 2 ë°˜ì˜: ì¦‰ì‹œ ì¢…ë£Œ)
        with col_email_end:
            if st.button(L["button_email_end_chat"], key="btn_email_end_chat"):
                # ì´ë©”ì¼ì€ ëì¸ì‚¬ì— ë¬¸ì˜ í™•ì¸ì´ í¬í•¨ë˜ë¯€ë¡œ, ë°”ë¡œ ìµœì¢… ì¢…ë£Œ ë‹¨ê³„ë¡œ ì´ë™
                st.session_state.sim_stage = "FINAL_CLOSING_ACTION"
                st.session_state.simulator_messages.append(
                    {"role": "system_end", "content": "(ì‹œìŠ¤í…œ: ì´ë©”ì¼ íŠ¹ì„±ìƒ, ì¦‰ì‹œ ìµœì¢… ì¢…ë£Œ ë‹¨ê³„ë¡œ ì§„ì…í•©ë‹ˆë‹¤.)"}
                )
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

                current_hold_duration = (now - st.session_state.hold_start_time) if st.session_state.is_on_hold and st.session_state.hold_start_time else timedelta(0)
    # =========================
    # 2. LLM ì¤€ë¹„ ì²´í¬ & ì±„íŒ… ì¢…ë£Œ ìƒíƒœ
    # =========================

    # ê¸°ì¡´ 1ì°¨ ê°€ë“œ â†’ ìœ ì§€
    if not st.session_state.is_llm_ready:
        st.warning(L["simulation_no_key_warning"])
        return

    # 2ì°¨ ì‹¤ì œ í˜¸ì¶œ ê¸°ë°˜ ê°€ë“œ â†’ ì¶”ê°€
    resp = run_llm("ping")

    if resp is None or len(resp.strip()) == 0 or "âŒ" in resp:
        st.session_state.is_llm_ready = False
        st.warning(L["simulation_no_key_warning"])
        return


elif feature_selection == L["rag_tab"]:
    # ... (ê¸°ì¡´ RAG íƒ­ ë¡œì§ ìœ ì§€)
    st.header(L["rag_header"])
    st.markdown(L["rag_desc"])

    # í•™ìŠµ ìë£Œ ì—…ë¡œë“œ (ë©”ì¸ ì»´í¬ë„ŒíŠ¸ë¡œ ì´ë™)
    st.markdown("---")
    st.subheader("ğŸ“š í•™ìŠµ ìë£Œ ì—…ë¡œë“œ")
    uploaded_files_widget = st.file_uploader(
        L["file_uploader"], type=["pdf", "txt", "html"], accept_multiple_files=True,
        key="rag_file_uploader"
    )
    if uploaded_files_widget:
        st.session_state.uploaded_files_state = uploaded_files_widget

    files_to_process = st.session_state.uploaded_files_state or []

    # RAG ì¸ë±ì‹± ë²„íŠ¼
    if files_to_process and st.session_state.is_llm_ready:
        if st.button(L["button_start_analysis"], key="rag_start_analysis_btn"):
            with st.spinner(L["data_analysis_progress"]):
                vs, count = build_rag_index(files_to_process)
                if vs is not None:
                    st.session_state.rag_vectorstore = vs
                    st.session_state.is_rag_ready = True
                    st.success(L["embed_success"].format(count=count))
                    # â­ ì¬ì‹¤í–‰
                    # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€
                else:
                    st.session_state.is_rag_ready = False
    elif not files_to_process:
        st.info(L["warning_no_files"])

    st.markdown("---")

    if not st.session_state.is_rag_ready or st.session_state.rag_vectorstore is None:
        if st.session_state.is_llm_ready:
            with st.spinner(L["firestore_loading"]):
                # RAG ì¸ë±ìŠ¤ ë¡œë“œ ì‹œì—ë„ ì„ë² ë”© í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, í‚¤ ìœ íš¨ì„± ì²´í¬ í•„ìš”
                vs = load_rag_index()
                if vs is not None:
                    st.session_state.rag_vectorstore = vs
                    st.session_state.is_rag_ready = True
                else:
                    st.info(L["firestore_no_index"])
        else:
            st.warning(L["warning_rag_not_ready"])

    if st.session_state.is_rag_ready and st.session_state.rag_vectorstore is not None:
        # ê¸°ì¡´ ëŒ€í™” ë¡œê·¸ í‘œì‹œ
        for m in st.session_state.rag_messages:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        user_q = st.chat_input(L["rag_input_placeholder"])
        if user_q:
            st.session_state.rag_messages.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)
            with st.chat_message("assistant"):
                with st.spinner(L["response_generating"]):
                    try:
                        ans = rag_answer(user_q, st.session_state.rag_vectorstore, st.session_state.language)
                        st.markdown(ans)
                        st.session_state.rag_messages.append({"role": "assistant", "content": ans})
                    except Exception as e:
                        st.error(f"ì±—ë´‡ ì˜¤ë¥˜: {e}")
                        msg = "ì˜¤ë¥˜ ë°œìƒ" if st.session_state.language == "ko" else "An error occurred"
                        st.session_state.rag_messages.append({"role": "assistant", "content": msg})
    else:
        st.warning(L["warning_rag_not_ready"])

# -------------------- Content Tab --------------------
elif feature_selection == L["content_tab"]:
    # ... (ê¸°ì¡´ ì½˜í…ì¸  íƒ­ ë¡œì§ ìœ ì§€)
    st.header(L["content_header"])
    st.markdown(L["content_desc"])

    if not st.session_state.is_llm_ready:
        st.error(L["llm_error_init"])
    else:
        topic = st.text_input(L["topic_label"])
        level_display = st.selectbox(L["level_label"], L["level_options"])
        content_display = st.selectbox(L["content_type_label"], L["content_options"])

        level_map = {
            "ì´ˆê¸‰": "Beginner",
            "ì¤‘ê¸‰": "Intermediate",
            "ê³ ê¸‰": "Advanced",
            "Beginner": "Beginner",
            "Intermediate": "Intermediate",
            "Advanced": "Advanced",
            "åˆç´š": "Beginner",
            "ä¸­ç´š": "Intermediate",
            "ä¸Šç´š": "Advanced",
        }
        content_map = {
            "í•µì‹¬ ìš”ì•½ ë…¸íŠ¸": "summary",
            "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­": "quiz",
            "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´": "example",
            "Key Summary Note": "summary",
            "10 MCQ Questions": "quiz",
            "Practical Example Idea": "example",
            "æ ¸å¿ƒè¦ç´„ãƒãƒ¼ãƒˆ": "summary",
            "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•": "quiz",
            "å®Ÿè·µä¾‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢": "example",
        }

        level = level_map.get(level_display, "Beginner")
        content_type = content_map.get(content_display, "summary")

        if st.button(L["button_generate"]):
            if not topic.strip():
                st.warning(L["warning_topic"])
            else:
                target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]

                if content_type == "quiz":
                    system_prompt = (
                        "You are an expert quiz creator.\n"
                        "Generate EXACTLY 10 multiple-choice questions.\n"
                        "Return ONLY valid JSON wrapped inside ```json ... ```.\n"
                        "JSON structure:\n"
                        "{\n"
                        '  \"quiz_questions\": [\n'
                        "    {\n"
                        '      \"question\": \"...\",\n'
                        '      \"options\": [\"A\", \"B\", \"C\", \"D\"],\n'
                        '      \"correct_index\": 0,\n'
                        '      \"explanation\": \"...\"\n'
                        "    }\n"
                        "  ]\n"
                        "}\n"
                        f"The language of questions MUST be {target_lang}.\n"
                    )
                    user_msg = f"Topic: {topic} (level: {level})"
                    with st.spinner("í€´ì¦ˆ ìƒì„± ì¤‘..."):
                        try:
                            resp = run_llm(system_prompt + "\n\n" + user_msg)
                            # ë‹¨ìˆœ ì¶œë ¥
                            st.success(f"**{topic}** - {content_display}")
                            st.code(resp, language="json")
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")
                else:
                    content_prompt = (
                        f"You are a professional AI coach at the {level} level.\n"
                        f"Generate clear and educational content in {target_lang}.\n"
                        f"Content type: {content_type}.\n"
                        f"Topic: {topic}\n"
                    )
                    with st.spinner("ì½˜í…ì¸  ìƒì„± ì¤‘..."):
                        try:
                            resp = run_llm(content_prompt)
                            st.success(f"**{topic}** - {content_display}")
                            st.markdown(resp)
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")

                            current_answer = st.session_state.quiz_answers[idx]

                            if current_answer is None or not isinstance(current_answer, int) or current_answer <= 0:
                                radio_index = -1
                            else:
                                radio_index = min(current_answer - 1, len(options) - 1)

                            selected_option = st.radio(
                                L["select_answer"],
                                options,
                                index=radio_index,
                                key=f"quiz_radio_{st.session_state.quiz_type_key}_{idx}"
                            )

# -------------------- LSTM Tab --------------------
elif feature_selection == L["lstm_tab"]:
    # ... (ê¸°ì¡´ LSTM íƒ­ ë¡œì§ ìœ ì§€)
    st.header(L["lstm_header"])
    st.markdown(L["lstm_desc"])

    # â­ ìµœì í™”: ë²„íŠ¼ ìì²´ê°€ rerunì„ ìœ ë„í•˜ë¯€ë¡œ ëª…ì‹œì  rerun ì œê±° (ë²„íŠ¼ í´ë¦­ ì‹œ ìë™ ì¬ì‹¤í–‰)
    # if st.button(L["lstm_rerun_button"]):
    #     st.rerun()

    try:
        data = load_or_train_lstm()
        predicted_score = float(np.clip(data[-1] + np.random.uniform(-3, 5), 50, 100))

        st.markdown("---")
        st.subheader(L["lstm_result_header"])

        col_score, col_chart = st.columns([1, 2])

        with col_score:
            suffix = "ì " if st.session_state.language == "ko" else ""
            st.metric(L["lstm_score_metric"], f"{predicted_score:.1f}{suffix}")
            st.info(L["lstm_score_info"].format(predicted_score=predicted_score))

        with col_chart:
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(data, label="Past Scores", marker="o")
            ax.plot(len(data), predicted_score, marker="*", markersize=10)
            ax.set_title(L["lstm_header"])
            ax.set_xlabel("Time (attempts)")
            ax.set_ylabel("Score (0-100)")
            ax.legend()
            st.pyplot(fig)
    except Exception as e:
        st.info(f"LSTM ê¸°ëŠ¥ ì—ëŸ¬: {e}")


elif st.session_state.sim_stage == "WAIT_CLOSING_CONFIRMATION_FROM_AGENT":
    st.success("ê³ ê°ì´ ì†”ë£¨ì…˜ì— ê¸ì •ì ìœ¼ë¡œ ë°˜ì‘í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

    col_chat_end, col_email_end = st.columns(2)  # ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜

    # [1] ì±„íŒ… - ì¶”ê°€ ë¬¸ì˜ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸° ë²„íŠ¼
    with col_chat_end:
        # ìƒíƒœ ì „í™˜ ëª…í™•í™”: ì´ ë²„íŠ¼ í´ë¦­ ì‹œ ë‹¤ìŒ ë‹¨ê³„ì¸ WAIT_CUSTOMER_CLOSING_RESPONSEë¡œ ë°˜ë“œì‹œ ë„˜ì–´ê°
        if st.button(L["send_closing_confirm_button"],
                     key=f"btn_send_closing_confirm_{st.session_state.sim_instance_id}"):
            closing_msg = L["customer_closing_confirm"]

            # ì—ì´ì „íŠ¸ ì‘ë‹µìœ¼ë¡œ ë¡œê·¸ ê¸°ë¡
            st.session_state.simulator_messages.append(
                {"role": "agent_response", "content": closing_msg}
            )

            # ë‹¤ìŒ ë‹¨ê³„: ê³ ê°ì˜ ìµœì¢… ë‹µë³€ ëŒ€ê¸°
            st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"

            # ì´ë ¥ ì €ì¥
            customer_type_display = st.session_state.get("customer_type_sim_select", "")
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=False,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )
            # â­ ì¬ì‹¤í–‰
            # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

    # [2] ì´ë©”ì¼ - ìƒë‹´ ì¢…ë£Œ ë²„íŠ¼ (ì¦‰ì‹œ ì¢…ë£Œ)
    with col_email_end:
        if st.button(L["button_email_end_chat"], key=f"btn_email_end_chat_{st.session_state.sim_instance_id}"):
            # ì´ë©”ì¼ì€ ëì¸ì‚¬ì— ë¬¸ì˜ í™•ì¸ì´ í¬í•¨ë˜ë¯€ë¡œ, ë°”ë¡œ ìµœì¢… ì¢…ë£Œ ë‹¨ê³„ë¡œ ì´ë™

            # AHT íƒ€ì´ë¨¸ ì •ì§€
            st.session_state.start_time = None

            # ìµœì¢… ì¢…ë£Œ ë©”ì‹œì§€ (ì„¤ë¬¸ ì¡°ì‚¬ í¬í•¨)
            end_msg = L["prompt_survey"]
            st.session_state.simulator_messages.append(
                {"role": "system_end", "content": "(ì‹œìŠ¤í…œ: ì´ë©”ì¼ ìƒë‹´ ì¢…ë£Œ) " + end_msg}
            )
            st.session_state.is_chat_ended = True
            st.session_state.sim_stage = "CLOSING"  # ë°”ë¡œ CLOSINGìœ¼ë¡œ ì „í™˜

            # ì´ë ¥ ì €ì¥
            customer_type_display = st.session_state.get("customer_type_sim_select", "")
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=True,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )
            # â­ ì¬ì‹¤í–‰
            # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

    # =========================
    # 8. ê³ ê° ìµœì¢… ì‘ë‹µ ìƒì„± ë° ì²˜ë¦¬ (WAIT_CUSTOMER_CLOSING_RESPONSE)
    # =========================
elif st.session_state.sim_stage == "WAIT_CUSTOMER_CLOSING_RESPONSE":
    L = LANG[st.session_state.language]
    st.info("ì—ì´ì „íŠ¸ê°€ ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³ ê°ì˜ ìµœì¢… ë‹µë³€ì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

    # ê³ ê° ë‹µë³€ ìë™ ìƒì„± (LLM Key ê²€ì¦ í¬í•¨)
    if st.session_state.is_llm_ready:
        with st.spinner(L["generating_customer_response"]):
            # ê³ ê°ì˜ ìµœì¢… ë‹µë³€ ìƒì„± (ì±„íŒ…ìš©)
            final_customer_reaction = generate_customer_closing_response(st.session_state.language)

        customer_type_display = st.session_state.get("customer_type_sim_select", L["customer_type_options"][0])

        # ë¡œê·¸ ê¸°ë¡
        st.session_state.simulator_messages.append(
            {"role": "customer_rebuttal", "content": final_customer_reaction}
        )

        # (A) "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤" ê²½ë¡œ -> FINAL_CLOSING_ACTIONìœ¼ë¡œ
        if L['customer_no_more_inquiries'] in final_customer_reaction:
            st.session_state.sim_stage = "FINAL_CLOSING_ACTION"
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=False,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )
        # (B) "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ë„ ìˆìŠµë‹ˆë‹¤" ê²½ë¡œ -> AGENT_TURNìœ¼ë¡œ ë³µê·€
        elif L['customer_has_additional_inquiries'] in final_customer_reaction:
            st.session_state.sim_stage = "AGENT_TURN"  # ë‹¤ì‹œ ì—ì´ì „íŠ¸ ì‘ë‹µ ë‹¨ê³„ë¡œ
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=False,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )

        st.session_state.realtime_hint_text = ""  # íŒíŠ¸ ì´ˆê¸°í™”
        # â­ í•„ìˆ˜ ìˆ˜ì •: ìƒíƒœ ë³€ê²½ í›„ UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ st.rerun() ì¶”ê°€
        # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)

    else:
        st.warning("LLM Keyê°€ ì—†ì–´ ê³ ê° ë°˜ì‘ ìë™ ìƒì„±ì´ ë¶ˆê°€í•©ë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ 'ê³ ê° ë°˜ì‘ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ AGENT_TURNìœ¼ë¡œ ëŒì•„ê°€ì„¸ìš”.")
        if st.button(L["customer_generate_response_button"], key="btn_generate_final_response"):
            # ìˆ˜ë™ ì²˜ë¦¬ ì‹œ AGENT_TURNìœ¼ë¡œ ë„˜ì–´ê°€ë„ë¡ ì²˜ë¦¬
            st.session_state.sim_stage = "AGENT_TURN"
            # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

    # =========================
    # 9. ìµœì¢… ì¢…ë£Œ í–‰ë™ (FINAL_CLOSING_ACTION)
    # =========================
if st.session_state.sim_stage == "FINAL_CLOSING_ACTION":
    st.success("ê³ ê°ì´ ë” ì´ìƒ ë¬¸ì˜í•  ì‚¬í•­ì´ ì—†ë‹¤ê³  í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

    if st.button(L["sim_end_chat_button"], key="btn_final_end_chat"):
        # AHT íƒ€ì´ë¨¸ ì •ì§€
        st.session_state.start_time = None

        end_msg = L["prompt_survey"]
        st.session_state.simulator_messages.append(
            {"role": "system_end", "content": end_msg}
        )
        st.session_state.is_chat_ended = True
        st.session_state.sim_stage = "CLOSING"

        customer_type_display = st.session_state.get("customer_type_sim_select", "")
        save_simulation_history_local(
            st.session_state.customer_query_text_area, customer_type_display,
            st.session_state.simulator_messages, is_chat_ended=True,
            attachment_context=st.session_state.sim_attachment_context_for_llm,
        )

        # â­ ì¬ì‹¤í–‰
        # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

elif feature_selection == L["sim_tab_phone"]:
    st.header(L["phone_header"])
    st.markdown(L["simulator_desc"])

    current_lang = st.session_state.language
    L = LANG[current_lang]

    # ========================================
    # ì „í™” ì‹œë®¬ë ˆì´í„° ë¡œì§
    # ========================================

    # ------------------
    # AHT íƒ€ì´ë¨¸ í‘œì‹œ (ì „í™” ì‹œë®¬ë ˆì´ì…˜ì—ì„œë§Œ)
    # ------------------
    if st.session_state.call_sim_stage == "IN_CALL":
        # AHT íƒ€ì´ë¨¸ ê³„ì‚° ë¡œì§
        col_timer, col_duration = st.columns([1, 4])

        if st.session_state.start_time is not None:
            now = datetime.now()

            # Hold ì¤‘ì´ë¼ë©´, Hold ìƒíƒœê°€ ëœ ì´í›„ì˜ ì‹œê°„ì„ í˜„ì¬ total_hold_durationì— ë”í•˜ì§€ ì•ŠìŒ (Resume ì‹œ ì •ì‚°)
            if st.session_state.is_on_hold and st.session_state.hold_start_time:
                # Hold ì¤‘ì´ì§€ë§Œ AHT íƒ€ì´ë¨¸ëŠ” ê³„ì† í˜ëŸ¬ê°€ì•¼ í•˜ë¯€ë¡œ, Hold ì‹œê°„ì€ ì œì™¸í•˜ì§€ ì•Šê³  ìµœì¢… AHT ê³„ì‚°ì—ë§Œ ì‚¬ìš©
                elapsed_time_total = now - st.session_state.start_time
            else:
                elapsed_time_total = now - st.session_state.start_time

            # â­ AHTëŠ” í†µí™” ì‹œì‘ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ì´ ê²½ê³¼ ì‹œê°„ì…ë‹ˆë‹¤.
            total_seconds = elapsed_time_total.total_seconds()
            total_seconds = max(0, total_seconds)  # ìŒìˆ˜ ë°©ì§€

            # ì‹œê°„ í˜•ì‹ í¬ë§·íŒ…
            minutes = int(total_seconds // 60)
            seconds = int(total_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            # ê²½ê³  ê¸°ì¤€
            if total_seconds > 900:  # 15ë¶„
                delta_str = L["timer_info_risk"]
                delta_color = "inverse"
            elif total_seconds > 600:  # 10ë¶„
                delta_str = L["timer_info_warn"]
                delta_color = "off"
            else:
                delta_str = L["timer_info_ok"]
                delta_color = "normal"

            with col_timer:
                # AHT íƒ€ì´ë¨¸ í‘œì‹œ
                st.metric(L["timer_metric"], time_str, delta=delta_str, delta_color=delta_color)

            # â­ ìˆ˜ì •: AHT íƒ€ì´ë¨¸ ì‹¤ì‹œê°„ ê°±ì‹ ì„ ìœ„í•œ ê°•ì œ ì¬ì‹¤í–‰ ë¡œì§ ì¶”ê°€
            # í†µí™” ì¤‘ì´ê³ , Hold ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸í•˜ì—¬ ì‹¤ì‹œê°„ì„±ì„ í™•ë³´
            if not st.session_state.is_on_hold and total_seconds < 1000:
                time.sleep(1)
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ë§¤ ì´ˆë§ˆë‹¤ ì¬ì‹¤í–‰ì€ ì„±ëŠ¥ ë¬¸ì œ ìœ ë°œ (ê³¼ë„í•œ rerun ë°©ì§€)

    # ------------------
    # WAIT_FIRST_QUERY / WAITING_CALL ìƒíƒœ
    # ------------------
    if st.session_state.call_sim_stage in ["WAITING_CALL", "RINGING"]:
        st.subheader(L["call_status_waiting"])

        # ì´ˆê¸° ë¬¸ì˜ ì…ë ¥ (ê³ ê°ì´ ì „í™”ë¡œ ë§í•  ë‚´ìš©)
        st.session_state.call_initial_query = st.text_area(
            L["customer_query_label"],
            key="call_initial_query_text_area",
            height=100,
            placeholder=L["call_query_placeholder"],
        )

        customer_type = st.radio(
            L["customer_type_label"],
            L["customer_type_options"],
            key=f"customer_type_sim_select_{st.session_state.sim_instance_id}"
        )
        st.session_state.customer_type_sim_select = customer_type

        # ê°€ìƒ ì „í™”ë²ˆí˜¸ í‘œì‹œ
        st.session_state.incoming_phone_number = st.text_input(
            "Incoming Phone Number",
            key="incoming_phone_number_input",
            value=st.session_state.incoming_phone_number,
            placeholder=L["call_number_placeholder"],
        )

        # ê³ ê° ìœ í˜• ì„ íƒ
        customer_type_options = L["customer_type_options"]
        default_idx = customer_type_options.index(
            st.session_state.customer_type_sim_select) if st.session_state.customer_type_sim_select in customer_type_options else 0

        st.session_state.customer_type_sim_select = st.selectbox(
            L["customer_type_label"],
            customer_type_options,
            index=default_idx,
            key="call_customer_type_sim_select_widget",
        )

        st.markdown("---")

        if st.button(L["button_answer"], key="answer_call_btn"):
            if not st.session_state.call_initial_query.strip():
                st.warning(L["simulation_warning_query"])
                st.stop()

            if not st.session_state.is_llm_ready or st.session_state.openai_client is None:
                st.error(L["simulation_no_key_warning"] + " " + L["openai_missing"])
                st.stop()

            # ì‹œë®¬ë ˆì´ì…˜ ì´ˆê¸°í™” ë° ì‹œì‘
            st.session_state.call_sim_stage = "IN_CALL"
            st.session_state.is_call_ended = False
            st.session_state.is_on_hold = False
            st.session_state.total_hold_duration = timedelta(0)
            st.session_state.hold_start_time = None
            st.session_state.start_time = datetime.now()  # í†µí™” ì‹œì‘ ì‹œê°„ (AHT ì‹œì‘)
            st.session_state.simulator_messages = []
            st.session_state.current_customer_audio_text = ""
            st.session_state.current_agent_audio_text = ""
            st.session_state.agent_response_input_box_widget_call = ""
            st.session_state.sim_instance_id = str(uuid.uuid4())
            st.session_state.call_summary_text = ""  # ìš”ì•½ ì´ˆê¸°í™”
            st.session_state.customer_initial_audio_bytes = None  # ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
            st.session_state.customer_history_summary = ""  # AI ìš”ì•½ ì´ˆê¸°í™” (ì¶”ê°€)
            st.session_state.sim_audio_bytes = None  # ë…¹ìŒ íŒŒì¼ ì´ˆê¸°í™” (ì¶”ê°€)

            # ê³ ê°ì˜ ì²« ë²ˆì§¸ ìŒì„± ë©”ì‹œì§€ (ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ë©”ì‹œì§€)
            initial_query_text = st.session_state.call_initial_query.strip()
            st.session_state.current_customer_audio_text = initial_query_text

            # â­ ê³ ê°ì˜ ì²« ë¬¸ì˜ TTS ìŒì„± ìƒì„± ë° ì €ì¥
            with st.spinner(L["tts_status_generating"] + " (Initial Customer Query)"):
                audio_bytes, msg = synthesize_tts(initial_query_text, st.session_state.language, role="customer")
                if audio_bytes:
                    st.session_state.customer_initial_audio_bytes = audio_bytes
                    st.audio(audio_bytes, format="audio/mp3", autoplay=True)
                else:
                    st.error(f"âŒ {msg}")
                    st.session_state.customer_initial_audio_bytes = None

            # âœ… ìƒíƒœ ë³€ê²½ í›„ ì¬ì‹¤í–‰í•˜ì—¬ IN_CALL ìƒíƒœë¡œ ì „í™˜
            # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)

    for idx, msg in enumerate(st.session_state.simulator_messages):
        role = msg["role"]
        content = msg["content"]
        avatar = {"customer": "ğŸ™‹", "supervisor": "ğŸ¤–", "agent_response": "ğŸ§‘â€ğŸ’»", "customer_rebuttal": "âœ¨",
                  "system_end": "ğŸ“Œ", "system_transfer": "ğŸ“Œ"}.get(role, "ğŸ’¬")
        tts_role = "customer" if role.startswith("customer") or role == "customer_rebuttal" else (
            "agent" if role == "agent_response" else "supervisor")

        with st.chat_message(role, avatar=avatar):
            st.markdown(content)
            # ì¸ë±ìŠ¤ë¥¼ render_tts_buttonì— ì „ë‹¬í•˜ì—¬ ê³ ìœ  í‚¤ ìƒì„±ì— ì‚¬ìš©
            render_tts_button(content, st.session_state.language, role=tts_role, prefix=f"{role}_", index=idx)

if st.session_state.call_sim_stage in ["WAITING_CALL", "RINGING"]:

    if "call_sim_mode" not in st.session_state:
        st.session_state.call_sim_mode = "INBOUND"  # INBOUND or OUTBOUND

    if st.session_state.call_sim_mode == "INBOUND":
        st.subheader(L["call_status_waiting"])
    else:
        st.subheader(L["button_call_outbound"])

    # ì´ˆê¸° ë¬¸ì˜ ì…ë ¥ (ê³ ê°ì´ ì „í™”ë¡œ ë§í•  ë‚´ìš©)
    st.session_state.call_initial_query = st.text_area(
        L["customer_query_label"],
        key="call_initial_query_text_area",
        height=100,
        placeholder=L["call_query_placeholder"],
    )

    # ê°€ìƒ ì „í™”ë²ˆí˜¸ í‘œì‹œ
    st.session_state.incoming_phone_number = st.text_input(
        "Incoming/Outgoing Phone Number",
        key="incoming_phone_number_input",
        value=st.session_state.incoming_phone_number,
        placeholder=L["call_number_placeholder"],
    )

    # ê³ ê° ìœ í˜• ì„ íƒ
    customer_type_options = L["customer_type_options"]
    default_idx = customer_type_options.index(
        st.session_state.customer_type_sim_select) if st.session_state.customer_type_sim_select in customer_type_options else 0

    st.session_state.customer_type_sim_select = st.selectbox(
        L["customer_type_label"],
        customer_type_options,
        index=default_idx,
        key="call_customer_type_sim_select_widget",
    )

    st.markdown("---")

    col_in, col_out = st.columns(2)

# -------------------- Content Tab --------------------
elif feature_selection == L["content_tab"]:
    st.header(L["content_header"])
    st.markdown(L["content_desc"])
    st.markdown("---")

    if not st.session_state.is_llm_ready:
        st.warning(L["simulation_no_key_warning"])
        st.stop()

    # ë‹¤êµ­ì–´ ë§µí•‘ ë³€ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
    level_map = {
        "ì´ˆê¸‰": "Beginner",
        "ì¤‘ê¸‰": "Intermediate",
        "ê³ ê¸‰": "Advanced",
        "Beginner": "Beginner",
        "Intermediate": "Intermediate",
        "Advanced": "Advanced",
        "åˆç´š": "Beginner",
        "ä¸­ç´š": "Intermediate",
        "ä¸Šç´š": "Advanced",
    }
    content_map = {
        "í•µì‹¬ ìš”ì•½ ë…¸íŠ¸": "summary",
        "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­": "quiz",
        "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´": "example",
        "Key Summary Note": "summary",
        "10 MCQ Questions": "quiz",
        "Practical Example Idea": "example",
        "æ ¸å¿ƒè¦ç´„ãƒãƒ¼ãƒˆ": "summary",
        "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•": "quiz",
        "å®Ÿè·µä¾‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢": "example",
    }

    topic = st.text_input(L["topic_label"])
    level_display = st.selectbox(L["level_label"], L["level_options"])
    content_display = st.selectbox(L["content_type_label"], L["content_options"])

    level = level_map.get(level_display, "Beginner")
    content_type = content_map.get(content_display, "summary")

    if st.button(L["button_generate"]):
        if not topic.strip():
            st.warning(L["warning_topic"])
            st.stop()

        target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]

        # ê³µí†µ í”„ë¡¬í”„íŠ¸ ì„¤ì • (í€´ì¦ˆ í˜•ì‹ì„ í¬í•¨í•˜ì§€ ì•ŠëŠ” ê¸°ë³¸ í…œí”Œë¦¿)
        system_prompt = f"""
            You are a professional AI coach. Generate learning content in {target_lang} for the topic '{topic}' at the '{level}' difficulty.
            The content format requested is: {content_display}.
            Output ONLY the raw content.
        """

        if content_type == "quiz":
            # í€´ì¦ˆ ì „ìš© í”„ë¡¬í”„íŠ¸ ë° JSON êµ¬ì¡° ê°•ì œ (ë¡œì§ ìœ ì§€)
            quiz_prompt = f"""
                You are an expert quiz generator. Based on the topic '{topic}' and difficulty '{level}', generate 10 multiple-choice questions.
                Your output MUST be a **raw JSON object** containing a single key "quiz_questions" which holds an array of 10 questions.
                Each object in the array must strictly follow the required keys: "question", "options" (array of 4 strings), and "answer" (an integer index starting from 1).
                DO NOT include any explanation, introductory text, or markdown code blocks (e.g., ```json).
                Output ONLY the raw JSON object, starting with '{{' and ending with '}}'.
                """

            generated_json_text = None
            llm_attempts = []

            # 1ìˆœìœ„: OpenAI (JSON modeê°€ ê°€ì¥ ì•ˆì •ì )
            if get_api_key("openai"):
                llm_attempts.append(("openai", get_api_key("openai"), "gpt-4o"))
            # 2ìˆœìœ„: Gemini (Fallback)
            if get_api_key("gemini"):
                llm_attempts.append(("gemini", get_api_key("gemini"), "gemini-2.5-flash"))

            with st.spinner(L["response_generating"]):
                for provider, api_key, model_name in llm_attempts:
                    try:
                        if provider == "openai":
                            client = OpenAI(api_key=api_key)
                            response = client.chat.completions.create(
                                model=model_name,
                                messages=[{"role": "user", "content": quiz_prompt}],
                                # JSON Mode ê°•ì œ
                                response_format={"type": "json_object"},
                            )
                            # OpenAIëŠ” JSON ê°ì²´ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, íœìŠ¤ ì œê±° ì—†ì´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•¨
                            generated_json_text = response.choices[0].message.content.strip()
                            break

                        elif provider == "gemini":
                            # GeminiëŠ” response_formatì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, run_llmì„ í†µí•´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ í˜¸ì¶œ
                            generated_json_text = run_llm(quiz_prompt)
                            # Markdown íœìŠ¤ ì œê±° ì‹œë„
                            raw_text = generated_json_text.strip()
                            if raw_text.startswith("```json"):
                                generated_json_text = raw_text.split("```json")[1].split("```")[0].strip()
                            elif raw_text.startswith("```"):
                                generated_json_text = raw_text.split("```")[1].split("```")[0].strip()

                            # Geminiì˜ ì‘ë‹µì´ JSONì²˜ëŸ¼ ë³´ì´ë©´ ì‹œë„ë¥¼ ë©ˆì¶¤
                            if generated_json_text.startswith('{'):
                                break

                    except Exception as e:
                        print(f"JSON generation failed with {provider}: {e}")
                        continue

            # --- START: JSON Parsing and Error Handling Logic ---
            if generated_json_text and generated_json_text.startswith('{'):
                try:
                    # JSON ê°ì²´ íŒŒì‹± ì‹œë„ (ìµœìƒìœ„ëŠ” ê°ì²´ì—¬ì•¼ í•¨)
                    parsed_obj = json.loads(generated_json_text)

                    # 'quiz_questions' í‚¤ì—ì„œ ë°°ì—´ ì¶”ì¶œ
                    quiz_data = parsed_obj.get("quiz_questions")

                    if not isinstance(quiz_data, list) or len(quiz_data) < 1:
                        raise ValueError("Missing 'quiz_questions' key or empty array.")

                    # 3. íŒŒì‹± ì„±ê³µ ë° ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ í›„ ìƒíƒœ ì €ì¥
                    st.session_state.quiz_data = quiz_data
                    st.session_state.current_question_index = 0
                    st.session_state.quiz_score = 0
                    st.session_state.quiz_answers = [1] * len(quiz_data)
                    st.session_state.show_explanation = False
                    st.session_state.is_quiz_active = True
                    st.session_state.quiz_type_key = str(uuid.uuid4())

                    st.success(f"**{topic}** - {content_display} ìƒì„± ì™„ë£Œ")
                    # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)

                except (json.JSONDecodeError, ValueError) as e:
                    # 4. íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„° êµ¬ì¡° ë¬¸ì œ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
                    st.error(L["quiz_error_llm"])
                    st.caption(f"Error Details: {type(e).__name__} - {e}")
                    st.subheader(L["quiz_original_response"])
                    st.code(generated_json_text, language="json")
                    st.stop()
            else:
                st.error(L["quiz_error_llm"])
                if generated_json_text:
                    st.text_area(L["quiz_original_response"], generated_json_text, height=200)
                st.stop()
            # --- END: JSON Parsing and Error Handling Logic ---

        else:  # ì¼ë°˜ í…ìŠ¤íŠ¸ ìƒì„±
            st.session_state.is_quiz_active = False
            with st.spinner(L["response_generating"]):
                content = run_llm(system_prompt)
            st.session_state.generated_content = content

            st.markdown("---")
            st.markdown(f"### {content_display}")
            st.markdown(st.session_state.generated_content)

    # --- í€´ì¦ˆ/ì¼ë°˜ ì½˜í…ì¸  ì¶œë ¥ ë¡œì§ ---
    if st.session_state.get("is_quiz_active", False) and st.session_state.get("quiz_data"):
        # í€´ì¦ˆ ì§„í–‰ ë¡œì§ (ìƒëµ - ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        quiz_data = st.session_state.quiz_data
        idx = st.session_state.current_question_index

        # â­ í€´ì¦ˆ ì™„ë£Œ ì‹œ IndexError ë°©ì§€ ë¡œì§ (idx >= len(quiz_data))
        if idx >= len(quiz_data):
            # í€´ì¦ˆ ì™„ë£Œ ì‹œ ìµœì¢… ì ìˆ˜ í‘œì‹œ
            st.success(L["quiz_complete"])
            total_questions = len(quiz_data)
            score = st.session_state.quiz_score
            st.subheader(f"{L['score']}: {score} / {total_questions} ({(score / total_questions) * 100:.1f}%)")

            if st.button(L["retake_quiz"], key="retake_quiz_btn"):
                # í€´ì¦ˆ ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.is_quiz_active = False
                st.session_state.quiz_data = None
                st.session_state.current_question_index = 0
                st.session_state.quiz_score = 0
                st.session_state.quiz_answers = []
                st.session_state.show_explanation = False
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            st.stop()  # í€´ì¦ˆ ì™„ë£Œ í›„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ì„ ì™„ì „íˆ ì¤‘ë‹¨

        # í€´ì¦ˆ ì§„í–‰ (í˜„ì¬ ë¬¸í•­)
        question_data = quiz_data[idx]
        st.subheader(f"Question {idx + 1}/{len(quiz_data)}")
        st.markdown(f"**{question_data['question']}**")

        # ê¸°ì¡´ í€´ì¦ˆ ì§„í–‰ ë° ì±„ì  ë¡œì§ (ë³€í™” ì—†ìŒ)
        current_selection_index = st.session_state.quiz_answers[idx]

        options = question_data['options']
        current_answer = st.session_state.quiz_answers[idx]

        if current_answer is None or not isinstance(current_answer, int) or current_answer <= 0:
            radio_index = 0
        else:
            radio_index = min(current_answer - 1, len(options) - 1)

        selected_option = st.radio(
            L["select_answer"],
            options,
            index=radio_index,
            key=f"quiz_radio_{st.session_state.quiz_type_key}_{idx}"
        )

        selected_option_index = options.index(selected_option) + 1 if selected_option in options else None

        check_col, next_col = st.columns([1, 1])

        if check_col.button(L["check_answer"], key=f"check_answer_btn_{idx}"):
            if selected_option_index is None:
                st.warning("ì„ íƒì§€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                # ì ìˆ˜ ê³„ì‚° ë¡œì§
                if st.session_state.quiz_answers[idx] != 'Correctly Scored':
                    correct_answer = question_data.get('answer')  # answer í‚¤ê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„
                    if selected_option_index == correct_answer:
                        st.session_state.quiz_score += 1
                        st.session_state.quiz_answers[idx] = 'Correctly Scored'
                        st.success(L["correct_answer"])
                    else:
                        st.session_state.quiz_answers[idx] = selected_option_index  # ì˜¤ë‹µì€ ì„ íƒì§€ ì¸ë±ìŠ¤ ì €ì¥
                        st.error(L["incorrect_answer"])

                st.session_state.show_explanation = True
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

        # ì •ë‹µ ë° í•´ì„¤ í‘œì‹œ
        if st.session_state.show_explanation:
            correct_index = question_data.get('answer', 1)
            correct_answer_text = question_data['options'][correct_index - 1] if 0 < correct_index <= len(
                question_data['options']) else "N/A"

            st.markdown("---")
            st.markdown(f"**{L['correct_is']}:** {correct_answer_text}")
            with st.expander(f"**{L['explanation']}**", expanded=True):
                st.info(question_data.get('explanation', 'í•´ì„¤ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'))

            # ë‹¤ìŒ ë¬¸í•­ ë²„íŠ¼
            if next_col.button(L["next_question"], key=f"next_question_btn_{idx}"):
                st.session_state.current_question_index += 1
                st.session_state.show_explanation = False
                # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

        else:
            # ì‚¬ìš©ìê°€ ì´ë¯¸ ì •ë‹µì„ ì²´í¬í–ˆê³  (ë‹¤ì‹œ ë¡œë“œëœ ê²½ìš°), ë‹¤ìŒ ë²„íŠ¼ì„ ë°”ë¡œ í‘œì‹œ
            if st.session_state.quiz_answers[idx] == 'Correctly Scored' or (
                    isinstance(st.session_state.quiz_answers[idx], int) and st.session_state.quiz_answers[idx] > 0):
                if next_col.button(L["next_question"], key=f"next_question_btn_after_check_{idx}"):
                    st.session_state.current_question_index += 1
                    st.session_state.show_explanation = False
                    # st.rerun()  # ì£¼ì„ ì²˜ë¦¬: ê³¼ë„í•œ rerun ë°©ì§€

    else:
        # ì¼ë°˜ ì½˜í…ì¸  (í•µì‹¬ ìš”ì•½ ë…¸íŠ¸, ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´) ì¶œë ¥
        if st.session_state.get("generated_content"):
            content = st.session_state.generated_content

            st.markdown("---")
            st.markdown(f"### {content_display}")

            # --- START: íš¨ìœ¨ì„± ê°œì„  (ìƒë‹¨ ë¶„ì„/í•˜ë‹¨ ë³¸ë¬¸) ---

            # 1. ìƒë‹¨ ë¶„ì„ ì˜ì—­: ì‹œê°í™” ëŒ€ì‹  í‚¤ì›Œë“œ/ì£¼ìš” ë¬¸ì¥ ì¶”ì¶œ ëª¨ì˜ (ì¤‘ë³µ ë°©ì§€)
            st.subheader("ğŸ’¡ ì½˜í…ì¸  ë¶„ì„ (ì‹œê°í™” ëª¨ì˜)")

            # ì½˜í…ì¸ ë¥¼ í…ìŠ¤íŠ¸ ì¤„ë¡œ ë¶„í• í•˜ì—¬ ëª¨ì˜ í‚¤ì›Œë“œ ë° ì£¼ìš” ë¬¸ì¥ ìƒì„±
            content_lines = content.split('\n')

            # ëª¨ì˜ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°€ì¥ ê¸´ 3ê°œ ë‹¨ì–´)
            all_words = ' '.join(content_lines).replace('.', '').replace(',', '').split()
            unique_words = sorted(set(all_words), key=len, reverse=True)[:5]

            # ëª¨ì˜ ì£¼ìš” ë¬¸ì¥ ì¶”ì¶œ (ì²« ë²ˆì§¸, ê°€ìš´ë°, ë§ˆì§€ë§‰ ë¬¸ì¥)
            key_sentences = [
                content_lines[0].strip() if content_lines else "N/A",
                content_lines[len(content_lines) // 2].strip() if len(content_lines) > 1 else "",
                content_lines[-1].strip() if len(content_lines) > 1 else ""
            ]
            key_sentences = [s for s in key_sentences if s]

            col_keyword, col_sentences = st.columns([1, 1])

            with col_keyword:
                st.markdown("**í•µì‹¬ í‚¤ì›Œë“œ/ê°œë…**")
                st.info(f"[{', '.join(unique_words)}...]")

            with col_sentences:
                st.markdown("**ì£¼ìš” ë¬¸ì¥ ìš”ì•½**")
                for sentence in key_sentences[:2]:
                    st.write(f"â€¢ {sentence[:50]}...")

            st.markdown("---")

            # 2. í•˜ë‹¨ ë³¸ë¬¸ ì¶œë ¥
            st.markdown(f"### ğŸ“ ì›ë³¸ ì½˜í…ì¸ ")
            st.markdown(content)

            # --- END: íš¨ìœ¨ì„± ê°œì„  ---

            # --- START: ì•„ì´ì½˜ ë²„íŠ¼ ì¶”ê°€ ---
            st.markdown("---")
            # ì½˜í…ì¸ ë¥¼ ë³µì‚¬í•˜ê¸° ìœ„í•´ JavaScript ì‚¬ìš© (Streamlit toastì™€ í•¨ê»˜)
            js_copy_script = f"""
                function copyToClipboard(text) {{
                    navigator.clipboard.writeText(text).then(function() {{
                        // Streamlit toast í˜¸ì¶œ (ëª¨ì˜)
                        const elements = window.parent.document.querySelectorAll('[data-testid="stToast"]');
                        if (elements.length === 0) {{
                            // Fallback UI update (use Streamlit's native mechanism if possible, or simple alert)
                            alert("ë³µì‚¬ ì™„ë£Œ!"); 
                        }}
                    }}, function(err) {{
                        // Fallback: Copy via execCommand (deprecated but often works in Streamlit's iframe)
                        const textarea = document.createElement('textarea');
                        textarea.value = text;
                        document.body.appendChild(textarea);
                        textarea.select();
                        document.execCommand('copy');
                        document.body.removeChild(textarea);
                        alert("ë³µì‚¬ ì™„ë£Œ!"); 
                    }});
                }}
                copyToClipboard('{content.replace( / '/g, "\\'").replace(/\\n/g, " ")}');
                                                     """
                                       
                                                   col_like, col_dislike, col_share, col_copy, col_more = st.columns([1, 1, 1, 1, 6])
                                       
                                                   # ì¢‹ì•„ìš” ë²„íŠ¼
                                                   if col_like.button("ğŸ‘", key="content_like"):
                                                       st.toast("âœ… 'ì¢‹ì•„ìš”' ê¸°ëŠ¥ í™œì„±í™” ì˜ˆì •")
                                       
                                                   # ì‹«ì–´ìš” ë²„íŠ¼
                                                   if col_dislike.button("ğŸ‘", key="content_dislike"):
                                                       st.toast("âœ… 'ì‹«ì–´ìš”' ê¸°ëŠ¥ í™œì„±í™” ì˜ˆì •")
                                       
                                                   # ê³µìœ  ë²„íŠ¼
                                                   if col_share.button("ğŸ”—", key="content_share"):
                                                       st.toast("âœ… 'ê³µìœ ' ê¸°ëŠ¥ í™œì„±í™” ì˜ˆì •")
                                       
                                                   # ë³µì‚¬ ë²„íŠ¼ (ê¸°ëŠ¥ í™œì„±í™”)
                                                   if col_copy.button("ğŸ“‹", key="content_copy"):
                                                       # Streamlitì—ì„œ ì§ì ‘ JavaScriptë¥¼ ì‹¤í–‰í•˜ì—¬ ë³µì‚¬
                                                       st.components.v1.html(
                                                           f""" < script > {js_copy_script} </ script > """,
                    height=0,
                )
                st.toast("âœ… ì½˜í…ì¸ ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!")

            # ë”ë³´ê¸° ë²„íŠ¼
            if col_more.button("â€¢â€¢â€¢", key="content_more"):
                st.toast("âœ… 'ë”ë³´ê¸°' ê¸°ëŠ¥ í™œì„±í™” ì˜ˆì •")
            # --- END: ì•„ì´ì½˜ ë²„íŠ¼ ì¶”ê°€ ---
for idx, msg in enumerate(st.session_state.simulator_messages):
    role = msg["role"]
    content = msg["content"]
    avatar = {"customer": "ğŸ™‹", "supervisor": "ğŸ¤–", "agent_response": "ğŸ§‘â€ğŸ’»", "customer_rebuttal": "âœ¨",
              "system_end": "ğŸ“Œ"}.get(role, "ğŸ’¬")
    tts_role = "customer" if role.startswith("customer") or role == "customer_rebuttal" else (
       "agent" if role == "agent_response" else "supervisor")

    with st.chat_message(role, avatar=avatar):
        st.markdown(content)
        # ì¸ë±ìŠ¤ë¥¼ render_tts_buttonì— ì „ë‹¬í•˜ì—¬ ê³ ìœ  í‚¤ ìƒì„±ì— ì‚¬ìš©
        render_tts_button(content, st.session_state.language, role=tts_role, prefix=f"{role}_", index=idx)