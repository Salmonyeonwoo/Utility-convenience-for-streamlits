# ========================================
# pages/rag_page.py
# RAG Tab ëª¨ë“ˆ
# ========================================

import os
import streamlit as st
from datetime import datetime
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS

from config import DATA_DIR, RAG_INDEX_DIR
from lang_pack import LANG
from rag_handler import (
    build_rag_index, get_embedding_function, split_documents,
    rag_answer
)
from simulation_handler import (
    load_simulation_histories_local,
    generate_daily_customer_guide, save_daily_customer_guide
)


def render_rag_page():
    """RAG Tab ë Œë”ë§ í•¨ìˆ˜"""
    # í˜„ì¬ ì–¸ì–´ í™•ì¸ ë° L ë³€ìˆ˜ ì •ì˜
    current_lang = st.session_state.get("language", "ko")
    if current_lang not in ["ko", "en", "ja"]:
        current_lang = "ko"
    L = LANG.get(current_lang, LANG["ko"])
    
    uploaded_files = st.file_uploader(
        L["file_uploader"],
        type=["pdf", "txt", "html"],
        key="rag_file_uploader", # RAG ì „ìš© í‚¤
        accept_multiple_files=True,
        help="RAGì— ì‚¬ìš©í•  í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. PDF, TXT, HTML íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )

    if uploaded_files:
        if uploaded_files != st.session_state.get("uploaded_files_state"):
            # íŒŒì¼ì´ ë³€ê²½ë˜ë©´ RAG ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.is_rag_ready = False
            st.session_state.rag_vectorstore = None
            st.session_state.uploaded_files_state = uploaded_files

        if not st.session_state.get("is_rag_ready", False):
            if st.button(L["button_start_analysis"]):
                if not st.session_state.get("is_llm_ready", False):
                    st.error(L["simulation_no_key_warning"])
                else:
                    with st.spinner(L["data_analysis_progress"]):
                        vectorstore, count = build_rag_index(uploaded_files)

                    if vectorstore:
                        st.session_state.rag_vectorstore = vectorstore
                        st.session_state.is_rag_ready = True
                        st.success(L["embed_success"].format(count=count))
                        st.session_state.rag_messages = [
                            {"role": "assistant", "content": f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ ë¶„ì„ ì™„ë£Œ. ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."}
                        ]
                    else:
                        st.error(L["embed_fail"])
                        st.session_state.is_rag_ready = False
    else:
        st.info(L["warning_no_files"])
        st.session_state.is_rag_ready = False
        st.session_state.rag_vectorstore = None
        st.session_state.rag_messages = []

    st.markdown("---")

    # â­ RAG ë°ì´í„° í•™ìŠµ ê¸°ëŠ¥ ì¶”ê°€ - AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„° ë°ì´í„°ë¥¼ ì¼ì¼ íŒŒì¼ë¡œ í•™ìŠµ
    st.subheader("ğŸ“š ê³ ê° ê°€ì´ë“œ ìë™ ìƒì„± ë° ê´€ë¦¬ (ì¼ì¼ í•™ìŠµ)")
    
    # ì˜¤ëŠ˜ ë‚ ì§œì˜ ê°€ì´ë“œ íŒŒì¼ í™•ì¸
    today_str = datetime.now().strftime("%y%m%d")
    guide_filename = f"{today_str}_ê³ ê°ê°€ì´ë“œ.TXT"
    guide_filepath = os.path.join(DATA_DIR, guide_filename)
    
    # ê¸°ì¡´ ê°€ì´ë“œ íŒŒì¼ í‘œì‹œ
    if os.path.exists(guide_filepath):
        st.info(f"âœ… ì˜¤ëŠ˜ì˜ ê³ ê° ê°€ì´ë“œê°€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {guide_filename}")
        with st.expander("ğŸ“„ ìƒì„±ëœ ê°€ì´ë“œ ë¯¸ë¦¬ë³´ê¸°"):
            try:
                with open(guide_filepath, "r", encoding="utf-8") as f:
                    guide_preview = f.read()
                st.text_area("ê°€ì´ë“œ ë‚´ìš©", guide_preview[:2000] + "..." if len(guide_preview) > 2000 else guide_preview, height=300, disabled=True)
            except Exception as e:
                st.error(f"ê°€ì´ë“œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    else:
        st.info("ğŸ’¡ ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ê°€ì´ë“œê°€ ìƒì„±ë©ë‹ˆë‹¤.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button(L.get("button_generate_daily_guide", "ğŸ”„ ì˜¤ëŠ˜ ë‚ ì§œ ê³ ê° ê°€ì´ë“œ ìˆ˜ë™ ìƒì„±/ì—…ë°ì´íŠ¸"), key="generate_daily_guide", use_container_width=True):
            # ìµœê·¼ ì´ë ¥ ë¡œë“œ
            all_histories = load_simulation_histories_local(st.session_state.language)
            
            if all_histories:
                if st.session_state.get("is_llm_ready", False):
                    # simulation_handlerì˜ í•¨ìˆ˜ ì‚¬ìš©
                    with st.spinner(L.get("generating_customer_guide", "ê³ ê° ê°€ì´ë“œ ìƒì„± ì¤‘...")):
                        guide_content = generate_daily_customer_guide(all_histories, st.session_state.language)
                        
                        if guide_content:
                            saved_path = save_daily_customer_guide(guide_content, st.session_state.language)
                            
                            if saved_path:
                                st.success(L.get("guide_generated", "âœ… ê³ ê° ê°€ì´ë“œê°€ ìƒì„±/ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}").format(filename=guide_filename))
                                st.info(L.get("guide_file_location", "íŒŒì¼ ìœ„ì¹˜: {path}").format(path=saved_path))
                            else:
                                st.error(L.get("guide_save_failed", "ê°€ì´ë“œ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."))
                        else:
                            st.warning(L.get("guide_generation_failed", "ê°€ì´ë“œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. LLM API Keyë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."))
                else:
                    st.error(L.get("llm_not_ready", "LLMì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API Keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."))
            else:
                st.warning(L.get("no_history_for_analysis", "ë¶„ì„í•  ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”."))
    
    with col2:
        # ìƒì„±ëœ ê°€ì´ë“œë¥¼ RAGì— ìë™ ì¶”ê°€í•˜ëŠ” ê¸°ëŠ¥
        if os.path.exists(guide_filepath):
            if st.button(L.get("button_add_guide_to_rag", "ğŸ“š ìƒì„±ëœ ê°€ì´ë“œë¥¼ RAG ì¸ë±ìŠ¤ì— ì¶”ê°€"), key="add_guide_to_rag", use_container_width=True):
                if not st.session_state.get("is_llm_ready", False):
                    st.error(L.get("llm_not_ready", "LLMì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API Keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."))
                else:
                    try:
                        # ê°€ì´ë“œ íŒŒì¼ì„ RAG ì¸ë±ìŠ¤ì— ì¶”ê°€
                        with st.spinner("RAG ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘..."):
                            # ê°€ì´ë“œ íŒŒì¼ ì½ê¸°
                            with open(guide_filepath, "r", encoding="utf-8") as f:
                                guide_text = f.read()
                            
                            # ë¬¸ì„œ ìƒì„±
                            new_doc = Document(
                                page_content=guide_text,
                                metadata={"source": guide_filepath, "type": "customer_guide", "date": today_str}
                            )
                            
                            # ê¸°ì¡´ RAG ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ë¡œë“œí•˜ì—¬ ë³‘í•©
                            if st.session_state.get("rag_vectorstore"):
                                # ì„ë² ë”© í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
                                embedding_func = get_embedding_function()
                                
                                if embedding_func:
                                    # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
                                    chunks = split_documents([new_doc])
                                    
                                    # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
                                    st.session_state.rag_vectorstore.add_documents(chunks)
                                    
                                    # ì¸ë±ìŠ¤ ì €ì¥
                                    st.session_state.rag_vectorstore.save_local(RAG_INDEX_DIR)
                                    
                                    st.success(f"âœ… ê³ ê° ê°€ì´ë“œê°€ RAG ì¸ë±ìŠ¤ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! (ì¶”ê°€ëœ ì²­í¬ ìˆ˜: {len(chunks)})")
                                else:
                                    st.error("ì„ë² ë”© í•¨ìˆ˜ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
                                try:
                                    vectorstore, count = build_rag_index([guide_filepath])
                                    
                                    if vectorstore:
                                        st.session_state.rag_vectorstore = vectorstore
                                        st.session_state.is_rag_ready = True
                                        st.success(f"âœ… RAG ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (ë¬¸ì„œ ìˆ˜: {count})")
                                    else:
                                        st.error("RAG ì¸ë±ìŠ¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                except Exception as e:
                                    st.error(f"RAG ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                                    import traceback
                                    st.code(traceback.format_exc())
                                
                    except Exception as e:
                        st.error(f"RAG ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        import traceback
                        st.code(traceback.format_exc())
        else:
            st.info("ë¨¼ì € ê³ ê° ê°€ì´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    
    st.markdown("---")

    # --- ì±—ë´‡ ì„¹ì…˜ (app.py ìŠ¤íƒ€ì¼ë¡œ ê°„ì†Œí™”) ---
    if st.session_state.get("is_rag_ready", False) and st.session_state.get("rag_vectorstore"):
        if "rag_messages" not in st.session_state:
            st.session_state.rag_messages = [{"role": "assistant", "content": "ë¶„ì„ëœ ìë£Œì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."}]

        # ë©”ì‹œì§€ í‘œì‹œ (app.py ìŠ¤íƒ€ì¼)
        for message in st.session_state.rag_messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])

        # ì…ë ¥ (app.py ìŠ¤íƒ€ì¼: st.chat_input ì‚¬ìš©)
        if prompt := st.chat_input(L.get("rag_input_placeholder", "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
            st.session_state.rag_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)

            # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
            with st.chat_message("assistant"):
                with st.spinner(L.get("response_generating", "ë‹µë³€ ìƒì„± ì¤‘...")):
                    response = rag_answer(
                        prompt,
                        st.session_state.rag_vectorstore,
                        st.session_state.language
                    )
                    st.write(response)

            # ì‘ë‹µì„ ë©”ì‹œì§€ì— ì¶”ê°€
            st.session_state.rag_messages.append({"role": "assistant", "content": response})
    else:
        st.warning(L.get("warning_rag_not_ready", "RAGê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”."))
