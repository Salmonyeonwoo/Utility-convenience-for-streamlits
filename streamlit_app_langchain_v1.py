# ========================================
# streamlit_app_rebuilt_langchain_v1.py
# ========================================
# ğŸ”¥ ìµœì‹  LangChain 1.x / LCEL ê¸°ë°˜ + ë¡œì»¬ JSON DB ë²„ì „
# - Firebase ì œê±°
# - ConversationalRetrievalChain / ConversationChain ì œê±°
# - ìµœì‹  Runnable ì²´ì¸ êµ¬ì¡° ì ìš©
# - Whisper / Audio / Simulator ì™„ì „ ì‘ë™
# ========================================

import os
import json
import uuid
import streamlit as st
import tempfile
import time
from datetime import datetime
from dotenv import load_dotenv
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI

# LangChain ìµœì‹  1.x êµ¬ì¡°
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores.faiss import FAISS
from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough

# ========================================
# 1. í™˜ê²½ ì¤€ë¹„
# ========================================
load_dotenv()
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
openai_client = OpenAI(api_key=OPENAI_KEY)

# JSON DB ë””ë ‰í† ë¦¬
BASE_DIR = ".venv/local_db"
AUDIO_DIR = os.path.join(BASE_DIR, "audio")
SIM_HISTORY_JSON = os.path.join(BASE_DIR, "simulation_histories.json")
VOICE_JSON = os.path.join(BASE_DIR, "voice_records.json")

os.makedirs(BASE_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)

# JSON DB utils

def json_load(path):
    if not os.path.exists(path): return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return []

def json_save(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ========================================
# 2. ìµœì‹  LangChain ê¸°ë°˜ Conversational Agent
# ========================================
# ë©”ëª¨ë¦¬ êµ¬ì¡° (ìˆ˜ë™ ê´€ë¦¬)
if "sim_history" not in st.session_state:
    st.session_state.sim_history = []  # {"user":..., "assistant":...}

# LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7, openai_api_key=OPENAI_KEY)

# Prompt
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI support agent. Maintain professional tone."),
    ("placeholder", "{history}"),
    ("human", "{input}")
])

# Runnable Chain
agent_chain = (
    {
        "input": RunnablePassthrough(),
        "history": lambda _: st.session_state.sim_history
    }
    | chat_prompt
    | llm
)

# ========================================
# 3. Whisper ìŒì„± ì „ì‚¬
# ========================================

def transcribe(audio_bytes, mime_type):
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp.write(audio_bytes)
    tmp.close()
    try:
        with open(tmp.name, "rb") as f:
            result = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="text"
            )
        return result
    except Exception as e:
        return f"Whisper Error: {e}"
    finally:
        os.remove(tmp.name)

# ========================================
# 4. JSON DB ì €ì¥ í•¨ìˆ˜
# ========================================

def save_simulation_json(initial_query, messages):
    db = json_load(SIM_HISTORY_JSON)
    db.append({
        "id": str(uuid.uuid4()),
        "initial_query": initial_query,
        "messages": messages,
        "created": datetime.now().isoformat()
    })
    json_save(SIM_HISTORY_JSON, db)


def save_voice_json(filename, audio_bytes, transcript, mime_type):
    db = json_load(VOICE_JSON)
    audio_path = os.path.join(AUDIO_DIR, filename)

    with open(audio_path, "wb") as f:
        f.write(audio_bytes)

    db.append({
        "id": str(uuid.uuid4()),
        "filename": filename,
        "audio_path": audio_path,
        "mime_type": mime_type,
        "transcript": transcript,
        "created": datetime.now().isoformat()
    })

    json_save(VOICE_JSON, db)

# ========================================
# 5. Streamlit UI ì‹œì‘
# ========================================
st.title("AI ìƒë‹´ ì‹œë®¬ë ˆì´í„° (LangChain v1 + JSON DB)")

# ========================================
# A. ìŒì„± ì—…ë¡œë“œ + Whisper
# ========================================
st.header("ğŸ™ ìŒì„± ì „ì‚¬")
audio_file = st.file_uploader("Upload audio", type=["wav","mp3","webm","m4a"])

if audio_file:
    audio_bytes = audio_file.getvalue()
    st.audio(audio_bytes, format=audio_file.type)

    if st.button("ì „ì‚¬ ì‹¤í–‰"):
        text = transcribe(audio_bytes, audio_file.type)
        st.session_state.last_transcript = text
        st.text_area("ì „ì‚¬ ê²°ê³¼", value=text)

    if st.button("ì €ì¥í•˜ê¸°"):
        filename = f"voice_{int(time.time())}.wav"
        save_voice_json(filename, audio_bytes, st.session_state.get("last_transcript", ""), audio_file.type)
        st.success("ìŒì„± ì €ì¥ ì™„ë£Œ!")

# ========================================
# B. ìƒë‹´ ì‹œë®¬ë ˆì´í„° (ìµœì‹  LCEL ê¸°ë°˜)
# ========================================
st.header("ğŸ§‘â€ğŸ’¼ ìƒë‹´ ì‹œë®¬ë ˆì´í„°")

initial_input = st.text_input("ê³ ê° ë©”ì‹œì§€ ì…ë ¥")

if st.button("ì‘ë‹µ ìƒì„±"):
    if not initial_input:
        st.warning("ì…ë ¥ í•„ìš”")
    else:
        # ìœ ì € ë©”ì‹œì§€ ê¸°ë¡
        st.session_state.sim_history.append({"role": "human", "content": initial_input})

        # AI ì‘ë‹µ ìƒì„±
        response = agent_chain.invoke(initial_input)

        st.session_state.sim_history.append(
            {"role": "assistant", "content": response.content}
        )

        # ì €ì¥
        save_simulation_json(initial_input, st.session_state.sim_history)

        st.rerun()

# ë©”ì‹œì§€ ë Œë”ë§
for msg in st.session_state.sim_history:
    sender = "user" if msg["role"] == "human" else "assistant"
    st.chat_message(sender).markdown(msg["content"])

# ========================================
# C. ìƒë‹´ ì´ë ¥
# ========================================
st.header("ğŸ“œ ìƒë‹´ ì´ë ¥")
histories = json_load(SIM_HISTORY_JSON)

if not histories:
    st.write("ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    for h in histories[-10:][::-1]:
        st.subheader(h["initial_query"])
        for msg in h["messages"]:
            role = msg["role"]
            st.write(f"**{role}**: {msg['content']}")
