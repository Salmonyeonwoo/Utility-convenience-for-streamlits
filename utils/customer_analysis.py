# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
ê³ ê° ë¶„ì„ ëª¨ë“ˆ
ê³ ê° í”„ë¡œí•„ ë¶„ì„, ìœ ì‚¬ ì¼€ì´ìŠ¤ ì°¾ê¸°, ì‹œê°í™”, ê°€ì´ë“œë¼ì¸ ìƒì„± ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import json
from datetime import datetime
from typing import List, Dict, Any
import streamlit as st

from utils.history_handler import load_simulation_histories_local
from llm_client import run_llm
from lang_pack import LANG

# ì‹œê°í™” í•¨ìˆ˜ë“¤ì€ visualization.pyì—ì„œ ì œê³µë©ë‹ˆë‹¤.


def detect_text_language(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ìë™ ê°ì§€í•©ë‹ˆë‹¤.
    Returns: "ko", "en", "ja" ì¤‘ í•˜ë‚˜ (ê¸°ë³¸ê°’: "ko")
    """
    if not text or not text.strip():
        return "ko"  # ê¸°ë³¸ê°’
    
    try:
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ì¼ë³¸ì–´ ë¬¸ì(íˆë¼ê°€ë‚˜, ê°€íƒ€ì¹´ë‚˜, í•œì)ê°€ ë§ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¼ë³¸ì–´
        japanese_chars = sum(1 for char in text if '\u3040' <= char <= '\u309F' or '\u30A0' <= char <= '\u30FF' or '\u4E00' <= char <= '\u9FAF')
        if japanese_chars > len(text) * 0.1:  # 10% ì´ìƒ ì¼ë³¸ì–´ ë¬¸ì
            return "ja"
        
        # ì˜ì–´ ë¬¸ì ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ì˜ì–´
        english_chars = sum(1 for char in text if char.isascii() and char.isalpha())
        if english_chars > len(text) * 0.7:  # 70% ì´ìƒ ì˜ì–´ ë¬¸ì
            return "en"
        
        # LLMì„ ì‚¬ìš©í•œ ì •í™•í•œ ì–¸ì–´ ê°ì§€ ì‹œë„ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œí•˜ê³  íœ´ë¦¬ìŠ¤í‹± ê²°ê³¼ ì‚¬ìš©)
        if st.session_state.is_llm_ready:
            try:
                detection_prompt = f"""Detect the language of the following text. Respond with ONLY one word: "ko" (Korean), "en" (English), or "ja" (Japanese).

Text: {text[:200]}

Language:"""
                detected = run_llm(detection_prompt).strip().lower()
                # ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì‚¬ìš©
                if detected and detected not in ["âŒ", "error", "failed"] and detected in ["ko", "en", "ja"]:
                    return detected
            except Exception as e:
                # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ íœ´ë¦¬ìŠ¤í‹± ê²°ê³¼ ì‚¬ìš©
                print(f"Language detection LLM call failed: {e}")
                pass
    except Exception as e:
        # ì „ì²´ í•¨ìˆ˜ì—ì„œ ì˜ˆì™¸ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        print(f"Language detection error: {e}")
        return "ko"
    
    # ê¸°ë³¸ê°’: í•œêµ­ì–´
    return "ko"


def analyze_customer_profile(customer_query: str, current_lang_key: str = None) -> Dict[str, Any]:
    """ì‹ ê·œ ê³ ê°ì˜ ë¬¸ì˜ì‚¬í•­ê³¼ ë§íˆ¬ë¥¼ ë¶„ì„í•˜ì—¬ ê³ ê°ì„±í–¥ ì ìˆ˜ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì‚° (ìš”ì²­ 4)"""
    # ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ìë™ ê°ì§€ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
    try:
        detected_lang = detect_text_language(customer_query)
    except Exception as e:
        print(f"Language detection failed in analyze_customer_profile: {e}")
        detected_lang = "ko"  # ê¸°ë³¸ê°’ ì‚¬ìš©
    
    # current_lang_keyê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©
    lang_key_to_use = current_lang_key if current_lang_key else detected_lang
    # lang_key_to_useê°€ ìœ íš¨í•œì§€ í™•ì¸
    if lang_key_to_use not in ["ko", "en", "ja"]:
        lang_key_to_use = "ko"  # ê¸°ë³¸ê°’ìœ¼ë¡œ í´ë°±
    
    lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}[lang_key_to_use]

    analysis_prompt = f"""
You are an AI analyst analyzing a customer's inquiry to determine their profile and sentiment.

Analyze the following customer inquiry and provide a structured analysis in JSON format (ONLY JSON, no markdown).

Analyze:
1. Customer gender (male/female/unknown - analyze based on name, language patterns, or cultural hints)
2. Customer sentiment score (0-100, where 0=very negative/angry, 50=neutral, 100=very positive/happy)
3. Communication style (formal/casual, brief/detailed, polite/direct)
4. Urgency level (low/medium/high)
5. Customer type prediction (normal/difficult/very_dissatisfied)
6. Language and cultural hints (if any)
7. Key concerns or pain points

Output format (JSON only):
{{
  "gender": "male",
  "sentiment_score": 45,
  "communication_style": "brief, direct, slightly frustrated",
  "urgency_level": "high",
  "predicted_customer_type": "difficult",
  "cultural_hints": "unknown",
  "key_concerns": ["issue 1", "issue 2"],
  "tone_analysis": "brief description of tone"
}}

Customer Inquiry:
{customer_query}

JSON Output:
"""

    if not st.session_state.is_llm_ready:
        return {
            "gender": "unknown",
            "sentiment_score": 50,
            "communication_style": "unknown",
            "urgency_level": "medium",
            "predicted_customer_type": "normal",
            "cultural_hints": "unknown",
            "key_concerns": [],
            "tone_analysis": "Unable to analyze"
        }

    try:
        analysis_text = run_llm(analysis_prompt).strip()
        # JSON ì¶”ì¶œ
        import re
        
        # JSON ì¶”ì¶œ (ë” ê°•ë ¥í•œ ë°©ë²•)
        if "```" in analysis_text:
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', analysis_text, re.DOTALL)
            if json_match:
                analysis_text = json_match.group(1)
            else:
                analysis_text = re.sub(r'```(?:json)?\s*', '', analysis_text)
                analysis_text = re.sub(r'\s*```', '', analysis_text)
        
        # JSON ê°ì²´ ì°¾ê¸°
        json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
        if json_match:
            analysis_text = json_match.group(0)
        
        analysis_text = analysis_text.strip()
        
        # JSON íŒŒì‹± ì‹œë„ (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)
        try:
            analysis_data = json.loads(analysis_text)
        except json.JSONDecodeError as json_err:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            print(f"ê³ ê° ë¶„ì„ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
            analysis_data = {
                "gender": "unknown",
                "sentiment_score": 50,
                "communication_style": "unknown",
                "urgency_level": "medium",
                "predicted_customer_type": "normal",
                "cultural_hints": "unknown",
                "key_concerns": [],
                "tone_analysis": f"Analysis error: {str(json_err)}"
            }
        
        return analysis_data
    except Exception as e:
        return {
            "gender": "unknown",
            "sentiment_score": 50,
            "communication_style": "unknown",
            "urgency_level": "medium",
            "predicted_customer_type": "normal",
            "cultural_hints": "unknown",
            "key_concerns": [],
            "tone_analysis": f"Analysis error: {str(e)}"
        }


def find_similar_cases(customer_query: str, customer_profile: Dict[str, Any], current_lang_key: str,
                       limit: int = 5) -> List[Dict[str, Any]]:
    """ì €ì¥ëœ ìš”ì•½ ë°ì´í„°ì—ì„œ ìœ ì‚¬í•œ ì¼€ì´ìŠ¤ë¥¼ ì°¾ì•„ ë°˜í™˜ (ìš”ì²­ 4)"""
    histories = load_simulation_histories_local(current_lang_key)

    if not histories:
        return []

    # ìš”ì•½ ë°ì´í„°ê°€ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ í•„í„°ë§
    cases_with_summary = [
        h for h in histories
        if h.get("summary") and isinstance(h.get("summary"), dict) and h.get("is_chat_ended", False)
           and not h.get("is_call", False)  # ì „í™” ì´ë ¥ ì œì™¸
    ]

    if not cases_with_summary:
        return []

    # ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ + ì ìˆ˜ ìœ ì‚¬ë„)
    similar_cases = []
    query_lower = customer_query.lower()
    customer_sentiment = customer_profile.get("sentiment_score", 50)
    customer_style = customer_profile.get("communication_style", "")

    for case in cases_with_summary:
        summary = case.get("summary", {})
        main_inquiry = summary.get("main_inquiry", "").lower()
        case_sentiment = summary.get("customer_sentiment_score", 50)
        case_satisfaction = summary.get("customer_satisfaction_score", 50)

        # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
        similarity_score = 0

        # 1. ë¬¸ì˜ ë‚´ìš© ìœ ì‚¬ë„ (í‚¤ì›Œë“œ ë§¤ì¹­)
        query_words = set(query_lower.split())
        inquiry_words = set(main_inquiry.split())
        if query_words and inquiry_words:
            word_overlap = len(query_words & inquiry_words) / len(query_words | inquiry_words)
            similarity_score += word_overlap * 40

        # 2. ê°ì • ì ìˆ˜ ìœ ì‚¬ë„
        sentiment_diff = abs(customer_sentiment - case_sentiment)
        sentiment_similarity = max(0, 1 - (sentiment_diff / 100)) * 30
        similarity_score += sentiment_similarity

        # 3. ë§Œì¡±ë„ ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ì¼€ì´ìŠ¤)
        satisfaction_bonus = (case_satisfaction / 100) * 30
        similarity_score += satisfaction_bonus

        if similarity_score > 30:  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
            similar_cases.append({
                "case": case,
                "similarity_score": similarity_score,
                "summary": summary
            })

    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    similar_cases.sort(key=lambda x: x["similarity_score"], reverse=True)
    return similar_cases[:limit]


# ì‹œê°í™” í•¨ìˆ˜ë“¤ì€ visualization.pyì—ì„œ ì œê³µë©ë‹ˆë‹¤.
# (ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì—¬ê¸°ì„œëŠ” ì œê±°)
    if not IS_PLOTLY_AVAILABLE:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    sentiment_score = customer_profile.get("sentiment_score", 50)
    urgency_map = {"low": 25, "medium": 50, "high": 75}
    urgency_level = customer_profile.get("urgency_level", "medium")
    urgency_score = urgency_map.get(urgency_level.lower(), 50)

    # ê²Œì´ì§€ ì°¨íŠ¸ ìƒì„±
    fig = make_subplots(
        rows=1, cols=2,
        specs=[[{"type": "indicator"}, {"type": "indicator"}]],
        subplot_titles=(
            L.get("sentiment_score_label", "ê³ ê° ê°ì • ì ìˆ˜"),
            L.get("urgency_score_label", "ê¸´ê¸‰ë„ ì ìˆ˜")
        )
    )

    # ê°ì • ì ìˆ˜ ê²Œì´ì§€
    fig.add_trace(
        go.Indicator(
            mode="gauge+number+delta",
            value=sentiment_score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': L.get("sentiment_score_label", "ê°ì • ì ìˆ˜")},
            delta={'reference': 50},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 33], 'color': "lightgray"},
                    {'range': [33, 66], 'color': "gray"},
                    {'range': [66, 100], 'color': "lightgreen"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ),
        row=1, col=1
    )

    # ê¸´ê¸‰ë„ ì ìˆ˜ ê²Œì´ì§€
    fig.add_trace(
        go.Indicator(
            mode="gauge+number",
            value=urgency_score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': L.get("urgency_score_label", "ê¸´ê¸‰ë„")},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkred"},
                'steps': [
                    {'range': [0, 50], 'color': "lightgreen"},
                    {'range': [50, 75], 'color': "yellow"},
                    {'range': [75, 100], 'color': "lightcoral"}
                ],
            }
        ),
        row=1, col=2
    )

    fig.update_layout(height=300, margin=dict(l=20, r=20, t=50, b=20))
    return fig


def visualize_similarity_cases(similar_cases: List[Dict[str, Any]], current_lang_key: str):
    """ìœ ì‚¬ ì¼€ì´ìŠ¤ ì¶”ì²œì„ ì‹œê°í™”"""
    if not IS_PLOTLY_AVAILABLE or not similar_cases:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    case_labels = []
    similarity_scores = []
    sentiment_scores = []
    satisfaction_scores = []

    for idx, similar_case in enumerate(similar_cases, 1):
        summary = similar_case["summary"]
        similarity = similar_case["similarity_score"]
        case_labels.append(f"Case {idx}")
        similarity_scores.append(similarity)
        sentiment_scores.append(summary.get("customer_sentiment_score", 50))
        satisfaction_scores.append(summary.get("customer_satisfaction_score", 50))

    # ìœ ì‚¬ë„ ì°¨íŠ¸
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=(
            L.get("similarity_chart_title", "ìœ ì‚¬ ì¼€ì´ìŠ¤ ìœ ì‚¬ë„"),
            L.get("scores_comparison_title",
                  "ê°ì • ë° ë§Œì¡±ë„ ì ìˆ˜ ë¹„êµ")
        ),
        vertical_spacing=0.15
    )

    # ìœ ì‚¬ë„ ë°” ì°¨íŠ¸
    fig.add_trace(
        go.Bar(
            x=case_labels,
            y=similarity_scores,
            name=L.get("similarity_score_label", "ìœ ì‚¬ë„"),
            marker_color='lightblue',
            text=[f"{s:.1f}%" for s in similarity_scores],
            textposition='outside'
        ),
        row=1, col=1
    )

    # ê°ì • ë° ë§Œì¡±ë„ ì ìˆ˜ ë¹„êµ
    fig.add_trace(
        go.Bar(
            x=case_labels,
            y=sentiment_scores,
            name=L.get("sentiment_score_label", "ê°ì • ì ìˆ˜"),
            marker_color='lightcoral'
        ),
        row=2, col=1
    )

    fig.add_trace(
        go.Bar(
            x=case_labels,
            y=satisfaction_scores,
            name=L.get("satisfaction_score_label", "ë§Œì¡±ë„"),
            marker_color='lightgreen'
        ),
        row=2, col=1
    )

    fig.update_layout(
        height=600,
        showlegend=True,
        margin=dict(l=20, r=20, t=50, b=20),
        barmode='group'
    )
    fig.update_yaxes(title_text="ì ìˆ˜", row=2, col=1)
    fig.update_yaxes(title_text="ìœ ì‚¬ë„ (%)", row=1, col=1)

    return fig


def visualize_case_trends(histories: List[Dict[str, Any]], current_lang_key: str):
    """ê³¼ê±° ì„±ê³µ ì‚¬ë¡€ íŠ¸ë Œë“œë¥¼ ì‹œê°í™”"""
    if not IS_PLOTLY_AVAILABLE or not histories:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    # ìš”ì•½ ë°ì´í„°ê°€ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ í•„í„°ë§
    cases_with_summary = [
        h for h in histories
        if h.get("summary") and isinstance(h.get("summary"), dict) and h.get("is_chat_ended", False)
    ]

    if not cases_with_summary:
        return None

    # ë‚ ì§œë³„ë¡œ ì •ë ¬
    cases_with_summary.sort(key=lambda x: x.get("timestamp", ""))

    dates = []
    sentiment_scores = []
    satisfaction_scores = []

    for case in cases_with_summary:
        summary = case.get("summary", {})
        timestamp = case.get("timestamp", "")
        try:
            dt = datetime.fromisoformat(timestamp)
            dates.append(dt)
            sentiment_scores.append(summary.get("customer_sentiment_score", 50))
            satisfaction_scores.append(summary.get("customer_satisfaction_score", 50))
        except Exception:
            continue

    if not dates:
        return None

    # íŠ¸ë Œë“œ ë¼ì¸ ì°¨íŠ¸
    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=dates,
        y=sentiment_scores,
        mode='lines+markers',
        name=L.get("sentiment_trend_label", "ê°ì • ì ìˆ˜ ì¶”ì´"),
        line=dict(color='lightcoral', width=2),
        marker=dict(size=6)
    ))

    fig.add_trace(go.Scatter(
        x=dates,
        y=satisfaction_scores,
        mode='lines+markers',
        name=L.get("satisfaction_trend_label", "ë§Œì¡±ë„ ì ìˆ˜ ì¶”ì´"),
        line=dict(color='lightgreen', width=2),
        marker=dict(size=6)
    ))

    fig.update_layout(
        title=L.get("case_trends_title", "ê³¼ê±° ì¼€ì´ìŠ¤ ì ìˆ˜ ì¶”ì´"),
        xaxis_title=L.get("date_label", "ë‚ ì§œ"),
        yaxis_title=L.get("score_label", "ì ìˆ˜ (0-100)"),
        height=400,
        hovermode='x unified',
        legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
    )

    return fig


def visualize_customer_characteristics(summary: Dict[str, Any], current_lang_key: str):
    """ê³ ê° íŠ¹ì„±ì„ ì‹œê°í™” (ì–¸ì–´, ë¬¸í™”ê¶Œ, ì§€ì—­ ë“±)"""
    if not IS_PLOTLY_AVAILABLE or not summary:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    characteristics = summary.get("customer_characteristics", {})
    privacy_info = summary.get("privacy_info", {})

    # íŠ¹ì„± ë°ì´í„° ì¤€ë¹„
    labels = []
    values = []

    # ì–¸ì–´ ì •ë³´
    language = characteristics.get("language", "unknown")
    if language != "unknown":
        labels.append(L.get("language_label", "ì–¸ì–´"))
        lang_map = {"ko": "í•œêµ­ì–´", "en": "English", "ja": "æ—¥æœ¬èª"}
        values.append(lang_map.get(language, language))

    # ê°œì¸ì •ë³´ ì œê³µ ì—¬ë¶€
    if privacy_info.get("has_email"):
        labels.append(L.get("email_provided_label", "ì´ë©”ì¼ ì œê³µ"))
        values.append("Yes")
    if privacy_info.get("has_phone"):
        labels.append(L.get("phone_provided_label", "ì „í™”ë²ˆí˜¸ ì œê³µ"))
        values.append("Yes")

    # ì§€ì—­ ì •ë³´
    region = privacy_info.get("region_hint", characteristics.get("region", "unknown"))
    if region != "unknown":
        labels.append(L.get("region_label", "ì§€ì—­"))
        values.append(region)

    if not labels:
        return None

    # íŒŒì´ ì°¨íŠ¸
    fig = go.Figure(data=[go.Pie(
        labels=labels,
        values=[1] * len(labels),
        hole=0.4,
        marker_colors=px.colors.qualitative.Set3[:len(labels)]
    )])

    fig.update_layout(
        title=L.get("customer_characteristics_title",
                    "ê³ ê° íŠ¹ì„± ë¶„í¬"),
        height=300,
        showlegend=True,
        margin=dict(l=20, r=20, t=50, b=20)
    )

    return fig


def generate_guideline_from_past_cases(customer_query: str, customer_profile: Dict[str, Any],
                                       similar_cases: List[Dict[str, Any]], current_lang_key: str) -> str:
    """ê³¼ê±° ìœ ì‚¬ ì¼€ì´ìŠ¤ì˜ ì„±ê³µì ì¸ í•´ê²° ë°©ë²•ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì´ë“œë¼ì¸ ìƒì„±"""
    lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}[current_lang_key]

    if not similar_cases:
        return ""

    # ìœ ì‚¬ ì¼€ì´ìŠ¤ ìš”ì•½
    past_cases_text = ""
    for idx, similar_case in enumerate(similar_cases, 1):
        case = similar_case["case"]
        summary = similar_case["summary"]
        similarity = similar_case["similarity_score"]

        past_cases_text += f"""
[Case {idx}] (Similarity: {similarity:.1f}%)
- Inquiry: {summary.get('main_inquiry', 'N/A')}
- Customer Sentiment: {summary.get('customer_sentiment_score', 50)}/100
- Customer Satisfaction: {summary.get('customer_satisfaction_score', 50)}/100
- Key Responses: {', '.join(summary.get('key_responses', [])[:3])}
- Summary: {summary.get('summary', 'N/A')[:200]}
"""

    # ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    if current_lang_key == "ko":
        guideline_prompt = f"""
ë‹¹ì‹ ì€ ê³¼ê±° ì„±ê³µ ì‚¬ë¡€ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” AI ê³ ê° ì§€ì› ìŠˆí¼ë°”ì´ì €ì…ë‹ˆë‹¤.

ë‹¤ìŒ ìœ ì‚¬í•œ ê³¼ê±° ì‚¬ë¡€ì™€ ê·¸ë“¤ì˜ ì„±ê³µì ì¸ í•´ê²° ì „ëµì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ê³ ê° ë¬¸ì˜ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•˜ì„¸ìš”.

í˜„ì¬ ê³ ê° ë¬¸ì˜:
{customer_query}

í˜„ì¬ ê³ ê° í”„ë¡œí•„:
- ì„±ë³„: {customer_profile.get('gender', 'unknown')}
- ê°ì • ì ìˆ˜: {customer_profile.get('sentiment_score', 50)}/100
- ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼: {customer_profile.get('communication_style', 'unknown')}
- ê¸´ê¸‰ë„: {customer_profile.get('urgency_level', 'medium')}
- ì˜ˆì¸¡ ìœ í˜•: {customer_profile.get('predicted_customer_type', 'normal')}

ìœ ì‚¬í•œ ê³¼ê±° ì‚¬ë¡€ (ì„±ê³µì ì¸ í•´ê²°):
{past_cases_text}

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ê°„ê²°í•œ ê°€ì´ë“œë¼ì¸ì„ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”:
1. ìœ ì‚¬í•œ ê³¼ê±° ì‚¬ë¡€ì—ì„œ ì˜ ì‘ë™í•œ ê²ƒ ì‹ë³„
2. ì„±ê³µì ì¸ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì²´ì ì¸ ì ‘ê·¼ ë°©ë²• ì œì•ˆ
3. ê³¼ê±° ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì ì¬ì  í•¨ì • ê²½ê³ 
4. ë†’ì€ ê³ ê° ë§Œì¡±ë„ë¡œ ì´ì–´ì§„ ì‘ë‹µ ì „ëµ ê¶Œì¥

ê°€ì´ë“œë¼ì¸ (í•œêµ­ì–´ë¡œ):
"""
    elif current_lang_key == "en":
        guideline_prompt = f"""
You are an AI Customer Support Supervisor analyzing past successful cases to provide guidance.

Based on the following similar past cases and their successful resolution strategies, provide actionable guidelines for handling the current customer inquiry.

Current Customer Inquiry:
{customer_query}

Current Customer Profile:
- Gender: {customer_profile.get('gender', 'unknown')}
- Sentiment Score: {customer_profile.get('sentiment_score', 50)}/100
- Communication Style: {customer_profile.get('communication_style', 'unknown')}
- Urgency: {customer_profile.get('urgency_level', 'medium')}
- Predicted Type: {customer_profile.get('predicted_customer_type', 'normal')}

Similar Past Cases (Successful Resolutions):
{past_cases_text}

Provide a concise guideline in English that:
1. Identifies what worked well in similar past cases
2. Suggests specific approaches based on successful patterns
3. Warns about potential pitfalls based on past experiences
4. Recommends response strategies that led to high customer satisfaction

Guideline (in English):
"""
    else:  # ja
        guideline_prompt = f"""
ã‚ãªãŸã¯éå»ã®æˆåŠŸäº‹ä¾‹ã‚’åˆ†æã—ã¦ã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã™ã‚‹AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚

ä»¥ä¸‹ã®é¡ä¼¼ã—ãŸéå»ã®äº‹ä¾‹ã¨ãã®æˆåŠŸã—ãŸè§£æ±ºæˆ¦ç•¥ã«åŸºã¥ã„ã¦ã€ç¾åœ¨ã®é¡§å®¢å•ã„åˆã‚ã›ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®å®Ÿè¡Œå¯èƒ½ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®é¡§å®¢å•ã„åˆã‚ã›:
{customer_query}

ç¾åœ¨ã®é¡§å®¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«:
- æ€§åˆ¥: {customer_profile.get('gender', 'unknown')}
- æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {customer_profile.get('sentiment_score', 50)}/100
- ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«: {customer_profile.get('communication_style', 'unknown')}
- ç·Šæ€¥åº¦: {customer_profile.get('urgency_level', 'medium')}
- äºˆæ¸¬ã‚¿ã‚¤ãƒ—: {customer_profile.get('predicted_customer_type', 'normal')}

é¡ä¼¼ã—ãŸéå»ã®äº‹ä¾‹ï¼ˆæˆåŠŸã—ãŸè§£æ±ºï¼‰:
{past_cases_text}

ä»¥ä¸‹ã®å†…å®¹ã‚’å«ã‚€ç°¡æ½”ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„:
1. é¡ä¼¼ã—ãŸéå»ã®äº‹ä¾‹ã§ã†ã¾ãã„ã£ãŸã“ã¨ã‚’ç‰¹å®š
2. æˆåŠŸã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãå…·ä½“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ–¹æ³•ã®ææ¡ˆ
3. éå»ã®çµŒé¨“ã«åŸºã¥ãæ½œåœ¨çš„ãªè½ã¨ã—ç©´ã®è­¦å‘Š
4. é«˜ã„é¡§å®¢æº€è¶³åº¦ã«ã¤ãªãŒã£ãŸå¿œç­”æˆ¦ç•¥ã®æ¨å¥¨

ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆæ—¥æœ¬èªã§ï¼‰:
"""

    if not st.session_state.is_llm_ready:
        return ""

    try:
        guideline = run_llm(guideline_prompt).strip()
        return guideline
    except Exception as e:
        error_msg = {
            "ko": f"ê°€ì´ë“œë¼ì¸ ìƒì„± ì˜¤ë¥˜: {str(e)}",
            "en": f"Guideline generation error: {str(e)}",
            "ja": f"ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        }.get(current_lang_key, f"Error: {str(e)}")
        return error_msg


def generate_initial_advice(customer_query, customer_type_display, customer_email, customer_phone, current_lang_key,
                             customer_attachment_file):
    """Supervisor ê°€ì´ë“œë¼ì¸ê³¼ ì´ˆì•ˆì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ì €ì¥ëœ ë°ì´í„° í™œìš©)"""
    # ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ìë™ ê°ì§€ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
    try:
        detected_lang = detect_text_language(customer_query)
    except Exception as e:
        print(f"Language detection failed in generate_initial_advice: {e}")
        detected_lang = current_lang_key if current_lang_key else "ko"
    
    # ê°ì§€ëœ ì–¸ì–´ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ë˜, current_lang_keyê°€ ëª…ì‹œì ìœ¼ë¡œ ì œê³µë˜ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
    lang_key_to_use = detected_lang if detected_lang else current_lang_key
    # lang_key_to_useê°€ ìœ íš¨í•œì§€ í™•ì¸
    if lang_key_to_use not in ["ko", "en", "ja"]:
        lang_key_to_use = current_lang_key if current_lang_key else "ko"
    
    # ì–¸ì–´ í‚¤ ê²€ì¦
    if lang_key_to_use not in ["ko", "en", "ja"]:
        lang_key_to_use = st.session_state.get("language", "ko")
        if lang_key_to_use not in ["ko", "en", "ja"]:
            lang_key_to_use = "ko"
    L = LANG.get(lang_key_to_use, LANG["ko"])
    lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}[lang_key_to_use]

    # ì–¸ì–´ë³„ contact_info_block
    if lang_key_to_use == "ko":
        contact_info_text = "ê³ ê° ì—°ë½ì²˜ ì •ë³´ (ì°¸ê³ ìš©, ì‘ëŒ€ ì´ˆì•ˆì—ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”!)"
    elif lang_key_to_use == "en":
        contact_info_text = "Customer contact info for reference (DO NOT use these in your reply draft!)"
    else:  # ja
        contact_info_text = "é¡§å®¢é€£çµ¡å…ˆæƒ…å ±ï¼ˆå‚è€ƒç”¨ã€å¯¾å¿œè‰æ¡ˆã«ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ï¼ï¼‰"
    
    contact_info_block = ""
    if customer_email or customer_phone:
        email_label = {"ko": "ì´ë©”ì¼", "en": "Email", "ja": "ãƒ¡ãƒ¼ãƒ«"}[lang_key_to_use]
        phone_label = {"ko": "ì „í™”ë²ˆí˜¸", "en": "Phone", "ja": "é›»è©±ç•ªå·"}[lang_key_to_use]
        na_text = {"ko": "ì—†ìŒ", "en": "N/A", "ja": "ãªã—"}[lang_key_to_use]
        contact_info_block = (
            f"\n\n[{contact_info_text}]\n"
            f"- {email_label}: {customer_email or na_text}\n"
            f"- {phone_label}: {customer_phone or na_text}"
        )

    attachment_block = ""
    if customer_attachment_file:
        file_name = customer_attachment_file.name
        attachment_block = f"\n\n[ATTACHMENT NOTE]: {L['attachment_info_llm'].format(filename=file_name)}"

    # ê³ ê° í”„ë¡œí•„ ë¶„ì„ (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
    customer_profile = analyze_customer_profile(customer_query, lang_key_to_use)

    # ìœ ì‚¬ ì¼€ì´ìŠ¤ ì°¾ê¸° (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
    similar_cases = find_similar_cases(customer_query, customer_profile, lang_key_to_use, limit=5)

    # ê³¼ê±° ì¼€ì´ìŠ¤ ê¸°ë°˜ ê°€ì´ë“œë¼ì¸ ìƒì„± (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
    past_cases_guideline = ""
    if similar_cases:
        past_cases_guideline = generate_guideline_from_past_cases(
            customer_query, customer_profile, similar_cases, lang_key_to_use
        )

    # ì–¸ì–´ë³„ ê³ ê° í”„ë¡œí•„ ì •ë³´
    gender_display = customer_profile.get('gender', 'unknown')
    if lang_key_to_use == "ko":
        profile_block = f"""
[ê³ ê° í”„ë¡œí•„ ë¶„ì„]
- ì„±ë³„: {gender_display}
- ê°ì • ì ìˆ˜: {customer_profile.get('sentiment_score', 50)}/100
- ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼: {customer_profile.get('communication_style', 'unknown')}
- ê¸´ê¸‰ë„: {customer_profile.get('urgency_level', 'medium')}
- ì˜ˆì¸¡ ìœ í˜•: {customer_profile.get('predicted_customer_type', 'normal')}
- ì£¼ìš” ê´€ì‹¬ì‚¬: {', '.join(customer_profile.get('key_concerns', []))}
- í†¤: {customer_profile.get('tone_analysis', 'unknown')}
"""
    elif lang_key_to_use == "en":
        profile_block = f"""
[Customer Profile Analysis]
- Gender: {gender_display}
- Sentiment Score: {customer_profile.get('sentiment_score', 50)}/100
- Communication Style: {customer_profile.get('communication_style', 'unknown')}
- Urgency Level: {customer_profile.get('urgency_level', 'medium')}
- Predicted Type: {customer_profile.get('predicted_customer_type', 'normal')}
- Key Concerns: {', '.join(customer_profile.get('key_concerns', []))}
- Tone: {customer_profile.get('tone_analysis', 'unknown')}
"""
    else:  # ja
        profile_block = f"""
[é¡§å®¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ]
- æ€§åˆ¥: {gender_display}
- æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {customer_profile.get('sentiment_score', 50)}/100
- ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«: {customer_profile.get('communication_style', 'unknown')}
- ç·Šæ€¥åº¦: {customer_profile.get('urgency_level', 'medium')}
- äºˆæ¸¬ã‚¿ã‚¤ãƒ—: {customer_profile.get('predicted_customer_type', 'normal')}
- ä¸»è¦ãªé–¢å¿ƒäº‹: {', '.join(customer_profile.get('key_concerns', []))}
- ãƒˆãƒ¼ãƒ³: {customer_profile.get('tone_analysis', 'unknown')}
"""

    # ì–¸ì–´ë³„ ê³¼ê±° ì¼€ì´ìŠ¤ ê¸°ë°˜ ê°€ì´ë“œë¼ì¸ ë¸”ë¡
    past_cases_block = ""
    if past_cases_guideline:
        if lang_key_to_use == "ko":
            past_cases_block = f"""
[ìœ ì‚¬í•œ ê³¼ê±° {len(similar_cases)}ê°œ ì‚¬ë¡€ ê¸°ë°˜ ê°€ì´ë“œë¼ì¸]
{past_cases_guideline}
"""
        elif lang_key_to_use == "en":
            past_cases_block = f"""
[Guidelines Based on {len(similar_cases)} Similar Past Cases]
{past_cases_guideline}
"""
        else:  # ja
            past_cases_block = f"""
[é¡ä¼¼ã—ãŸéå»{len(similar_cases)}ä»¶ã®äº‹ä¾‹ã«åŸºã¥ãã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³]
{past_cases_guideline}
"""
    elif similar_cases:
        if lang_key_to_use == "ko":
            past_cases_block = f"""
[ì°¸ê³ : ìœ ì‚¬í•œ ê³¼ê±° ì‚¬ë¡€ {len(similar_cases)}ê°œë¥¼ ì°¾ì•˜ì§€ë§Œ ìƒì„¸ ê°€ì´ë“œë¼ì¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
íŒ¨í„´ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ê³¼ê±° ì‚¬ë¡€ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê²€í† í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.]
"""
        elif lang_key_to_use == "en":
            past_cases_block = f"""
[Note: Found {len(similar_cases)} similar past cases, but unable to generate detailed guidelines.
Consider reviewing past cases manually for patterns.]
"""
        else:  # ja
            past_cases_block = f"""
[æ³¨: é¡ä¼¼ã—ãŸéå»ã®äº‹ä¾‹{len(similar_cases)}ä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸãŒã€è©³ç´°ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚
ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã€éå»ã®äº‹ä¾‹ã‚’æ‰‹å‹•ã§ç¢ºèªã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚]
"""

    # ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê° ì–¸ì–´ë¡œ ëª…í™•í•˜ê²Œ ì‘ì„±)
    if lang_key_to_use == "ko":
        initial_prompt = f"""
ğŸ”´ ğŸ”´ ğŸ”´ ê·¹ë„ë¡œ ì¤‘ìš” ğŸ”´ ğŸ”´ ğŸ”´
ë‹¹ì‹ ì˜ ëª¨ë“  ì‘ë‹µ(ê°€ì´ë“œë¼ì¸ê³¼ ì´ˆì•ˆ í¬í•¨)ì€ ë°˜ë“œì‹œ 100% í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ì˜ì–´ë‚˜ ì¼ë³¸ì–´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ì—¬ì•¼ í•©ë‹ˆë‹¤.
ğŸ”´ ğŸ”´ ğŸ”´ ê·¹ë„ë¡œ ì¤‘ìš” ğŸ”´ ğŸ”´ ğŸ”´

ë‹¹ì‹ ì€ AI ê³ ê° ì§€ì› ìŠˆí¼ë°”ì´ì €ì…ë‹ˆë‹¤. ë‹¤ìŒ ê³ ê° ë¬¸ì˜ë¥¼ ë¶„ì„í•˜ì—¬ ì œê³µí•˜ì„¸ìš”:
ê³ ê° ìœ í˜•: **{st.session_state.customer_type_sim_select}**

1) ìƒë‹´ì›ì„ ìœ„í•œ ìƒì„¸í•œ **ì‘ëŒ€ ê°€ì´ë“œë¼ì¸** (ë‹¨ê³„ë³„, ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ)
2) **ì „ì†¡ ê°€ëŠ¥í•œ ì‘ëŒ€ ì´ˆì•ˆ** (ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ)

[ì‘ë‹µ í˜•ì‹ - ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”]
### {L['simulation_advice_header']}

(ì—¬ê¸°ì— í•œêµ­ì–´ë¡œ ê°€ì´ë“œë¼ì¸ ì‘ì„±)

### {L['simulation_draft_header']}

(ì—¬ê¸°ì— í•œêµ­ì–´ë¡œ ì´ˆì•ˆ ì‘ì„±)

[ì¤‘ìš” ê°€ì´ë“œë¼ì¸ ê·œì¹™]
1. **ì´ˆê¸° ì •ë³´ ìˆ˜ì§‘ (ìš”ì²­ 3):** ê°€ì´ë“œë¼ì¸ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” ë¬¸ì œ í•´ê²°ì„ ì‹œë„í•˜ê¸° ì „ì— í•„ìˆ˜ì ì¸ ì´ˆê¸° ì§„ë‹¨ ì •ë³´(ì˜ˆ: ê¸°ê¸° í˜¸í™˜ì„±, í˜„ì§€ ìƒíƒœ/ìœ„ì¹˜, ì£¼ë¬¸ ë²ˆí˜¸)ë¥¼ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤.
2. **ì–´ë ¤ìš´ ê³ ê°ì— ëŒ€í•œ ê³µê° (ìš”ì²­ 5):** ê³ ê° ìœ í˜•ì´ 'ì–´ë ¤ìš´ ê³ ê°' ë˜ëŠ” 'ë§¤ìš° ë¶ˆë§Œì¡± ê³ ê°'ì¸ ê²½ìš°, ì •ì±…(ì˜ˆ: í™˜ë¶ˆ ë¶ˆê°€)ì„ ê°•ì œí•´ì•¼ í•˜ë”ë¼ë„ ê°€ì´ë“œë¼ì¸ì€ ê·¹ë„ì˜ ì •ì¤‘í•¨, ê³µê°, ì‚¬ê³¼ë¥¼ ê°•ì¡°í•´ì•¼ í•©ë‹ˆë‹¤.
3. **24-48ì‹œê°„ í›„ì† ì¡°ì¹˜ (ìš”ì²­ 6):** ë¬¸ì œë¥¼ ì¦‰ì‹œ í•´ê²°í•  ìˆ˜ ì—†ê±°ë‚˜ í˜„ì§€ íŒŒíŠ¸ë„ˆ/ìŠˆí¼ë°”ì´ì €ì˜ í™•ì¸ì´ í•„ìš”í•œ ê²½ìš°, ê°€ì´ë“œë¼ì¸ì€ ë‹¤ìŒ ì ˆì°¨ë¥¼ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤:
   - ë¬¸ì œë¥¼ ì¸ì •í•©ë‹ˆë‹¤.
   - ê³ ê°ì—ê²Œ 24ì‹œê°„ ë˜ëŠ” 48ì‹œê°„ ë‚´ì— ëª…í™•í•œ ë‹µë³€ì„ ë°›ì„ ê²ƒì„ì„ ì•Œë¦½ë‹ˆë‹¤.
   - í›„ì† ì—°ë½ì„ ìœ„í•´ ê³ ê°ì˜ ì´ë©”ì¼ ë˜ëŠ” ì „í™”ë²ˆí˜¸ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤. (ì œê³µëœ ì—°ë½ì²˜ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©)
4. **ê³¼ê±° ì‚¬ë¡€ í•™ìŠµ:** ê³¼ê±° ì‚¬ë¡€ ê°€ì´ë“œë¼ì¸ì´ ì œê³µëœ ê²½ìš°, í•´ë‹¹ ì‚¬ë¡€ì˜ ì„±ê³µì ì¸ ì „ëµì„ ê¶Œì¥ì‚¬í•­ì— í†µí•©í•˜ì„¸ìš”.

âš ï¸ ì–¸ì–´ ìš”êµ¬ì‚¬í•­: ëª¨ë“  í…ìŠ¤íŠ¸(ê°€ì´ë“œë¼ì¸, ì´ˆì•ˆ, ì„¤ëª… ë“±)ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. ì˜ì–´ë‚˜ ì¼ë³¸ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.

ê³ ê° ë¬¸ì˜:
{customer_query}
{contact_info_block}
{attachment_block}
{profile_block}
{past_cases_block}
"""
    elif lang_key_to_use == "en":
        initial_prompt = f"""
ğŸ”´ ğŸ”´ ğŸ”´ EXTREMELY IMPORTANT ğŸ”´ ğŸ”´ ğŸ”´
ALL your responses (including guidelines and draft) MUST be written 100% in English.
Do NOT use Korean or Japanese. All text must be in English.
ğŸ”´ ğŸ”´ ğŸ”´ EXTREMELY IMPORTANT ğŸ”´ ğŸ”´ ğŸ”´

You are an AI Customer Support Supervisor. Your role is to analyze the following customer inquiry
from a **{st.session_state.customer_type_sim_select}** and provide:

1) A detailed **response guideline for the human agent** (step-by-step, must be in English).
2) A **ready-to-send draft reply** (must be in English).

[RESPONSE FORMAT - You MUST write in this format]
### {L['simulation_advice_header']}

(Write guidelines here in English)

### {L['simulation_draft_header']}

(Write draft here in English)

[CRITICAL GUIDELINE RULES]
1. **Initial Information Collection (Req 3):** The first step in the guideline MUST be to request the necessary initial diagnostic information (e.g., device compatibility, local status/location, order number) BEFORE attempting to troubleshoot or solve the problem.
2. **Empathy for Difficult Customers (Req 5):** If the customer type is 'Difficult Customer' or 'Highly Dissatisfied Customer', the guideline MUST emphasize extreme politeness, empathy, and apologies, even if the policy (e.g., no refund) must be enforced.
3. **24-48 Hour Follow-up (Req 6):** If the issue cannot be solved immediately or requires confirmation from a local partner/supervisor, the guideline MUST state the procedure:
   - Acknowledge the issue.
   - Inform the customer they will receive a definite answer within 24 or 48 hours.
   - Request the customer's email or phone number for follow-up contact. (Use provided contact info if available)
4. **Past Cases Learning:** If past cases guidelines are provided, incorporate successful strategies from those cases into your recommendations.

âš ï¸ LANGUAGE REQUIREMENT: All text (guidelines, draft, descriptions, etc.) MUST be written ONLY in English. Do NOT use Korean or Japanese.

Customer Inquiry:
{customer_query}
{contact_info_block}
{attachment_block}
{profile_block}
{past_cases_block}
"""
    else:  # ja
        initial_prompt = f"""
ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¨è‰æ¡ˆï¼‰ã‚’å¿…ãšæ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚ãªãŸã¯AIã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®é¡§å®¢å•ã„åˆã‚ã›ã‚’åˆ†æã—ã€æä¾›ã—ã¦ãã ã•ã„ï¼š
é¡§å®¢ã‚¿ã‚¤ãƒ—: **{st.session_state.customer_type_sim_select}**

1) äººé–“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã®è©³ç´°ãª**å¯¾å¿œã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³**ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
2) **é€ä¿¡å¯èƒ½ãªå¯¾å¿œè‰æ¡ˆ**ï¼ˆæ—¥æœ¬èªã§ï¼‰

[å½¢å¼]
- ä»¥ä¸‹ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ­£ç¢ºã«ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼š
  - "### {L['simulation_advice_header']}"
  - "### {L['simulation_draft_header']}"

[é‡è¦ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è¦å‰‡]
1. **åˆæœŸæƒ…å ±åé›†ï¼ˆè¦ä»¶3ï¼‰ï¼š** ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€å•é¡Œã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚„è§£æ±ºã‚’è©¦ã¿ã‚‹å‰ã«ã€å¿…è¦ãªåˆæœŸè¨ºæ–­æƒ…å ±ï¼ˆä¾‹ï¼šãƒ‡ãƒã‚¤ã‚¹ã®äº’æ›æ€§ã€ç¾åœ°ã®çŠ¶æ…‹/å ´æ‰€ã€æ³¨æ–‡ç•ªå·ï¼‰ã‚’è¦æ±‚ã™ã‚‹ã“ã¨ã§ã™ã€‚
2. **å›°é›£ãªé¡§å®¢ã¸ã®å…±æ„Ÿï¼ˆè¦ä»¶5ï¼‰ï¼š** é¡§å®¢ã‚¿ã‚¤ãƒ—ãŒã€Œå›°é›£ãªé¡§å®¢ã€ã¾ãŸã¯ã€Œéå¸¸ã«ä¸æº€è¶³ãªé¡§å®¢ã€ã®å ´åˆã€ãƒãƒªã‚·ãƒ¼ï¼ˆä¾‹ï¼šè¿”é‡‘ä¸å¯ï¼‰ã‚’å¼·åˆ¶ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã§ã‚‚ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¯æ¥µåº¦ã®ä¸å¯§ã•ã€å…±æ„Ÿã€è¬ç½ªã‚’å¼·èª¿ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
3. **24-48æ™‚é–“ã®ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ï¼ˆè¦ä»¶6ï¼‰ï¼š** å•é¡Œã‚’å³åº§ã«è§£æ±ºã§ããªã„å ´åˆã€ã¾ãŸã¯ç¾åœ°ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼/ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ã‚¶ãƒ¼ã®ç¢ºèªãŒå¿…è¦ãªå ´åˆã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¯æ¬¡ã®æ‰‹é †ã‚’è¨˜è¼‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š
   - å•é¡Œã‚’èªè­˜ã—ã¾ã™ã€‚
   - é¡§å®¢ã«24æ™‚é–“ã¾ãŸã¯48æ™‚é–“ä»¥å†…ã«æ˜ç¢ºãªå›ç­”ã‚’å—ã‘ã‚‹ã“ã¨ã‚’é€šçŸ¥ã—ã¾ã™ã€‚
   - ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—é€£çµ¡ã®ãŸã‚ã«é¡§å®¢ã®ãƒ¡ãƒ¼ãƒ«ã¾ãŸã¯é›»è©±ç•ªå·ã‚’è¦æ±‚ã—ã¾ã™ã€‚ï¼ˆæä¾›ã•ã‚ŒãŸé€£çµ¡å…ˆæƒ…å ±ãŒã‚ã‚‹å ´åˆã¯ä½¿ç”¨ï¼‰
4. **éå»ã®äº‹ä¾‹å­¦ç¿’ï¼š** éå»ã®äº‹ä¾‹ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œã‚‰ã®äº‹ä¾‹ã®æˆåŠŸæˆ¦ç•¥ã‚’æ¨å¥¨äº‹é …ã«çµ„ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚

é¡§å®¢å•ã„åˆã‚ã›:
{customer_query}
{contact_info_block}
{attachment_block}
{profile_block}
{past_cases_block}
"""
    if not st.session_state.is_llm_ready:
        # ì–¸ì–´ë³„ Mock í…ìŠ¤íŠ¸
        if lang_key_to_use == "ko":
            mock_text = (
                f"### {L['simulation_advice_header']}\n\n"
                f"- (Mock) {st.session_state.customer_type_sim_select} ìœ í˜• ê³ ê° ì‘ëŒ€ ê°€ì´ë“œì…ë‹ˆë‹¤. (ìš”ì²­ 3, 5, 6 ë°˜ì˜)\n\n"
                f"### {L['simulation_draft_header']}\n\n"
                f"(Mock) ì—ì´ì „íŠ¸ ì‘ëŒ€ ì´ˆì•ˆì´ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤.\n\n"
            )
        elif lang_key_to_use == "en":
            mock_text = (
                f"### {L['simulation_advice_header']}\n\n"
                f"- (Mock) Response guide for {st.session_state.customer_type_sim_select} type customer. (Reflects Req 3, 5, 6)\n\n"
                f"### {L['simulation_draft_header']}\n\n"
                f"(Mock) Agent response draft will appear here.\n\n"
            )
        else:  # ja
            mock_text = (
                f"### {L['simulation_advice_header']}\n\n"
                f"- (Mock) {st.session_state.customer_type_sim_select}ã‚¿ã‚¤ãƒ—ã®é¡§å®¢å¯¾å¿œã‚¬ã‚¤ãƒ‰ã§ã™ã€‚ï¼ˆè¦ä»¶3ã€5ã€6ã‚’åæ˜ ï¼‰\n\n"
                f"### {L['simulation_draft_header']}\n\n"
                f"(Mock) ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¯¾å¿œè‰æ¡ˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n\n"
            )
        return mock_text
    else:
        with st.spinner(L["response_generating"]):
            try:
                return run_llm(initial_prompt)
            except Exception as e:
                error_msg = {
                    "ko": f"AI ì¡°ì–¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}",
                    "en": f"Error occurred while generating AI advice: {e}",
                    "ja": f"AIã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                }.get(lang_key_to_use, f"Error: {e}")
                st.error(error_msg)
                return f"âŒ {error_msg}"


# ë³„ì¹­ ì¶”ê°€ (í•˜ìœ„ í˜¸í™˜ì„±)
_generate_initial_advice = generate_initial_advice

