"""
ë¹„ë””ì˜¤ ì²˜ë¦¬ ëª¨ë“ˆ
ë¹„ë””ì˜¤ ì„ íƒ, ë Œë”ë§, ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
import streamlit as st

from config import DATA_DIR, VIDEO_MAPPING_DB_FILE
from utils.audio_handler import synthesize_tts


def analyze_text_for_video_selection(text: str, current_lang_key: str, 
                                     agent_last_response: str = None,
                                     conversation_context: List[Dict] = None) -> Dict[str, Any]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ì ì ˆí•œ ê°ì • ìƒíƒœì™€ ì œìŠ¤ì²˜ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
    OpenAI/Gemini APIë¥¼ í™œìš©í•œ ì˜ìƒ RAGì˜ í•µì‹¬ ê¸°ëŠ¥ì…ë‹ˆë‹¤.
    
    â­ Gemini ì œì•ˆ ì ìš©: ê¸´ê¸‰ë„, ë§Œì¡±ë„ ë³€í™”, ì—ì´ì „íŠ¸ ë‹µë³€ ê¸°ë°˜ ì˜ˆì¸¡ ì¶”ê°€
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸ (ê³ ê°ì˜ ì§ˆë¬¸/ì‘ë‹µ)
        current_lang_key: í˜„ì¬ ì–¸ì–´ í‚¤
        agent_last_response: ì—ì´ì „íŠ¸ì˜ ë§ˆì§€ë§‰ ë‹µë³€ (ì„ íƒì , ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ)
        conversation_context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì , ë§Œì¡±ë„ ë³€í™” ë¶„ì„ìš©)
    
    Returns:
        {
            "emotion": "NEUTRAL" | "HAPPY" | "ANGRY" | "ASKING" | "SAD",
            "gesture": "NONE" | "HAND_WAVE" | "NOD" | "SHAKE_HEAD" | "POINT",
            "urgency": "LOW" | "MEDIUM" | "HIGH",  # â­ ì¶”ê°€: ê¸´ê¸‰ë„
            "satisfaction_delta": -1.0 to 1.0,  # â­ ì¶”ê°€: ë§Œì¡±ë„ ë³€í™” (-1: ê°ì†Œ, 0: ìœ ì§€, 1: ì¦ê°€)
            "confidence": 0.0-1.0
        }
    """
    if not text or not text.strip():
        return {
            "emotion": "NEUTRAL", 
            "gesture": "NONE", 
            "urgency": "LOW",
            "satisfaction_delta": 0.0,
            "confidence": 0.5
        }
    
    from lang_pack import LANG
    L = LANG.get(current_lang_key, LANG["ko"])
    
    # â­ Gemini ì œì•ˆ: ì—ì´ì „íŠ¸ ë‹µë³€ ê¸°ë°˜ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_info = ""
    if agent_last_response:
        context_info = f"""
ì—ì´ì „íŠ¸ì˜ ë§ˆì§€ë§‰ ë‹µë³€: "{agent_last_response}"

ì—ì´ì „íŠ¸ì˜ ë‹µë³€ì„ ê³ ë ¤í–ˆì„ ë•Œ, ê³ ê°ì´ ì§€ê¸ˆ ë§í•˜ëŠ” ë‚´ìš©ì€ ì–´ë–¤ ê°ì •ì„ ìˆ˜ë°˜í•  ê²ƒì¸ì§€ ì˜ˆì¸¡í•˜ì„¸ìš”.
ì˜ˆë¥¼ ë“¤ì–´:
- ì—ì´ì „íŠ¸ê°€ ì†”ë£¨ì…˜ì„ ì œì‹œí–ˆë‹¤ë©´ â†’ ê³ ê°ì€ HAPPY ë˜ëŠ” ASKING (ì¶”ê°€ ì§ˆë¬¸)
- ì—ì´ì „íŠ¸ê°€ ê±°ì ˆí–ˆë‹¤ë©´ â†’ ê³ ê°ì€ ANGRY ë˜ëŠ” SAD
- ì—ì´ì „íŠ¸ê°€ ì§ˆë¬¸ì„ í–ˆë‹¤ë©´ â†’ ê³ ê°ì€ ASKING (ë‹µë³€) ë˜ëŠ” NEUTRAL
"""
    
    # â­ Gemini ì œì•ˆ: ë§Œì¡±ë„ ë³€í™” ë¶„ì„ ì»¨í…ìŠ¤íŠ¸
    satisfaction_context = ""
    if conversation_context and len(conversation_context) > 1:
        # ìµœê·¼ ëŒ€í™”ì˜ ê°ì • ë³€í™” ì¶”ì 
        recent_emotions = []
        for msg in conversation_context[-3:]:  # ìµœê·¼ 3ê°œ ë©”ì‹œì§€
            if msg.get("role") == "customer_rebuttal" or msg.get("role") == "customer":
                recent_emotions.append(msg.get("content", ""))
        
        if len(recent_emotions) >= 2:
            satisfaction_context = f"""
ìµœê·¼ ëŒ€í™” íë¦„:
- ì´ì „ ê³ ê° ë©”ì‹œì§€: "{recent_emotions[-2] if len(recent_emotions) >= 2 else ''}"
- í˜„ì¬ ê³ ê° ë©”ì‹œì§€: "{recent_emotions[-1]}"

ë§Œì¡±ë„ ë³€í™”ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
- ì´ì „ë³´ë‹¤ ë” ê¸ì •ì ì´ë©´ satisfaction_delta > 0
- ì´ì „ë³´ë‹¤ ë” ë¶€ì •ì ì´ë©´ satisfaction_delta < 0
- ë¹„ìŠ·í•˜ë©´ satisfaction_delta â‰ˆ 0
"""
    
    # â­ Gemini ì œì•ˆ: ê°œì„ ëœ LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    from llm_client import run_llm
    prompt = f"""ë‹¤ìŒ ê³ ê°ì˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ê°ì • ìƒíƒœ, ì œìŠ¤ì²˜, ê¸´ê¸‰ë„, ë§Œì¡±ë„ ë³€í™”ë¥¼ íŒë‹¨í•˜ì„¸ìš”.

ê³ ê° í…ìŠ¤íŠ¸: "{text}"
{context_info}
{satisfaction_context}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):
{{
    "emotion": "NEUTRAL" | "HAPPY" | "ANGRY" | "ASKING" | "SAD",
    "gesture": "NONE" | "HAND_WAVE" | "NOD" | "SHAKE_HEAD" | "POINT",
    "urgency": "LOW" | "MEDIUM" | "HIGH",
    "satisfaction_delta": -1.0 to 1.0,
    "confidence": 0.0-1.0
}}

ê°ì • íŒë‹¨ ê¸°ì¤€ (ì„¸ë¶„í™”):
- HAPPY: ê¸ì •ì  í‘œí˜„, ê°ì‚¬, ë§Œì¡±, í•´ê²°ë¨ ("ê°ì‚¬í•©ë‹ˆë‹¤", "ì¢‹ì•„ìš”", "ì™„ë²½í•´ìš”", "ì´ì œ ì´í•´í–ˆì–´ìš”")
- ANGRY: ë¶ˆë§Œ, í™”ë‚¨, ê±°ë¶€, ê°•í•œ ë¶€ì • ("í™”ê°€ ë‚˜ìš”", "ë¶ˆê°€ëŠ¥í•´ìš”", "ê±°ì ˆí•©ë‹ˆë‹¤", "ë§ë„ ì•ˆ ë¼ìš”")
- ASKING: ì§ˆë¬¸, ê¶ê¸ˆí•¨, í™•ì¸ ìš”ì²­, ì •ë³´ ìš”êµ¬ ("ì–´ë–»ê²Œ", "ì™œ", "ì•Œë ¤ì£¼ì„¸ìš”", "ì£¼ë¬¸ë²ˆí˜¸ê°€ ë­ì˜ˆìš”?")
- SAD: ìŠ¬í””, ì‹¤ë§, ì¢Œì ˆ ("ìŠ¬í”„ë„¤ìš”", "ì‹¤ë§í–ˆì–´ìš”", "ì•„ì‰½ìŠµë‹ˆë‹¤", "ê·¸ë ‡ë‹¤ë©´ ì–´ì©” ìˆ˜ ì—†ë„¤ìš”")
- NEUTRAL: ì¤‘ë¦½ì  í‘œí˜„, ë‹¨ìˆœ ì •ë³´ ì „ë‹¬ (ê¸°ë³¸ê°’)

ì œìŠ¤ì²˜ íŒë‹¨ ê¸°ì¤€:
- HAND_WAVE: ì¸ì‚¬, í™˜ì˜ ("ì•ˆë…•í•˜ì„¸ìš”", "ë°˜ê°‘ìŠµë‹ˆë‹¤")
- NOD: ë™ì˜, ê¸ì •, ì´í•´ ("ë„¤", "ë§ì•„ìš”", "ê·¸ë ‡ìŠµë‹ˆë‹¤", "ì•Œê² ìŠµë‹ˆë‹¤")
- SHAKE_HEAD: ë¶€ì •, ê±°ë¶€, ë¶ˆë§Œì¡± ("ì•„ë‹ˆìš”", "ì•ˆ ë©ë‹ˆë‹¤", "ê·¸ê±´ ì•„ë‹ˆì—ìš”")
- POINT: ì„¤ëª…, ì§€ì‹œ, íŠ¹ì • í•­ëª© ì–¸ê¸‰ ("ì—¬ê¸°", "ì´ê²ƒ", "ì €ê²ƒ", "ì£¼ë¬¸ë²ˆí˜¸ëŠ”")
- NONE: íŠ¹ë³„í•œ ì œìŠ¤ì²˜ ì—†ìŒ (ê¸°ë³¸ê°’)

ê¸´ê¸‰ë„ íŒë‹¨ ê¸°ì¤€:
- HIGH: ì¦‰ì‹œ í•´ê²° í•„ìš”, ê¸´ê¸‰í•œ ë¬¸ì œ ("ì§€ê¸ˆ ë‹¹ì¥", "ë°”ë¡œ", "ê¸´ê¸‰", "ì¤‘ìš”í•´ìš”")
- MEDIUM: ë¹ ë¥¸ í•´ê²° ì„ í˜¸, ì¤‘ìš”í•˜ì§€ë§Œ ê¸´ê¸‰í•˜ì§€ ì•ŠìŒ
- LOW: ì¼ë°˜ì ì¸ ë¬¸ì˜, ê¸´ê¸‰í•˜ì§€ ì•ŠìŒ (ê¸°ë³¸ê°’)

ë§Œì¡±ë„ ë³€í™” (satisfaction_delta):
- 1.0: ë§¤ìš° ë§Œì¡±, ë¬¸ì œ í•´ê²°ë¨, ê°ì‚¬ í‘œí˜„
- 0.5: ë§Œì¡±, ê¸ì •ì  ë°˜ì‘
- 0.0: ì¤‘ë¦½, ë³€í™” ì—†ìŒ
- -0.5: ë¶ˆë§Œì¡±, ë¶€ì •ì  ë°˜ì‘
- -1.0: ë§¤ìš° ë¶ˆë§Œì¡±, í™”ë‚¨, ê±°ë¶€

JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”:"""

    try:
        # LLM í˜¸ì¶œ
        if st.session_state.is_llm_ready:
            response_text = run_llm(prompt)
            
            # JSON íŒŒì‹± ì‹œë„ (ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬)
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì½”ë“œ ë¸”ë¡ ì œê±°)
                import re
                import json
                
                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                if "```" in response_text:
                    json_match_block = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
                    if json_match_block:
                        json_text = json_match_block.group(1)
                    else:
                        json_text = response_text
                else:
                    json_text = response_text
                
                # JSON ê°ì²´ ì°¾ê¸° (ì¤‘ì²© ì¤‘ê´„í˜¸ ì§€ì›)
                json_match = re.search(r'\{.*\}', json_text, re.DOTALL)
                if json_match:
                    try:
                        result = json.loads(json_match.group())
                    except json.JSONDecodeError as json_err:
                        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ê³„ì† ì§„í–‰
                        print(f"ë¹„ë””ì˜¤ í•¸ë“¤ëŸ¬ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
                        raise  # ì™¸ë¶€ exceptë¡œ ì „ë‹¬
                    
                    # ìœ íš¨ì„± ê²€ì‚¬
                    valid_emotions = ["NEUTRAL", "HAPPY", "ANGRY", "ASKING", "SAD"]
                    valid_gestures = ["NONE", "HAND_WAVE", "NOD", "SHAKE_HEAD", "POINT"]
                    valid_urgencies = ["LOW", "MEDIUM", "HIGH"]
                    
                    emotion = result.get("emotion", "NEUTRAL")
                    gesture = result.get("gesture", "NONE")
                    urgency = result.get("urgency", "LOW")
                    satisfaction_delta = float(result.get("satisfaction_delta", 0.0))
                    confidence = float(result.get("confidence", 0.7))
                    
                    if emotion not in valid_emotions:
                        emotion = "NEUTRAL"
                    if gesture not in valid_gestures:
                        gesture = "NONE"
                    if urgency not in valid_urgencies:
                        urgency = "LOW"
                    
                    # â­ Gemini ì œì•ˆ: ìƒí™©ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
                    context_keywords = []
                    text_lower_for_context = text.lower()
                    
                    # ì£¼ìš” ìƒí™©ë³„ í‚¤ì›Œë“œ ë§¤í•‘
                    if any(word in text_lower_for_context for word in ["ì£¼ë¬¸ë²ˆí˜¸", "order number", "ì£¼ë¬¸ ë²ˆí˜¸"]):
                        context_keywords.append("order_number")
                    if any(word in text_lower_for_context for word in ["í•´ê²°", "ì™„ë£Œ", "ê°ì‚¬", "solution", "resolved"]):
                        if satisfaction_delta > 0.3:
                            context_keywords.append("solution_accepted")
                    if any(word in text_lower_for_context for word in ["ê±°ì ˆ", "ë¶ˆê°€", "ì•ˆ ë©ë‹ˆë‹¤", "denied", "cannot"]):
                        if emotion == "ANGRY":
                            context_keywords.append("policy_denial")
                    
                    return {
                        "emotion": emotion,
                        "gesture": gesture,
                        "urgency": urgency,
                        "satisfaction_delta": max(-1.0, min(1.0, satisfaction_delta)),
                        "context_keywords": context_keywords,  # â­ ì¶”ê°€
                        "confidence": max(0.0, min(1.0, confidence))
                    }
            except json.JSONDecodeError:
                pass
        
        # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ ë¶„ì„
        text_lower = text.lower()
        emotion = "NEUTRAL"
        gesture = "NONE"
        urgency = "LOW"
        satisfaction_delta = 0.0
        
        # ê°ì • í‚¤ì›Œë“œ ë¶„ì„
        if any(word in text_lower for word in ["ê°ì‚¬", "ì¢‹ì•„", "ì™„ë²½", "ë§Œì¡±", "ê³ ë§ˆì›Œ", "í•´ê²°"]):
            emotion = "HAPPY"
            satisfaction_delta = 0.5
        elif any(word in text_lower for word in ["í™”", "ë¶ˆë§Œ", "ê±°ì ˆ", "ë¶ˆê°€ëŠ¥", "ì•ˆ ë©ë‹ˆë‹¤", "ë§ë„ ì•ˆ ë¼"]):
            emotion = "ANGRY"
            satisfaction_delta = -0.5
        elif any(word in text_lower for word in ["ì–´ë–»ê²Œ", "ì™œ", "ì•Œë ¤", "ì§ˆë¬¸", "ê¶ê¸ˆ", "ì£¼ë¬¸ë²ˆí˜¸"]):
            emotion = "ASKING"
        elif any(word in text_lower for word in ["ìŠ¬í”„", "ì‹¤ë§", "ì•„ì‰½", "ê·¸ë ‡ë‹¤ë©´"]):
            emotion = "SAD"
            satisfaction_delta = -0.3
        
        # ê¸´ê¸‰ë„ í‚¤ì›Œë“œ ë¶„ì„
        if any(word in text_lower for word in ["ì§€ê¸ˆ ë‹¹ì¥", "ë°”ë¡œ", "ê¸´ê¸‰", "ì¤‘ìš”í•´ìš”", "ì¦‰ì‹œ"]):
            urgency = "HIGH"
        elif any(word in text_lower for word in ["ë¹¨ë¦¬", "ê°€ëŠ¥í•œ í•œ", "ìµœëŒ€í•œ"]):
            urgency = "MEDIUM"
        
        # ì œìŠ¤ì²˜ í‚¤ì›Œë“œ ë¶„ì„
        if any(word in text_lower for word in ["ì•ˆë…•", "ë°˜ê°‘", "ì¸ì‚¬"]):
            gesture = "HAND_WAVE"
        elif any(word in text_lower for word in ["ë„¤", "ë§ì•„", "ê·¸ë˜", "ë™ì˜", "ì•Œê² ìŠµë‹ˆë‹¤"]):
            gesture = "NOD"
            if emotion == "HAPPY":
                satisfaction_delta = 0.3
        elif any(word in text_lower for word in ["ì•„ë‹ˆ", "ì•ˆ ë©ë‹ˆë‹¤", "ê±°ì ˆ"]):
            gesture = "SHAKE_HEAD"
            satisfaction_delta = -0.2
        elif any(word in text_lower for word in ["ì—¬ê¸°", "ì´ê²ƒ", "ì €ê²ƒ", "ì´ê±°", "ì£¼ë¬¸ë²ˆí˜¸"]):
            gesture = "POINT"
        
        # â­ Gemini ì œì•ˆ: ìƒí™©ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ (í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„)
        context_keywords = []
        if any(word in text_lower for word in ["ì£¼ë¬¸ë²ˆí˜¸", "order number", "ì£¼ë¬¸ ë²ˆí˜¸"]):
            context_keywords.append("order_number")
        if any(word in text_lower for word in ["í•´ê²°", "ì™„ë£Œ", "ê°ì‚¬", "solution"]):
            if satisfaction_delta > 0.3:
                context_keywords.append("solution_accepted")
        if any(word in text_lower for word in ["ê±°ì ˆ", "ë¶ˆê°€", "ì•ˆ ë©ë‹ˆë‹¤"]):
            if emotion == "ANGRY":
                context_keywords.append("policy_denial")
        
        return {
            "emotion": emotion,
            "gesture": gesture,
            "urgency": urgency,
            "satisfaction_delta": satisfaction_delta,
            "context_keywords": context_keywords,  # â­ ì¶”ê°€
            "confidence": 0.6  # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ì€ ë‚®ì€ ì‹ ë¢°ë„
        }
    
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {
            "emotion": "NEUTRAL", 
            "gesture": "NONE", 
            "urgency": "LOW",
            "satisfaction_delta": 0.0,
            "context_keywords": [],  # â­ ì¶”ê°€
            "confidence": 0.5
        }


def get_video_path_by_avatar(gender: str, emotion: str, is_speaking: bool = False, 
                             gesture: str = "NONE", context_keywords: List[str] = None) -> str:
    """
    ê³ ê° ì•„ë°”íƒ€ ì •ë³´(ì„±ë³„, ê°ì • ìƒíƒœ, ì œìŠ¤ì²˜, ìƒí™©)ì— ë”°ë¼ ì ì ˆí•œ ë¹„ë””ì˜¤ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    OpenAI/Gemini ê¸°ë°˜ ì˜ìƒ RAG: LLMì´ ë¶„ì„í•œ ê°ì •/ì œìŠ¤ì²˜ì— ë”°ë¼ ë¹„ë””ì˜¤ í´ë¦½ì„ ì„ íƒí•©ë‹ˆë‹¤.
    
    â­ Gemini ì œì•ˆ: ìƒí™©ë³„ ë¹„ë””ì˜¤ í´ë¦½ íŒ¨í„´ í™•ì¥ (ì˜ˆ: male_asking_order_number.mp4)
    
    Args:
        gender: "male" ë˜ëŠ” "female"
        emotion: "NEUTRAL", "HAPPY", "ANGRY", "ASKING", "SAD", "HOLD"
        is_speaking: ë§í•˜ëŠ” ì¤‘ì¸ì§€ ì—¬ë¶€
        gesture: "NONE", "HAND_WAVE", "NOD", "SHAKE_HEAD", "POINT"
        context_keywords: ìƒí™©ë³„ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["order_number", "solution_accepted", "policy_denial"])
    
    Returns:
        ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
    """
    # ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì‚¬ìš©ìê°€ ì„¤ì •í•œ ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì´ ì €ì¥ëœ ìœ„ì¹˜)
    video_base_dir = os.path.join(DATA_DIR, "videos")
    os.makedirs(video_base_dir, exist_ok=True)
    
    # â­ Gemini ì œì•ˆ: ìš°ì„ ìˆœìœ„ -1 - ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì¶”ì²œ ë¹„ë””ì˜¤ (ê°€ì¥ ìš°ì„ )
    if context_keywords:
        db_recommended = get_recommended_video_from_database(emotion, gesture, context_keywords)
        if db_recommended:
            return db_recommended
    else:
        db_recommended = get_recommended_video_from_database(emotion, gesture, [])
        if db_recommended:
            return db_recommended
    
    # â­ Gemini ì œì•ˆ: ìš°ì„ ìˆœìœ„ 0 - ìƒí™©ë³„ ë¹„ë””ì˜¤ í´ë¦½ (ê°€ì¥ êµ¬ì²´ì )
    if context_keywords:
        for keyword in context_keywords:
            # ìƒí™©ë³„ íŒŒì¼ëª… íŒ¨í„´ ì‹œë„ (ì˜ˆ: male_asking_order_number.mp4)
            context_filename = f"{gender}_{emotion.lower()}_{keyword}"
            if is_speaking:
                context_filename += "_speaking"
            context_filename += ".mp4"
            context_path = os.path.join(video_base_dir, context_filename)
            if os.path.exists(context_path):
                return context_path
            
            # ì„¸ì…˜ ìƒíƒœì—ì„œë„ í™•ì¸
            context_video_key = f"video_{gender}_{emotion.lower()}_{keyword}"
            if context_video_key in st.session_state and st.session_state[context_video_key]:
                video_path = st.session_state[context_video_key]
                if os.path.exists(video_path):
                    return video_path
    
    # ìš°ì„ ìˆœìœ„ 1: ì œìŠ¤ì²˜ê°€ ìˆëŠ” ê²½ìš° ì œìŠ¤ì²˜ë³„ ë¹„ë””ì˜¤ ì‹œë„
    if gesture != "NONE" and gesture:
        gesture_video_key = f"video_{gender}_{emotion.lower()}_{gesture.lower()}"
        if gesture_video_key in st.session_state and st.session_state[gesture_video_key]:
            video_path = st.session_state[gesture_video_key]
            if os.path.exists(video_path):
                return video_path
        
        # ì œìŠ¤ì²˜ë³„ íŒŒì¼ëª… íŒ¨í„´ ì‹œë„
        gesture_filename = f"{gender}_{emotion.lower()}_{gesture.lower()}"
        if is_speaking:
            gesture_filename += "_speaking"
        gesture_filename += ".mp4"
        gesture_path = os.path.join(video_base_dir, gesture_filename)
        if os.path.exists(gesture_path):
            return gesture_path
    
    # ìš°ì„ ìˆœìœ„ 2: ê°ì • ìƒíƒœë³„ ë¹„ë””ì˜¤ (ì œìŠ¤ì²˜ ì—†ì´)
    video_key = f"video_{gender}_{emotion.lower()}"
    if is_speaking:
        video_key += "_speaking"
    
    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ë¹„ë””ì˜¤ ê²½ë¡œê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if video_key in st.session_state and st.session_state[video_key]:
        video_path = st.session_state[video_key]
        if os.path.exists(video_path):
            return video_path
    
    # ê¸°ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ëª… íŒ¨í„´ ì‹œë„
    video_filename = f"{gender}_{emotion.lower()}"
    if is_speaking:
        video_filename += "_speaking"
    video_filename += ".mp4"
    
    video_path = os.path.join(video_base_dir, video_filename)
    if os.path.exists(video_path):
        return video_path
    
    # ìš°ì„ ìˆœìœ„ 3: ê¸°ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ì‹œë„ (ì¤‘ë¦½ ìƒíƒœ)
    default_video = os.path.join(video_base_dir, f"{gender}_neutral.mp4")
    if os.path.exists(default_video):
        return default_video
    
    # ìš°ì„ ìˆœìœ„ 4: ì„¸ì…˜ ìƒíƒœì—ì„œ ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ í™•ì¸
    if "current_customer_video" in st.session_state and st.session_state.current_customer_video:
        return st.session_state.current_customer_video
    
    return None


# â­ Gemini ì œì•ˆ: ë¹„ë””ì˜¤ ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í•¨ìˆ˜
def load_video_mapping_database() -> Dict[str, Any]:
    """ë¹„ë””ì˜¤ ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(VIDEO_MAPPING_DB_FILE):
        try:
            with open(VIDEO_MAPPING_DB_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"ë¹„ë””ì˜¤ ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {"mappings": [], "feedback_history": []}
    return {"mappings": [], "feedback_history": []}


def save_video_mapping_database(db_data: Dict[str, Any]):
    """ë¹„ë””ì˜¤ ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        with open(VIDEO_MAPPING_DB_FILE, 'w', encoding='utf-8') as f:
            json.dump(db_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ë¹„ë””ì˜¤ ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")


def add_video_mapping_feedback(
    customer_text: str,
    selected_video_path: str,
    emotion: str,
    gesture: str,
    context_keywords: List[str],
    user_rating: int,  # 1-5 ì ìˆ˜
    user_comment: str = ""
) -> None:
    """
    â­ Gemini ì œì•ˆ: ì‚¬ìš©ì í”¼ë“œë°±ì„ ë¹„ë””ì˜¤ ë§¤í•‘ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        customer_text: ê³ ê°ì˜ í…ìŠ¤íŠ¸
        selected_video_path: ì„ íƒëœ ë¹„ë””ì˜¤ ê²½ë¡œ
        emotion: ë¶„ì„ëœ ê°ì •
        gesture: ë¶„ì„ëœ ì œìŠ¤ì²˜
        context_keywords: ìƒí™©ë³„ í‚¤ì›Œë“œ
        user_rating: ì‚¬ìš©ì í‰ê°€ (1-5)
        user_comment: ì‚¬ìš©ì ì½”ë©˜íŠ¸ (ì„ íƒì )
    """
    db_data = load_video_mapping_database()
    
    feedback_entry = {
        "timestamp": datetime.now().isoformat(),
        "customer_text": customer_text[:200],  # ìµœëŒ€ 200ì
        "selected_video": os.path.basename(selected_video_path) if selected_video_path else None,
        "video_path": selected_video_path,
        "emotion": emotion,
        "gesture": gesture,
        "context_keywords": context_keywords,
        "user_rating": user_rating,
        "user_comment": user_comment[:500] if user_comment else "",  # ìµœëŒ€ 500ì
        "is_natural_match": user_rating >= 4  # 4ì  ì´ìƒì´ë©´ ìì—°ìŠ¤ëŸ¬ìš´ ë§¤ì¹­ìœ¼ë¡œ ê°„ì£¼
    }
    
    db_data["feedback_history"].append(feedback_entry)
    
    # ë§¤í•‘ ê·œì¹™ ì—…ë°ì´íŠ¸ (í‰ê°€ê°€ ë†’ì€ ê²½ìš°)
    if user_rating >= 4:
        mapping_key = f"{emotion}_{gesture}_{'_'.join(context_keywords) if context_keywords else 'none'}"
        
        # ê¸°ì¡´ ë§¤í•‘ ì°¾ê¸°
        existing_mapping = None
        for mapping in db_data["mappings"]:
            if mapping.get("key") == mapping_key:
                existing_mapping = mapping
                break
        
        if existing_mapping:
            # ê¸°ì¡´ ë§¤í•‘ ì—…ë°ì´íŠ¸ (í‰ê·  ì ìˆ˜ ê³„ì‚°)
            total_rating = existing_mapping.get("total_rating", 0) + user_rating
            count = existing_mapping.get("count", 0) + 1
            existing_mapping["total_rating"] = total_rating
            existing_mapping["count"] = count
            existing_mapping["avg_rating"] = total_rating / count
            existing_mapping["last_updated"] = datetime.now().isoformat()
        else:
            # ìƒˆ ë§¤í•‘ ì¶”ê°€
            db_data["mappings"].append({
                "key": mapping_key,
                "emotion": emotion,
                "gesture": gesture,
                "context_keywords": context_keywords,
                "recommended_video": os.path.basename(selected_video_path) if selected_video_path else None,
                "video_path": selected_video_path,
                "total_rating": user_rating,
                "count": 1,
                "avg_rating": float(user_rating),
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat()
            })
    
    save_video_mapping_database(db_data)


def get_recommended_video_from_database(
    emotion: str,
    gesture: str,
    context_keywords: List[str]
) -> str:
    """
    â­ Gemini ì œì•ˆ: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¶”ì²œ ë¹„ë””ì˜¤ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        emotion: ê°ì • ìƒíƒœ
        gesture: ì œìŠ¤ì²˜
        context_keywords: ìƒí™©ë³„ í‚¤ì›Œë“œ
    
    Returns:
        ì¶”ì²œ ë¹„ë””ì˜¤ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
    """
    db_data = load_video_mapping_database()
    
    mapping_key = f"{emotion}_{gesture}_{'_'.join(context_keywords) if context_keywords else 'none'}"
    
    # ì •í™•í•œ ë§¤ì¹­ ì°¾ê¸°
    for mapping in db_data["mappings"]:
        if mapping.get("key") == mapping_key and mapping.get("avg_rating", 0) >= 4.0:
            video_path = mapping.get("video_path")
            if video_path and os.path.exists(video_path):
                return video_path
    
    # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ê°ì •ê³¼ ì œìŠ¤ì²˜ë§Œ)
    partial_key = f"{emotion}_{gesture}_none"
    for mapping in db_data["mappings"]:
        if mapping.get("key") == partial_key and mapping.get("avg_rating", 0) >= 4.0:
            video_path = mapping.get("video_path")
            if video_path and os.path.exists(video_path):
                return video_path
    
    return None


def render_synchronized_video(text: str, audio_bytes: bytes, gender: str, emotion: str, 
                               role: str = "customer", autoplay: bool = True,
                               gesture: str = "NONE", context_keywords: List[str] = None):
    """
    TTS ì˜¤ë””ì˜¤ì™€ ë™ê¸°í™”ëœ ë¹„ë””ì˜¤ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    
    â­ Gemini ì œì•ˆ: í”¼ë“œë°± í‰ê°€ ê¸°ëŠ¥ ì¶”ê°€
    
    Args:
        text: ë§í•˜ëŠ” í…ìŠ¤íŠ¸ ë‚´ìš©
        audio_bytes: TTSë¡œ ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸
        gender: ê³ ê° ì„±ë³„ ("male" ë˜ëŠ” "female")
        emotion: ê°ì • ìƒíƒœ ("NEUTRAL", "HAPPY", "ANGRY", "ASKING", "SAD", "HOLD")
        role: ì—­í•  ("customer" ë˜ëŠ” "agent")
        autoplay: ìë™ ì¬ìƒ ì—¬ë¶€
        gesture: ì œìŠ¤ì²˜ (ì„ íƒì )
        context_keywords: ìƒí™©ë³„ í‚¤ì›Œë“œ (ì„ íƒì )
    """
    if role == "customer":
        is_speaking = True
        if context_keywords is None:
            context_keywords = []
        
        # â­ Gemini ì œì•ˆ: ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì¶”ì²œ ë¹„ë””ì˜¤ ìš°ì„  ì‚¬ìš©
        video_path = get_video_path_by_avatar(gender, emotion, is_speaking, gesture, context_keywords)
        
        if video_path and os.path.exists(video_path):
            try:
                with open(video_path, "rb") as f:
                    video_bytes = f.read()
                
                # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ë¥¼ í•¨ê»˜ ì¬ìƒ
                # Streamlitì˜ st.videoëŠ” ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ìˆëŠ” ë¹„ë””ì˜¤ë¥¼ ì§€ì›í•©ë‹ˆë‹¤
                # ì—¬ê¸°ì„œëŠ” ë¹„ë””ì˜¤ë§Œ í‘œì‹œí•˜ê³ , ì˜¤ë””ì˜¤ëŠ” ë³„ë„ë¡œ ì¬ìƒí•©ë‹ˆë‹¤
                st.video(video_bytes, format="video/mp4", autoplay=autoplay, loop=False, muted=False)
                
                # ì˜¤ë””ì˜¤ë„ í•¨ê»˜ ì¬ìƒ (ë™ê¸°í™”)
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3", autoplay=autoplay, loop=False)
                
                # â­ Gemini ì œì•ˆ: ì‚¬ìš©ì í”¼ë“œë°± í‰ê°€ UI ì¶”ê°€ (ì±„íŒ…/ì´ë©”ì¼ íƒ­ìš©)
                if not autoplay:  # ìë™ ì¬ìƒì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ í”¼ë“œë°± UI í‘œì‹œ
                    st.markdown("---")
                    st.markdown("**ğŸ’¬ ë¹„ë””ì˜¤ ë§¤ì¹­ í‰ê°€**")
                    st.caption("ì´ ë¹„ë””ì˜¤ê°€ ê³ ê°ì˜ í…ìŠ¤íŠ¸ì™€ ê°ì •ì— ìì—°ìŠ¤ëŸ½ê²Œ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆê¹Œ?")
                    
                    feedback_key = f"video_feedback_chat_{st.session_state.get('sim_instance_id', 'default')}_{hash(text) % 10000}"
                    
                    col_rating, col_comment = st.columns([2, 3])
                    with col_rating:
                        rating = st.slider(
                            "í‰ê°€ ì ìˆ˜ (1-5ì )",
                            min_value=1,
                            max_value=5,
                            value=3,
                            key=f"{feedback_key}_rating",
                            help="1ì : ë§¤ìš° ë¶€ìì—°ìŠ¤ëŸ¬ì›€, 5ì : ë§¤ìš° ìì—°ìŠ¤ëŸ¬ì›€"
                        )
                    
                    with col_comment:
                        comment = st.text_input(
                            "ì˜ê²¬ (ì„ íƒì‚¬í•­)",
                            key=f"{feedback_key}_comment",
                            placeholder="ì˜ˆ: ë¹„ë””ì˜¤ê°€ í…ìŠ¤íŠ¸ì™€ ì˜ ë§ì•˜ìŠµë‹ˆë‹¤"
                        )
                    
                    if st.button("í”¼ë“œë°± ì œì¶œ", key=f"{feedback_key}_submit"):
                        # í”¼ë“œë°±ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                        add_video_mapping_feedback(
                            customer_text=text[:200],
                            selected_video_path=video_path,
                            emotion=emotion,
                            gesture=gesture,
                            context_keywords=context_keywords,
                            user_rating=rating,
                            user_comment=comment
                        )
                        st.success(f"âœ… í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ì ìˆ˜: {rating}/5)")
                        st.info("ğŸ’¡ ì´ í”¼ë“œë°±ì€ í–¥í›„ ë¹„ë””ì˜¤ ì„ íƒ ì •í™•ë„ë¥¼ ê°œì„ í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.")
                
                return True
            except Exception as e:
                st.warning(f"ë¹„ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")
                # ë¹„ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨ ì‹œ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
                if audio_bytes:
                    st.audio(audio_bytes, format="audio/mp3", autoplay=autoplay, loop=False)
                return False
        else:
            # ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3", autoplay=autoplay, loop=False)
            return False
    else:
        # ì—ì´ì „íŠ¸ëŠ” ë¹„ë””ì˜¤ ì—†ì´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
        if audio_bytes:
            st.audio(audio_bytes, format="audio/mp3", autoplay=autoplay, loop=False)
        return False


def generate_virtual_human_video(text: str, audio_bytes: bytes, gender: str, emotion: str, 
                                 provider: str = "hyperclova") -> bytes:
    """
    ê°€ìƒ íœ´ë¨¼ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ì— ë§ëŠ” ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    âš ï¸ ì£¼ì˜: OpenAI/Gemini APIë§Œìœ¼ë¡œëŠ” ì…ëª¨ì–‘ ë™ê¸°í™” ë¹„ë””ì˜¤ ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
    ê°€ìƒ íœ´ë¨¼ ë¹„ë””ì˜¤ ìƒì„±ì€ ë³„ë„ì˜ ê°€ìƒ íœ´ë¨¼ API (ì˜ˆ: Hyperclova)ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    
    í˜„ì¬ëŠ” ë¯¸ë¦¬ ì¤€ë¹„ëœ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    
    Args:
        text: ë§í•˜ëŠ” í…ìŠ¤íŠ¸ ë‚´ìš©
        audio_bytes: TTSë¡œ ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸
        gender: ê³ ê° ì„±ë³„ ("male" ë˜ëŠ” "female")
        emotion: ê°ì • ìƒíƒœ ("NEUTRAL", "HAPPY", "ANGRY", "ASKING", "SAD", "HOLD")
        provider: ê°€ìƒ íœ´ë¨¼ ì œê³µì ("hyperclova", "other")
    
    Returns:
        ìƒì„±ëœ ë¹„ë””ì˜¤ ë°”ì´íŠ¸ (ì—†ìœ¼ë©´ None)
    """
    from llm_client import get_api_key
    # ê°€ìƒ íœ´ë¨¼ API í‚¤ í™•ì¸
    if provider == "hyperclova":
        api_key = get_api_key("hyperclova")
        if not api_key:
            return None
        
        # TODO: Hyperclova API ì—°ë™ êµ¬í˜„ (ë³„ë„ API í•„ìš”)
        # OpenAI/Gemini APIë§Œìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ì‹¤ì œ ê°€ìƒ íœ´ë¨¼ APIê°€ í•„ìš”í•©ë‹ˆë‹¤.
        # ì˜ˆì‹œ êµ¬ì¡°:
        # response = requests.post(
        #     "https://api.hyperclova.com/virtual-human/generate",
        #     headers={"Authorization": f"Bearer {api_key}"},
        #     json={
        #         "text": text,
        #         "audio": base64.b64encode(audio_bytes).decode(),
        #         "gender": gender,
        #         "emotion": emotion
        #     }
        # )
        # return response.content
    
    # ë‹¤ë¥¸ ì œê³µìë„ ì—¬ê¸°ì— ì¶”ê°€ ê°€ëŠ¥
    # elif provider == "other":
    #     ...
    
    return None


def get_virtual_human_config() -> Dict[str, Any]:
    """
    ê°€ìƒ íœ´ë¨¼ ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        ê°€ìƒ íœ´ë¨¼ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    from llm_client import get_api_key
    return {
        "enabled": st.session_state.get("virtual_human_enabled", False),
        "provider": st.session_state.get("virtual_human_provider", "hyperclova"),
        "api_key": get_api_key("hyperclova") if st.session_state.get("virtual_human_provider", "hyperclova") == "hyperclova" else None
    }









