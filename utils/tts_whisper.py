"""
TTS ë° Whisper ê´€ë ¨ í•¨ìˆ˜ ëª¨ë“ˆ
ìŒì„± ì „ì‚¬, TTS ìƒì„±, TTS ë²„íŠ¼ ë Œë”ë§ ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""
import os
import tempfile
import hashlib
import streamlit as st
from utils.llm_clients import get_api_key
from utils.i18n import LANG

# ì—­í• ë³„ TTS ìŒì„± ìŠ¤íƒ€ì¼ ì„¤ì •
TTS_VOICES = {
    "customer": {
        "gender": "male",
        "voice": "alloy"  # Distinct Male, Generic/Customer
    },
    "agent": {
        "gender": "female",
        "voice": "shimmer"  # Distinct Female, Professional/Agent
    },
    "supervisor": {
        "gender": "female",
        "voice": "nova"  # Another Distinct Female, Informative/Supervisor
    }
}


def transcribe_bytes_with_whisper(audio_bytes: bytes, mime_type: str = "audio/webm", lang_code: str = "ko") -> str:
    """
    OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì „ì‚¬í•©ë‹ˆë‹¤.
    """
    L = LANG[st.session_state.language]
    client = st.session_state.openai_client
    if client is None:
        return f"âŒ {L['openai_missing']}"

    whisper_lang = {"ko": "ko", "en": "en", "ja": "ja"}.get(lang_code, "en")

    # ì„ì‹œ íŒŒì¼ ì €ì¥ (Whisper API í˜¸í™˜ì„±)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp.write(audio_bytes)
    tmp.flush()
    tmp.close()

    try:
        with open(tmp.name, "rb") as f:
            res = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="text",
                language=whisper_lang,
            )
        # res.text ì†ì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ res ìì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        return res.text.strip() if hasattr(res, 'text') else str(res).strip()
    except Exception as e:
        # íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜ ë“± ìƒì„¸ ì˜¤ë¥˜ ì²˜ë¦¬
        return f"âŒ {L['error']} Whisper: {e}"
    finally:
        try:
            os.remove(tmp.name)
        except OSError:
            pass


def transcribe_audio(audio_bytes, filename="audio.wav"):
    """ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì „ì‚¬ (OpenAI Whisper ìš°ì„ , Gemini Fallback)"""
    import io
    client = st.session_state.openai_client

    # 1ï¸âƒ£ OpenAI Whisper ì‹œë„
    if client:
        try:
            bio = io.BytesIO(audio_bytes)
            bio.name = filename
            resp = client.audio.transcriptions.create(
                model="whisper-1",
                file=bio,
            )
            return resp.text
        except Exception as e:
            print("Whisper OpenAI failed:", e)

    # 2ï¸âƒ£ Gemini STT fallback
    try:
        # google.generativeaiëŠ” ì§€ì—° ë¡œë”©
        try:
            import google.generativeai as genai
            genai.configure(api_key=get_api_key("gemini"))
            model = genai.GenerativeModel("gemini-2.5-flash")
            text = model.generate_content("Transcribe this audio:").text
            return text or ""
        except (ImportError, Exception) as e:
            print("Gemini STT failed:", e)
    except Exception as e:
        print("Gemini STT failed:", e)

    return "âŒ STT not available"


def synthesize_tts(text: str, lang_key: str, role: str = "agent"):
    """TTSë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    L = LANG[lang_key]
    client = st.session_state.openai_client
    if client is None:
        return None, L["openai_missing"]

    if role not in TTS_VOICES:
        role = "agent"

    voice_name = TTS_VOICES[role]["voice"]

    try:
        # tts-1 ëª¨ë¸ ì‚¬ìš© (ì•ˆì •ì„±)
        resp = client.audio.speech.create(
            model="tts-1",
            voice=voice_name,
            input=text
            # format="mp3"ì€ ê¸°ë³¸ê°’ì…ë‹ˆë‹¤.
        )
        return resp.read(), L["tts_status_success"]

    except Exception as e:
        return None, f"{L['tts_status_error']}: {e}"


def render_tts_button(text, lang_key, role="customer", prefix="", index: int = -1):
    """TTS ì¬ìƒ ë²„íŠ¼ì„ ë Œë”ë§"""
    L = LANG[lang_key]

    # â­ ìˆ˜ì •: index=-1ì¸ ê²½ìš°, UUIDë¥¼ ì‚¬ìš©í•˜ì—¬ safe_key ìƒì„±
    if index == -1:
        # ì´ê´€ ìš”ì•½ì²˜ëŸ¼ ì¸ë±ìŠ¤ê°€ ê³ ì •ë˜ì§€ ì•ŠëŠ” ê²½ìš°, í…ìŠ¤íŠ¸ í•´ì‹œì™€ ì„¸ì…˜ ì¸ìŠ¤í„´ìŠ¤ IDë¥¼ ì¡°í•©
        content_hash = hashlib.md5(text[:100].encode()).hexdigest()
        session_id_part = st.session_state.get('sim_instance_id', 'default_session')
        safe_key = f"{prefix}_tts_{session_id_part}_{content_hash}"
    else:
        safe_key = f"{prefix}_tts_{index}"

    if st.button(f"ğŸ”Š {L['button_listen_audio']}", key=safe_key):
        with st.spinner(L["tts_status_generating"]):
            audio_bytes, status_msg = synthesize_tts(text, lang_key, role)
            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3")
                st.success(status_msg)
            else:
                st.error(status_msg)
