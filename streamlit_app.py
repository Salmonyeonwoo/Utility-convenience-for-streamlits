# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ========================================
# streamlit_app.py (ëª¨ë“ˆí™”ëœ ë²„ì „)
# ========================================

# â­ OpenMP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶©ëŒ í•´ê²°
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import io
import json
import time
import uuid
import base64
import tempfile
import hashlib
import random
from datetime import datetime, timedelta
from typing import List, Dict, Any, Union, Tuple

# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import google.generativeai as genai
import numpy as np
import streamlit as st
from matplotlib import pyplot as plt
import requests
from openai import OpenAI
from anthropic import Anthropic
from streamlit_mic_recorder import mic_recorder

# LangChain ê´€ë ¨
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
except ImportError:
    raise ImportError("âŒ 'langchain-text-splitters' íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
try:
    try:
        from langchain.memory import ConversationBufferMemory
    except ImportError:
        try:
            from langchain_classic.memory import ConversationBufferMemory
        except ImportError:
            from langchain_core.memory import ConversationBufferMemory
except ImportError:
    raise ImportError("âŒ 'langchain' íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
try:
    try:
        from langchain.chains import ConversationChain
    except ImportError:
        try:
            from langchain_classic.chains import ConversationChain
        except ImportError:
            ConversationChain = None
except ImportError:
    ConversationChain = None

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_community.embeddings import HuggingFaceEmbeddings

# Word, PPTX, PDF ìƒì„± ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from docx import Document as DocxDocument
    from docx.shared import Pt, RGBColor, Inches
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    IS_DOCX_AVAILABLE = True
except ImportError:
    IS_DOCX_AVAILABLE = False

try:
    from pptx import Presentation
    from pptx.util import Inches, Pt
    IS_PPTX_AVAILABLE = True
except ImportError:
    IS_PPTX_AVAILABLE = False

try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.lib import colors
    from reportlab.lib.colors import black
    IS_REPORTLAB_AVAILABLE = True
except ImportError:
    IS_REPORTLAB_AVAILABLE = False

# Plotly ì‹œê°í™”
try:
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    IS_PLOTLY_AVAILABLE = True
except ImportError:
    IS_PLOTLY_AVAILABLE = False

# ì„ë² ë”© ëª¨ë¸
try:
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    IS_GEMINI_EMBEDDING_AVAILABLE = True
except ImportError:
    IS_GEMINI_EMBEDDING_AVAILABLE = False

try:
    from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings
    IS_NVIDIA_EMBEDDING_AVAILABLE = True
except ImportError:
    IS_NVIDIA_EMBEDDING_AVAILABLE = False

# ========================================
# ëª¨ë“ˆ Import
# ========================================
from config import (
    BASE_DIR, DATA_DIR, AUDIO_DIR, RAG_INDEX_DIR, VIDEO_DIR,
    VOICE_META_FILE, SIM_META_FILE, VIDEO_MAPPING_DB_FILE,
    FAQ_DB_FILE, PRODUCT_IMAGE_CACHE_FILE, PRODUCT_IMAGE_DIR,
    SUPPORTED_APIS, DEFAULT_LANG
)
from utils import _load_json, _save_json
from lang_pack import LANG, DEFAULT_LANG as LANG_DEFAULT
from llm_client import get_api_key, get_llm_client, run_llm, init_openai_audio_client
from faq_manager import (
    load_faq_database, save_faq_database, get_company_info_faq,
    visualize_company_data, load_product_image_cache, save_product_image_cache,
    generate_product_image_prompt, generate_product_image_with_ai,
    get_product_image_url, search_faq, get_common_product_faqs,
    generate_company_info_with_llm
)
from audio_handler import (
    transcribe_bytes_with_whisper, transcribe_audio, synthesize_tts,
    render_tts_button, load_voice_records, save_voice_records,
    save_audio_record_local, delete_audio_record_local, get_audio_bytes_local,
    TTS_VOICES
)
from video_handler import (
    analyze_text_for_video_selection, get_video_path_by_avatar,
    load_video_mapping_database, save_video_mapping_database,
    add_video_mapping_feedback, get_recommended_video_from_database,
    render_synchronized_video, generate_virtual_human_video,
    get_virtual_human_config
)
from rag_handler import (
    load_documents, split_documents, get_embedding_model,
    get_embedding_function, build_rag_index, load_rag_index,
    rag_answer, load_or_train_lstm
)
from simulation_handler import (
    translate_text_with_llm, generate_realtime_hint,
    generate_agent_response_draft, generate_outbound_call_summary,
    load_simulation_histories_local, generate_chat_summary,
    save_simulation_history_local, export_history_to_word,
    export_history_to_pptx, export_history_to_pdf,
    get_chat_history_for_prompt, generate_customer_reaction,
    summarize_history_with_ai, generate_customer_reaction_for_call,
    generate_customer_reaction_for_first_greeting, summarize_history_for_call,
    generate_customer_closing_response, generate_agent_first_greeting,
    detect_text_language, analyze_customer_profile, find_similar_cases,
    generate_guideline_from_past_cases, _generate_initial_advice
)
from visualization import (
    visualize_customer_profile_scores, visualize_similarity_cases,
    visualize_case_trends, visualize_customer_characteristics
)


# ========================================
# Streamlit í˜ì´ì§€ ì„¤ì •
# ========================================
st.set_page_config(
    page_title="AI Study Coach & Customer Service Simulator",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========================================
# 0. ê¸°ë³¸ ê²½ë¡œ/ë¡œì»¬ DB ì„¤ì •
# ========================================



os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(PRODUCT_IMAGE_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(RAG_INDEX_DIR, exist_ok=True)

# ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ë„ ì´ˆê¸°í™” ì‹œ ìƒì„±
os.makedirs(VIDEO_DIR, exist_ok=True)




# ----------------------------------------
# JSON HelperëŠ” utils.pyë¡œ ì´ë™ë¨
# ----------------------------------------





# ========================================
# 1. ë‹¤êµ­ì–´ ì„¤ì • (ì „í™” ë°œì‹  ê´€ë ¨ í…ìŠ¤íŠ¸ ì¶”ê°€)
# ========================================


# ========================================
# 1-1. Session State ì´ˆê¸°í™” (ì „í™” ë°œì‹  ê´€ë ¨ ìƒíƒœ ì¶”ê°€)
# ========================================
# â­ ì‚¬ì´ë“œë°” ë²„íŠ¼ì€ ì‚¬ì´ë“œë°” ë¸”ë¡ ì•ˆìœ¼ë¡œ ì´ë™í•´ì•¼ í•¨
# ì—¬ê¸°ì„œëŠ” ì„¸ì…˜ ìƒíƒœë§Œ ì´ˆê¸°í™”

if "language" not in st.session_state:
    st.session_state.language = DEFAULT_LANG
if "is_llm_ready" not in st.session_state:
    st.session_state.is_llm_ready = False
if "llm_init_error_msg" not in st.session_state:
    st.session_state.llm_init_error_msg = ""
if "uploaded_files_state" not in st.session_state:
    st.session_state.uploaded_files_state = None
if "is_rag_ready" not in st.session_state:
    st.session_state.is_rag_ready = False
if "rag_vectorstore" not in st.session_state:
    st.session_state.rag_vectorstore = None
if "rag_messages" not in st.session_state:
    st.session_state.rag_messages = []
if "agent_input" not in st.session_state:
    st.session_state.agent_input = ""
if "last_audio" not in st.session_state:
    st.session_state.last_audio = None
if "simulator_messages" not in st.session_state:
    st.session_state.simulator_messages = []
if "simulator_memory" not in st.session_state:
    st.session_state.simulator_memory = ConversationBufferMemory(memory_key="chat_history")
if "simulator_chain" not in st.session_state:
    st.session_state.simulator_chain = None
if "initial_advice_provided" not in st.session_state:
    st.session_state.initial_advice_provided = False
if "is_chat_ended" not in st.session_state:
    st.session_state.is_chat_ended = False
if "show_delete_confirm" not in st.session_state:
    st.session_state.show_delete_confirm = False
if "customer_query_text_area" not in st.session_state:
    st.session_state.customer_query_text_area = ""
if "agent_response_area_text" not in st.session_state:
    st.session_state.agent_response_area_text = ""
if "reset_agent_response_area" not in st.session_state:
    st.session_state.reset_agent_response_area = False
if "last_transcript" not in st.session_state:
    st.session_state.last_transcript = ""
if "sim_audio_bytes" not in st.session_state:
    st.session_state.sim_audio_bytes = None
if "chat_state" not in st.session_state:
    st.session_state.chat_state = "idle"
    # idle â†’ initial_customer â†’ supervisor_advice â†’ agent_turn â†’ customer_turn â†’ closing
if "openai_client" not in st.session_state:
    st.session_state.openai_client = None
if "openai_init_msg" not in st.session_state:
    st.session_state.openai_init_msg = ""
if "sim_stage" not in st.session_state:
    st.session_state.sim_stage = "WAIT_FIRST_QUERY"
    # WAIT_FIRST_QUERY (ì´ˆê¸° ë¬¸ì˜ ì…ë ¥)
    # AGENT_TURN (ì—ì´ì „íŠ¸ ì‘ë‹µ ì…ë ¥)
    # CUSTOMER_TURN (ê³ ê° ë°˜ì‘ ìƒì„± ìš”ì²­)
    # WAIT_CLOSING_CONFIRMATION_FROM_AGENT (ê³ ê°ì´ ê°ì‚¬, ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸° ëŒ€ê¸°)
    # WAIT_CUSTOMER_CLOSING_RESPONSE (ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ë³´ëƒ„, ê³ ê°ì˜ ë§ˆì§€ë§‰ ì‘ë‹µ ëŒ€ê¸°)
    # FINAL_CLOSING_ACTION (ìµœì¢… ì¢…ë£Œ ë²„íŠ¼ ëŒ€ê¸°)
    # CLOSING (ì±„íŒ… ì¢…ë£Œ)
    # â­ ì¶”ê°€: OUTBOUND_CALL_IN_PROGRESS (ì „í™” ë°œì‹  ì§„í–‰ ì¤‘)
if "start_time" not in st.session_state:  # AHT íƒ€ì´ë¨¸ ì‹œì‘ ì‹œê°„
    st.session_state.start_time = None
if "is_solution_provided" not in st.session_state:  # ì†”ë£¨ì…˜ ì œê³µ ì—¬ë¶€ í”Œë˜ê·¸
    st.session_state.is_solution_provided = False
if "transfer_summary_text" not in st.session_state:  # ì´ê´€ ì‹œ ë²ˆì—­ëœ ìš”ì•½
    st.session_state.transfer_summary_text = ""
if "translation_success" not in st.session_state:  # ë²ˆì—­ ì„±ê³µ ì—¬ë¶€ ì¶”ì 
    st.session_state.translation_success = True
if "language_transfer_requested" not in st.session_state:  # ê³ ê°ì˜ ì–¸ì–´ ì´ê´€ ìš”ì²­ ì—¬ë¶€
    st.session_state.language_transfer_requested = False
if "customer_attachment_file" not in st.session_state:  # ê³ ê° ì²¨ë¶€ íŒŒì¼ ì •ë³´
    st.session_state.customer_attachment_file = None
if "language_at_transfer" not in st.session_state:  # í˜„ì¬ ì–¸ì–´ì™€ ë¹„êµë¥¼ ìœ„í•œ ë³€ìˆ˜
    st.session_state.language_at_transfer = st.session_state.language
if "language_at_transfer_start" not in st.session_state:  # ë²ˆì—­ ì¬ì‹œë„ë¥¼ ìœ„í•œ ì›ë³¸ ì–¸ì–´
    st.session_state.language_at_transfer_start = st.session_state.language
if "transfer_retry_count" not in st.session_state:
    st.session_state.transfer_retry_count = 0
if "customer_type_sim_select" not in st.session_state:  # FIX: Attribute Error í•´ê²°
    # LANGì´ ì •ì˜ë˜ê¸° ì „ì´ë¯€ë¡œ ê¸°ë³¸ê°’ì„ ì§ì ‘ ì„¤ì •
    default_customer_type = "ê¹Œë‹¤ë¡œìš´ ê³ ê°"  # í•œêµ­ì–´ ê¸°ë³¸ê°’
    if st.session_state.language == "en":
        default_customer_type = "Difficult Customer"
    elif st.session_state.language == "ja":
        default_customer_type = "é›£ã—ã„é¡§å®¢"
    st.session_state.customer_type_sim_select = default_customer_type
if "customer_email" not in st.session_state:  # FIX: customer_email ì´ˆê¸°í™”
    st.session_state.customer_email = ""
if "customer_phone" not in st.session_state:  # FIX: customer_phone ì´ˆê¸°í™”
    st.session_state.customer_phone = ""
if "agent_response_input_box_widget" not in st.session_state:  # FIX: customer_phone ì´ˆê¸°í™”
    st.session_state.agent_response_input_box_widget = ""
if "sim_instance_id" not in st.session_state:  # FIX: DuplicateWidgetID ë°©ì§€ìš© ì¸ìŠ¤í„´ìŠ¤ ID ì´ˆê¸°í™”
    st.session_state.sim_instance_id = str(uuid.uuid4())
if "sim_attachment_context_for_llm" not in st.session_state:
    st.session_state.sim_attachment_context_for_llm = ""
if "realtime_hint_text" not in st.session_state:
    st.session_state.realtime_hint_text = ""
# â­ ì¶”ê°€: ì „í™” ë°œì‹  ê´€ë ¨ ìƒíƒœ
if "sim_call_outbound_summary" not in st.session_state:
    st.session_state.sim_call_outbound_summary = ""
if "sim_call_outbound_target" not in st.session_state:
    st.session_state.sim_call_outbound_target = None
# ----------------------------------------------------------------------
# â­ ì „í™” ê¸°ëŠ¥ ê´€ë ¨ ìƒíƒœ ì¶”ê°€
if "call_sim_stage" not in st.session_state:
    st.session_state.call_sim_stage = "WAITING_CALL"  # WAITING_CALL, RINGING, IN_CALL, CALL_ENDED
if "call_sim_mode" not in st.session_state:
    st.session_state.call_sim_mode = "INBOUND"  # INBOUND or OUTBOUND
if "incoming_phone_number" not in st.session_state:
    st.session_state.incoming_phone_number = "+82 10-1234-5678"
if "is_on_hold" not in st.session_state:
    st.session_state.is_on_hold = False
if "hold_start_time" not in st.session_state:
    st.session_state.hold_start_time = None
if "total_hold_duration" not in st.session_state:
    st.session_state.total_hold_duration = timedelta(0)
if "current_customer_audio_text" not in st.session_state:
    st.session_state.current_customer_audio_text = ""
if "current_agent_audio_text" not in st.session_state:
    st.session_state.current_agent_audio_text = ""
if "agent_response_input_box_widget_call" not in st.session_state:  # ì „í™” íƒ­ ì „ìš© ì…ë ¥ì°½
    st.session_state.agent_response_input_box_widget_call = ""
if "call_initial_query" not in st.session_state:  # ì „í™” íƒ­ ì „ìš© ì´ˆê¸° ë¬¸ì˜
    st.session_state.call_initial_query = ""
if "call_website_url" not in st.session_state:  # ì „í™” íƒ­ ì „ìš© í™ˆí˜ì´ì§€ ì£¼ì†Œ
    st.session_state.call_website_url = ""
# â­ ì¶”ê°€: í†µí™” ìš”ì•½ ë° ì´ˆê¸° ê³ ê° ìŒì„± ì €ì¥ì†Œ
if "call_summary_text" not in st.session_state:
    st.session_state.call_summary_text = ""
if "customer_initial_audio_bytes" not in st.session_state:  # ê³ ê°ì˜ ì²« ìŒì„± (TTS ê²°ê³¼) ì €ì¥
    st.session_state.customer_initial_audio_bytes = None
if "supervisor_policy_context" not in st.session_state:
    # Supervisorê°€ ì—…ë¡œë“œí•œ ì˜ˆì™¸ ì •ì±… í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    st.session_state.supervisor_policy_context = ""
if "agent_policy_attachment_content" not in st.session_state:
    # ì—ì´ì „íŠ¸ê°€ ì—…ë¡œë“œí•œ ì •ì±… íŒŒì¼ ê°ì²´(ë˜ëŠ” ë‚´ìš©)ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    st.session_state.agent_policy_attachment_content = ""
if "customer_attachment_b64" not in st.session_state:
    st.session_state.customer_attachment_b64 = ""
if "customer_history_summary" not in st.session_state:
    st.session_state.customer_history_summary = ""
if "customer_avatar" not in st.session_state:
    st.session_state.customer_avatar = {
        "gender": "male",  # ê¸°ë³¸ê°’
        "state": "NEUTRAL",  # ê¸°ë³¸ ì•„ë°”íƒ€ ìƒíƒœ
    }
# â­ ì¶”ê°€: ë¹„ë””ì˜¤ ë™ê¸°í™” ê´€ë ¨ ì„¸ì…˜ ìƒíƒœ
if "current_customer_video" not in st.session_state:
    st.session_state.current_customer_video = None  # í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ê³ ê° ë¹„ë””ì˜¤ ê²½ë¡œ
if "current_customer_video_bytes" not in st.session_state:
    st.session_state.current_customer_video_bytes = None  # í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ê³ ê° ë¹„ë””ì˜¤ ë°”ì´íŠ¸
if "is_video_sync_enabled" not in st.session_state:
    st.session_state.is_video_sync_enabled = True  # ë¹„ë””ì˜¤ ë™ê¸°í™” í™œì„±í™” ì—¬ë¶€
if "video_male_neutral" not in st.session_state:
    st.session_state.video_male_neutral = None  # ë‚¨ì ì¤‘ë¦½ ë¹„ë””ì˜¤ ê²½ë¡œ
if "video_male_happy" not in st.session_state:
    st.session_state.video_male_happy = None
if "video_male_angry" not in st.session_state:
    st.session_state.video_male_angry = None
if "video_male_asking" not in st.session_state:
    st.session_state.video_male_asking = None
if "video_male_sad" not in st.session_state:
    st.session_state.video_male_sad = None
if "video_female_neutral" not in st.session_state:
    st.session_state.video_female_neutral = None  # ì—¬ì ì¤‘ë¦½ ë¹„ë””ì˜¤ ê²½ë¡œ
if "video_female_happy" not in st.session_state:
    st.session_state.video_female_happy = None
if "video_female_angry" not in st.session_state:
    st.session_state.video_female_angry = None
if "video_female_asking" not in st.session_state:
    st.session_state.video_female_asking = None
if "video_female_sad" not in st.session_state:
    st.session_state.video_female_sad = None
# â­ ì¶”ê°€: ì „ì‚¬í•  ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ì„ì‹œ ì €ì¥ì†Œ
if "bytes_to_process" not in st.session_state:
    st.session_state.bytes_to_process = None

# ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
current_lang = st.session_state.get("language", "ko")
if current_lang not in ["ko", "en", "ja"]:
    current_lang = "ko"
L = LANG.get(current_lang, LANG["ko"])

# â­ 2-A. Gemini í‚¤ ì´ˆê¸°í™” (ì˜ëª»ëœ í‚¤ ì”ì¡´ ë°©ì§€)
if "user_gemini_key" in st.session_state and st.session_state["user_gemini_key"].startswith("AIza"):
    pass

# ========================================
# 0. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ========================================

# ì„¸ì…˜ ì´ˆê¸°í™” (SUPPORTED_APISëŠ” configì—ì„œ importë¨)
for api, cfg in SUPPORTED_APIS.items():
    if cfg["session_key"] not in st.session_state:
        st.session_state[cfg["session_key"]] = ""

if "selected_llm" not in st.session_state:
    st.session_state.selected_llm = "openai_gpt4"


# ========================================
# 1. Sidebar UI: API Key ì…ë ¥ ì œê±°
# ========================================
# API Key ì…ë ¥ UIëŠ” ì œê±°í•˜ê³ , í™˜ê²½ë³€ìˆ˜ì™€ Streamlit Secretsë§Œ ì‚¬ìš©í•˜ë„ë¡ í•¨.


# ========================================
# 2. LLM í´ë¼ì´ì–¸íŠ¸ ë¼ìš°íŒ… & ì‹¤í–‰
# ========================================
# ========================================
# 2-A. Whisper / TTS ìš© OpenAI Client ë³„ë„ë¡œ ì´ˆê¸°í™”
# ========================================

if "openai_client" not in st.session_state or st.session_state.openai_client is None:
    try:
        st.session_state.openai_client = init_openai_audio_client()
    except Exception as e:
        st.session_state.openai_client = None
        print(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")

# LLM ì¤€ë¹„ ìƒíƒœ ìºì‹± (API í‚¤ ë³€ê²½ ì‹œì—ë§Œ ì¬í™•ì¸)
# â­ ìˆ˜ì •: ì´ˆê¸°í™” ì‹œ ë¸”ë¡œí‚¹ ë°©ì§€ë¥¼ ìœ„í•´ try-except ì¶”ê°€
if "is_llm_ready" not in st.session_state or "llm_ready_checked" not in st.session_state:
    try:
        probe_client, _ = get_llm_client()
        st.session_state.is_llm_ready = probe_client is not None
    except Exception as e:
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë„ ì•±ì´ ê³„ì† ì‹¤í–‰ë˜ë„ë¡ Falseë¡œ ì„¤ì •
        st.session_state.is_llm_ready = False
        print(f"LLM ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
    st.session_state.llm_ready_checked = True

# API í‚¤ ë³€ê²½ ê°ì§€ë¥¼ ìœ„í•œ í•´ì‹œ ì²´í¬
current_api_keys_hash = hashlib.md5(
    f"{get_api_key('openai')}{get_api_key('gemini')}{get_api_key('claude')}{get_api_key('groq')}".encode()
).hexdigest()

if "api_keys_hash" not in st.session_state:
    st.session_state.api_keys_hash = current_api_keys_hash
elif st.session_state.api_keys_hash != current_api_keys_hash:
    # API í‚¤ê°€ ë³€ê²½ëœ ê²½ìš°ë§Œ ì¬í™•ì¸
    # â­ ìˆ˜ì •: ì´ˆê¸°í™” ì‹œ ë¸”ë¡œí‚¹ ë°©ì§€ë¥¼ ìœ„í•´ try-except ì¶”ê°€
    try:
        probe_client, _ = get_llm_client()
        st.session_state.is_llm_ready = probe_client is not None
    except Exception as e:
        st.session_state.is_llm_ready = False
        print(f"LLM ì¬ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
    st.session_state.api_keys_hash = current_api_keys_hash
    # OpenAI í´ë¼ì´ì–¸íŠ¸ë„ ì¬ì´ˆê¸°í™”
    try:
        st.session_state.openai_client = init_openai_audio_client()
    except Exception as e:
        st.session_state.openai_client = None
        print(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")

if st.session_state.openai_client:
    # í‚¤ë¥¼ ì°¾ì•˜ê³  í´ë¼ì´ì–¸íŠ¸ ê°ì²´ëŠ” ìƒì„±ë˜ì—ˆìœ¼ë‚˜, ì‹¤ì œ ì¸ì¦ì€ API í˜¸ì¶œ ì‹œ ì´ë£¨ì–´ì§ (401 ì˜¤ë¥˜ëŠ” ì—¬ê¸°ì„œ ë°œìƒ)
    st.session_state.openai_init_msg = "âœ… OpenAI TTS/Whisper í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ (Key í™•ì¸ë¨)"
else:
    # í‚¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
    st.session_state.openai_init_msg = L["openai_missing"]

if not st.session_state.is_llm_ready:
    st.session_state.llm_init_error_msg = L["simulation_no_key_warning"]
else:
    st.session_state.llm_init_error_msg = ""


# ----------------------------------------
# LLM ë²ˆì—­ í•¨ìˆ˜ëŠ” simulation_handler.pyë¡œ ì´ë™ë¨
# ----------------------------------------

# ========================================
# 3. Whisper / TTS HelperëŠ” audio_handler.pyë¡œ ì´ë™ë¨
# ========================================

# ========================================
# ë¹„ë””ì˜¤ ë™ê¸°í™” ê´€ë ¨ í•¨ìˆ˜ëŠ” video_handler.pyë¡œ ì´ë™ë¨
# ì‹œë®¬ë ˆì´ì…˜ ê´€ë ¨ í•¨ìˆ˜ëŠ” simulation_handler.pyë¡œ ì´ë™ë¨
# ========================================

# ========================================
# 8. LLM (ChatOpenAI) for Simulator / Content
# (RAGì™€ ë™ì¼í•˜ê²Œ run_llmìœ¼ë¡œ í†µí•©)
# ========================================

# ConversationChain ëŒ€ì‹  run_llmì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„
# st.session_state.simulator_memoryëŠ” ìœ ì§€í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

def visualize_customer_profile_scores(customer_profile: Dict[str, Any], current_lang_key: str):
    """ê³ ê° í”„ë¡œí•„ ì ìˆ˜ë¥¼ ì‹œê°í™” (ê°ì • ì ìˆ˜, ê¸´ê¸‰ë„)"""
    if not IS_PLOTLY_AVAILABLE:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    sentiment_score = customer_profile.get("sentiment_score", 50)
    urgency_map = {"low": 25, "medium": 50, "high": 75}
    urgency_level = customer_profile.get("urgency_level", "medium")
    urgency_score = urgency_map.get(urgency_level.lower(), 50)

    # ê²Œì´ì§€ ì°¨íŠ¸ ìƒì„±
    fig = make_subplots(
        rows=1, cols=2,
        specs=[[{"type": "indicator"}, {"type": "indicator"}]],
        subplot_titles=(
            L.get("sentiment_score_label", "ê³ ê° ê°ì • ì ìˆ˜"),
            L.get("urgency_score_label", "ê¸´ê¸‰ë„ ì ìˆ˜")
        )
    )

    # ê°ì • ì ìˆ˜ ê²Œì´ì§€
    fig.add_trace(
        go.Indicator(
            mode="gauge+number+delta",
            value=sentiment_score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': L.get("sentiment_score_label", "ê°ì • ì ìˆ˜")},
            delta={'reference': 50},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 33], 'color': "lightgray"},
                    {'range': [33, 66], 'color': "gray"},
                    {'range': [66, 100], 'color': "lightgreen"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ),
        row=1, col=1
    )

    # ê¸´ê¸‰ë„ ì ìˆ˜ ê²Œì´ì§€
    fig.add_trace(
        go.Indicator(
            mode="gauge+number",
            value=urgency_score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': L.get("urgency_score_label", "ê¸´ê¸‰ë„")},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkred"},
                'steps': [
                    {'range': [0, 50], 'color': "lightgreen"},
                    {'range': [50, 75], 'color': "yellow"},
                    {'range': [75, 100], 'color': "lightcoral"}
                ],
            }
        ),
        row=1, col=2
    )

    fig.update_layout(height=300, margin=dict(l=20, r=20, t=50, b=20))
    return fig


def visualize_similarity_cases(similar_cases: List[Dict[str, Any]], current_lang_key: str):
    """ìœ ì‚¬ ì¼€ì´ìŠ¤ ì¶”ì²œì„ ì‹œê°í™”"""
    if not IS_PLOTLY_AVAILABLE or not similar_cases:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    case_labels = []
    similarity_scores = []
    sentiment_scores = []
    satisfaction_scores = []

    for idx, similar_case in enumerate(similar_cases, 1):
        summary = similar_case["summary"]
        similarity = similar_case["similarity_score"]
        case_labels.append(f"Case {idx}")
        similarity_scores.append(similarity)
        sentiment_scores.append(summary.get("customer_sentiment_score", 50))
        satisfaction_scores.append(summary.get("customer_satisfaction_score", 50))

    # ìœ ì‚¬ë„ ì°¨íŠ¸
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=(
            L.get("similarity_chart_title", "ìœ ì‚¬ ì¼€ì´ìŠ¤ ìœ ì‚¬ë„"),
            L.get("scores_comparison_title",
                  "ê°ì • ë° ë§Œì¡±ë„ ì ìˆ˜ ë¹„êµ")
        ),
        vertical_spacing=0.15
    )

    # ìœ ì‚¬ë„ ë°” ì°¨íŠ¸
    fig.add_trace(
        go.Bar(
            x=case_labels,
            y=similarity_scores,
            name=L.get("similarity_score_label", "ìœ ì‚¬ë„"),
            marker_color='lightblue',
            text=[f"{s:.1f}%" for s in similarity_scores],
            textposition='outside'
        ),
        row=1, col=1
    )

    # ê°ì • ë° ë§Œì¡±ë„ ì ìˆ˜ ë¹„êµ
    fig.add_trace(
        go.Bar(
            x=case_labels,
            y=sentiment_scores,
            name=L.get("sentiment_score_label", "ê°ì • ì ìˆ˜"),
            marker_color='lightcoral'
        ),
        row=2, col=1
    )

    fig.add_trace(
        go.Bar(
            x=case_labels,
            y=satisfaction_scores,
            name=L.get("satisfaction_score_label", "ë§Œì¡±ë„"),
            marker_color='lightgreen'
        ),
        row=2, col=1
    )

    fig.update_layout(
        height=600,
        showlegend=True,
        margin=dict(l=20, r=20, t=50, b=20),
        barmode='group'
    )
    fig.update_yaxes(title_text="ì ìˆ˜", row=2, col=1)
    fig.update_yaxes(title_text="ìœ ì‚¬ë„ (%)", row=1, col=1)

    return fig


def visualize_case_trends(histories: List[Dict[str, Any]], current_lang_key: str):
    """ê³¼ê±° ì„±ê³µ ì‚¬ë¡€ íŠ¸ë Œë“œë¥¼ ì‹œê°í™”"""
    if not IS_PLOTLY_AVAILABLE or not histories:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    # ìš”ì•½ ë°ì´í„°ê°€ ìˆëŠ” ì¼€ì´ìŠ¤ë§Œ í•„í„°ë§
    cases_with_summary = [
        h for h in histories
        if h.get("summary") and isinstance(h.get("summary"), dict) and h.get("is_chat_ended", False)
    ]

    if not cases_with_summary:
        return None

    # ë‚ ì§œë³„ë¡œ ì •ë ¬
    cases_with_summary.sort(key=lambda x: x.get("timestamp", ""))

    dates = []
    sentiment_scores = []
    satisfaction_scores = []

    for case in cases_with_summary:
        summary = case.get("summary", {})
        timestamp = case.get("timestamp", "")
        try:
            dt = datetime.fromisoformat(timestamp)
            dates.append(dt)
            sentiment_scores.append(summary.get("customer_sentiment_score", 50))
            satisfaction_scores.append(summary.get("customer_satisfaction_score", 50))
        except Exception:
            continue

    if not dates:
        return None

    # íŠ¸ë Œë“œ ë¼ì¸ ì°¨íŠ¸
    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=dates,
        y=sentiment_scores,
        mode='lines+markers',
        name=L.get("sentiment_trend_label", "ê°ì • ì ìˆ˜ ì¶”ì´"),
        line=dict(color='lightcoral', width=2),
        marker=dict(size=6)
    ))

    fig.add_trace(go.Scatter(
        x=dates,
        y=satisfaction_scores,
        mode='lines+markers',
        name=L.get("satisfaction_trend_label", "ë§Œì¡±ë„ ì ìˆ˜ ì¶”ì´"),
        line=dict(color='lightgreen', width=2),
        marker=dict(size=6)
    ))

    fig.update_layout(
        title=L.get("case_trends_title", "ê³¼ê±° ì¼€ì´ìŠ¤ ì ìˆ˜ ì¶”ì´"),
        xaxis_title=L.get("date_label", "ë‚ ì§œ"),
        yaxis_title=L.get("score_label", "ì ìˆ˜ (0-100)"),
        height=400,
        hovermode='x unified',
        legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
    )

    return fig


def visualize_customer_characteristics(summary: Dict[str, Any], current_lang_key: str):
    """ê³ ê° íŠ¹ì„±ì„ ì‹œê°í™” (ì–¸ì–´, ë¬¸í™”ê¶Œ, ì§€ì—­ ë“±)"""
    if not IS_PLOTLY_AVAILABLE or not summary:
        return None

    # ì–¸ì–´ í‚¤ ê²€ì¦
    if current_lang_key not in ["ko", "en", "ja"]:
        current_lang_key = st.session_state.get("language", "ko")
        if current_lang_key not in ["ko", "en", "ja"]:
            current_lang_key = "ko"
    L = LANG.get(current_lang_key, LANG["ko"])

    characteristics = summary.get("customer_characteristics", {})
    privacy_info = summary.get("privacy_info", {})

    # íŠ¹ì„± ë°ì´í„° ì¤€ë¹„
    labels = []
    values = []

    # ì–¸ì–´ ì •ë³´
    language = characteristics.get("language", "unknown")
    if language != "unknown":
        labels.append(L.get("language_label", "ì–¸ì–´"))
        lang_map = {"ko": "í•œêµ­ì–´", "en": "English", "ja": "æ—¥æœ¬èª"}
        values.append(lang_map.get(language, language))

    # ê°œì¸ì •ë³´ ì œê³µ ì—¬ë¶€
    if privacy_info.get("has_email"):
        labels.append(L.get("email_provided_label", "ì´ë©”ì¼ ì œê³µ"))
        values.append("Yes")
    if privacy_info.get("has_phone"):
        labels.append(L.get("phone_provided_label", "ì „í™”ë²ˆí˜¸ ì œê³µ"))
        values.append("Yes")

    # ì§€ì—­ ì •ë³´
    region = privacy_info.get("region_hint", characteristics.get("region", "unknown"))
    if region != "unknown":
        labels.append(L.get("region_label", "ì§€ì—­"))
        values.append(region)

    if not labels:
        return None

    # íŒŒì´ ì°¨íŠ¸
    fig = go.Figure(data=[go.Pie(
        labels=labels,
        values=[1] * len(labels),
        hole=0.4,
        marker_colors=px.colors.qualitative.Set3[:len(labels)]
    )])

    fig.update_layout(
        title=L.get("customer_characteristics_title",
                    "ê³ ê° íŠ¹ì„± ë¶„í¬"),
        height=300,
        showlegend=True,
        margin=dict(l=20, r=20, t=50, b=20)
    )

    return fig


[Case {idx}] (Similarity: {similarity:.1f}%)
- Inquiry: {summary.get('main_inquiry', 'N/A')}
- Customer Sentiment: {summary.get('customer_sentiment_score', 50)}/100
- Customer Satisfaction: {summary.get('customer_satisfaction_score', 50)}/100
- Key Responses: {', '.join(summary.get('key_responses', [])[:3])}
- Summary: {summary.get('summary', 'N/A')[:200]}
"""

    guideline_prompt = f"""
You are an AI Customer Support Supervisor analyzing past successful cases to provide guidance.

Based on the following similar past cases and their successful resolution strategies, provide actionable guidelines for handling the current customer inquiry.

Current Customer Inquiry:
{customer_query}

Current Customer Profile:
- Gender: {customer_profile.get('gender', 'unknown')}
- Sentiment Score: {customer_profile.get('sentiment_score', 50)}/100
- Communication Style: {customer_profile.get('communication_style', 'unknown')}
- Urgency: {customer_profile.get('urgency_level', 'medium')}
- Predicted Type: {customer_profile.get('predicted_customer_type', 'normal')}

Similar Past Cases (Successful Resolutions):
{past_cases_text}

Provide a concise guideline in {lang_name} that:
1. Identifies what worked well in similar past cases
2. Suggests specific approaches based on successful patterns
3. Warns about potential pitfalls based on past experiences
4. Recommends response strategies that led to high customer satisfaction

Guideline (in {lang_name}):
def _generate_initial_advice(customer_query, customer_type_display, customer_email, customer_phone, current_lang_key,
                             customer_attachment_file):
    """Supervisor ê°€ì´ë“œë¼ì¸ê³¼ ì´ˆì•ˆì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ì €ì¥ëœ ë°ì´í„° í™œìš©)"""
    # ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ìë™ ê°ì§€ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
    try:
        detected_lang = detect_text_language(customer_query)
    except Exception as e:
        print(f"Language detection failed in _generate_initial_advice: {e}")
        detected_lang = current_lang_key if current_lang_key else "ko"
    
    # ê°ì§€ëœ ì–¸ì–´ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ë˜, current_lang_keyê°€ ëª…ì‹œì ìœ¼ë¡œ ì œê³µë˜ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
    lang_key_to_use = detected_lang if detected_lang else current_lang_key
    # lang_key_to_useê°€ ìœ íš¨í•œì§€ í™•ì¸
    if lang_key_to_use not in ["ko", "en", "ja"]:
        lang_key_to_use = current_lang_key if current_lang_key else "ko"
    
    # ì–¸ì–´ í‚¤ ê²€ì¦
    if lang_key_to_use not in ["ko", "en", "ja"]:
        lang_key_to_use = st.session_state.get("language", "ko")
        if lang_key_to_use not in ["ko", "en", "ja"]:
            lang_key_to_use = "ko"
    L = LANG.get(lang_key_to_use, LANG["ko"])
    lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}[lang_key_to_use]

    contact_info_block = ""
    if customer_email or customer_phone:
        contact_info_block = (
            f"\n\n[Customer contact info for reference (DO NOT use these in your reply draft!)]"
            f"\n- Email: {customer_email or 'N/A'}"
            f"\n- Phone: {customer_phone or 'N/A'}"
        )

    attachment_block = ""
    if customer_attachment_file:
        file_name = customer_attachment_file.name
        attachment_block = f"\n\n[ATTACHMENT NOTE]: {L['attachment_info_llm'].format(filename=file_name)}"

    # ê³ ê° í”„ë¡œí•„ ë¶„ì„ (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
    customer_profile = analyze_customer_profile(customer_query, lang_key_to_use)

    # ìœ ì‚¬ ì¼€ì´ìŠ¤ ì°¾ê¸° (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
    similar_cases = find_similar_cases(customer_query, customer_profile, lang_key_to_use, limit=5)

    # ê³¼ê±° ì¼€ì´ìŠ¤ ê¸°ë°˜ ê°€ì´ë“œë¼ì¸ ìƒì„± (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
    past_cases_guideline = ""
    if similar_cases:
        past_cases_guideline = generate_guideline_from_past_cases(
            customer_query, customer_profile, similar_cases, lang_key_to_use
        )

    # ê³ ê° í”„ë¡œí•„ ì •ë³´
    gender_display = customer_profile.get('gender', 'unknown')
    profile_block = f"""
[Customer Profile Analysis]
- Gender: {gender_display}
- Sentiment Score: {customer_profile.get('sentiment_score', 50)}/100
- Communication Style: {customer_profile.get('communication_style', 'unknown')}
- Urgency Level: {customer_profile.get('urgency_level', 'medium')}
- Predicted Type: {customer_profile.get('predicted_customer_type', 'normal')}
- Key Concerns: {', '.join(customer_profile.get('key_concerns', []))}
- Tone: {customer_profile.get('tone_analysis', 'unknown')}
"""

    # ê³¼ê±° ì¼€ì´ìŠ¤ ê¸°ë°˜ ê°€ì´ë“œë¼ì¸ ë¸”ë¡
    past_cases_block = ""
    if past_cases_guideline:
        past_cases_block = f"""
[Guidelines Based on {len(similar_cases)} Similar Past Cases]
{past_cases_guideline}
"""
    elif similar_cases:
        past_cases_block = f"""
[Note: Found {len(similar_cases)} similar past cases, but unable to generate detailed guidelines.
Consider reviewing past cases manually for patterns.]
"""

    # Output ALL text (guidelines and draft) STRICTLY in {lang_name}. <--- ê°•ë ¥í•œ ì–¸ì–´ ê°•ì œ ì§€ì‹œ
    initial_prompt = f"""
Output ALL text (guidelines and draft) STRICTLY in {lang_name}.

You are an AI Customer Support Supervisor. Your role is to analyze the following customer inquiry
from a **{st.session_state.customer_type_sim_select}** and provide:

1) A detailed **response guideline for the human agent** (step-by-step).
2) A **ready-to-send draft reply** in {lang_name}.

[FORMAT]
- Use the exact markdown headers:
  - "### {L['simulation_advice_header']}"
  - "### {L['simulation_draft_header']}"

[CRITICAL GUIDELINE RULES]
1. **Initial Information Collection (Req 3):** The first step in the guideline MUST be to request the necessary initial diagnostic information (e.g., device compatibility, local status/location, order number) BEFORE attempting to troubleshoot or solve the problem.
2. **Empathy for Difficult Customers (Req 5):** If the customer type is 'Difficult Customer' or 'Highly Dissatisfied Customer', the guideline MUST emphasize extreme politeness, empathy, and apologies, even if the policy (e.g., no refund) must be enforced.
3. **24-48 Hour Follow-up (Req 6):** If the issue cannot be solved immediately or requires confirmation from a local partner/supervisor, the guideline MUST state the procedure:
   - Acknowledge the issue.
   - Inform the customer they will receive a definite answer within 24 or 48 hours.
   - Request the customer's email or phone number for follow-up contact. (Use provided contact info if available)
4. **Past Cases Learning:** If past cases guidelines are provided, incorporate successful strategies from those cases into your recommendations.

Customer Inquiry:
{customer_query}
{contact_info_block}
{attachment_block}
{profile_block}
{past_cases_block}
# ========================================
# 9. ì‚¬ì´ë“œë°”
# ========================================

with st.sidebar:
    # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
    if "language" not in st.session_state:
        st.session_state.language = "ko"
    current_lang = st.session_state.get("language", "ko")
    if current_lang not in ["ko", "en", "ja"]:
        current_lang = "ko"
    L = LANG.get(current_lang, LANG["ko"])
    
    # íšŒì‚¬ ëª©ë¡ ì´ˆê¸°í™” (íšŒì‚¬ ì •ë³´ íƒ­ì—ì„œ ì‚¬ìš©)
    if "company_language_priority" not in st.session_state:
        st.session_state.company_language_priority = {
            "default": ["ko", "en", "ja"],
            "companies": {}
        }
    
    st.markdown("---")
    
    # ì–¸ì–´ ì„ íƒ
    if "language" not in st.session_state:
        st.session_state.language = "ko"
    current_lang = st.session_state.get("language", "ko")
    if current_lang not in ["ko", "en", "ja"]:
        current_lang = "ko"
    L = LANG.get(current_lang, LANG["ko"])
    
    lang_priority = st.session_state.company_language_priority["default"]
    
    selected_lang_key = st.selectbox(
        L["lang_select"],
        options=lang_priority,
        index=lang_priority.index(st.session_state.language) if st.session_state.language in lang_priority else 0,
        format_func=lambda x: {"ko": "í•œêµ­ì–´", "en": "English", "ja": "æ—¥æœ¬èª"}[x],
    )

    # ğŸ”¹ ì–¸ì–´ ë³€ê²½ ê°ì§€
    if selected_lang_key != st.session_state.language:
        st.session_state.language = selected_lang_key
        # ì±„íŒ…/ì „í™” ê³µí†µ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.simulator_messages = []
        # â­ ì•ˆì „í•œ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        try:
            if hasattr(st.session_state, 'simulator_memory') and st.session_state.simulator_memory is not None:
                st.session_state.simulator_memory.clear()
        except Exception:
            # ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ìƒˆë¡œ ìƒì„±
            try:
                st.session_state.simulator_memory = ConversationBufferMemory(memory_key="chat_history")
            except Exception:
                pass  # ì´ˆê¸°í™” ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        st.session_state.initial_advice_provided = False
        st.session_state.is_chat_ended = False
        # â­ ìˆ˜ì •: ìœ„ì ¯ì´ ìƒì„±ëœ í›„ì—ëŠ” session_stateë¥¼ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ í”Œë˜ê·¸ ì‚¬ìš©
        st.session_state.reset_agent_response_area = True
        st.session_state.customer_query_text_area = ""
        st.session_state.last_transcript = ""
        st.session_state.sim_audio_bytes = None
        st.session_state.sim_stage = "WAIT_FIRST_QUERY"
        st.session_state.customer_attachment_file = []  # ì–¸ì–´ ë³€ê²½ ì‹œ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
        st.session_state.sim_attachment_context_for_llm = ""  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        st.session_state.agent_attachment_file = []  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
        # ì „í™” ì‹œë®¬ë ˆì´í„° ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.call_sim_stage = "WAITING_CALL"
        st.session_state.call_sim_mode = "INBOUND"
        st.session_state.is_on_hold = False
        st.session_state.total_hold_duration = timedelta(0)
        st.session_state.hold_start_time = None
        st.session_state.current_customer_audio_text = ""
        st.session_state.current_agent_audio_text = ""
        st.session_state.agent_response_input_box_widget_call = ""
        st.session_state.call_initial_query = ""
        # ì „í™” ë°œì‹  ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.sim_call_outbound_summary = ""
        st.session_state.sim_call_outbound_target = None
        # â­ ì–¸ì–´ ë³€ê²½ ì‹œ ì¬ì‹¤í–‰ - ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ í”Œë˜ê·¸ ì‚¬ìš©
        if "language_changed" not in st.session_state or not st.session_state.language_changed:
            st.session_state.language_changed = True
        else:
            # ì´ë¯¸ í•œ ë²ˆ ì¬ì‹¤í–‰í–ˆìœ¼ë©´ í”Œë˜ê·¸ ì´ˆê¸°í™”
            st.session_state.language_changed = False

    # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
    current_lang = st.session_state.get("language", "ko")
    if current_lang not in ["ko", "en", "ja"]:
        current_lang = "ko"
    L = LANG.get(current_lang, LANG["ko"])

    st.title(L["sidebar_title"])
    st.markdown("---")

    # â­ API Key ì„¤ì • ì„¹ì…˜ ì¶”ê°€
    st.subheader("ğŸ”‘ API Key ì„¤ì •")
    
    # LLM ì„ íƒ
    llm_options = {
        "openai_gpt4": "OpenAI GPT-4",
        "openai_gpt35": "OpenAI GPT-3.5",
        "gemini_pro": "Google Gemini Pro",
        "gemini_flash": "Google Gemini Flash",
        "claude": "Anthropic Claude",
        "groq": "Groq",
        "nvidia": "NVIDIA NIM"
    }
    
    current_llm = st.session_state.get("selected_llm", "openai_gpt4")
    selected_llm = st.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ",
        options=list(llm_options.keys()),
        format_func=lambda x: llm_options[x],
        index=list(llm_options.keys()).index(current_llm) if current_llm in llm_options else 0,
        key="sidebar_llm_select"
    )
    if selected_llm != current_llm:
        st.session_state.selected_llm = selected_llm
    
    # API Key ë§¤í•‘
    api_key_map = {
        "openai_gpt4": "openai",
        "openai_gpt35": "openai",
        "gemini_pro": "gemini",
        "gemini_flash": "gemini",
        "claude": "claude",
        "groq": "groq",
        "nvidia": "nvidia"
    }
    
    api_name = api_key_map.get(selected_llm, "openai")
    api_config = SUPPORTED_APIS.get(api_name, {})
    
    if api_config:
        # í˜„ì¬ API Key í™•ì¸
        current_key = get_api_key(api_name)
        if not current_key:
            # ìˆ˜ë™ ì…ë ¥ í•„ë“œ
            session_key = api_config.get("session_key", "")
            manual_key = st.text_input(
                api_config.get("label", "API Key"),
                value=st.session_state.get(session_key, ""),
                type="password",
                placeholder=api_config.get("placeholder", "API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”"),
                key=f"manual_api_key_{selected_llm}"
            )
            if manual_key and manual_key != st.session_state.get(session_key, ""):
                st.session_state[session_key] = manual_key
        else:
            st.success(f"âœ… {api_config.get('label', 'API Key')} ì„¤ì •ë¨")
    
    st.markdown("---")

    # â­ ê¸°ëŠ¥ ì„ íƒ - ê¸°ë³¸ê°’ì„ AI ì±— ì‹œë®¬ë ˆì´í„°ë¡œ ì„¤ì •
    if "feature_selection" not in st.session_state:
        st.session_state.feature_selection = L["sim_tab_chat_email"]

    # â­ í•µì‹¬ ê¸°ëŠ¥ê³¼ ë”ë³´ê¸° ê¸°ëŠ¥ ë¶„ë¦¬ (íšŒì‚¬ ì •ë³´ ë° FAQ ì¶”ê°€)
    core_features = [L["sim_tab_chat_email"], L["sim_tab_phone"], L["company_info_tab"]]
    other_features = [L["rag_tab"], L["content_tab"], L["lstm_tab"], L["voice_rec_header"]]
    
    # ëª¨ë“  ê¸°ëŠ¥ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•© (í•˜ë‚˜ë§Œ ì„ íƒ ê°€ëŠ¥í•˜ë„ë¡)
    all_features = core_features + other_features
    
    # í˜„ì¬ ì„ íƒëœ ê¸°ëŠ¥
    current_selection = st.session_state.get("feature_selection", L["sim_tab_chat_email"])
    
    # í˜„ì¬ ì„ íƒì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
    try:
        current_index = all_features.index(current_selection) if current_selection in all_features else 0
    except (ValueError, AttributeError):
        current_index = 0
    
    # â­ í•˜ë‚˜ì˜ í†µí•©ëœ ì„ íƒ ë¡œì§ (í•˜ë‚˜ë§Œ ì„ íƒ ê°€ëŠ¥) - ì„¤ëª… ì œê±°
    selected_feature = st.radio(
        "ê¸°ëŠ¥ ì„ íƒ",
        all_features,
        index=current_index,
        key="unified_feature_selection",
        label_visibility="hidden"
    )
    
    # ì„ íƒëœ ê¸°ëŠ¥ ì—…ë°ì´íŠ¸
    if selected_feature != current_selection:
        st.session_state.feature_selection = selected_feature
    
    feature_selection = st.session_state.get("feature_selection", L["sim_tab_chat_email"])

# ë©”ì¸ íƒ€ì´í‹€
# â­ L ë³€ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì‚¬ì´ë“œë°”ì—ì„œ ì´ë¯¸ ì •ì˜ë¨)
if "language" not in st.session_state:
    st.session_state.language = "ko"
# ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
current_lang = st.session_state.get("language", "ko")
if current_lang not in ["ko", "en", "ja"]:
    current_lang = "ko"
L = LANG.get(current_lang, LANG["ko"])

# â­ íƒ€ì´í‹€ê³¼ ì„¤ëª…ì„ í•œ ì¤„ë¡œ ê°„ê²°í•˜ê²Œ í‘œì‹œ
feature_selection = st.session_state.get("feature_selection", L["sim_tab_chat_email"])
if feature_selection == L["sim_tab_chat_email"]:
    st.markdown(f"### ğŸ“§ {L['sim_tab_chat_email']}")
    st.caption(L['sim_tab_chat_email_desc'])
elif feature_selection == L["sim_tab_phone"]:
    st.markdown(f"### ğŸ“ {L['sim_tab_phone']}")
    st.caption(L['sim_tab_phone_desc'])
elif feature_selection == L["rag_tab"]:
    st.markdown(f"### ğŸ“š {L['rag_tab']}")
    st.caption(L['rag_tab_desc'])
elif feature_selection == L["content_tab"]:
    st.markdown(f"### ğŸ“ {L['content_tab']}")
    st.caption(L['content_tab_desc'])
elif feature_selection == L["lstm_tab"]:
    st.markdown(f"### ğŸ“Š {L['lstm_tab']}")
    st.caption(L['lstm_tab_desc'])
elif feature_selection == L["voice_rec_header"]:
    st.markdown(f"### ğŸ¤ {L['voice_rec_header']}")
    st.caption(L['voice_rec_header_desc'])
elif feature_selection == L["company_info_tab"]:
    # ê³µë°± ì¶•ì†Œ: ì œëª©ê³¼ ì„¤ëª…ì„ í•œ ì¤„ë¡œ ê°„ê²°í•˜ê²Œ í‘œì‹œ
    st.markdown(f"#### ğŸ“‹ {L['company_info_tab']}")
    st.caption(L['company_info_tab_desc'])

# ========================================
# 10. ê¸°ëŠ¥ë³„ í˜ì´ì§€
# ========================================

# -------------------- Company Info & FAQ Tab --------------------
if feature_selection == L["company_info_tab"]:
    current_lang = st.session_state.get("language", "ko")
    if current_lang not in ["ko", "en", "ja"]:
        current_lang = "ko"
    L = LANG.get(current_lang, LANG["ko"])
    
    # FAQ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
    faq_data = load_faq_database()
    companies = list(faq_data.get("companies", {}).keys())
    
    # íšŒì‚¬ëª… ê²€ìƒ‰ ì…ë ¥ (ìƒë‹¨ì— ë°°ì¹˜) - ì…ë ¥ë€ì€ ê¸€ë¡œë²Œ ê¸°ì—… ì˜ë¬¸ëª… ê³ ë ¤í•˜ì—¬ ì›ë˜ í¬ê¸° ìœ ì§€
    col_search_header, col_search_input, col_search_btn = st.columns([0.5, 1.2, 0.2])
    with col_search_header:
        st.write(f"**{L['search_company']}**")
    with col_search_input:
        company_search_input = st.text_input(
            "",
            placeholder=L["company_search_placeholder"],
            key="company_search_input",
            value=st.session_state.get("searched_company", ""),
            label_visibility="collapsed"
        )
    with col_search_btn:
        search_button = st.button(f"ğŸ” {L['company_search_button']}", key="company_search_btn", type="primary", use_container_width=True)
    
    # ê²€ìƒ‰ëœ íšŒì‚¬ ì •ë³´ ì €ì¥
    searched_company = st.session_state.get("searched_company", "")
    searched_company_data = st.session_state.get("searched_company_data", None)
    
    # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì‹œ LLMìœ¼ë¡œ íšŒì‚¬ ì •ë³´ ìƒì„±
    if search_button and company_search_input:
        with st.spinner(f"{company_search_input} {L['generating_company_info']}"):
            generated_data = generate_company_info_with_llm(company_search_input, current_lang)
            st.session_state.searched_company = company_search_input
            st.session_state.searched_company_data = generated_data
            searched_company = company_search_input
            searched_company_data = generated_data
            
            # ìƒì„±ëœ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            if company_search_input not in faq_data.get("companies", {}):
                faq_data.setdefault("companies", {})[company_search_input] = {
                    f"info_{current_lang}": generated_data.get("company_info", ""),
                    "info_ko": generated_data.get("company_info", ""),
                    "info_en": "",
                    "info_ja": "",
                    "popular_products": generated_data.get("popular_products", []),
                    "trending_topics": generated_data.get("trending_topics", []),
                    "faqs": generated_data.get("faqs", []),
                    "interview_questions": generated_data.get("interview_questions", []),
                    "ceo_info": generated_data.get("ceo_info", {})
                }
                save_faq_database(faq_data)
    
    # ê²€ìƒ‰ëœ íšŒì‚¬ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë°ì´í„° ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ íšŒì‚¬ ì„ íƒ
    if searched_company and searched_company_data:
        display_company = searched_company
        display_data = searched_company_data
        # ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥ë˜ì–´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
        if display_company in faq_data.get("companies", {}):
            faq_data["companies"][display_company].update({
                f"info_{current_lang}": display_data.get("company_info", ""),
                "popular_products": display_data.get("popular_products", []),
                "trending_topics": display_data.get("trending_topics", []),
                "faqs": display_data.get("faqs", []),
                "interview_questions": display_data.get("interview_questions", []),
                "ceo_info": display_data.get("ceo_info", {})
            })
            save_faq_database(faq_data)
    elif companies:
        display_company = st.selectbox(
            L["select_company"],
            options=companies,
            key="company_select_display"
        )
        company_db_data = faq_data["companies"][display_company]
        display_data = {
            "company_info": company_db_data.get(f"info_{current_lang}", company_db_data.get("info_ko", "")),
            "popular_products": company_db_data.get("popular_products", []),
            "trending_topics": company_db_data.get("trending_topics", []),
            "faqs": company_db_data.get("faqs", []),
            "interview_questions": company_db_data.get("interview_questions", []),
            "ceo_info": company_db_data.get("ceo_info", {})
        }
    else:
        display_company = None
        display_data = None
    
    # íƒ­ ìƒì„± (FAQ ê²€ìƒ‰ íƒ­ ì œê±°, FAQ íƒ­ì— í†µí•©) - ê³µë°± ì¶•ì†Œ
    tab1, tab2, tab3 = st.tabs([
        L["company_info"], 
        L["company_faq"], 
        L["button_add_company"]
    ])
    
    # íƒ­ 1: íšŒì‚¬ ì†Œê°œ ë° ì‹œê°í™”
    with tab1:
        if display_company and display_data:
            # ì œëª©ì„ ë” ê°„ê²°í•˜ê²Œ í‘œì‹œ
            st.markdown(f"#### {display_company} - {L['company_info']}")
            
            # íšŒì‚¬ ì†Œê°œ í‘œì‹œ
            if display_data.get("company_info"):
                st.markdown(display_data["company_info"])
            
            # ì‹œê°í™” ì°¨íŠ¸ í‘œì‹œ
            if display_data.get("popular_products") or display_data.get("trending_topics"):
                charts = visualize_company_data(
                    {
                        "popular_products": display_data.get("popular_products", []),
                        "trending_topics": display_data.get("trending_topics", [])
                    },
                    current_lang
                )
                
                if charts:
                    # ë§‰ëŒ€ ê·¸ë˜í”„ í‘œì‹œ - ê³µë°± ì¶•ì†Œ
                    st.markdown(f"#### ğŸ“Š {L['visualization_chart']}")
                    col1_bar, col2_bar = st.columns(2)
                    
                    if "products_bar" in charts:
                        with col1_bar:
                            st.plotly_chart(charts["products_bar"], use_container_width=True)
                    
                    if "topics_bar" in charts:
                        with col2_bar:
                            st.plotly_chart(charts["topics_bar"], use_container_width=True)
                    
                    # ì„ í˜• ê·¸ë˜í”„ í‘œì‹œ
                    col1_line, col2_line = st.columns(2)
                    
                    if "products_line" in charts:
                        with col1_line:
                            st.plotly_chart(charts["products_line"], use_container_width=True)
                    
                    if "topics_line" in charts:
                        with col2_line:
                            st.plotly_chart(charts["topics_line"], use_container_width=True)
            
            # ì¸ê¸° ìƒí’ˆ ëª©ë¡ (ì´ë¯¸ì§€ í¬í•¨) - ê³µë°± ì¶•ì†Œ
            if display_data.get("popular_products"):
                st.markdown(f"#### {L['popular_products']}")
                # ìƒí’ˆì„ ê·¸ë¦¬ë“œ í˜•íƒœë¡œ í‘œì‹œ
                product_cols = st.columns(min(3, len(display_data["popular_products"])))
                for idx, product in enumerate(display_data["popular_products"]):
                    product_text = product.get(f"text_{current_lang}", product.get("text_ko", ""))
                    product_score = product.get("score", 0)
                    product_image_url = product.get("image_url", "")
                    
                    with product_cols[idx % len(product_cols)]:
                        # ì´ë¯¸ì§€ í‘œì‹œ - ìƒí’ˆëª… ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì´ë¯¸ì§€ ê²€ìƒ‰
                        if not product_image_url:
                            # ëª¨ë“  ì–¸ì–´ ë²„ì „ì˜ ìƒí’ˆëª…ì„ í™•ì¸í•˜ì—¬ ì´ë¯¸ì§€ URL ìƒì„±
                            # ìš°ì„ ìˆœìœ„: í˜„ì¬ ì–¸ì–´ > í•œêµ­ì–´ > ì˜ì–´ > ì¼ë³¸ì–´
                            image_found = False
                            for lang_key in [current_lang, "ko", "en", "ja"]:
                                check_text = product.get(f"text_{lang_key}", "")
                                if check_text:
                                    check_url = get_product_image_url(check_text)
                                    if check_url:
                                        product_image_url = check_url
                                        image_found = True
                                        break
                            
                            # ëª¨ë“  ì–¸ì–´ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                            if not image_found:
                                product_image_url = get_product_image_url(product_text)
                        
                        # ì´ë¯¸ì§€ í‘œì‹œ ì‹œë„ (ë¡œì»¬ íŒŒì¼ ë° URL ëª¨ë‘ ì§€ì›)
                        image_displayed = False
                        if product_image_url:
                            try:
                                # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                                if os.path.exists(product_image_url):
                                    st.image(product_image_url, caption=product_text[:30], use_container_width=True)
                                    image_displayed = True
                                # URLì¸ ê²½ìš°
                                elif product_image_url.startswith("http://") or product_image_url.startswith("https://"):
                                    try:
                                        # HEAD ìš”ì²­ìœ¼ë¡œ ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (íƒ€ì„ì•„ì›ƒ 2ì´ˆ)
                                        response = requests.head(product_image_url, timeout=2, allow_redirects=True)
                                        if response.status_code == 200:
                                            st.image(product_image_url, caption=product_text[:30], use_container_width=True)
                                            image_displayed = True
                                        else:
                                            image_displayed = False
                                    except Exception:
                                        # HEAD ìš”ì²­ ì‹¤íŒ¨ ì‹œì—ë„ ì´ë¯¸ì§€ í‘œì‹œ ì‹œë„ (ì¼ë¶€ ì„œë²„ëŠ” HEADë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ)
                                        try:
                                            st.image(product_image_url, caption=product_text[:30], use_container_width=True)
                                            image_displayed = True
                                        except Exception:
                                            image_displayed = False
                                else:
                                    # ê¸°íƒ€ ê²½ë¡œ ì‹œë„
                                    try:
                                        st.image(product_image_url, caption=product_text[:30], use_container_width=True)
                                        image_displayed = True
                                    except Exception:
                                        image_displayed = False
                            except Exception as img_error:
                                # ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨
                                image_displayed = False
                        
                        # ì´ë¯¸ì§€ í‘œì‹œ ì‹¤íŒ¨ ì‹œ ì´ëª¨ì§€ ì¹´ë“œ í‘œì‹œ
                        if not image_displayed:
                            product_emoji = "ğŸ«" if "í‹°ì¼“" in product_text or "ticket" in product_text.lower() else \
                                          "ğŸ¢" if "í…Œë§ˆíŒŒí¬" in product_text or "theme" in product_text.lower() or "ë””ì¦ˆë‹ˆ" in product_text or "ìœ ë‹ˆë²„ì…œ" in product_text or "ìŠ¤íŠœë””ì˜¤" in product_text else \
                                          "âœˆï¸" if "í•­ê³µ" in product_text or "flight" in product_text.lower() else \
                                          "ğŸ¨" if "í˜¸í…”" in product_text or "hotel" in product_text.lower() else \
                                          "ğŸ”" if "ìŒì‹" in product_text or "food" in product_text.lower() else \
                                          "ğŸŒ" if "ì—¬í–‰" in product_text or "travel" in product_text.lower() or "ì‚¬íŒŒë¦¬" in product_text else \
                                          "ğŸ“¦"
                            st.markdown(
                                f"""
                                <div style='text-align: center; padding: 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                                border-radius: 10px; color: white; min-height: 200px; display: flex; flex-direction: column; justify-content: center;'>
                                    <h1 style='font-size: 64px; margin: 0;'>{product_emoji}</h1>
                                    <p style='font-size: 16px; margin-top: 15px; font-weight: bold;'>{product_text[:25]}</p>
                                </div>
                                """, 
                                unsafe_allow_html=True
                            )
                        
                        st.write(f"**{product_text}**")
                        st.caption(f"{L.get('popularity', 'ì¸ê¸°ë„')}: {product_score}")
                        st.markdown("---")
            
            # í™”ì œì˜ ì†Œì‹ ëª©ë¡ (ìƒì„¸ ë‚´ìš© í¬í•¨) - ê³µë°± ì¶•ì†Œ
            if display_data.get("trending_topics"):
                st.markdown(f"#### {L['trending_topics']}")
                for idx, topic in enumerate(display_data["trending_topics"], 1):
                    topic_text = topic.get(f"text_{current_lang}", topic.get("text_ko", ""))
                    topic_score = topic.get("score", 0)
                    topic_detail = topic.get(f"detail_{current_lang}", topic.get("detail_ko", ""))
                    
                    with st.expander(f"{idx}. **{topic_text}** ({L.get('trend_score', 'í™”ì œë„')}: {topic_score})"):
                        if topic_detail:
                            st.write(topic_detail)
                        else:
                            # ìƒì„¸ ë‚´ìš©ì´ ì—†ìœ¼ë©´ LLMìœ¼ë¡œ ìƒì„±
                            if display_company:
                                try:
                                    # ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸
                                    detail_prompts = {
                                        "ko": f"{display_company}ì˜ '{topic_text}'ì— ëŒ€í•œ ìƒì„¸ ë‚´ìš©ì„ 200ì ì´ìƒ ì‘ì„±í•´ì£¼ì„¸ìš”.",
                                        "en": f"Please write detailed content of at least 200 characters about '{topic_text}' from {display_company}.",
                                        "ja": f"{display_company}ã®ã€Œ{topic_text}ã€ã«é–¢ã™ã‚‹è©³ç´°å†…å®¹ã‚’200æ–‡å­—ä»¥ä¸Šã§ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                                    }
                                    detail_prompt = detail_prompts.get(current_lang, detail_prompts["ko"])
                                    generated_detail = run_llm(detail_prompt)
                                    if generated_detail and not generated_detail.startswith("âŒ"):
                                        st.write(generated_detail)
                                        # ìƒì„±ëœ ìƒì„¸ ë‚´ìš©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                                        if display_company in faq_data.get("companies", {}):
                                            topic_idx = idx - 1
                                            if topic_idx < len(faq_data["companies"][display_company].get("trending_topics", [])):
                                                faq_data["companies"][display_company]["trending_topics"][topic_idx][f"detail_{current_lang}"] = generated_detail
                                                save_faq_database(faq_data)
                                    else:
                                        st.write(L.get("generating_detail", "ìƒì„¸ ë‚´ìš©ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."))
                                except Exception as e:
                                    st.write(L.get("checking_additional_info", "ìƒì„¸ ë‚´ìš©: {topic}ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.").format(topic=topic_text))
                            else:
                                st.write(L.get("checking_additional_info", "ìƒì„¸ ë‚´ìš©: {topic}ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.").format(topic=topic_text))
            
            # CEO/ëŒ€í‘œì´ì‚¬ ì •ë³´ í‘œì‹œ
            if display_data.get("ceo_info"):
                ceo_info = display_data["ceo_info"]
                ceo_name = ceo_info.get(f"name_{current_lang}", ceo_info.get("name_ko", ""))
                ceo_position = ceo_info.get(f"position_{current_lang}", ceo_info.get("position_ko", ""))
                ceo_bio = ceo_info.get(f"bio_{current_lang}", ceo_info.get("bio_ko", ""))
                ceo_tenure = ceo_info.get(f"tenure_{current_lang}", ceo_info.get("tenure_ko", ""))
                ceo_education = ceo_info.get(f"education_{current_lang}", ceo_info.get("education_ko", ""))
                ceo_career = ceo_info.get(f"career_{current_lang}", ceo_info.get("career_ko", ""))
                
                if ceo_name or ceo_position:
                    st.markdown(f"#### ğŸ‘” {L.get('ceo_info', 'CEO/ëŒ€í‘œì´ì‚¬ ì •ë³´')}")
                    st.markdown("---")
                    
                    # CEO ì •ë³´ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
                    col_ceo_left, col_ceo_right = st.columns([1, 2])
                    
                    with col_ceo_left:
                        # CEO ì´ë¦„ê³¼ ì§ì±…
                        if ceo_name:
                            st.markdown(f"### {ceo_name}")
                        if ceo_position:
                            st.markdown(f"**{L.get('position', 'ì§ì±…')}:** {ceo_position}")
                        if ceo_tenure:
                            st.markdown(f"**{L.get('tenure', 'ì¬ì„ ê¸°ê°„')}:** {ceo_tenure}")
                    
                    with col_ceo_right:
                        # ìƒì„¸ ì†Œê°œ
                        if ceo_bio:
                            st.markdown(f"**{L.get('ceo_bio', 'ì†Œê°œ')}**")
                            st.markdown(ceo_bio)
                    
                    # í•™ë ¥ ë° ê²½ë ¥ ì •ë³´
                    if ceo_education or ceo_career:
                        st.markdown("---")
                        col_edu, col_career = st.columns(2)
                        
                        with col_edu:
                            if ceo_education:
                                st.markdown(f"**{L.get('education', 'í•™ë ¥')}**")
                                st.markdown(ceo_education)
                        
                        with col_career:
                            if ceo_career:
                                st.markdown(f"**{L.get('career', 'ì£¼ìš” ê²½ë ¥')}**")
                                st.markdown(ceo_career)
                    
                    st.markdown("---")
            
            # ë©´ì ‘ ì§ˆë¬¸ ëª©ë¡ í‘œì‹œ
            if display_data.get("interview_questions"):
                st.markdown(f"#### ğŸ’¼ {L.get('interview_questions', 'ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸')}")
                st.markdown(f"*{L.get('interview_questions_desc', 'ë©´ì ‘ì—ì„œ ë‚˜ì˜¬ ë§Œí•œ í•µì‹¬ ì§ˆë¬¸ë“¤ê³¼ ìƒì„¸í•œ ë‹µë³€ì…ë‹ˆë‹¤. ë©´ì ‘ ì¤€ë¹„ì™€ íšŒì‚¬ ì´í•´ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.')}*")
                st.markdown("---")
                
                # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
                interview_by_category = {}
                for idx, iq in enumerate(display_data["interview_questions"]):
                    question = iq.get(f"question_{current_lang}", iq.get("question_ko", ""))
                    answer = iq.get(f"answer_{current_lang}", iq.get("answer_ko", ""))
                    category = iq.get(f"category_{current_lang}", iq.get("category_ko", L.get("interview_category_other", "ê¸°íƒ€")))
                    
                    if category not in interview_by_category:
                        interview_by_category[category] = []
                    interview_by_category[category].append({
                        "question": question,
                        "answer": answer,
                        "index": idx + 1
                    })
                
                # ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‘œì‹œ
                for category, questions in interview_by_category.items():
                    with st.expander(f"ğŸ“‹ **{category}** ({len(questions)}{L.get('items', 'ê°œ')})"):
                        for item in questions:
                            st.markdown(f"**{item['index']}. {item['question']}**")
                            st.markdown(item['answer'])
                            st.markdown("---")
        else:
            st.info(L["company_search_or_select"])
    
    # íƒ­ 2: ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ) - ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨
    with tab2:
        if display_company and display_data:
            # ì œëª©ì„ ë” ê°„ê²°í•˜ê²Œ í‘œì‹œ
            st.markdown(f"#### {display_company} - {L['company_faq']}")
            
            # FAQ ê²€ìƒ‰ ê¸°ëŠ¥ (íƒ­ ë‚´ë¶€ì— í†µí•©) - ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€, ê³µë°± ì¶•ì†Œ
            col_search_faq, col_btn_faq = st.columns([3.5, 1])
            with col_search_faq:
                faq_search_query = st.text_input(
                    L["faq_search_placeholder"],
                    key="faq_search_in_tab",
                    placeholder=L.get("faq_search_placeholder_extended", L["faq_search_placeholder"])
                )
            with col_btn_faq:
                faq_search_btn = st.button(L["button_search_faq"], key="faq_search_btn_in_tab")
            
            faqs = display_data.get("faqs", [])
            popular_products = display_data.get("popular_products", [])
            trending_topics = display_data.get("trending_topics", [])
            company_info = display_data.get("company_info", "")
            
            # ê²€ìƒ‰ ê´€ë ¨ ë³€ìˆ˜ ì´ˆê¸°í™”
            matched_products = []
            matched_topics = []
            matched_info = False
            
            # ê²€ìƒ‰ì–´ê°€ ìˆìœ¼ë©´ í™•ì¥ëœ ê²€ìƒ‰ (FAQ, ìƒí’ˆ, í™”ì œ ì†Œì‹, íšŒì‚¬ ì†Œê°œ ëª¨ë‘ ê²€ìƒ‰)
            if faq_search_query and faq_search_btn:
                query_lower = faq_search_query.lower()
                filtered_faqs = []
                
                # 1. FAQ ê²€ìƒ‰ (ê¸°ë³¸ FAQ + ìƒí’ˆëª… ê´€ë ¨ FAQ)
                for faq in faqs:
                    question = faq.get(f"question_{current_lang}", faq.get("question_ko", ""))
                    answer = faq.get(f"answer_{current_lang}", faq.get("answer_ko", ""))
                    if query_lower in question.lower() or query_lower in answer.lower():
                        filtered_faqs.append(faq)
                
                # 2. ìƒí’ˆëª…ìœ¼ë¡œ FAQ ê²€ìƒ‰ (ìƒí’ˆëª…ì´ ê²€ìƒ‰ì–´ì™€ ì¼ì¹˜í•˜ê±°ë‚˜ í¬í•¨ë˜ëŠ” ê²½ìš°)
                # ê²€ìƒ‰ì–´ê°€ ìƒí’ˆëª…ì— í¬í•¨ë˜ë©´ í•´ë‹¹ ìƒí’ˆê³¼ ê´€ë ¨ëœ FAQë¥¼ ì°¾ì•„ì„œ í‘œì‹œ
                for product in popular_products:
                    product_text = product.get(f"text_{current_lang}", product.get("text_ko", ""))
                    product_text_lower = product_text.lower()
                    
                    # ê²€ìƒ‰ì–´ê°€ ìƒí’ˆëª…ì— í¬í•¨ë˜ëŠ” ê²½ìš°
                    if query_lower in product_text_lower:
                        # í•´ë‹¹ ìƒí’ˆëª…ì´ FAQ ì§ˆë¬¸/ë‹µë³€ì— í¬í•¨ëœ ê²½ìš° ì°¾ê¸°
                        product_related_faqs = []
                        for faq in faqs:
                            question = faq.get(f"question_{current_lang}", faq.get("question_ko", ""))
                            answer = faq.get(f"answer_{current_lang}", faq.get("answer_ko", ""))
                            # ìƒí’ˆëª…ì´ FAQì— ì–¸ê¸‰ë˜ì–´ ìˆìœ¼ë©´ ì¶”ê°€
                            if product_text_lower in question.lower() or product_text_lower in answer.lower():
                                if faq not in filtered_faqs:
                                    filtered_faqs.append(faq)
                                    product_related_faqs.append(faq)
                        
                        # ìƒí’ˆëª…ì´ ë§¤ì¹­ë˜ì—ˆì§€ë§Œ ê´€ë ¨ FAQê°€ ì—†ëŠ” ê²½ìš°, ìƒí’ˆ ì •ë³´ë§Œ í‘œì‹œ
                        if not product_related_faqs:
                            matched_products.append(product)
                
                # 2. ì¸ê¸° ìƒí’ˆ ê²€ìƒ‰
                for product in popular_products:
                    product_text = product.get(f"text_{current_lang}", product.get("text_ko", ""))
                    if query_lower in product_text.lower():
                        matched_products.append(product)
                
                # 3. í™”ì œì˜ ì†Œì‹ ê²€ìƒ‰
                for topic in trending_topics:
                    topic_text = topic.get(f"text_{current_lang}", topic.get("text_ko", ""))
                    if query_lower in topic_text.lower():
                        matched_topics.append(topic)
                
                # 4. íšŒì‚¬ ì†Œê°œ ê²€ìƒ‰
                if query_lower in company_info.lower():
                    matched_info = True
                
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                if filtered_faqs or matched_products or matched_topics or matched_info:
                    # ë§¤ì¹­ëœ ìƒí’ˆ í‘œì‹œ (FAQê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ)
                    if matched_products and not filtered_faqs:
                        st.subheader(f"ğŸ” {L.get('related_products', 'ê´€ë ¨ ìƒí’ˆ')} ({len(matched_products)}{L.get('items', 'ê°œ')})")
                        st.info(L.get("no_faq_for_product", "í•´ë‹¹ ìƒí’ˆê³¼ ê´€ë ¨ëœ FAQë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒí’ˆ ì •ë³´ë§Œ í‘œì‹œë©ë‹ˆë‹¤."))
                        for idx, product in enumerate(matched_products, 1):
                            product_text = product.get(f"text_{current_lang}", product.get("text_ko", ""))
                            product_score = product.get("score", 0)
                            st.write(f"â€¢ **{product_text}** ({L.get('popularity', 'ì¸ê¸°ë„')}: {product_score})")
                        st.markdown("---")
                    
                    # ë§¤ì¹­ëœ í™”ì œ ì†Œì‹ í‘œì‹œ
                    if matched_topics:
                        st.subheader(f"ğŸ” {L.get('related_trending_news', 'ê´€ë ¨ í™”ì œ ì†Œì‹')} ({len(matched_topics)}{L.get('items', 'ê°œ')})")
                        for idx, topic in enumerate(matched_topics, 1):
                            topic_text = topic.get(f"text_{current_lang}", topic.get("text_ko", ""))
                            topic_score = topic.get("score", 0)
                            st.write(f"â€¢ **{topic_text}** ({L.get('trend_score', 'í™”ì œë„')}: {topic_score})")
                        st.markdown("---")
                    
                    # ë§¤ì¹­ëœ íšŒì‚¬ ì†Œê°œ í‘œì‹œ
                    if matched_info:
                        st.subheader(f"ğŸ” {L.get('related_company_info', 'ê´€ë ¨ íšŒì‚¬ ì†Œê°œ ë‚´ìš©')}")
                        # ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ë¶€ë¶„ ê°•ì¡°í•˜ì—¬ í‘œì‹œ
                        info_lower = company_info.lower()
                        query_pos = info_lower.find(query_lower)
                        if query_pos != -1:
                            start = max(0, query_pos - 100)
                            end = min(len(company_info), query_pos + len(query_lower) + 100)
                            snippet = company_info[start:end]
                            if start > 0:
                                snippet = "..." + snippet
                            if end < len(company_info):
                                snippet = snippet + "..."
                            # ê²€ìƒ‰ì–´ ê°•ì¡°
                            highlighted = snippet.replace(
                                query_lower, 
                                f"**{query_lower}**"
                            )
                            st.write(highlighted)
                        st.markdown("---")
                    
                    # FAQ ê²°ê³¼
                    faqs = filtered_faqs
                else:
                    faqs = []
            
            # FAQ ëª©ë¡ í‘œì‹œ
            if faqs:
                if faq_search_query and faq_search_btn:
                    st.subheader(f"ğŸ” {L.get('related_faq', 'ê´€ë ¨ FAQ')} ({len(faqs)}{L.get('items', 'ê°œ')})")
                else:
                    st.subheader(f"{L['company_faq']} ({len(faqs)}{L.get('items', 'ê°œ')})")
                for idx, faq in enumerate(faqs, 1):
                    question = faq.get(f"question_{current_lang}", faq.get("question_ko", ""))
                    answer = faq.get(f"answer_{current_lang}", faq.get("answer_ko", ""))
                    with st.expander(f"{L['faq_question_prefix'].format(num=idx)} {question}"):
                        st.write(f"**{L['faq_answer']}:** {answer}")
            else:
                if faq_search_query and faq_search_btn:
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œë§Œ ë©”ì‹œì§€ í‘œì‹œ (ìœ„ì—ì„œ ì´ë¯¸ ê´€ë ¨ ìƒí’ˆ/ì†Œì‹ ë“±ì´ í‘œì‹œë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
                    if not (matched_products or matched_topics or matched_info):
                        st.info(L["no_faq_results"])
                else:
                    st.info(L.get("no_faq_for_company", f"{display_company}ì˜ FAQê°€ ì—†ìŠµë‹ˆë‹¤.").format(company=display_company))
        else:
            st.info(L.get("no_company_selected", "íšŒì‚¬ëª…ì„ ê²€ìƒ‰í•˜ê±°ë‚˜ ì„ íƒí•´ì£¼ì„¸ìš”."))
    
    # íƒ­ 3: ê³ ê° ë¬¸ì˜ ì¬í™•ì¸ (ì—ì´ì „íŠ¸ìš©)
    with tab3:
        # ì œëª©ê³¼ ì„¤ëª…ì„ í•œ ì¤„ë¡œ ê°„ê²°í•˜ê²Œ í‘œì‹œ
        st.markdown(f"#### {L['customer_inquiry_review']}")
        st.caption(L.get("customer_inquiry_review_desc", "ì—ì´ì „íŠ¸ê°€ ìƒì‚¬ë“¤ì—ê²Œ ê³ ê° ë¬¸ì˜ ë‚´ìš©ì„ ì¬í™•ì¸í•˜ê³ , AI ë‹µì•ˆ ë° íŒíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤."))
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "generated_ai_answer" not in st.session_state:
            st.session_state.generated_ai_answer = None
        if "generated_hint" not in st.session_state:
            st.session_state.generated_hint = None
        
        # íšŒì‚¬ ì„ íƒ (ì„ íƒì‚¬í•­)
        selected_company_for_inquiry = None
        if companies:
            all_option = L.get("all_companies", "ì „ì²´")
            selected_company_for_inquiry = st.selectbox(
                f"{L['select_company']} ({L.get('optional', 'ì„ íƒì‚¬í•­')})",
                options=[all_option] + companies,
                key="inquiry_company_select"
            )
            if selected_company_for_inquiry == all_option:
                selected_company_for_inquiry = None
        
        # ê³ ê° ë¬¸ì˜ ë‚´ìš© ì…ë ¥
        customer_inquiry = st.text_area(
            L["inquiry_question_label"],
            placeholder=L["inquiry_question_placeholder"],
            key="customer_inquiry_input",
            height=150
        )
        
        # ê³ ê° ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            L.get("inquiry_attachment_label", "ğŸ“ ê³ ê° ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë“œ (ì‚¬ì§„/ìŠ¤í¬ë¦°ìƒ·)"),
            type=["png", "jpg", "jpeg", "pdf"],
            key="customer_inquiry_attachment",
            help=L.get("inquiry_attachment_help", "íŠ¹íˆ ì·¨ì†Œ ë¶ˆê°€ ì—¬í–‰ìƒí’ˆì˜ ë¹„í–‰ê¸° ì§€ì—°, ì—¬ê¶Œ ì´ìŠˆ ë“± ë¶ˆê°€í”¼í•œ ì‚¬ìœ ì˜ ê²½ìš°, ë°˜ë“œì‹œ ì‚¬ì§„ì´ë‚˜ ìŠ¤í¬ë¦°ìƒ·ì„ ì²¨ë¶€í•´ì£¼ì„¸ìš”.")
        )
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ ì €ì¥
        attachment_info = ""
        uploaded_file_info = None
        file_content_extracted = ""
        file_content_translated = ""
        
        if uploaded_file is not None:
            file_name = uploaded_file.name
            file_type = uploaded_file.type
            file_size = len(uploaded_file.getvalue())
            st.success(L.get("inquiry_attachment_uploaded", "âœ… ì²¨ë¶€ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {filename}").format(filename=file_name))
            
            # íŒŒì¼ ì •ë³´ ì €ì¥
            uploaded_file_info = {
                "name": file_name,
                "type": file_type,
                "size": file_size
            }
            
            # íŒŒì¼ ë‚´ìš© ì¶”ì¶œ (PDF, TXT, ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°)
            if file_name.lower().endswith(('.pdf', '.txt', '.png', '.jpg', '.jpeg')):
                try:
                    with st.spinner(L.get("extracting_file_content", "íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘...")):
                        if file_name.lower().endswith('.pdf'):
                            import tempfile
                            import os
                            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
                            tmp.write(uploaded_file.getvalue())
                            tmp.flush()
                            tmp.close()
                            try:
                                loader = PyPDFLoader(tmp.name)
                                file_docs = loader.load()
                                file_content_extracted = "\n".join([doc.page_content for doc in file_docs])
                            finally:
                                try:
                                    os.remove(tmp.name)
                                except:
                                    pass
                        elif file_name.lower().endswith('.txt'):
                            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ë™
                            file_content_extracted = uploaded_file.read().decode("utf-8", errors="ignore")
                        elif file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                            # ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ìš° OCRì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                            uploaded_file.seek(0)
                            image_bytes = uploaded_file.getvalue()
                            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                            
                            # Gemini Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                            ocr_prompt = """ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”. 
ì´ë¯¸ì§€ì— í•œêµ­ì–´, ì¼ë³¸ì–´, ì˜ì–´ ë“± ì–´ë–¤ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸ê°€ ìˆë“  ëª¨ë‘ ì¶”ì¶œí•˜ê³ , 
í…ìŠ¤íŠ¸ì˜ êµ¬ì¡°ì™€ ìˆœì„œë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”. 
ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ "í…ìŠ¤íŠ¸ ì—†ìŒ"ì´ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

ì¶”ì¶œëœ í…ìŠ¤íŠ¸:"""
                            
                            try:
                                # Gemini Vision API í˜¸ì¶œ
                                gemini_key = get_api_key("gemini")
                                if gemini_key:
                                    import google.generativeai as genai
                                    genai.configure(api_key=gemini_key)
                                    model = genai.GenerativeModel('gemini-2.0-flash-exp')
                                    
                                    # ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ë¥¼ í•¨ê»˜ ì „ì†¡
                                    response = model.generate_content([
                                        {
                                            "mime_type": file_type,
                                            "data": image_bytes
                                        },
                                        ocr_prompt
                                    ])
                                    file_content_extracted = response.text if response.text else ""
                                else:
                                    # Gemini í‚¤ê°€ ì—†ìœ¼ë©´ LLMì— base64 ì´ë¯¸ì§€ë¥¼ ì „ì†¡í•˜ì—¬ OCR ìš”ì²­
                                    ocr_llm_prompt = f"""{ocr_prompt}

ì´ë¯¸ì§€ëŠ” base64ë¡œ ì¸ì½”ë”©ë˜ì–´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""
                                    # LLMì´ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì²˜ë¦¬í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´
                                    file_content_extracted = ""
                                    st.info(L.get("ocr_requires_manual", "ì´ë¯¸ì§€ OCRì„ ìœ„í•´ì„œëŠ” Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."))
                            except Exception as ocr_error:
                                error_msg = L.get("ocr_error", "ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {error}")
                                st.warning(error_msg.format(error=str(ocr_error)))
                                file_content_extracted = ""
                        
                        # íŒŒì¼ ë‚´ìš©ì´ ì¶”ì¶œëœ ê²½ìš° ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­ (ì¼ë³¸ì–´/ì˜ì–´ ë²„ì „ì—ì„œ í•œêµ­ì–´ íŒŒì¼ ë²ˆì—­)
                        if file_content_extracted and current_lang in ["ja", "en"]:
                            # í•œêµ­ì–´ ë‚´ìš©ì¸ì§€ í™•ì¸í•˜ê³  ë²ˆì—­
                            with st.spinner(L.get("detecting_language", "ì–¸ì–´ ê°ì§€ ì¤‘...")):
                                # ì–¸ì–´ ê°ì§€ í”„ë¡¬í”„íŠ¸ (í˜„ì¬ ì–¸ì–´ì— ë§ì¶¤)
                                detect_prompts = {
                                    "ja": f"""æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªã‚’æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚éŸ“å›½èªã€æ—¥æœ¬èªã€è‹±èªã®ã„ãšã‚Œã‹ã§ç­”ãˆã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{file_content_extracted[:500]}

è¨€èª:""",
                                    "en": f"""Detect the language of the following text. Answer with only one of: Korean, Japanese, or English.

Text:
{file_content_extracted[:500]}

Language:""",
                                    "ko": f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•´ì£¼ì„¸ìš”. í•œêµ­ì–´, ì¼ë³¸ì–´, ì˜ì–´ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸:
{file_content_extracted[:500]}

ì–¸ì–´:"""
                                }
                                detect_prompt = detect_prompts.get(current_lang, detect_prompts["ko"])
                                detected_lang = run_llm(detect_prompt).strip().lower()
                                
                                # í•œêµ­ì–´ë¡œ ê°ì§€ëœ ê²½ìš° í˜„ì¬ ì–¸ì–´ë¡œ ë²ˆì—­
                                if "í•œêµ­ì–´" in detected_lang or "korean" in detected_lang or "ko" in detected_lang:
                                    with st.spinner(L.get("translating_content", "íŒŒì¼ ë‚´ìš© ë²ˆì—­ ì¤‘...")):
                                        # ë²ˆì—­ í”„ë¡¬í”„íŠ¸ (í˜„ì¬ ì–¸ì–´ì— ë§ì¶¤)
                                        translate_prompts = {
                                            "ja": f"""æ¬¡ã®éŸ“å›½èªãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚åŸæ–‡ã®æ„å‘³ã¨ãƒˆãƒ¼ãƒ³ã‚’æ­£ç¢ºã«ç¶­æŒã—ãªãŒã‚‰ã€è‡ªç„¶ãªæ—¥æœ¬èªã§ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

éŸ“å›½èªãƒ†ã‚­ã‚¹ãƒˆ:
{file_content_extracted}

æ—¥æœ¬èªç¿»è¨³:""",
                                            "en": f"""Please translate the following Korean text into English. Maintain the exact meaning and tone of the original text while translating into natural English.

Korean text:
{file_content_extracted}

English translation:"""
                                        }
                                        translate_prompt = translate_prompts.get(current_lang)
                                        if translate_prompt:
                                            file_content_translated = run_llm(translate_prompt)
                                            if file_content_translated and not file_content_translated.startswith("âŒ"):
                                                st.info(L.get("file_translated", "âœ… íŒŒì¼ ë‚´ìš©ì´ ë²ˆì—­ë˜ì—ˆìŠµë‹ˆë‹¤."))
                                            else:
                                                file_content_translated = ""
                except Exception as e:
                    error_msg = L.get("file_extraction_error", "íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}")
                    st.warning(error_msg.format(error=str(e)))
            
            # ì–¸ì–´ë³„ íŒŒì¼ ì •ë³´ í…ìŠ¤íŠ¸ ìƒì„±
            file_content_to_include = file_content_translated if file_content_translated else file_content_extracted
            content_section = ""
            if file_content_to_include:
                content_section = f"\n\n[íŒŒì¼ ë‚´ìš©]\n{file_content_to_include[:2000]}"  # ìµœëŒ€ 2000ìë§Œ í¬í•¨
                if len(file_content_to_include) > 2000:
                    content_section += "\n...(ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œë¨)"
            
            attachment_info_by_lang = {
                "ko": f"\n\n[ê³ ê° ì²¨ë¶€ íŒŒì¼ ì •ë³´]\n- íŒŒì¼ëª…: {file_name}\n- íŒŒì¼ íƒ€ì…: {file_type}\n- íŒŒì¼ í¬ê¸°: {file_size} bytes\n- ì°¸ê³ : ê³ ê°ì´ {file_name} íŒŒì¼ì„ ì²¨ë¶€í–ˆìŠµë‹ˆë‹¤. ì´ íŒŒì¼ì€ ë¹„í–‰ê¸° ì§€ì—°, ì—¬ê¶Œ ì´ìŠˆ, ì§ˆë³‘ ë“± ë¶ˆê°€í”¼í•œ ì‚¬ìœ ë¡œ ì¸í•œ ì·¨ì†Œ ë¶ˆê°€ ì—¬í–‰ìƒí’ˆ ê´€ë ¨ ì¦ë¹™ ìë£Œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ëŒ€í•˜ì„¸ìš”.{content_section}",
                "en": f"\n\n[Customer Attachment Information]\n- File name: {file_name}\n- File type: {file_type}\n- File size: {file_size} bytes\n- Note: The customer has attached the file {file_name}. This file may be evidence related to non-refundable travel products due to unavoidable reasons such as flight delays, passport issues, illness, etc. Please refer to the file content when responding.{content_section}",
                "ja": f"\n\n[é¡§å®¢æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±]\n- ãƒ•ã‚¡ã‚¤ãƒ«å: {file_name}\n- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—: {file_type}\n- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes\n- å‚è€ƒ: é¡§å®¢ãŒ{file_name}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¾ã—ãŸã€‚ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€é£›è¡Œæ©Ÿã®é…å»¶ã€ãƒ‘ã‚¹ãƒãƒ¼ãƒˆã®å•é¡Œã€ç—…æ°—ãªã©ã‚„ã‚€ã‚’å¾—ãªã„ç†ç”±ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸å¯ã®æ—…è¡Œå•†å“ã«é–¢é€£ã™ã‚‹è¨¼æ‹ è³‡æ–™ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å‚ç…§ã—ã¦å¯¾å¿œã—ã¦ãã ã•ã„ã€‚{content_section}"
            }
            attachment_info = attachment_info_by_lang.get(current_lang, attachment_info_by_lang["ko"])
            
            # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
            if file_type and file_type.startswith("image/"):
                st.image(uploaded_file, caption=file_name, use_container_width=True)
        
        col_ai_answer, col_hint = st.columns(2)
        
        # AI ë‹µì•ˆ ìƒì„±
        with col_ai_answer:
            if st.button(L["button_generate_ai_answer"], key="generate_ai_answer_btn", type="primary"):
                if customer_inquiry:
                    with st.spinner(L["generating_ai_answer"]):
                        # íšŒì‚¬ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨í•˜ì—¬ ë‹µì•ˆ ìƒì„±
                        company_context = ""
                        if selected_company_for_inquiry and selected_company_for_inquiry in faq_data.get("companies", {}):
                            company_data = get_company_info_faq(selected_company_for_inquiry, current_lang)
                            company_info_label = L.get("company_info", "íšŒì‚¬ ì •ë³´")
                            company_context = f"\n\n{company_info_label}: {company_data.get('info', '')}"
                            # ê´€ë ¨ FAQë„ í¬í•¨
                            related_faqs = company_data.get("faqs", [])[:5]  # ìƒìœ„ 5ê°œë§Œ
                            if related_faqs:
                                faq_label = L.get("company_faq", "ìì£¼ ë‚˜ì˜¤ëŠ” ì§ˆë¬¸")
                                faq_context = f"\n\n{faq_label}:\n"
                                for faq in related_faqs:
                                    q = faq.get(f"question_{current_lang}", faq.get("question_ko", ""))
                                    a = faq.get(f"answer_{current_lang}", faq.get("answer_ko", ""))
                                    faq_context += f"Q: {q}\nA: {a}\n"
                                company_context += faq_context
                        
                        # ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸
                        lang_prompts_inquiry = {
                            "ko": f"""ë‹¤ìŒ ê³ ê° ë¬¸ì˜ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ë‹µì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ê³ ê° ë¬¸ì˜: {customer_inquiry}
{company_context}
{attachment_info if attachment_info else ""}

ë‹µì•ˆì€ ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
1. ê³ ê°ì˜ ë¬¸ì˜ì— ëŒ€í•œ ëª…í™•í•œ ë‹µë³€
2. í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì •ë³´ë‚˜ ì•ˆë‚´
3. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤
4. ì²¨ë¶€ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°, í•´ë‹¹ íŒŒì¼ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ëŒ€í•˜ì„¸ìš”. íŠ¹íˆ ì·¨ì†Œ ë¶ˆê°€ ì—¬í–‰ìƒí’ˆì˜ ë¹„í–‰ê¸° ì§€ì—°, ì—¬ê¶Œ ì´ìŠˆ ë“± ë¶ˆê°€í”¼í•œ ì‚¬ìœ ì˜ ê²½ìš°, ì²¨ë¶€ëœ ì¦ë¹™ ìë£Œë¥¼ í™•ì¸í•˜ê³  ì ì ˆíˆ ëŒ€ì‘í•˜ì„¸ìš”.

ë‹µì•ˆ:""",
                            "en": f"""Please write a professional and friendly answer to the following customer inquiry.

Customer Inquiry: {customer_inquiry}
{company_context}
{attachment_info if attachment_info else ""}

The answer should include:
1. Clear answer to the customer's inquiry
2. Additional information or guidance if needed
3. Friendly and professional tone
4. If there is an attachment, please reference the file content in your response. For non-refundable travel products with unavoidable reasons (flight delays, passport issues, etc.), review the attached evidence and respond appropriately.

Answer:""",
                            "ja": f"""æ¬¡ã®é¡§å®¢å•ã„åˆã‚ã›ã«å¯¾ã™ã‚‹å°‚é–€çš„ã§è¦ªåˆ‡ãªå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

é¡§å®¢å•ã„åˆã‚ã›: {customer_inquiry}
{company_context}
{attachment_info if attachment_info else ""}

å›ç­”ã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:
1. é¡§å®¢ã®å•ã„åˆã‚ã›ã«å¯¾ã™ã‚‹æ˜ç¢ºãªå›ç­”
2. å¿…è¦ã«å¿œã˜ã¦è¿½åŠ æƒ…å ±ã‚„æ¡ˆå†…
3. è¦ªåˆ‡ã§å°‚é–€çš„ãªãƒˆãƒ¼ãƒ³
4. æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å‚ç…§ã—ã¦å¯¾å¿œã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸å¯ã®æ—…è¡Œå•†å“ã§ã€é£›è¡Œæ©Ÿã®é…å»¶ã€ãƒ‘ã‚¹ãƒãƒ¼ãƒˆã®å•é¡Œãªã©ã‚„ã‚€ã‚’å¾—ãªã„ç†ç”±ãŒã‚ã‚‹å ´åˆã¯ã€æ·»ä»˜ã•ã‚ŒãŸè¨¼æ‹ è³‡æ–™ã‚’ç¢ºèªã—ã€é©åˆ‡ã«å¯¾å¿œã—ã¦ãã ã•ã„ã€‚

å›ç­”:"""
                        }
                        prompt = lang_prompts_inquiry.get(current_lang, lang_prompts_inquiry["ko"])
                        
                        ai_answer = run_llm(prompt)
                        st.session_state.generated_ai_answer = ai_answer
                        st.success(f"âœ… {L.get('ai_answer_generated', 'AI ë‹µì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.')}")
                else:
                    st.warning(L.get("warning_enter_inquiry", "ê³ ê° ë¬¸ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."))
        
        # ì‘ëŒ€ íŒíŠ¸ ìƒì„±
        with col_hint:
            if st.button(L["button_generate_hint"], key="generate_hint_btn", type="primary"):
                if customer_inquiry:
                    with st.spinner(L["generating_hint"]):
                        # íšŒì‚¬ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨í•˜ì—¬ íŒíŠ¸ ìƒì„±
                        company_context = ""
                        if selected_company_for_inquiry and selected_company_for_inquiry in faq_data.get("companies", {}):
                            company_data = get_company_info_faq(selected_company_for_inquiry, current_lang)
                            company_info_label = L.get("company_info", "íšŒì‚¬ ì •ë³´")
                            company_context = f"\n\n{company_info_label}: {company_data.get('info', '')}"
                        
                        # ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸
                        lang_prompts_hint = {
                            "ko": f"""ë‹¤ìŒ ê³ ê° ë¬¸ì˜ì— ëŒ€í•œ ì‘ëŒ€ íŒíŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ê³ ê° ë¬¸ì˜: {customer_inquiry}
{company_context}
{attachment_info if attachment_info else ""}

ì‘ëŒ€ íŒíŠ¸ëŠ” ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
1. ê³ ê° ë¬¸ì˜ì˜ í•µì‹¬ í¬ì¸íŠ¸
2. ì‘ëŒ€ ì‹œ ì£¼ì˜ì‚¬í•­
3. ê¶Œì¥ ì‘ëŒ€ ë°©ì‹
4. ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ (ìˆëŠ” ê²½ìš°)
5. ì²¨ë¶€ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°, í•´ë‹¹ íŒŒì¼ì„ í™•ì¸í•˜ê³  ì¦ë¹™ ìë£Œë¡œ í™œìš©í•˜ì„¸ìš”. íŠ¹íˆ ì·¨ì†Œ ë¶ˆê°€ ì—¬í–‰ìƒí’ˆì˜ ê²½ìš°, ì²¨ë¶€ëœ ì‚¬ì§„ì´ë‚˜ ìŠ¤í¬ë¦°ìƒ·ì„ í†µí•´ ë¶ˆê°€í”¼í•œ ì‚¬ìœ ë¥¼ í™•ì¸í•˜ê³  ì ì ˆí•œ ì¡°ì¹˜ë¥¼ ì·¨í•˜ì„¸ìš”.

ì‘ëŒ€ íŒíŠ¸:""",
                            "en": f"""Please write response hints for the following customer inquiry.

Customer Inquiry: {customer_inquiry}
{company_context}
{attachment_info if attachment_info else ""}

Response hints should include:
1. Key points of the customer inquiry
2. Precautions when responding
3. Recommended response method
4. Items that need additional confirmation (if any)
5. If there is an attachment, review the file and use it as evidence. For non-refundable travel products, verify unavoidable reasons through attached photos or screenshots and take appropriate action.

Response Hints:""",
                            "ja": f"""æ¬¡ã®é¡§å®¢å•ã„åˆã‚ã›ã«å¯¾ã™ã‚‹å¯¾å¿œãƒ’ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

é¡§å®¢å•ã„åˆã‚ã›: {customer_inquiry}
{company_context}
{attachment_info if attachment_info else ""}

å¯¾å¿œãƒ’ãƒ³ãƒˆã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:
1. é¡§å®¢å•ã„åˆã‚ã›ã®æ ¸å¿ƒãƒã‚¤ãƒ³ãƒˆ
2. å¯¾å¿œæ™‚ã®æ³¨æ„äº‹é …
3. æ¨å¥¨å¯¾å¿œæ–¹æ³•
4. è¿½åŠ ç¢ºèªãŒå¿…è¦ãªäº‹é …ï¼ˆã‚ã‚‹å ´åˆï¼‰
5. æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã€è¨¼æ‹ è³‡æ–™ã¨ã—ã¦æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«ä¸å¯ã®æ—…è¡Œå•†å“ã®å ´åˆã€æ·»ä»˜ã•ã‚ŒãŸå†™çœŸã‚„ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’é€šã˜ã¦ã‚„ã‚€ã‚’å¾—ãªã„ç†ç”±ã‚’ç¢ºèªã—ã€é©åˆ‡ãªæªç½®ã‚’å–ã£ã¦ãã ã•ã„ã€‚

å¯¾å¿œãƒ’ãƒ³ãƒˆ:"""
                        }
                        prompt = lang_prompts_hint.get(current_lang, lang_prompts_hint["ko"])
                        
                        hint = run_llm(prompt)
                        st.session_state.generated_hint = hint
                        st.success(f"âœ… {L.get('hint_generated', 'ì‘ëŒ€ íŒíŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.')}")
                else:
                    st.warning(L.get("warning_enter_inquiry", "ê³ ê° ë¬¸ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."))
        
        # ìƒì„±ëœ ê²°ê³¼ í‘œì‹œ
        if st.session_state.get("generated_ai_answer"):
            st.markdown("---")
            st.subheader(L["ai_answer_header"])
            
            answer_text = st.session_state.generated_ai_answer
            
            # ë‹µì•ˆì„ ì„ íƒ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ (í°íŠ¸ í¬ê¸° í™•ëŒ€)
            import html as html_escape
            answer_escaped = html_escape.escape(answer_text)
            st.markdown(f"""
            <div style="font-size: 18px; line-height: 1.8; padding: 20px; background-color: #f8f9fa; border-radius: 5px; border: 1px solid #dee2e6;">
            <pre style="white-space: pre-wrap; word-wrap: break-word; font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', 'Noto Sans JP', sans-serif; margin: 0; font-size: 18px; color: #212529;">{answer_escaped}</pre>
            </div>
            """, unsafe_allow_html=True)
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€ (ë” ì•ˆì •ì ì¸ ë³µì‚¬ ë°©ë²•)
            col_copy, col_download = st.columns(2)
            with col_copy:
                st.info(L.get("copy_instruction", "ğŸ’¡ ìœ„ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ê³  Ctrl+C (Mac: Cmd+C)ë¡œ ë³µì‚¬í•˜ì„¸ìš”."))
            with col_download:
                st.download_button(
                    label=f"ğŸ“¥ {L.get('button_download_answer', 'ë‹µì•ˆ ë‹¤ìš´ë¡œë“œ')}",
                    data=answer_text.encode('utf-8'),
                    file_name=f"ai_answer_{st.session_state.get('copy_answer_id', 0)}.txt",
                    mime="text/plain",
                    key="download_answer_btn"
                )
        
        if st.session_state.get("generated_hint"):
            st.markdown("---")
            st.subheader(L["hint_header"])
            
            hint_text = st.session_state.generated_hint
            
            # íŒíŠ¸ë¥¼ ì„ íƒ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ (í°íŠ¸ í¬ê¸° í™•ëŒ€)
            import html as html_escape
            hint_escaped = html_escape.escape(hint_text)
            st.markdown(f"""
            <div style="font-size: 18px; line-height: 1.8; padding: 20px; background-color: #f8f9fa; border-radius: 5px; border: 1px solid #dee2e6;">
            <pre style="white-space: pre-wrap; word-wrap: break-word; font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', 'Noto Sans JP', sans-serif; margin: 0; font-size: 18px; color: #212529;">{hint_escaped}</pre>
            </div>
    # =========================
    # 0. ì „ì²´ ì´ë ¥ ì‚­ì œ
    # =========================
    col_del, _ = st.columns([1, 4])
    with col_del:
        if st.button(L["delete_history_button"], key="trigger_delete_hist"):
            st.session_state.show_delete_confirm = True

    if st.session_state.show_delete_confirm:
        with st.container():
            st.warning(L["delete_confirm_message"])
            c_yes, c_no = st.columns(2)
            if c_yes.button(L["delete_confirm_yes"], key="confirm_del_yes"):
                with st.spinner(L["deleting_history_progress"]):
                    delete_all_history_local()
                    st.session_state.simulator_messages = []
                    st.session_state.simulator_memory.clear()
                    st.session_state.show_delete_confirm = False
                    st.session_state.is_chat_ended = False
                    st.session_state.sim_stage = "WAIT_FIRST_QUERY"
                    st.session_state.customer_attachment_file = []  # ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
                    st.session_state.sim_attachment_context_for_llm = ""  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                    st.session_state.agent_attachment_file = []  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
                    st.success(L["delete_success"])
            if c_no.button(L["delete_confirm_no"], key="confirm_del_no"):
                st.session_state.show_delete_confirm = False

    # =========================
    # 1. ì´ì „ ì´ë ¥ ë¡œë“œ (ê²€ìƒ‰/í•„í„°ë§ ê¸°ëŠ¥ ê°œì„ )
    # =========================
    with st.expander(L["history_expander_title"]):
        # Always load all available histories for the current language (sorted by recency)
        histories = load_simulation_histories_local(current_lang)

        # ì „ì²´ í†µê³„ ë° íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ (ìš”ì•½ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
        cases_with_summary = [
            h for h in histories
            if h.get("summary") and isinstance(h.get("summary"), dict) and h.get("is_chat_ended", False)
               and not h.get("is_call", False)  # ì „í™” ì´ë ¥ ì œì™¸
        ]

        if cases_with_summary:
            st.markdown("---")
            st.subheader("ğŸ“ˆ ê³¼ê±° ì¼€ì´ìŠ¤ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ")

            # íŠ¸ë Œë“œ ì°¨íŠ¸ í‘œì‹œ
            trend_chart = visualize_case_trends(histories, current_lang)
            if trend_chart:
                st.plotly_chart(trend_chart, use_container_width=True)
            else:
                # Plotlyê°€ ì—†ì„ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                avg_sentiment = np.mean(
                    [h["summary"].get("customer_sentiment_score", 50) for h in cases_with_summary if h.get("summary")])
                avg_satisfaction = np.mean(
                    [h["summary"].get("customer_satisfaction_score", 50) for h in cases_with_summary if
                     h.get("summary")])
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("í‰ê·  ê°ì • ì ìˆ˜", f"{avg_sentiment:.1f}/100", f"ì´ {len(cases_with_summary)}ê±´")
                with col2:
                    st.metric("í‰ê·  ë§Œì¡±ë„", f"{avg_satisfaction:.1f}/100", f"ì´ {len(cases_with_summary)}ê±´")

            st.markdown("---")

        # â­ ê²€ìƒ‰ í¼ ì œê±° ë° ë…ë¦½ëœ ìœ„ì ¯ ì‚¬ìš©
        col_search, col_btn = st.columns([4, 1])

        with col_search:
            # st.text_inputì€ Enter í‚¤ ì…ë ¥ ì‹œ ì•±ì„ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤.
            search_query = st.text_input(L["search_history_label"], key="sim_hist_search_input_new")

        with col_btn:
            # ê²€ìƒ‰ ë²„íŠ¼: ëˆ„ë¥´ë©´ ì•±ì„ ê°•ì œ ì¬ì‹¤í–‰í•˜ì—¬ ê²€ìƒ‰/í•„í„°ë§ ë¡œì§ì„ ë‹¤ì‹œ íƒ€ë„ë¡ í•©ë‹ˆë‹¤.
            st.markdown("<br>", unsafe_allow_html=True)  # Align button vertically
            search_clicked = st.button(L["history_search_button"], key="apply_search_btn_new")

        # ë‚ ì§œ ë²”ìœ„ í•„í„°
        today = datetime.now().date()
        date_range_value = [today - timedelta(days=7), today]
        dr = st.date_input(
            L["date_range_label"],
            value=date_range_value,
            key="sim_hist_date_range_actual",
        )

        # --- Filtering Logic ---
        current_search_query = search_query.strip()

        if histories:
            start_date = min(dr)
            end_date = max(dr)

            filtered = []
            for h in histories:
                # ì „í™” ì´ë ¥ì€ ì œì™¸ (ì±„íŒ…/ì´ë©”ì¼ íƒ­ì´ë¯€ë¡œ)
                if h.get("is_call", False):
                    continue

                ok_search = True
                if current_search_query:
                    q = current_search_query.lower()
                    # ê²€ìƒ‰ ëŒ€ìƒ: ì´ˆê¸° ë¬¸ì˜, ê³ ê° ìœ í˜•, ìš”ì•½ ë°ì´í„°
                    text = (h["initial_query"] + " " + h["customer_type"]).lower()

                    # ìš”ì•½ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš”ì•½ ë‚´ìš©ë„ ê²€ìƒ‰ ëŒ€ìƒì— í¬í•¨
                    summary = h.get("summary")
                    if summary and isinstance(summary, dict):
                        summary_text = summary.get("main_inquiry", "") + " " + summary.get("summary", "")
                        text += " " + summary_text.lower()

                    # Check if query matches in initial query, customer type, or summary
                    if q not in text:
                        ok_search = False

                ok_date = True
                ts = h.get("timestamp")
                if ts:
                    try:
                        d = datetime.fromisoformat(ts).date()
                        # Apply date filtering
                        if not (start_date <= d <= end_date):
                            ok_date = False
                    except Exception:
                        pass  # Ignore histories with invalid timestamp

                if ok_search and ok_date:
                    filtered.append(h)
        else:
            filtered = []

        # Determine the list for display (â­ ìš”ì²­ ì‚¬í•­: ê²€ìƒ‰ì–´/í•„í„°ê°€ ì—†ìœ¼ë©´ ìµœê·¼ 10ê±´ë§Œ í‘œì‹œ)
        is_searching_or_filtering = bool(current_search_query) or dr != date_range_value

        if not is_searching_or_filtering:
            # ê²€ìƒ‰/í•„í„° ì¡°ê±´ì´ ì—†ìœ¼ë©´, ì „ì²´ ì´ë ¥ ì¤‘ ìµœì‹  10ê±´ë§Œ í‘œì‹œ
            filtered_for_display = filtered[:10]  # í•„í„°ë§ëœ ëª©ë¡(ì „í™” ì œì™¸) ì¤‘ 10ê°œ
        else:
            # ê²€ìƒ‰/í•„í„° ì¡°ê±´ì´ ìˆìœ¼ë©´, í•„í„°ë§ëœ ëª¨ë“  ê²°ê³¼ë¥¼ í‘œì‹œ
            filtered_for_display = filtered

        # --- Display Logic ---

        if filtered_for_display:
            def _label(h):
                try:
                    t = datetime.fromisoformat(h["timestamp"])
                    t_str = t.strftime("%m-%d %H:%M")
                except Exception:
                    t_str = h.get("timestamp", "")

                # ìš”ì•½ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš”ì•½ ì •ë³´ í‘œì‹œ, ì—†ìœ¼ë©´ ì´ˆê¸° ë¬¸ì˜ í‘œì‹œ
                summary = h.get("summary")
                if summary and isinstance(summary, dict):
                    main_inquiry = summary.get("main_inquiry", h["initial_query"][:30])
                    sentiment = summary.get("customer_sentiment_score", 50)
                    satisfaction = summary.get("customer_satisfaction_score", 50)
                    q = main_inquiry[:30].replace("\n", " ")
                    # ì²¨ë¶€ íŒŒì¼ ì—¬ë¶€ í‘œì‹œ ì¶”ê°€
                    attachment_icon = "ğŸ“" if h.get("attachment_context") else ""
                    # ìš”ì•½ ë°ì´í„° í‘œì‹œ (ê°ì •/ë§Œì¡±ë„ ì ìˆ˜ í¬í•¨)
                    return f"[{t_str}] {attachment_icon} {h['customer_type']} | ê°ì •:{sentiment} ë§Œì¡±:{satisfaction} - {q}..."
                else:
                    q = h["initial_query"][:30].replace("\n", " ")
                    attachment_icon = "ğŸ“" if h.get("attachment_context") else ""
                    return f"[{t_str}] {attachment_icon} {h['customer_type']} - {q}..."


            options_map = {_label(h): h for h in filtered_for_display}

            # Show a message indicating what is displayed if filters were applied
            if is_searching_or_filtering:
                st.caption(f"ğŸ” ì´ {len(filtered_for_display)}ê°œ ì´ë ¥ ê²€ìƒ‰ë¨ (ì „í™” ì´ë ¥ ì œì™¸)")
            else:
                st.caption(f"â­ ìµœê·¼ {len(filtered_for_display)}ê°œ ì´ë ¥ í‘œì‹œ ì¤‘ (ì „í™” ì´ë ¥ ì œì™¸)")

            sel_key = st.selectbox(L["history_selectbox_label"], options=list(options_map.keys()))

            if st.button(L["history_load_button"], key="load_hist_btn"):
                h = options_map[sel_key]
                st.session_state.customer_query_text_area = h["initial_query"]

                # ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆê³  ìš”ì•½ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°, ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì†Œí•œì˜ ë©”ì‹œì§€ ì¬êµ¬ì„±
                if not h.get("messages") and h.get("summary"):
                    summary = h["summary"]
                    # ìš”ì•½ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ ë©”ì‹œì§€ êµ¬ì¡° ìƒì„±
                    reconstructed_messages = [
                        {"role": "customer", "content": h["initial_query"]}
                    ]
                    # ìš”ì•½ì—ì„œ í•µì‹¬ ì‘ë‹µ ì¶”ê°€
                    if summary.get("key_responses"):
                        for response in summary.get("key_responses", [])[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                            reconstructed_messages.append({"role": "agent_response", "content": response})
                    # ìš”ì•½ ì •ë³´ë¥¼ supervisor ë©”ì‹œì§€ë¡œ ì¶”ê°€
                    summary_text = f"**ìš”ì•½ëœ ìƒë‹´ ì´ë ¥**\n\n"
                    summary_text += f"ì£¼ìš” ë¬¸ì˜: {summary.get('main_inquiry', 'N/A')}\n"
                    summary_text += f"ê³ ê° ê°ì • ì ìˆ˜: {summary.get('customer_sentiment_score', 50)}/100\n"
                    summary_text += f"ê³ ê° ë§Œì¡±ë„: {summary.get('customer_satisfaction_score', 50)}/100\n"
                    summary_text += f"\nì „ì²´ ìš”ì•½:\n{summary.get('summary', 'N/A')}"
                    reconstructed_messages.append({"role": "supervisor", "content": summary_text})
                    st.session_state.simulator_messages = reconstructed_messages

                    # ìš”ì•½ ë°ì´í„° ì‹œê°í™”
                    st.markdown("---")
                    st.subheader("ğŸ“Š ë¡œë“œëœ ì¼€ì´ìŠ¤ ë¶„ì„")

                    # ìš”ì•½ ë°ì´í„°ë¥¼ í”„ë¡œí•„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    loaded_profile = {
                        "sentiment_score": summary.get("customer_sentiment_score", 50),
                        "urgency_level": "medium",  # ê¸°ë³¸ê°’
                        "predicted_customer_type": h.get("customer_type", "normal")
                    }

                    # í”„ë¡œí•„ ì ìˆ˜ ì°¨íŠ¸
                    profile_chart = visualize_customer_profile_scores(loaded_profile, current_lang)
                    if profile_chart:
                        st.plotly_chart(profile_chart, use_container_width=True)
                    else:
                        # Plotlyê°€ ì—†ì„ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(L.get("sentiment_score_label", "ê°ì • ì ìˆ˜"),
                                      f"{summary.get('customer_sentiment_score', 50)}/100")
                        with col2:
                            st.metric(L.get("urgency_score_label", "ê¸´ê¸‰ë„"), f"50/100")
                        with col3:
                            st.metric(L.get("customer_type_label", "ê³ ê° ìœ í˜•"), h.get("customer_type", "normal"))

                    # ê³ ê° íŠ¹ì„± ì‹œê°í™”
                    if summary.get("customer_characteristics") or summary.get("privacy_info"):
                        characteristics_chart = visualize_customer_characteristics(summary, current_lang)
                        if characteristics_chart:
                            st.plotly_chart(characteristics_chart, use_container_width=True)
                else:
                    # ê¸°ì¡´ ë©”ì‹œì§€ê°€ ìˆëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    st.session_state.simulator_messages = h.get("messages", [])

                st.session_state.initial_advice_provided = True
                st.session_state.is_chat_ended = h.get("is_chat_ended", False)
                st.session_state.sim_attachment_context_for_llm = h.get("attachment_context", "")  # ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
                st.session_state.customer_attachment_file = []  # ë¡œë“œëœ ì´ë ¥ì—ëŠ” íŒŒì¼ ê°ì²´ ëŒ€ì‹  ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë§Œ ì‚¬ìš©
                st.session_state.agent_attachment_file = []  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”

                # ìƒíƒœ ë³µì›
                if st.session_state.is_chat_ended:
                    st.session_state.sim_stage = "CLOSING"
                else:
                    messages = st.session_state.simulator_messages
                    last_role = messages[-1]["role"] if messages else None
                    if last_role == "agent_response":
                        st.session_state.sim_stage = "CUSTOMER_TURN"
                    elif last_role == "customer_rebuttal":
                        st.session_state.sim_stage = "AGENT_TURN"
                    elif last_role == "supervisor" and messages and messages[-1]["content"] == L[
                        "customer_closing_confirm"]:
                        st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"
                    else:
                        st.session_state.sim_stage = "AGENT_TURN"

                st.session_state.simulator_memory.clear()  # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        else:
            st.info(L["no_history_found"])

    # =========================
    # AHT íƒ€ì´ë¨¸ (í™”ë©´ ìµœìƒë‹¨)
    # =========================
    if st.session_state.sim_stage not in ["WAIT_FIRST_QUERY", "CLOSING", "idle"]:
        elapsed_placeholder = st.empty()

        if st.session_state.start_time is not None:
            # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ í˜ì´ì§€ ë¡œë“œ ì‹œë§ˆë‹¤ í˜„ì¬ ì‹œê°„ ê³„ì‚°
            elapsed_time = datetime.now() - st.session_state.start_time
            total_seconds = elapsed_time.total_seconds()

            # Hold ì‹œê°„ ì œì™¸ (ì±„íŒ…/ì´ë©”ì¼ì€ Hold ì—†ìŒ, ì „í™” íƒ­ê³¼ ë¡œì§ í†µì¼ ìœ„í•´ ìœ ì§€)
            # total_seconds -= st.session_state.total_hold_duration.total_seconds()

            # ì‹œê°„ í˜•ì‹ í¬ë§·íŒ…
            minutes = int(total_seconds // 60)
            seconds = int(total_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            # ê²½ê³  ê¸°ì¤€
            if total_seconds > 900:  # 15ë¶„
                delta_str = L["timer_info_risk"]
                delta_color = "inverse"
            elif total_seconds > 600:  # 10ë¶„
                delta_str = L["timer_info_warn"]
                delta_color = "off"
            else:
                delta_str = L["timer_info_ok"]
                delta_color = "normal"

            elapsed_placeholder.metric(
                L["timer_metric"],
                time_str,
                delta=delta_str,
                delta_color=delta_color
            )

            # â­ ìˆ˜ì •: 3ì´ˆë§ˆë‹¤ ì¬ì‹¤í–‰í•˜ì—¬ AHT ì‹¤ì‹œê°„ì„± í™•ë³´
            if seconds % 3 == 0 and total_seconds < 1000:
                time.sleep(1)

        st.markdown("---")

    # =========================
    # 2. LLM ì¤€ë¹„ ì²´í¬ & ì±„íŒ… ì¢…ë£Œ ìƒíƒœ
    # =========================
    if not st.session_state.is_llm_ready:
        st.warning(L["simulation_no_key_warning"])

    if st.session_state.sim_stage == "CLOSING":
        st.success(L["survey_sent_confirm"])
        st.info(L["new_simulation_ready"])
        
        # â­ ì¶”ê°€: í˜„ì¬ ì„¸ì…˜ ì´ë ¥ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
        st.markdown("---")
        st.markdown("**ğŸ“¥ í˜„ì¬ ì„¸ì…˜ ì´ë ¥ ë‹¤ìš´ë¡œë“œ**")
        download_col1, download_col2, download_col3 = st.columns(3)
        
        # í˜„ì¬ ì„¸ì…˜ì˜ ì´ë ¥ì„ ìƒì„±
        current_session_history = None
        if st.session_state.simulator_messages:
            try:
                customer_type_display = st.session_state.get("customer_type_sim_select", L["customer_type_options"][0])
                current_session_summary = generate_chat_summary(
                    st.session_state.simulator_messages,
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.language
                )
                current_session_history = [{
                    "id": f"session_{st.session_state.sim_instance_id}",
                    "timestamp": datetime.now().isoformat(),
                    "initial_query": st.session_state.customer_query_text_area,
                    "customer_type": customer_type_display,
                    "language_key": st.session_state.language,
                    "messages": st.session_state.simulator_messages,
                    "summary": current_session_summary,
                    "is_chat_ended": True,
                    "attachment_context": st.session_state.sim_attachment_context_for_llm
                }]
            except Exception as e:
                st.warning(f"ì´ë ¥ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ì„ ì§ì ‘ í‘œì‹œ
        if current_session_history:
            # í˜„ì¬ ì–¸ì–´ ê°€ì ¸ì˜¤ê¸°
            current_lang = st.session_state.get("language", "ko")
            if current_lang not in ["ko", "en", "ja"]:
                current_lang = "ko"
            
            with download_col1:
                try:
                    filepath_word = export_history_to_word(current_session_history, lang=current_lang)
                    with open(filepath_word, "rb") as f:
                        st.download_button(
                            label=L.get("download_history_word", "ğŸ“¥ ì´ë ¥ ë‹¤ìš´ë¡œë“œ (Word)"),
                            data=f.read(),
                            file_name=os.path.basename(filepath_word),
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key="download_word_file"
                        )
                except Exception as e:
                    st.error(f"Word ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            
            with download_col2:
                try:
                    filepath_pptx = export_history_to_pptx(current_session_history, lang=current_lang)
                    with open(filepath_pptx, "rb") as f:
                        st.download_button(
                            label=L.get("download_history_pptx", "ğŸ“¥ ì´ë ¥ ë‹¤ìš´ë¡œë“œ (PPTX)"),
                            data=f.read(),
                            file_name=os.path.basename(filepath_pptx),
                            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                            key="download_pptx_file"
                        )
                except Exception as e:
                    st.error(f"PPTX ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            
            with download_col3:
                try:
                    filepath_pdf = export_history_to_pdf(current_session_history, lang=current_lang)
                    with open(filepath_pdf, "rb") as f:
                        st.download_button(
                            label=L.get("download_history_pdf", "ğŸ“¥ ì´ë ¥ ë‹¤ìš´ë¡œë“œ (PDF)"),
                            data=f.read(),
                            file_name=os.path.basename(filepath_pdf),
                            mime="application/pdf",
                            key="download_pdf_file"
                        )
                except Exception as e:
                    st.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        else:
            st.warning("ë‹¤ìš´ë¡œë“œí•  ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
        
        if st.button(L["new_simulation_button"], key="new_simulation_btn"):
            # ì´ˆê¸°í™” ë¡œì§
            st.session_state.simulator_messages = []
            st.session_state.simulator_memory.clear()
            st.session_state.initial_advice_provided = False
            st.session_state.is_chat_ended = False
            st.session_state.agent_response_area_text = ""
            st.session_state.customer_query_text_area = ""
            st.session_state.last_transcript = ""
            st.session_state.sim_audio_bytes = None
            st.session_state.sim_stage = "WAIT_FIRST_QUERY"
            st.session_state.customer_attachment_file = []  # ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            st.session_state.sim_attachment_context_for_llm = ""  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
            st.session_state.agent_attachment_file = []  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            st.session_state.start_time = None
            # ì „í™” ë°œì‹  ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.sim_call_outbound_summary = ""
            st.session_state.sim_call_outbound_target = None
        # st.stop()

    # =========================
    # 5-A. ì „í™” ë°œì‹  ì§„í–‰ ì¤‘ (OUTBOUND_CALL_IN_PROGRESS)
    # =========================
    elif st.session_state.sim_stage == "OUTBOUND_CALL_IN_PROGRESS":
        # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
        current_lang = st.session_state.get("language", "ko")
        if current_lang not in ["ko", "en", "ja"]:
            current_lang = "ko"
        L = LANG.get(current_lang, LANG["ko"])
        target = st.session_state.get("sim_call_outbound_target", "ëŒ€ìƒ")
        st.warning(L["call_outbound_loading"])

        # LLM í˜¸ì¶œ ë° ìš”ì•½ ìƒì„±
        with st.spinner(L["call_outbound_loading"]):
            # 1. LLM í˜¸ì¶œí•˜ì—¬ í†µí™” ìš”ì•½ ìƒì„±
            summary = generate_outbound_call_summary(
                st.session_state.customer_query_text_area,
                st.session_state.language,
                target
            )

            # 2. ì‹œìŠ¤í…œ ë©”ì‹œì§€ (ì „í™” ì‹œë„) ì¶”ê°€
            st.session_state.simulator_messages.append(
                {"role": "system_end", "content": L["call_outbound_system_msg"].format(target=target)}
            )

            # 3. ìš”ì•½ ë©”ì‹œì§€ (ê²°ê³¼) ì¶”ê°€
            summary_markdown = f"### {L['call_outbound_summary_header']}\n\n{summary}"
            st.session_state.simulator_messages.append(
                {"role": "supervisor", "content": summary_markdown}
            )

            # 4. Agent Turnìœ¼ë¡œ ë³µê·€
            st.session_state.sim_stage = "AGENT_TURN"
            st.session_state.sim_call_outbound_summary = summary_markdown  # Save for display/reference
            st.session_state.sim_call_outbound_target = None  # Reset target

            # 5. ì´ë ¥ ì €ì¥ (ì „í™” ë°œì‹  í›„ ìƒíƒœ ì €ì¥)
            customer_type_display = st.session_state.get("customer_type_sim_select", "")
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display + f" (Outbound Call to {target})",
                st.session_state.simulator_messages, is_chat_ended=False,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )

        st.success(f"âœ… {L['call_outbound_simulation_header']}ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìš”ì•½ì„ í™•ì¸í•˜ê³  ê³ ê°ì—ê²Œ íšŒì‹ í•˜ì„¸ìš”.")

    # ========================================
    # 3. ì´ˆê¸° ë¬¸ì˜ ì…ë ¥ (WAIT_FIRST_QUERY)
    # ========================================
    if st.session_state.sim_stage == "WAIT_FIRST_QUERY":
        customer_query = st.text_area(
            L["customer_query_label"],
            key="customer_query_text_area",
            height=150,
            placeholder=L["initial_query_sample"],
        )

        # --- í•„ìˆ˜ ì…ë ¥ í•„ë“œ (ìš”ì²­ 3 ë°˜ì˜: UI í…ìŠ¤íŠ¸ ë³€ê²½) ---
        customer_email = st.text_input(
            L["customer_email_label"],
            key="customer_email_input",
            value=st.session_state.customer_email,
        )
        customer_phone = st.text_input(
            L["customer_phone_label"],
            key="customer_phone_input",
            value=st.session_state.customer_phone,
        )
        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state.customer_email = customer_email
        st.session_state.customer_phone = customer_phone
        # --------------------------------------------------

        customer_type_options = L["customer_type_options"]
        # st.session_state.customer_type_sim_selectëŠ” ì´ë¯¸ ì´ˆê¸°í™”ë¨
        default_idx = customer_type_options.index(
            st.session_state.customer_type_sim_select) if st.session_state.customer_type_sim_select in customer_type_options else 0

        # SelectboxëŠ” ìì²´ì ìœ¼ë¡œ ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ë¯€ë¡œ, ì—¬ê¸°ì— valueë¥¼ ì„¤ì •í•  í•„ìš” ì—†ìŒ
        st.session_state.customer_type_sim_select = st.selectbox(
            L["customer_type_label"],
            customer_type_options,
            index=default_idx,
            key="customer_type_sim_select_widget",
        )

        # --- ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë” ì¶”ê°€ ---
        customer_attachment_widget = st.file_uploader(
            L["attachment_label"],
            type=["png", "jpg", "jpeg", "pdf"],
            key="customer_attachment_file_uploader",
            help=L["attachment_placeholder"],
            accept_multiple_files=False  # ì±„íŒ…/ì´ë©”ì¼ì€ ë‹¨ì¼ íŒŒì¼ë§Œ í—ˆìš©
        )

        # íŒŒì¼ ì •ë³´ ì €ì¥ ë° LLM ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        if customer_attachment_widget:
            st.session_state.customer_attachment_file = customer_attachment_widget
            st.session_state.sim_attachment_context_for_llm = L["attachment_status_llm"].format(
                filename=customer_attachment_widget.name, filetype=customer_attachment_widget.type
            )
        else:
            st.session_state.customer_attachment_file = None
            st.session_state.sim_attachment_context_for_llm = ""
        # --------------------------

        if st.button(L["button_simulate"], key=f"btn_simulate_initial_{st.session_state.sim_instance_id}"):  # ê³ ìœ  í‚¤ ì‚¬ìš©
            if not customer_query.strip():
                st.warning(L["simulation_warning_query"])
                # st.stop()

            # --- í•„ìˆ˜ ì…ë ¥ í•„ë“œ ê²€ì¦ (ìš”ì²­ 3 ë°˜ì˜: ê²€ì¦ ë¡œì§ ì¶”ê°€) ---
            if not st.session_state.customer_email.strip() or not st.session_state.customer_phone.strip():
                st.error(L["error_mandatory_contact"])
                # st.stop()
            # ------------------------------------------

            # ì´ˆê¸° ìƒíƒœ ë¦¬ì…‹
            st.session_state.simulator_messages = []
            st.session_state.simulator_memory.clear()
            st.session_state.is_chat_ended = False
            st.session_state.initial_advice_provided = False
            st.session_state.is_solution_provided = False  # ì†”ë£¨ì…˜ í”Œë˜ê·¸ ë¦¬ì…‹
            st.session_state.language_transfer_requested = False  # ì–¸ì–´ ìš”ì²­ í”Œë˜ê·¸ ë¦¬ì…‹
            st.session_state.transfer_summary_text = ""  # ì´ê´€ ìš”ì•½ ë¦¬ì…‹
            st.session_state.start_time = None  # AHT íƒ€ì´ë¨¸ ì´ˆê¸°í™” (ì²« ê³ ê° ë°˜ì‘ í›„ ì‹œì‘)
            st.session_state.sim_instance_id = str(uuid.uuid4())  # ìƒˆ ì‹œë®¬ë ˆì´ì…˜ ID í• ë‹¹
            # ì „í™” ë°œì‹  ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.sim_call_outbound_summary = ""
            st.session_state.sim_call_outbound_target = None

            # 1) ê³ ê° ì²« ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.simulator_messages.append(
                {"role": "customer", "content": customer_query}
            )

            # 2) Supervisor ê°€ì´ë“œ + ì´ˆì•ˆ ìƒì„±
            # ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ìë™ ê°ì§€ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
            try:
                detected_lang = detect_text_language(customer_query)
                # ê°ì§€ëœ ì–¸ì–´ê°€ ìœ íš¨í•œì§€ í™•ì¸
                if detected_lang not in ["ko", "en", "ja"]:
                    detected_lang = current_lang
                else:
                    # ì–¸ì–´ê°€ ê°ì§€ë˜ì—ˆê³  í˜„ì¬ ì–¸ì–´ì™€ ë‹¤ë¥´ë©´ ìë™ìœ¼ë¡œ ì–¸ì–´ ì„¤ì • ì—…ë°ì´íŠ¸
                    if detected_lang != current_lang:
                        st.session_state.language = detected_lang
                        st.info(f"ğŸŒ ì…ë ¥ ì–¸ì–´ê°€ ê°ì§€ë˜ì–´ ì–¸ì–´ ì„¤ì •ì´ '{detected_lang}'ë¡œ ìë™ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"Language detection failed: {e}")
                detected_lang = current_lang  # ê¸°ë³¸ê°’ìœ¼ë¡œ í´ë°±
            
            # ê³ ê° í”„ë¡œí•„ ë¶„ì„ (ì‹œê°í™”ë¥¼ ìœ„í•´ ë¨¼ì € ìˆ˜í–‰, ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
            customer_profile = analyze_customer_profile(customer_query, detected_lang)
            similar_cases = find_similar_cases(customer_query, customer_profile, detected_lang, limit=5)

            # ì‹œê°í™” ì°¨íŠ¸ í‘œì‹œ
            st.markdown("---")
            st.subheader("ğŸ“Š ê³ ê° í”„ë¡œí•„ ë¶„ì„")

            # ê³ ê° í”„ë¡œí•„ ì ìˆ˜ ì°¨íŠ¸ (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
            profile_chart = visualize_customer_profile_scores(customer_profile, detected_lang)
            if profile_chart:
                st.plotly_chart(profile_chart, use_container_width=True)
            else:
                # Plotlyê°€ ì—†ì„ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    gender_display = customer_profile.get("gender", "unknown")
                    if gender_display == "male":
                        gender_display = "ë‚¨ì"
                    elif gender_display == "female":
                        gender_display = "ì—¬ì"
                    else:
                        gender_display = "ì•Œ ìˆ˜ ì—†ìŒ"
                    st.metric(
                        "ì„±ë³„",
                        gender_display
                    )
                with col2:
                    st.metric(
                        L.get("sentiment_score_label", "ê°ì • ì ìˆ˜"),
                        f"{customer_profile.get('sentiment_score', 50)}/100"
                    )
                with col3:
                    urgency_map = {"low": 25, "medium": 50, "high": 75}
                    urgency_score = urgency_map.get(customer_profile.get("urgency_level", "medium").lower(), 50)
                    st.metric(
                        L.get("urgency_score_label", "ê¸´ê¸‰ë„"),
                        f"{urgency_score}/100"
                    )
                with col4:
                    st.metric(
                        L.get("customer_type_label", "ê³ ê° ìœ í˜•"),
                        customer_profile.get("predicted_customer_type", "normal")
                    )

            # ìœ ì‚¬ ì¼€ì´ìŠ¤ ì‹œê°í™”
            if similar_cases:
                st.markdown("---")
                st.subheader("ğŸ” ìœ ì‚¬ ì¼€ì´ìŠ¤ ì¶”ì²œ")
                similarity_chart = visualize_similarity_cases(similar_cases, detected_lang)
                if similarity_chart:
                    st.plotly_chart(similarity_chart, use_container_width=True)

                # ìœ ì‚¬ ì¼€ì´ìŠ¤ ìš”ì•½ í‘œì‹œ
                with st.expander(f"ğŸ’¡ {len(similar_cases)}ê°œ ìœ ì‚¬ ì¼€ì´ìŠ¤ ìƒì„¸ ì •ë³´"):
                    for idx, similar_case in enumerate(similar_cases, 1):
                        case = similar_case["case"]
                        summary = similar_case["summary"]
                        similarity = similar_case["similarity_score"]
                        st.markdown(f"### ì¼€ì´ìŠ¤ {idx} (ìœ ì‚¬ë„: {similarity:.1f}%)")
                        st.markdown(f"**ë¬¸ì˜ ë‚´ìš©:** {summary.get('main_inquiry', 'N/A')}")
                        st.markdown(f"**ê°ì • ì ìˆ˜:** {summary.get('customer_sentiment_score', 50)}/100")
                        st.markdown(f"**ë§Œì¡±ë„ ì ìˆ˜:** {summary.get('customer_satisfaction_score', 50)}/100")
                        if summary.get("key_responses"):
                            st.markdown("**í•µì‹¬ ì‘ë‹µ:**")
                            for response in summary.get("key_responses", [])[:3]:
                                st.markdown(f"- {response[:100]}...")
                        st.markdown("---")

            # ì´ˆê¸° ì¡°ì–¸ ìƒì„± (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
            text = _generate_initial_advice(
                customer_query,
                st.session_state.customer_type_sim_select,
                st.session_state.customer_email,
                st.session_state.customer_phone,
                detected_lang,  # ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©
                st.session_state.customer_attachment_file
            )
            st.session_state.simulator_messages.append({"role": "supervisor", "content": text})

            st.session_state.initial_advice_provided = True
            save_simulation_history_local(
                customer_query,
                st.session_state.customer_type_sim_select,
                st.session_state.simulator_messages,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
                is_chat_ended=False,
            )
            st.session_state.sim_stage = "AGENT_TURN"

    # =========================
    # 4. ëŒ€í™” ë¡œê·¸ í‘œì‹œ (ê³µí†µ)
    # =========================
    
    # í”¼ë“œë°± ì €ì¥ ì½œë°± í•¨ìˆ˜
    def save_feedback(index):
        """ì—ì´ì „íŠ¸ ì‘ë‹µì— ëŒ€í•œ ê³ ê° í”¼ë“œë°±ì„ ì €ì¥"""
        feedback_key = f"feedback_{st.session_state.sim_instance_id}_{index}"
        if feedback_key in st.session_state:
            feedback_value = st.session_state[feedback_key]
            # ë©”ì‹œì§€ì— í”¼ë“œë°± ì •ë³´ ì €ì¥
            if index < len(st.session_state.simulator_messages):
                st.session_state.simulator_messages[index]["feedback"] = feedback_value
    
    for idx, msg in enumerate(st.session_state.simulator_messages):
        role = msg["role"]
        content = msg["content"]
        avatar = {"customer": "ğŸ™‹", "supervisor": "ğŸ¤–", "agent_response": "ğŸ§‘â€ğŸ’»", "customer_rebuttal": "âœ¨",
                  "system_end": "ğŸ“Œ", "system_transfer": "ğŸ“Œ"}.get(role, "ğŸ’¬")
        tts_role = "customer" if role.startswith("customer") or role == "customer_rebuttal" else (
            "agent" if role == "agent_response" else "supervisor")

        with st.chat_message(role, avatar=avatar):
            st.markdown(content)
            # ì¸ë±ìŠ¤ë¥¼ render_tts_buttonì— ì „ë‹¬í•˜ì—¬ ê³ ìœ  í‚¤ ìƒì„±ì— ì‚¬ìš©
            render_tts_button(content, st.session_state.language, role=tts_role, prefix=f"{role}_", index=idx)
            
            # â­ ì—ì´ì „íŠ¸ ì‘ë‹µì— ëŒ€í•œ í”¼ë“œë°± ìœ„ì ¯ ì¶”ê°€
            if role == "agent_response":
                feedback_key = f"feedback_{st.session_state.sim_instance_id}_{idx}"
                # ê¸°ì¡´ í”¼ë“œë°± ê°’ ê°€ì ¸ì˜¤ê¸°
                existing_feedback = msg.get("feedback", None)
                if existing_feedback is not None:
                    st.session_state[feedback_key] = existing_feedback
                
                # í”¼ë“œë°± ìœ„ì ¯ í‘œì‹œ
                st.feedback(
                    "thumbs",
                    key=feedback_key,
                    disabled=existing_feedback is not None,
                    on_change=save_feedback,
                    args=[idx],
                )

            # â­ [ìƒˆë¡œìš´ ë¡œì§] ê³ ê° ì²¨ë¶€ íŒŒì¼ ë Œë”ë§ (ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ ê²½ìš°)
            if idx == 0 and role == "customer" and st.session_state.customer_attachment_b64:
                mime = st.session_state.customer_attachment_mime or "image/png"
                data_url = f"data:{mime};base64,{st.session_state.customer_attachment_b64}"

                # ì´ë¯¸ì§€ íŒŒì¼ë§Œ í‘œì‹œ (PDF ë“±ì€ ì•„ì§ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ)
                if mime.startswith("image/"):
                    st.image(data_url, caption=f"ì²¨ë¶€ëœ ì¦ê±°ë¬¼ ({st.session_state.customer_attachment_file.name})",
                             use_column_width=True)
                elif mime == "application/pdf":
                    # PDF íŒŒì¼ì¼ ê²½ìš°, íŒŒì¼ ì´ë¦„ê³¼ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ ë§í¬ ë˜ëŠ” ê²½ê³  í‘œì‹œ
                    st.warning(
                        f"ì²¨ë¶€ëœ PDF íŒŒì¼ ({st.session_state.customer_attachment_file.name})ì€ í˜„ì¬ ì¸ë¼ì¸ ë¯¸ë¦¬ë³´ê¸°ê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ì´ê´€ ìš”ì•½ í‘œì‹œ (ì´ê´€ í›„ì—ë§Œ) - ë£¨í”„ ë°–ìœ¼ë¡œ ì´ë™í•˜ì—¬ í•œ ë²ˆë§Œ í‘œì‹œ
    if st.session_state.transfer_summary_text or (st.session_state.language != st.session_state.language_at_transfer_start and st.session_state.language_at_transfer_start):
                st.markdown("---")
                st.markdown(f"**{L['transfer_summary_header']}**")
                st.info(L["transfer_summary_intro"])

                # ë²ˆì—­ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš° í™•ì¸ (ë²ˆì—­ ì„±ê³µ ì—¬ë¶€ í”Œë˜ê·¸ ì‚¬ìš©)
                is_translation_failed = not st.session_state.get("translation_success", True) or not st.session_state.transfer_summary_text

                if is_translation_failed:
                    # ë²ˆì—­ ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ í…ìŠ¤íŠ¸ê°€ í‘œì‹œë˜ë¯€ë¡œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì—†ì´ ì›ë³¸ í…ìŠ¤íŠ¸ë§Œ í‘œì‹œ
                    # (ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ì§€ ì•Šì•„ë„ ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ ê³„ì† ì§„í–‰ ê°€ëŠ¥)
                    if st.session_state.transfer_summary_text:
                        st.info(st.session_state.transfer_summary_text)
                    # ë²ˆì—­ ì¬ì‹œë„ ë²„íŠ¼ ì¶”ê°€ (ì„ íƒì )
                    if st.button(L.get("button_retry_translation", "ë²ˆì—­ ë‹¤ì‹œ ì‹œë„"),
                                 key=f"btn_retry_translation_{st.session_state.sim_instance_id}"):  # ê³ ìœ  í‚¤ ì‚¬ìš©
                        # ì¬ì‹œë„ ë¡œì§ ì‹¤í–‰
                        with st.spinner(L.get("transfer_loading", "ë²ˆì—­ ì¤‘...")):
                            source_lang = st.session_state.language_at_transfer_start
                            target_lang = st.session_state.language

                            # ì´ì „ ëŒ€í™” ë‚´ìš© ì¬ê°€ê³µ
                            history_text = get_chat_history_for_prompt(include_attachment=False)
                            for msg in st.session_state.simulator_messages:
                                role = "Customer" if msg["role"].startswith("customer") or msg[
                                    "role"] == "initial_query" else "Agent"
                                if msg["role"] in ["initial_query", "customer_rebuttal", "agent_response",
                                                   "customer_closing_response"]:
                                    history_text += f"{role}: {msg['content']}\n"

                            # â­ ìˆ˜ì •: ë¨¼ì € í•µì‹¬ í¬ì¸íŠ¸ë§Œ ìš”ì•½í•œ í›„ ë²ˆì—­
                            lang_name_source = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(source_lang, "Korean")
                            summary_prompt = f"""
You are an AI assistant that summarizes customer service conversations. 
Extract ONLY the key points from the conversation below. Keep it concise and focused on:
1. Customer's main inquiry/question
2. Key information provided by the agent
3. Important decisions or outcomes
4. Any unresolved issues

Write the summary in {lang_name_source}. Maximum 200 words. Be brief and to the point.

--- Conversation ---
{history_text}
---

Key Points Summary:
    # =========================
    # 5. ì—ì´ì „íŠ¸ ì…ë ¥ ë‹¨ê³„ (AGENT_TURN)
    # =========================
    if st.session_state.sim_stage == "AGENT_TURN":
        st.markdown(f"### {L['agent_response_header']}")

        # --- ì‹¤ì‹œê°„ ì‘ëŒ€ íŒíŠ¸ ì˜ì—­ ---
        hint_cols = st.columns([4, 1])
        with hint_cols[0]:
            st.info(L["hint_placeholder"] + st.session_state.realtime_hint_text)

        with hint_cols[1]:
            # íŒíŠ¸ ìš”ì²­ ë²„íŠ¼
            if st.button(L["button_request_hint"], key=f"btn_request_hint_{st.session_state.sim_instance_id}"):
                with st.spinner(L["response_generating"]):
                    # ì±„íŒ…/ì´ë©”ì¼ íƒ­ì´ë¯€ë¡œ is_call=False
                    hint = generate_realtime_hint(current_lang, is_call=False)
                    st.session_state.realtime_hint_text = hint

        # --- ì–¸ì–´ ì´ê´€ ìš”ì²­ ê°•ì¡° í‘œì‹œ ---
        if st.session_state.language_transfer_requested:
            st.error("ğŸš¨ ê³ ê°ì´ ì–¸ì–´ ì „í™˜(ì´ê´€)ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì‘ëŒ€í•˜ê±°ë‚˜ ì´ê´€ì„ ì§„í–‰í•˜ì„¸ìš”ã€‚")

        # --- ê³ ê° ì²¨ë¶€ íŒŒì¼ ì •ë³´ ì¬í‘œì‹œ ---
        if st.session_state.sim_attachment_context_for_llm:
            st.info(
                f"ğŸ“ ìµœì´ˆ ë¬¸ì˜ ì‹œ ì²¨ë¶€ëœ íŒŒì¼ ì •ë³´:\n\n{st.session_state.sim_attachment_context_for_llm.replace('[ATTACHMENT STATUS]', '').strip()}")

        # --- AI ì‘ë‹µ ì´ˆì•ˆ ìƒì„± ë²„íŠ¼ (ìš”ì²­ 1 ë°˜ì˜) ---
        if st.button(L["button_generate_draft"], key=f"btn_generate_ai_draft_{st.session_state.sim_instance_id}"):
            if not st.session_state.is_llm_ready:
                st.warning(L["simulation_no_key_warning"])
            else:
                with st.spinner(L["draft_generating"]):
                    # ì´ˆì•ˆ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
                    ai_draft = generate_agent_response_draft(current_lang)
                    if ai_draft and not ai_draft.startswith("âŒ"):
                        st.session_state.agent_response_area_text = ai_draft
                        st.success(L["draft_success"])
                    else:
                        st.error(ai_draft if ai_draft else L.get("draft_error", "ì‘ë‹µ ì´ˆì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."))

        # --- ì „í™” ë°œì‹  ë²„íŠ¼ ì¶”ê°€ (ìš”ì²­ 2 ë°˜ì˜) ---
        st.markdown("---")
        st.subheader(L["button_call_outbound"])
        call_cols = st.columns(2)

        with call_cols[0]:
            if st.button(L["button_call_outbound_to_provider"], key="btn_call_outbound_partner", use_container_width=True):
                # ì „í™” ë°œì‹  ì‹œë®¬ë ˆì´ì…˜: í˜„ì§€ ì—…ì²´
                st.session_state.sim_call_outbound_target = "í˜„ì§€ ì—…ì²´/íŒŒíŠ¸ë„ˆ"
                st.session_state.sim_stage = "OUTBOUND_CALL_IN_PROGRESS"

        with call_cols[1]:
            if st.button(L["button_call_outbound_to_customer"], key="btn_call_outbound_customer", use_container_width=True):
                # ì „í™” ë°œì‹  ì‹œë®¬ë ˆì´ì…˜: ê³ ê°
                st.session_state.sim_call_outbound_target = "ê³ ê°"
                st.session_state.sim_stage = "OUTBOUND_CALL_IN_PROGRESS"

        st.markdown("---")
        # --- ì „í™” ë°œì‹  ë²„íŠ¼ ì¶”ê°€ ë ---

        st.markdown("### ğŸš¨ Supervisor ì •ì±…/ì§€ì‹œ ì‚¬í•­ ì—…ë¡œë“œ (ì˜ˆì™¸ ì²˜ë¦¬ ë°©ì¹¨)")

        # --- Supervisor ì •ì±… ì—…ë¡œë” ì¶”ê°€ ---
        supervisor_attachment_widget = st.file_uploader(
            "Supervisor ì§€ì‹œ ì‚¬í•­/ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ (ì˜ˆì™¸ ì •ì±… í¬í•¨)",
            type=["png", "jpg", "jpeg", "pdf", "txt"],
            key="supervisor_policy_uploader",
            help="ë¹„í–‰ê¸° ì§€ì—°, ì§ˆë³‘ ë“± ì˜ˆì™¸ì  ìƒí™©ì— ëŒ€í•œ Supervisorì˜ ìµœì‹  ì§€ì‹œ ì‚¬í•­ì„ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
            accept_multiple_files=False
        )

        # íŒŒì¼ ì •ë³´ ì €ì¥ ë° LLM ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        if supervisor_attachment_widget:
            # í…ìŠ¤íŠ¸ íŒŒì¼ ë˜ëŠ” PDF/ì´ë¯¸ì§€ íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ì»¨í…ì¸ ë¥¼ ì¶”ì¶œí•˜ì—¬ policy_contextì— ì €ì¥í•´ì•¼ í•¨
            # ì—¬ê¸°ì„œëŠ” íŒŒì¼ ì´ë¦„ê³¼ íƒ€ì…ë§Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ê³ , LLMì´ ì´ê²ƒì´ 'ì˜ˆì™¸ ì •ì±…'ì„ì„ ì•Œë„ë¡ ìœ ë„
            file_name = supervisor_attachment_widget.name
            st.session_state.supervisor_policy_context = f"[Supervisor Policy Attached] Filename: {file_name}, Filetype: {supervisor_attachment_widget.type}. This file contains a CRITICAL, temporary policy update regarding exceptions (e.g., flight delays, illness, natural disasters). Analyze and prioritize this policy in the response."
            st.success(f"âœ… Supervisor ì •ì±… íŒŒì¼: **{file_name}**ì´(ê°€) ì‘ëŒ€ ê°€ì´ë“œì— ë°˜ì˜ë©ë‹ˆë‹¤.")
        elif st.session_state.supervisor_policy_context:
            st.info("â­ í˜„ì¬ ì ìš© ì¤‘ì¸ Supervisor ì •ì±…ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.session_state.supervisor_policy_context = ""

        # --- ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë” (ë‹¤ì¤‘ íŒŒì¼ í—ˆìš©) ---
        agent_attachment_files = st.file_uploader(
            L["agent_attachment_label"],
            type=["png", "jpg", "jpeg", "pdf"],
            key="agent_attachment_file_uploader",
            help=L["agent_attachment_placeholder"],
            accept_multiple_files=True
        )

        if agent_attachment_files:
            st.session_state.agent_attachment_file = [
                {"name": f.name, "type": f.type, "size": f.size} for f in agent_attachment_files
            ]
            file_names = ", ".join([f["name"] for f in
                                    st.session_state.agent_attachment_file])  # ìˆ˜ì •: file_infos ëŒ€ì‹  st.session_state.agent_attachment_file ì‚¬ìš©
            st.info(f"âœ… {len(agent_attachment_files)}ê°œ ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ: {file_names}")
        else:
            st.session_state.agent_attachment_file = []

        # --- ì…ë ¥ í•„ë“œ ë° ë²„íŠ¼ ---
        col_mic, col_text = st.columns([1, 2])

        # --- ë§ˆì´í¬ ë…¹ìŒ ---
        with col_mic:
            mic_audio = mic_recorder(
                start_prompt=L["button_mic_input"],
                stop_prompt=L["button_mic_stop"],
                just_once=False,
                format="wav",
                use_container_width=True,
                key="sim_mic_recorder",
            )

        if mic_audio and mic_audio.get("bytes"):
            st.session_state.sim_audio_bytes = mic_audio["bytes"]
            # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
            current_lang = st.session_state.get("language", "ko")
            if current_lang not in ["ko", "en", "ja"]:
                current_lang = "ko"
            L = LANG.get(current_lang, LANG["ko"])
            st.info(L["recording_complete_press_transcribe"])

        if st.session_state.sim_audio_bytes:
            col_audio, col_transcribe, col_del = st.columns([3, 1, 1])

            # 1. ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´
            # Streamlit ë¬¸ì„œ: bytes ë°ì´í„°ë¥¼ ì§ì ‘ ì „ë‹¬ ê°€ëŠ¥
            with col_audio:
                try:
                    st.audio(st.session_state.sim_audio_bytes, format="audio/wav", autoplay=False)
                except Exception as e:
                    st.error(f"ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")

            # 2. ë…¹ìŒ ì‚­ì œ ë²„íŠ¼ (ì¶”ê°€ ìš”ì²­ ë°˜ì˜)
            with col_del:
                st.markdown("<br>", unsafe_allow_html=True)  # ë²„íŠ¼ ìˆ˜ì§ ì •ë ¬
                if st.button(L["delete_mic_record"], key="btn_delete_sim_audio_call"):
                    # ì˜¤ë””ì˜¤ ë° ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
                    st.session_state.sim_audio_bytes = None
                    st.session_state.last_transcript = ""
                    # â­ ìˆ˜ì •: ìœ„ì ¯ì´ ìƒì„±ëœ í›„ì—ëŠ” session_stateë¥¼ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ í”Œë˜ê·¸ ì‚¬ìš©
                    st.session_state.reset_agent_response_area = True
                    st.success("ë…¹ìŒì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒí•´ ì£¼ì„¸ìš”.")

            # 3. ì „ì‚¬(Whisper) ë²„íŠ¼ (ê¸°ì¡´ ë¡œì§ ëŒ€ì²´)
            col_tr, _ = st.columns([1, 2])
            if col_tr.button(L["transcribe_btn"], key="sim_transcribe_btn"):
                if st.session_state.sim_audio_bytes is None:
                    st.warning("ë¨¼ì € ë§ˆì´í¬ë¡œ ë…¹ìŒì„ ì™„ë£Œí•˜ì„¸ìš”.")
                else:
                    # â­ ìˆ˜ì •: OpenAI ë˜ëŠ” Gemini API í‚¤ ì²´í¬
                    has_openai = st.session_state.openai_client is not None
                    has_gemini = bool(get_api_key("gemini"))
                    
                    if not has_openai and not has_gemini:
                        st.error(L["whisper_client_error"] + " (OpenAI ë˜ëŠ” Gemini API Key í•„ìš”)")
                    else:
                        with st.spinner(L["whisper_processing"]):
                            # transcribe_bytes_with_whisper í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
                            # ìë™ ì–¸ì–´ ê°ì§€ ì‚¬ìš© (ì…ë ¥ ì–¸ì–´ì™€ ê´€ê³„ì—†ì´ ì •í™•í•œ ì „ì‚¬)
                            transcribed_text = transcribe_bytes_with_whisper(
                                st.session_state.sim_audio_bytes,
                                "audio/wav",
                                lang_code=None,
                                auto_detect=True,
                            )
                            if transcribed_text.startswith("âŒ"):
                                st.error(transcribed_text)
                                st.session_state.last_transcript = ""
                            else:
                                st.session_state.last_transcript = transcribed_text.strip()
                                # â­ ìˆ˜ì •: ì „ì‚¬ëœ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ì°½ì˜ ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ì— ë°˜ì˜
                                st.session_state.agent_response_area_text = transcribed_text.strip()
                                st.session_state.agent_response_input_box_widget = transcribed_text.strip()

                                snippet = transcribed_text[:50].replace("\n", " ")
                                if len(transcribed_text) > 50:
                                    snippet += "..."
                                st.success(L["whisper_success"] + f"\n\n**ì¸ì‹ ë‚´ìš©:** *{snippet}*")

        col_text, col_button = st.columns([4, 1])

        # --- ì…ë ¥ í•„ë“œ ë° ë²„íŠ¼ ---
        with col_text:
            # â­ ìˆ˜ì •: ìœ„ì ¯ ìƒì„± ì „ì— ì´ˆê¸°í™” í”Œë˜ê·¸ë¥¼ í™•ì¸í•˜ì—¬ ê°’ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
            if st.session_state.get("reset_agent_response_area", False):
                st.session_state.agent_response_area_text = ""
                st.session_state.reset_agent_response_area = False
            
            # st.text_areaì˜ ê°’ì„ ì½ì–´ ì„¸ì…˜ ìƒíƒœë¥¼ ì§ì ‘ ì—…ë°ì´íŠ¸í•˜ëŠ” on_changeë¥¼ ì œê±°í•˜ê³ 
            # st.text_area ìœ„ì ¯ ìì²´ì˜ í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ send_clicked ì‹œ ìµœì‹  ê°’ì„ ì½ë„ë¡ í•©ë‹ˆë‹¤.
            # (Streamlit ê¸°ë³¸ ë™ì‘: ë²„íŠ¼ í´ë¦­ ì‹œ ìœ„ì ¯ì˜ ìµœì¢… ê°’ì´ ì„¸ì…˜ ìƒíƒœì— ë°˜ì˜ë¨)
            # â­ ìˆ˜ì •: keyë¥¼ agent_response_area_textë¡œ í†µì¼í•˜ì—¬ ì„¸ì…˜ ìƒíƒœì™€ ë™ê¸°í™”
            agent_response_input = st.text_area(
                L["agent_response_placeholder"],
                value=st.session_state.agent_response_area_text,
                key="agent_response_area_text",  # ì„¸ì…˜ ìƒíƒœ í‚¤ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ì—¬ ë™ê¸°í™” ë³´ì¥
                height=150,
            )

            # ì†”ë£¨ì…˜ ì œê³µ ì²´í¬ë°•ìŠ¤
            st.session_state.is_solution_provided = st.checkbox(
                L["solution_check_label"],
                value=st.session_state.is_solution_provided,
                key="solution_checkbox_widget",
            )

        with col_button:
            send_clicked = st.button(L["send_response_button"], key="send_agent_response_btn")

        if send_clicked:
            # â­ ìˆ˜ì •: st.session_state.agent_response_area_textì—ì„œ ìµœì‹  ì…ë ¥ê°’ì„ ê°€ì ¸ì˜´ (keyì™€ ë™ì¼)
            agent_response = st.session_state.agent_response_area_text.strip()

            if not agent_response:
                st.warning(L["empty_response_warning"])
                # st.stop()

            # AHT íƒ€ì´ë¨¸ ì‹œì‘
            if st.session_state.start_time is None and len(st.session_state.simulator_messages) >= 1:
                st.session_state.start_time = datetime.now()

            # --- ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì²˜ë¦¬ (ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬) ---
            final_response_content = agent_response
            if st.session_state.agent_attachment_file:
                file_infos = st.session_state.agent_attachment_file
                file_names = ", ".join([f["name"] for f in file_infos])
                attachment_msg = L["agent_attachment_status"].format(
                    filename=file_names, filetype=f"ì´ {len(file_infos)}ê°œ íŒŒì¼"
                )
                final_response_content = f"{agent_response}\n\n---\n{attachment_msg}"

            # ë¡œê·¸ ì—…ë°ì´íŠ¸
            st.session_state.simulator_messages.append(
                {"role": "agent_response", "content": final_response_content}
            )

            # â­ ì¶”ê°€: ì—ì´ì „íŠ¸ ì‘ë‹µì— ë©”ì¼ ëì¸ì‚¬ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            email_closing_patterns = [
                "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì—°ë½", "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì—°ë½",
                "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´", "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´",
                "ì–¸ì œë“ ì§€ ì—°ë½", "ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì„¸ìš”",
                "additional inquiries", "any additional questions", "any further questions",
                "feel free to contact", "please feel free to contact",
                "please don't hesitate to contact", "don't hesitate to contact",
                "please let me know", "let me know", "let me know if",
                "please let me know so", "let me know so",
                "if you have any questions", "if you have any further questions",
                "if you need any assistance", "if you need further assistance",
                "if you encounter any issues", "if you still have", "if you remain unclear",
                "I can assist further", "I can help further", "I can assist",
                "so I can assist", "so I can help", "so I can assist further",
                "è¿½åŠ ã®ã”è³ªå•", "è¿½åŠ ã®ãŠå•ã„åˆã‚ã›", "ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰", "ãŠå•ã„åˆã‚ã›ãŒã”ã–ã„ã¾ã—ãŸã‚‰"
            ]
            is_email_closing_in_response = any(pattern.lower() in final_response_content.lower() for pattern in email_closing_patterns)
            if is_email_closing_in_response:
                st.session_state.has_email_closing = True  # í”Œë˜ê·¸ ì„¤ì •

            # ì…ë ¥ì°½/ì˜¤ë””ì˜¤/ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            # â­ ìˆ˜ì •: ìœ„ì ¯ì´ ìƒì„±ëœ í›„ì—ëŠ” session_stateë¥¼ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,
            # rerun í›„ ìœ„ì ¯ì´ ë‹¤ì‹œ ìƒì„±ë  ë•Œ ì´ˆê¸°ê°’ì´ ì ìš©ë˜ë„ë¡ í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            st.session_state.sim_audio_bytes = None
            st.session_state.agent_attachment_file = []  # ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            st.session_state.language_transfer_requested = False
            st.session_state.realtime_hint_text = ""  # íŒíŠ¸ ì´ˆê¸°í™”
            st.session_state.sim_call_outbound_summary = ""  # ì „í™” ë°œì‹  ìš”ì•½ ì´ˆê¸°í™”

            # â­ ìˆ˜ì •: agent_response_area_textëŠ” rerun í›„ ìœ„ì ¯ì´ ë‹¤ì‹œ ìƒì„±ë  ë•Œ ì´ˆê¸°í™”ë˜ë„ë¡
            # í”Œë˜ê·¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ìœ„ì ¯ ìƒì„± ì „ì— ì´ í”Œë˜ê·¸ë¥¼ í™•ì¸í•˜ì—¬ ê°’ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
            st.session_state.reset_agent_response_area = True
            
            # â­ ìˆ˜ì •: ì‘ë‹µ ì „ì†¡ ì‹œ ë°”ë¡œ ê³ ê° ë°˜ì‘ ìë™ ìƒì„±
            if st.session_state.is_llm_ready:
                # LLMì´ ì¤€ë¹„ëœ ê²½ìš° ë°”ë¡œ ê³ ê° ë°˜ì‘ ìƒì„±
                with st.spinner(L["generating_customer_response"]):
                    customer_response = generate_customer_reaction(st.session_state.language, is_call=False)
                
                # ê³ ê° ë°˜ì‘ì„ ë©”ì‹œì§€ì— ì¶”ê°€
                st.session_state.simulator_messages.append(
                    {"role": "customer", "content": customer_response}
                )
                
                # â­ ì¶”ê°€: ë©”ì¼ ëì¸ì‚¬ê°€ í¬í•¨ëœ ê²½ìš° ê³ ê° ì‘ë‹µ í™•ì¸ ë° ì„¤ë¬¸ ì¡°ì‚¬ ë²„íŠ¼ í™œì„±í™”
                if st.session_state.get("has_email_closing", False):
                    # ê³ ê°ì˜ ê¸ì • ë°˜ì‘ í™•ì¸
                    positive_keywords = [
                        "No, that will be all", "no more", "ì—†ìŠµë‹ˆë‹¤", "ê°ì‚¬í•©ë‹ˆë‹¤", "Thank you", "ã‚ã‚ŠãŒã¨ã†",
                        "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤", "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤", "no additional", "è¿½åŠ ã®è³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“",
                        "ì•Œê² ìŠµë‹ˆë‹¤", "ì•Œê² ì–´ìš”", "ok", "okay", "ë„¤", "yes", "ì¢‹ìŠµë‹ˆë‹¤", "good", "fine", "ê´œì°®ìŠµë‹ˆë‹¤"
                    ]
                    is_positive = any(keyword.lower() in customer_response.lower() for keyword in positive_keywords)
                    
                    if is_positive or L.get('customer_no_more_inquiries', '') in customer_response:
                        # ì„¤ë¬¸ ì¡°ì‚¬ ë²„íŠ¼ í™œì„±í™”ë¥¼ ìœ„í•´ WAIT_CUSTOMER_CLOSING_RESPONSE ë‹¨ê³„ë¡œ ì´ë™
                        st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"
                        st.rerun()
            else:
                # LLMì´ ì—†ëŠ” ê²½ìš° í”Œë˜ê·¸ ì„¤ì •í•˜ì—¬ CUSTOMER_TURN ë‹¨ê³„ì—ì„œ ìˆ˜ë™ ìƒì„± ê°€ëŠ¥í•˜ë„ë¡
                st.session_state.need_customer_response = True
            
            # â­ ìˆ˜ì •: ê³ ê° ë°˜ì‘ ìƒì„± í›„ CUSTOMER_TURN ë‹¨ê³„ë¡œ ì´ë™í•˜ê³  UI ì—…ë°ì´íŠ¸
            st.session_state.sim_stage = "CUSTOMER_TURN"
            st.rerun()
            

        # --- ì–¸ì–´ ì´ê´€ ë²„íŠ¼ ---
        st.markdown("---")
        st.markdown(f"**{L['transfer_header']}**")
        transfer_cols = st.columns(len(LANG) - 1)

        languages = list(LANG.keys())
        languages.remove(current_lang)


        def transfer_session(target_lang: str, current_messages: List[Dict[str, str]]):
            """ì–¸ì–´ ì´ê´€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  ì„¸ì…˜ ì–¸ì–´ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤."""

            # API í‚¤ ì²´í¬ëŠ” run_llm ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ Gemini í‚¤ë¥¼ ìš”êµ¬í•¨
            if not get_api_key("gemini"):
                st.error(LANG[current_lang]["simulation_no_key_warning"].replace('API Key', 'Gemini API Key'))
                # st.stop()
                return

            current_lang_at_start = st.session_state.language  # Source language

            # AHT íƒ€ì´ë¨¸ ì¤‘ì§€
            st.session_state.start_time = None

            # 1. ë¡œë”© ì‹œì‘ (ì‹œê°„ ì–‘í•´ ë©”ì‹œì§€ ì‹œë®¬ë ˆì´ì…˜)
            with st.spinner(L["transfer_loading"]):
                # ì‹¤ì œ ëŒ€ê¸° ì‹œê°„ 5~10ì´ˆ (3~10ë¶„ ì‹œë®¬ë ˆì´ì…˜)
                time.sleep(np.random.uniform(5, 10))

                # 2. ëŒ€í™” ê¸°ë¡ì„ ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¡œ ê°€ê³µ
                history_text = ""
                for msg in current_messages:
                    role = "Customer" if msg["role"].startswith("customer") or msg[
                        "role"] == "initial_query" else "Agent"
                    if msg["role"] in ["initial_query", "customer_rebuttal", "agent_response",
                                       "customer_closing_response"]:
                        history_text += f"{role}: {msg['content']}\n"

                # â­ ìˆ˜ì •: ë¨¼ì € í•µì‹¬ í¬ì¸íŠ¸ë§Œ ìš”ì•½í•œ í›„ ë²ˆì—­
                # ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±
                lang_name_source = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(current_lang_at_start, "Korean")
                summary_prompt = f"""
You are an AI assistant that summarizes customer service conversations. 
Extract ONLY the key points from the conversation below. Keep it concise and focused on:
1. Customer's main inquiry/question
2. Key information provided by the agent
3. Important decisions or outcomes
4. Any unresolved issues

Write the summary in {lang_name_source}. Maximum 200 words. Be brief and to the point.

--- Conversation ---
{history_text}
---

Key Points Summary:
    # =========================
    # 6. ê³ ê° ë°˜ì‘ ìƒì„± ë‹¨ê³„ (CUSTOMER_TURN)
    # =========================
    elif st.session_state.sim_stage == "CUSTOMER_TURN":
        # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
        current_lang = st.session_state.get("language", "ko")
        if current_lang not in ["ko", "en", "ja"]:
            current_lang = "ko"
        L = LANG.get(current_lang, LANG["ko"])
        customer_type_display = st.session_state.get("customer_type_sim_select", L["customer_type_options"][0])
        st.info(L["customer_turn_info"])

        # 1. ê³ ê° ë°˜ì‘ ìƒì„±
        # ì´ë¯¸ ê³ ê° ë°˜ì‘ì´ ìƒì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        last_customer_message = None
        for msg in reversed(st.session_state.simulator_messages):
            if msg.get("role") == "customer" and msg.get("content"):
                last_customer_message = msg.get("content", "")
                break
        
        if last_customer_message is None:
            # ê³ ê° ë°˜ì‘ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒì„±
            with st.spinner(L["generating_customer_response"]):
                customer_response = generate_customer_reaction(st.session_state.language, is_call=False)

            # 2. ëŒ€í™” ë¡œê·¸ ì—…ë°ì´íŠ¸
            st.session_state.simulator_messages.append(
                {"role": "customer", "content": customer_response}
            )
            
            # 3. ìƒì„± ì§í›„ ë°”ë¡œ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
            positive_closing_phrases = [L["customer_positive_response"], L["customer_no_more_inquiries"]]
            is_positive_closing = any(phrase in customer_response for phrase in positive_closing_phrases)
            
            # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
            if L["customer_positive_response"] in customer_response:
                if st.session_state.is_solution_provided:
                    st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
                else:
                    st.session_state.sim_stage = "AGENT_TURN"
            elif is_positive_closing:
                if L['customer_no_more_inquiries'] in customer_response:
                    st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
                else:
                    if st.session_state.is_solution_provided:
                        st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
                    else:
                        st.session_state.sim_stage = "AGENT_TURN"
            elif customer_response.startswith(L["customer_escalation_start"]):
                st.session_state.sim_stage = "ESCALATION_REQUIRED"
            else:
                # ê³ ê°ì´ ì¶”ê°€ ì§ˆë¬¸í•˜ê±°ë‚˜ ì •ë³´ ì œê³µí•œ ê²½ìš° -> ì—ì´ì „íŠ¸ í„´ìœ¼ë¡œ ì´ë™
                st.session_state.sim_stage = "AGENT_TURN"
            
            # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ rerun
            st.rerun()
        else:
            customer_response = last_customer_message

        # 3. ì¢…ë£Œ ì¡°ê±´ ê²€í†  (ì´ë¯¸ ê³ ê° ë°˜ì‘ì´ ìˆëŠ” ê²½ìš°)
        positive_closing_phrases = [L["customer_positive_response"], L["customer_no_more_inquiries"]]
        is_positive_closing = any(phrase in customer_response for phrase in positive_closing_phrases)

        # â­ ì¶”ê°€: ë©”ì¼ ì‘ëŒ€ ì¢…ë£Œ ë¬¸êµ¬ í™•ì¸ (í”Œë˜ê·¸ ë˜ëŠ” ì—ì´ì „íŠ¸ì˜ ë§ˆì§€ë§‰ ì‘ë‹µ í™•ì¸)
        # ë¨¼ì € í”Œë˜ê·¸ í™•ì¸ (ì—ì´ì „íŠ¸ ì‘ë‹µ ì „ì†¡ ì‹œ ì„¤ì •ë¨)
        is_email_closing = st.session_state.get("has_email_closing", False)
        
        # í”Œë˜ê·¸ê°€ ì—†ìœ¼ë©´ ì—ì´ì „íŠ¸ì˜ ë§ˆì§€ë§‰ ì‘ë‹µì—ì„œ ì§ì ‘ í™•ì¸
        if not is_email_closing:
            last_agent_response = None
            for msg in reversed(st.session_state.simulator_messages):
                if msg.get("role") == "agent_response" and msg.get("content"):
                    last_agent_response = msg.get("content", "")
                    break
            
            # ë©”ì¼ ëì¸ì‚¬ ë¬¸êµ¬ íŒ¨í„´ (ë‹¤êµ­ì–´ ì§€ì›) - ë” í¬ê´„ì ì¸ íŒ¨í„´ ì¶”ê°€
            email_closing_patterns = [
                "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì—°ë½", "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì—°ë½",
                "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´", "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´",
                "ì–¸ì œë“ ì§€ ì—°ë½", "ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì„¸ìš”",
                "additional inquiries", "any additional questions", "any further questions",
                "feel free to contact", "please feel free to contact",
                "please don't hesitate to contact", "don't hesitate to contact",
                "please let me know", "let me know", "let me know if",
                "please let me know so", "let me know so",
                "if you have any questions", "if you have any further questions",
                "if you need any assistance", "if you need further assistance",
                "if you encounter any issues", "if you still have", "if you remain unclear",
                "I can assist further", "I can help further", "I can assist",
                "so I can assist", "so I can help", "so I can assist further",
                "è¿½åŠ ã®ã”è³ªå•", "è¿½åŠ ã®ãŠå•ã„åˆã‚ã›", "ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰", "ãŠå•ã„åˆã‚ã›ãŒã”ã–ã„ã¾ã—ãŸã‚‰"
            ]
            
            if last_agent_response:
                is_email_closing = any(pattern.lower() in last_agent_response.lower() for pattern in email_closing_patterns)
                if is_email_closing:
                    st.session_state.has_email_closing = True  # í”Œë˜ê·¸ ì—…ë°ì´íŠ¸

        # â­ ìˆ˜ì •: ë©”ì¼ ëì¸ì‚¬ê°€ í¬í•¨ëœ ê²½ìš°, ê³ ê°ì˜ ê¸ì • ë°˜ì‘ì´ë‚˜ "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤" ë‹µë³€ì„ ì¸ì‹í•˜ë©´ ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë²„íŠ¼ ìë™ í™œì„±í™”
        if is_email_closing:
            # ê³ ê°ì˜ ê¸ì • ë°˜ì‘ ë˜ëŠ” "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤" ë‹µë³€ í™•ì¸
            no_more_keywords = [
                L['customer_no_more_inquiries'],
                "No, that will be all",
                "no more",
                "ì—†ìŠµë‹ˆë‹¤",
                "ê°ì‚¬í•©ë‹ˆë‹¤",
                "Thank you",
                "ã‚ã‚ŠãŒã¨ã†",
                "è¿½åŠ  ë¬¸ì˜ ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤",
                "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤",
                "no additional",
                "è¿½åŠ ã®è³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“",
                "ì•Œê² ìŠµë‹ˆë‹¤",
                "ì•Œê² ì–´ìš”",
                "ok",
                "okay",
                "ë„¤",
                "yes"
            ]
            has_no_more_inquiry = any(keyword.lower() in customer_response.lower() for keyword in no_more_keywords)
            
            # ê¸ì • ë°˜ì‘ í‚¤ì›Œë“œ ì¶”ê°€ (ë” í¬ê´„ì ì¸ ì¸ì‹)
            positive_keywords = [
                "ì•Œê² ìŠµë‹ˆë‹¤", "ì•Œê² ì–´ìš”", "ë„¤", "yes", "ok", "okay", "ê°ì‚¬í•©ë‹ˆë‹¤", "thank you", "ã‚ã‚ŠãŒã¨ã†",
                "ì¢‹ìŠµë‹ˆë‹¤", "good", "fine", "ê´œì°®ìŠµë‹ˆë‹¤", "ì•Œê² ìŠµë‹ˆë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤"
            ]
            is_positive_response = any(keyword.lower() in customer_response.lower() for keyword in positive_keywords)
            
            # ê¸ì • ë°˜ì‘ì´ ìˆê±°ë‚˜ "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤" ë‹µë³€ì´ ìˆìœ¼ë©´ ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë²„íŠ¼ í™œì„±í™”
            if is_positive_closing or has_no_more_inquiry or L['customer_no_more_inquiries'] in customer_response or is_positive_response:
                # ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ê°€ ì•„ì§ ì¶”ê°€ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¶”ê°€
                agent_closing_added = False
                for msg in reversed(st.session_state.simulator_messages):
                    if msg.get("role") == "agent_response":
                        agent_msg_content = msg.get("content", "")
                        if "ê°ì‚¬" in agent_msg_content or "Thank you" in agent_msg_content or "ã‚ã‚ŠãŒã¨ã†" in agent_msg_content:
                            agent_closing_added = True
                        break
                
                if not agent_closing_added:
                    # ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ ë©”ì‹œì§€ ì „ì†¡
                    agent_name = st.session_state.get("agent_name", "000")
                    if current_lang == "ko":
                        agent_closing_msg = f"ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› {agent_name}ì˜€ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”."
                    elif current_lang == "en":
                        agent_closing_msg = f"Thank you for contacting us. This was {agent_name}. Have a great day!"
                    else:  # ja
                        agent_closing_msg = f"ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚æ‹…å½“ã¯{agent_name}ã§ã—ãŸã€‚è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚"
                    
                    # ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    st.session_state.simulator_messages.append(
                        {"role": "agent_response", "content": agent_closing_msg}
                    )
                
                # ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë²„íŠ¼ í™œì„±í™”ë¥¼ ìœ„í•´ WAIT_CUSTOMER_CLOSING_RESPONSE ë‹¨ê³„ë¡œ ì´ë™
                # (ì‹¤ì œë¡œëŠ” ê³ ê° ì‘ë‹µì´ ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ ë°”ë¡œ ì„¤ë¬¸ ì¡°ì‚¬ ë²„íŠ¼ í‘œì‹œ)
                st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"
                st.rerun()
            else:
                # ë©”ì¼ ëì¸ì‚¬ê°€ ìˆì§€ë§Œ ê³ ê°ì´ ì¶”ê°€ ì§ˆë¬¸ì„ í•œ ê²½ìš°
                st.session_state.sim_stage = "AGENT_TURN"
                st.rerun()
        # â­ ìˆ˜ì •: ê³ ê°ì´ "ì•Œê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤"ë¼ê³  ë‹µë³€í–ˆì„ ë•Œ, ì†”ë£¨ì…˜ì´ ì œê³µëœ ê²½ìš°ì—ë§Œ ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë‹¨ê³„ë¡œ ì´ë™
        # ì •í™•í•œ ë¬¸ìì—´ ë¹„êµê°€ ì•„ë‹Œ í¬í•¨ ì—¬ë¶€ë¡œ í™•ì¸ (LLM ì‘ë‹µì´ ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        elif L["customer_positive_response"] in customer_response:
            # ì†”ë£¨ì…˜ì´ ì œê³µëœ ê²½ìš°ì—ë§Œ ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë‹¨ê³„ë¡œ ì´ë™
            if st.session_state.is_solution_provided:
                st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
            else:
                # ì†”ë£¨ì…˜ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ì—ì´ì „íŠ¸ í„´ìœ¼ë¡œ ìœ ì§€
                st.session_state.sim_stage = "AGENT_TURN"
        elif is_positive_closing:
            # ê¸ì • ì¢…ë£Œ ì‘ë‹µ ì²˜ë¦¬
            if L['customer_no_more_inquiries'] in customer_response:
                # â­ ìˆ˜ì •: "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤" ë‹µë³€ ì‹œ ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ë¥¼ í•œ í›„ ì¢…ë£Œí•˜ë„ë¡ ë³€ê²½
                # ë°”ë¡œ ì¢…ë£Œí•˜ì§€ ì•Šê³  WAIT_CLOSING_CONFIRMATION_FROM_AGENT ë‹¨ê³„ë¡œ ì´ë™í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ í›„ ì¢…ë£Œ
                st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
            else:
                # "ì•Œê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤"ì™€ ìœ ì‚¬í•œ ê¸ì • ì‘ë‹µì¸ ê²½ìš°, ì†”ë£¨ì…˜ ì œê³µ ì—¬ë¶€ í™•ì¸
                if st.session_state.is_solution_provided:
                    st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
                else:
                    st.session_state.sim_stage = "AGENT_TURN"


        # â­ ìˆ˜ì •: ê³ ê°ì´ ì•„ì§ ì†”ë£¨ì…˜ì— ë§Œì¡±í•˜ì§€ ì•Šê±°ë‚˜ ì¶”ê°€ ì§ˆë¬¸ì„ í•œ ê²½ìš° (ì¼ë°˜ì ì¸ í„´)
        elif customer_response.startswith(L["customer_escalation_start"]):
            st.session_state.sim_stage = "ESCALATION_REQUIRED"  # ì—ìŠ¤ì»¬ë ˆì´ì…˜ í•„ìš”
        else:
            # ì—ì´ì „íŠ¸ í„´ìœ¼ë¡œ ìœ ì§€ (ê³ ê°ì´ ì¶”ê°€ ì§ˆë¬¸í•˜ê±°ë‚˜ ì •ë³´ ì œê³µ)
            st.session_state.sim_stage = "AGENT_TURN"

        st.session_state.is_solution_provided = False  # ì¢…ë£Œ ë‹¨ê³„ ì§„ì… í›„ í”Œë˜ê·¸ ë¦¬ì…‹

        # ì´ë ¥ ì €ì¥ (ì¢…ë£Œë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì €ì¥)
        # â­ ìˆ˜ì •: "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤" ë‹µë³€ ì‹œì—ëŠ” ì´ë¯¸ ì´ë ¥ ì €ì¥ì„ í–ˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì €ì¥ ë°©ì§€
        if st.session_state.sim_stage != "CLOSING":
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=False,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )

        st.session_state.realtime_hint_text = ""  # íŒíŠ¸ ì´ˆê¸°í™”
        
        # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ rerun
        st.rerun()


    # =========================
    # 7. ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ëŒ€ê¸° (WAIT_CLOSING_CONFIRMATION_FROM_AGENT)
    # =========================
    elif st.session_state.sim_stage == "WAIT_CLOSING_CONFIRMATION_FROM_AGENT":
        # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
        current_lang = st.session_state.get("language", "ko")
        if current_lang not in ["ko", "en", "ja"]:
            current_lang = "ko"
        L = LANG.get(current_lang, LANG["ko"])
        st.success(L["customer_positive_solution_reaction"])

        col_chat_end, col_email_end = st.columns(2)  # ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜

        # [1] ì±„íŒ… - ì¶”ê°€ ë¬¸ì˜ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸° ë²„íŠ¼
        with col_chat_end:
            # [ìˆ˜ì • 1] ë‹¤êµ­ì–´ ë ˆì´ë¸” ì‚¬ìš©
            if st.button(L["send_closing_confirm_button"],
                         key=f"btn_send_closing_confirm_{st.session_state.sim_instance_id}"):
                # â­ ìˆ˜ì •: ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ë¥¼ í¬í•¨í•œ ì¢…ë£Œ ë©”ì‹œì§€ ì „ì†¡
                # ì–¸ì–´ë³„ ê°ì‚¬ ì¸ì‚¬ ë©”ì‹œì§€ ìƒì„±
                agent_name = st.session_state.get("agent_name", "000")
                if current_lang == "ko":
                    closing_msg = f"ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› {agent_name}ì˜€ìŠµë‹ˆë‹¤. {L['customer_closing_confirm']} ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”."
                elif current_lang == "en":
                    closing_msg = f"Thank you for contacting us. This was {agent_name}. {L['customer_closing_confirm']} Have a great day!"
                else:  # ja
                    closing_msg = f"ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚æ‹…å½“ã¯{agent_name}ã§ã—ãŸã€‚{L['customer_closing_confirm']} è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚"

                # ì—ì´ì „íŠ¸ ì‘ë‹µìœ¼ë¡œ ë¡œê·¸ ê¸°ë¡
                st.session_state.simulator_messages.append(
                    {"role": "agent_response", "content": closing_msg}
                )

                # [ì¶”ê°€] TTS ë²„íŠ¼ ë Œë”ë§ì„ ìœ„í•´ sleep/rerun ê°•ì œ
                time.sleep(0.1)
                st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"
                st.rerun()

        # [2] ì´ë©”ì¼ - ìƒë‹´ ì¢…ë£Œ ë²„íŠ¼ (ì¦‰ì‹œ ì¢…ë£Œ)
        with col_email_end:
            # [ìˆ˜ì • 1] ë‹¤êµ­ì–´ ë ˆì´ë¸” ì‚¬ìš©
            if st.button(L["button_email_end_chat"], key=f"btn_email_end_chat_{st.session_state.sim_instance_id}"):
                # AHT íƒ€ì´ë¨¸ ì •ì§€
                st.session_state.start_time = None

                # [ìˆ˜ì • 1] ë‹¤êµ­ì–´ ë ˆì´ë¸” ì‚¬ìš©
                end_msg = L["prompt_survey"]
                st.session_state.simulator_messages.append(
                    {"role": "system_end", "content": "(ì‹œìŠ¤í…œ: ì´ë©”ì¼ ìƒë‹´ ì¢…ë£Œ) " + end_msg}
                )

                # [ì¶”ê°€] TTS ë²„íŠ¼ ë Œë”ë§ì„ ìœ„í•´ sleep/rerun ê°•ì œ
                time.sleep(0.1)
                st.session_state.is_chat_ended = True
                st.session_state.sim_stage = "CLOSING"  # ë°”ë¡œ CLOSINGìœ¼ë¡œ ì „í™˜

    # =========================
    # 8. ê³ ê° ìµœì¢… ì‘ë‹µ ìƒì„± ë° ì²˜ë¦¬ (WAIT_CUSTOMER_CLOSING_RESPONSE)
    # =========================
    elif st.session_state.sim_stage == "WAIT_CUSTOMER_CLOSING_RESPONSE":
        # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
        current_lang = st.session_state.get("language", "ko")
        if current_lang not in ["ko", "en", "ja"]:
            current_lang = "ko"
        L = LANG.get(current_lang, LANG["ko"])
        customer_type_display = st.session_state.get("customer_type_sim_select", L["customer_type_options"][0])
        
        # â­ ì¶”ê°€: ë©”ì¼ ì‘ëŒ€ ì¢…ë£Œ ë¬¸êµ¬ í™•ì¸ (ì—ì´ì „íŠ¸ì˜ ë§ˆì§€ë§‰ ì‘ë‹µì— "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì„¸ìš”" ê°™ì€ ë¬¸êµ¬ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸)
        last_agent_response = None
        for msg in reversed(st.session_state.simulator_messages):
            if msg.get("role") == "agent_response" and msg.get("content"):
                last_agent_response = msg.get("content", "")
                break
        
        # ë©”ì¼ ëì¸ì‚¬ ë¬¸êµ¬ íŒ¨í„´ (ë‹¤êµ­ì–´ ì§€ì›) - ë” í¬ê´„ì ì¸ íŒ¨í„´ ì¶”ê°€
        email_closing_patterns = [
            "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì—°ë½",
            "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ì—°ë½",
            "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½",
            "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½",
            "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´",
            "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´",
            "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´",
            "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ë©´",
            "ì–¸ì œë“ ì§€ ì—°ë½",
            "ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì„¸ìš”",
            "ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤",
            "additional inquiries",
            "any additional questions",
            "any further questions",
            "feel free to contact",
            "please feel free to contact",
            "please don't hesitate to contact",
            "don't hesitate to contact",
            "è¿½åŠ ã®ã”è³ªå•",
            "è¿½åŠ ã®ãŠå•ã„åˆã‚ã›",
            "ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰",
            "ãŠå•ã„åˆã‚ã›ãŒã”ã–ã„ã¾ã—ãŸã‚‰"
        ]
        
        is_email_closing = False
        if last_agent_response:
            is_email_closing = any(pattern.lower() in last_agent_response.lower() for pattern in email_closing_patterns)
        
        # â­ ìˆ˜ì •: ì´ë¯¸ ê³ ê° ì‘ë‹µì´ ìƒì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        last_customer_message = None
        for msg in reversed(st.session_state.simulator_messages):
            if msg.get("role") == "customer_rebuttal":
                last_customer_message = msg.get("content", "")
                break
            # â­ ì¶”ê°€: customer ì—­í• ì˜ ë©”ì‹œì§€ë„ í™•ì¸ (ë©”ì¼ ëì¸ì‚¬ê°€ í¬í•¨ëœ ê²½ìš° CUSTOMER_TURNì—ì„œ ì´ë¯¸ ê³ ê° ì‘ë‹µì´ ìƒì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
            elif msg.get("role") == "customer" and is_email_closing:
                last_customer_message = msg.get("content", "")
                break
        
        # ê³ ê° ì‘ë‹µì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ìƒì„±
        if last_customer_message is None:
            # ê³ ê° ë‹µë³€ ìë™ ìƒì„± (LLM Key ê²€ì¦ í¬í•¨)
            if not st.session_state.is_llm_ready:
                st.warning(L["llm_key_missing_customer_response"])
                if st.button(L["customer_generate_response_button"], key="btn_generate_final_response"):
                    st.session_state.sim_stage = "AGENT_TURN"
                    st.rerun()
                st.stop()
            
            # LLMì´ ì¤€ë¹„ëœ ê²½ìš° ê³ ê° ì‘ë‹µ ìƒì„±
            st.info(L["agent_confirmed_additional_inquiry"])
            with st.spinner(L["generating_customer_response"]):
                final_customer_reaction = generate_customer_closing_response(st.session_state.language)

            # ë¡œê·¸ ê¸°ë¡
            st.session_state.simulator_messages.append(
                {"role": "customer_rebuttal", "content": final_customer_reaction}
            )
            last_customer_message = final_customer_reaction
        
        # ê³ ê° ì‘ë‹µì— ë”°ë¼ ì²˜ë¦¬ (ìƒì„± ì§í›„ ë˜ëŠ” ì´ë¯¸ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì²˜ë¦¬)
        if last_customer_message is None:
            # ê³ ê° ì‘ë‹µì´ ì—†ëŠ” ê²½ìš° (ì´ë¯¸ ìƒì„±í–ˆëŠ”ë°ë„ Noneì¸ ê²½ìš°ëŠ” ì—ëŸ¬)
            st.warning(L["customer_response_generation_failed"])
        else:
            final_customer_reaction = last_customer_message
            
            # (A) "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤" ê²½ë¡œ -> ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ í›„ ë²„íŠ¼ í‘œì‹œ
            # ë” ìœ ì—°í•œ ë§¤ì¹­ì„ ìœ„í•´ í‚¤ì›Œë“œ ì²´í¬ ì¶”ê°€
            no_more_keywords = [
                L['customer_no_more_inquiries'],
                "No, that will be all",
                "no more",
                "ì—†ìŠµë‹ˆë‹¤",
                "ê°ì‚¬í•©ë‹ˆë‹¤",
                "çµæ§‹ã§ã™",
                "ã‚ã‚ŠãŒã¨ã†",
                "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤",
                "ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤",
                "no additional",
                "è¿½åŠ ã®è³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“"
            ]
            has_no_more_inquiry = any(keyword.lower() in final_customer_reaction.lower() for keyword in no_more_keywords)
            
            # â­ ì¶”ê°€: ë©”ì¼ ëì¸ì‚¬ê°€ í¬í•¨ëœ ê²½ìš°, ê³ ê°ì˜ ê¸ì • ë°˜ì‘ì´ë‚˜ "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ ì—†ìŠµë‹ˆë‹¤" ë‹µë³€ì„ ì¸ì‹í•˜ë©´ ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë²„íŠ¼ ìë™ í™œì„±í™”
            # ê¸ì • ë°˜ì‘ í‚¤ì›Œë“œ ì¶”ê°€
            positive_keywords = [
                "ì•Œê² ìŠµë‹ˆë‹¤", "ì•Œê² ì–´ìš”", "ë„¤", "yes", "ok", "okay", "ê°ì‚¬í•©ë‹ˆë‹¤", "thank you", "ã‚ã‚ŠãŒã¨ã†"
            ]
            is_positive_response = any(keyword.lower() in final_customer_reaction.lower() for keyword in positive_keywords)
            
            if is_email_closing and (has_no_more_inquiry or L['customer_no_more_inquiries'] in final_customer_reaction or is_positive_response):
                # ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ê°€ ì•„ì§ ì¶”ê°€ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¶”ê°€
                agent_closing_added = False
                for msg in reversed(st.session_state.simulator_messages):
                    if msg.get("role") == "agent_response":
                        agent_msg_content = msg.get("content", "")
                        if "ê°ì‚¬" in agent_msg_content or "Thank you" in agent_msg_content or "ã‚ã‚ŠãŒã¨ã†" in agent_msg_content:
                            agent_closing_added = True
                        break
                
                if not agent_closing_added:
                    # ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ ë©”ì‹œì§€ ì „ì†¡
                    agent_name = st.session_state.get("agent_name", "000")
                    if current_lang == "ko":
                        agent_closing_msg = f"ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› {agent_name}ì˜€ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”."
                    elif current_lang == "en":
                        agent_closing_msg = f"Thank you for contacting us. This was {agent_name}. Have a great day!"
                    else:  # ja
                        agent_closing_msg = f"ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚æ‹…å½“ã¯{agent_name}ã§ã—ãŸã€‚è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚"
                    
                    # ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    st.session_state.simulator_messages.append(
                        {"role": "agent_response", "content": agent_closing_msg}
                    )
                
                # ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë²„íŠ¼ í‘œì‹œ
                st.markdown("---")
                st.success(L["no_more_inquiries_confirmed"])
                st.markdown(f"### {L['consultation_end_header']}")
                st.info(L["click_survey_button_to_end"])
                st.markdown("---")
                
                # ë²„íŠ¼ì„ ì¤‘ì•™ì— í¬ê²Œ í‘œì‹œ
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    end_chat_button = st.button(
                        L["sim_end_chat_button"], 
                        key="btn_final_end_chat_email_closing", 
                        use_container_width=True, 
                        type="primary"
                    )
                
                if end_chat_button:
                    # AHT íƒ€ì´ë¨¸ ì •ì§€
                    st.session_state.start_time = None

                    # ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë©”ì‹œì§€ ì¶”ê°€
                    end_msg = L["prompt_survey"]
                    st.session_state.simulator_messages.append(
                        {"role": "system_end", "content": end_msg}
                    )

                    # ì±„íŒ… ì¢…ë£Œ ì²˜ë¦¬
                    st.session_state.is_chat_ended = True
                    st.session_state.sim_stage = "CLOSING"
                    
                    # ì´ë ¥ ì €ì¥
                    save_simulation_history_local(
                        st.session_state.customer_query_text_area, customer_type_display,
                        st.session_state.simulator_messages, is_chat_ended=True,
                        attachment_context=st.session_state.sim_attachment_context_for_llm,
                    )
                    
                    st.session_state.realtime_hint_text = ""  # íŒíŠ¸ ì´ˆê¸°í™”
                    st.rerun()  # ë²„íŠ¼ í´ë¦­ í›„ UI ì—…ë°ì´íŠ¸
            # ë©”ì¼ ëì¸ì‚¬ê°€ í¬í•¨ëœ ê²½ìš° ì—¬ê¸°ì„œ ì²˜ë¦¬ ì™„ë£Œ, ë‹¤ë¥¸ ë¡œì§ì€ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
            elif L['customer_no_more_inquiries'] in final_customer_reaction or has_no_more_inquiry:
                # â­ ìˆ˜ì •: ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ê°€ ì•„ì§ ì¶”ê°€ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¶”ê°€
                agent_closing_added = False
                for msg in reversed(st.session_state.simulator_messages):
                    if msg.get("role") == "agent_response":
                        # ì´ë¯¸ ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ê°€ ìˆëŠ”ì§€ í™•ì¸
                        agent_msg_content = msg.get("content", "")
                        if "ê°ì‚¬" in agent_msg_content or "Thank you" in agent_msg_content or "ã‚ã‚ŠãŒã¨ã†" in agent_msg_content:
                            agent_closing_added = True
                        break
                
                if not agent_closing_added:
                    # â­ ì¶”ê°€: ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ ë©”ì‹œì§€ ì „ì†¡
                    agent_name = st.session_state.get("agent_name", "000")
                    if current_lang == "ko":
                        agent_closing_msg = f"ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› {agent_name}ì˜€ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”."
                    elif current_lang == "en":
                        agent_closing_msg = f"Thank you for contacting us. This was {agent_name}. Have a great day!"
                    else:  # ja
                        agent_closing_msg = f"ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚æ‹…å½“ã¯{agent_name}ã§ã—ãŸã€‚è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚"
                    
                    # ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    st.session_state.simulator_messages.append(
                        {"role": "agent_response", "content": agent_closing_msg}
                    )
                
                # â­ ìˆ˜ì •: í˜„ì¬ ë‹¨ê³„ì—ì„œ ë°”ë¡œ ë²„íŠ¼ í‘œì‹œ (FINAL_CLOSING_ACTIONìœ¼ë¡œ ì´ë™í•˜ì§€ ì•ŠìŒ)
                st.markdown("---")
                st.success(L["no_more_inquiries_confirmed"])
                st.markdown(f"### {L['consultation_end_header']}")
                st.info(L["click_survey_button_to_end"])
                st.markdown("---")
                
                # ë²„íŠ¼ì„ ì¤‘ì•™ì— í¬ê²Œ í‘œì‹œ
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    end_chat_button = st.button(
                        L["sim_end_chat_button"], 
                        key="btn_final_end_chat_in_wait", 
                        use_container_width=True, 
                        type="primary"
                    )
                
                if end_chat_button:
                    # AHT íƒ€ì´ë¨¸ ì •ì§€
                    st.session_state.start_time = None

                    # ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë©”ì‹œì§€ ì¶”ê°€
                    end_msg = L["prompt_survey"]
                    st.session_state.simulator_messages.append(
                        {"role": "system_end", "content": end_msg}
                    )

                    # ì±„íŒ… ì¢…ë£Œ ì²˜ë¦¬
                    st.session_state.is_chat_ended = True
                    st.session_state.sim_stage = "CLOSING"
                    
                    # ì´ë ¥ ì €ì¥
                    save_simulation_history_local(
                        st.session_state.customer_query_text_area, customer_type_display,
                        st.session_state.simulator_messages, is_chat_ended=True,
                        attachment_context=st.session_state.sim_attachment_context_for_llm,
                    )
                    
                    st.session_state.realtime_hint_text = ""  # íŒíŠ¸ ì´ˆê¸°í™”
                    st.rerun()  # ë²„íŠ¼ í´ë¦­ í›„ UI ì—…ë°ì´íŠ¸
            # (B) "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ë„ ìˆìŠµë‹ˆë‹¤" ê²½ë¡œ -> AGENT_TURNìœ¼ë¡œ ë³µê·€
            elif L['customer_has_additional_inquiries'] in final_customer_reaction:
                st.session_state.sim_stage = "AGENT_TURN"
                save_simulation_history_local(
                    st.session_state.customer_query_text_area, customer_type_display,
                    st.session_state.simulator_messages, is_chat_ended=False,
                    attachment_context=st.session_state.sim_attachment_context_for_llm,
                )
                st.session_state.realtime_hint_text = ""
                st.rerun()  # AGENT_TURNìœ¼ë¡œ ì´ë™ í›„ UI ì—…ë°ì´íŠ¸
            else:
                # ê³ ê° ì‘ë‹µì´ ìƒì„±ë˜ì—ˆì§€ë§Œ ì¡°ê±´ì— ë§ì§€ ì•ŠëŠ” ê²½ìš°ì—ë„ ë²„íŠ¼ í‘œì‹œ
                # (ê¸°ë³¸ì ìœ¼ë¡œ "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤"ë¡œ ê°„ì£¼)
                # â­ ìˆ˜ì •: fallback ê²½ë¡œì—ì„œë„ ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ ë©”ì‹œì§€ ì¶”ê°€
                agent_closing_added = False
                for msg in reversed(st.session_state.simulator_messages):
                    if msg.get("role") == "agent_response":
                        # ì´ë¯¸ ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ê°€ ìˆëŠ”ì§€ í™•ì¸
                        agent_msg_content = msg.get("content", "")
                        if "ê°ì‚¬" in agent_msg_content or "Thank you" in agent_msg_content or "ã‚ã‚ŠãŒã¨ã†" in agent_msg_content:
                            agent_closing_added = True
                        break
                
                if not agent_closing_added:
                    # â­ ì¶”ê°€: ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ ë©”ì‹œì§€ ì „ì†¡
                    agent_name = st.session_state.get("agent_name", "000")
                    if current_lang == "ko":
                        agent_closing_msg = f"ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› {agent_name}ì˜€ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”."
                    elif current_lang == "en":
                        agent_closing_msg = f"Thank you for contacting us. This was {agent_name}. Have a great day!"
                    else:  # ja
                        agent_closing_msg = f"ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚æ‹…å½“ã¯{agent_name}ã§ã—ãŸã€‚è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚"
                    
                    # ì—ì´ì „íŠ¸ ê°ì‚¬ ì¸ì‚¬ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    st.session_state.simulator_messages.append(
                        {"role": "agent_response", "content": agent_closing_msg}
                    )
                
                st.markdown("---")
                st.success(L["no_more_inquiries_confirmed"])
                st.markdown(f"### {L['consultation_end_header']}")
                st.info(L["click_survey_button_to_end"])
                st.markdown("---")
                
                col1, col2, col3 = st.columns([1, 3, 1])
                with col2:
                    end_chat_button = st.button(
                        L["sim_end_chat_button"], 
                        key="btn_final_end_chat_fallback", 
                        use_container_width=True, 
                        type="primary"
                    )
                
                if end_chat_button:
                    # AHT íƒ€ì´ë¨¸ ì •ì§€
                    st.session_state.start_time = None
                    
                    # ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë©”ì‹œì§€ ì¶”ê°€
                    end_msg = L["prompt_survey"]
                    st.session_state.simulator_messages.append(
                        {"role": "system_end", "content": end_msg}
                    )
                    
                    # ì±„íŒ… ì¢…ë£Œ ì²˜ë¦¬
                    st.session_state.is_chat_ended = True
                    st.session_state.sim_stage = "CLOSING"
                    
                    # ì´ë ¥ ì €ì¥
                    save_simulation_history_local(
                        st.session_state.customer_query_text_area, customer_type_display,
                        st.session_state.simulator_messages, is_chat_ended=True,
                        attachment_context=st.session_state.sim_attachment_context_for_llm,
                    )
                    
                    st.session_state.realtime_hint_text = ""  # íŒíŠ¸ ì´ˆê¸°í™”
                    st.rerun()  # ë²„íŠ¼ í´ë¦­ í›„ UI ì—…ë°ì´íŠ¸

    # =========================
    # 9. ìµœì¢… ì¢…ë£Œ í–‰ë™ (FINAL_CLOSING_ACTION)
    # =========================
    elif st.session_state.sim_stage == "FINAL_CLOSING_ACTION":
        # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
        current_lang = st.session_state.get("language", "ko")
        if current_lang not in ["ko", "en", "ja"]:
            current_lang = "ko"
        L = LANG.get(current_lang, LANG["ko"])
        
        # â­ ìˆ˜ì •: ëª…í™•í•œ ì•ˆë‚´ ë©”ì‹œì§€ì™€ í•¨ê»˜ ë²„íŠ¼ í‘œì‹œ
        st.markdown("---")
        st.success(L["no_more_inquiries_confirmed"])
        st.markdown(f"### {L['consultation_end_header']}")
        st.info(L["click_survey_button_to_end"])
        st.markdown("---")
        
        # ë²„íŠ¼ì„ ì¤‘ì•™ì— í¬ê²Œ í‘œì‹œ
        col1, col2, col3 = st.columns([1, 3, 1])
        with col2:
            end_chat_button = st.button(
                L["sim_end_chat_button"], 
                key="btn_final_end_chat", 
                use_container_width=True, 
                type="primary"
            )
        
        if end_chat_button:
            # AHT íƒ€ì´ë¨¸ ì •ì§€
            st.session_state.start_time = None

            # ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë©”ì‹œì§€ ì¶”ê°€
            end_msg = L["prompt_survey"]
            st.session_state.simulator_messages.append(
                {"role": "system_end", "content": end_msg}
            )

            # ì±„íŒ… ì¢…ë£Œ ì²˜ë¦¬
            st.session_state.is_chat_ended = True
            st.session_state.sim_stage = "CLOSING"
            
            # ì´ë ¥ ì €ì¥
            customer_type_display = st.session_state.get("customer_type_sim_select", L["customer_type_options"][0])
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=True,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )
            
            st.session_state.realtime_hint_text = ""  # íŒíŠ¸ ì´ˆê¸°í™”

# ========================================
# ì „í™” ì‹œë®¬ë ˆì´í„° ë¡œì§
# ========================================

elif feature_selection == L["sim_tab_phone"]:
    st.header(L["phone_header"])
    st.markdown(L["simulator_desc"])

    current_lang = st.session_state.language
    L = LANG[current_lang]



    # ========================================
    # AHT íƒ€ì´ë¨¸ (IN_CALL ìƒíƒœì—ì„œë§Œ ë™ì‘)
    # ========================================
    if st.session_state.call_sim_stage == "IN_CALL":
        # AHT íƒ€ì´ë¨¸ ê³„ì‚° ë¡œì§
        col_timer, col_duration = st.columns([1, 4])

        if st.session_state.start_time is not None:
            now = datetime.now()

            # Hold ì¤‘ì´ë¼ë©´, Hold ìƒíƒœê°€ ëœ ì´í›„ì˜ ì‹œê°„ì„ í˜„ì¬ total_hold_durationì— ë”í•˜ì§€ ì•ŠìŒ (Resume ì‹œ ì •ì‚°)
            if st.session_state.is_on_hold and st.session_state.hold_start_time:
                # Hold ì¤‘ì´ì§€ë§Œ AHT íƒ€ì´ë¨¸ëŠ” ê³„ì† í˜ëŸ¬ê°€ì•¼ í•˜ë¯€ë¡œ, Hold ì‹œê°„ì€ ì œì™¸í•˜ì§€ ì•Šê³  ìµœì¢… AHT ê³„ì‚°ì—ë§Œ ì‚¬ìš©
                elapsed_time_total = now - st.session_state.start_time
            else:
                elapsed_time_total = now - st.session_state.start_time

            # â­ AHTëŠ” í†µí™” ì‹œì‘ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ì´ ê²½ê³¼ ì‹œê°„ì…ë‹ˆë‹¤.
            total_seconds = elapsed_time_total.total_seconds()
            total_seconds = max(0, total_seconds)  # ìŒìˆ˜ ë°©ì§€

            # ì‹œê°„ í˜•ì‹ í¬ë§·íŒ…
            minutes = int(total_seconds // 60)
            seconds = int(total_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            # ê²½ê³  ê¸°ì¤€
            if total_seconds > 900:  # 15ë¶„
                delta_str = L["timer_info_risk"]
                delta_color = "inverse"
            elif total_seconds > 600:  # 10ë¶„
                delta_str = L["timer_info_warn"]
                delta_color = "off"
            else:
                delta_str = L["timer_info_ok"]
                delta_color = "normal"

                with col_timer:
                    # AHT íƒ€ì´ë¨¸ í‘œì‹œ
                    st.metric(L["timer_metric"], time_str, delta=delta_str, delta_color=delta_color)

                # â­ ìˆ˜ì •: AHT íƒ€ì´ë¨¸ ì‹¤ì‹œê°„ ê°±ì‹ ì„ ìœ„í•œ ê°•ì œ ì¬ì‹¤í–‰ ë¡œì§ ì¶”ê°€
                # í†µí™” ì¤‘ì´ê³ , Hold ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸í•˜ì—¬ ì‹¤ì‹œê°„ì„±ì„ í™•ë³´
                if not st.session_state.is_on_hold and total_seconds < 1000:
                    time.sleep(1)

        # ========================================
        # í™”ë©´ êµ¬ë¶„ (ì• ë‹ˆë©”ì´ì…˜ / CC)
        # ========================================
    col_video, col_cc = st.columns([1, 2])

    with col_video:
        st.subheader(f"ğŸ“º {L['customer_video_simulation']}")

        if st.session_state.call_sim_stage == "WAITING_CALL":
            st.info("í†µí™” ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")

        elif st.session_state.call_sim_stage == "CALL_ENDED":
            st.info("í†µí™” ì¢…ë£Œ")

        else:
            # â­ ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ ì˜µì…˜ ì¶”ê°€ (ë¡œì»¬ ê²½ë¡œ ì§€ì›)
            # í•­ìƒ í¼ì³ì§„ ìƒíƒœë¡œ í‘œì‹œí•˜ì—¬ ë¹„ë””ì˜¤ë¥¼ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ í•¨
            with st.expander(L["video_upload_expander"], expanded=True):
                # ë¹„ë””ì˜¤ ë™ê¸°í™” í™œì„±í™” ì—¬ë¶€
                st.session_state.is_video_sync_enabled = st.checkbox(
                    L["video_sync_enable"],
                    value=st.session_state.is_video_sync_enabled,
                    key="video_sync_checkbox"
                )
                
                # OpenAI/Gemini ê¸°ë°˜ ì˜ìƒ RAG ì„¤ëª…
                st.markdown("---")
                st.markdown(f"**{L['video_rag_title']}**")
                st.success(L["video_rag_desc"])
                
                # ê°€ìƒ íœ´ë¨¼ ê¸°ìˆ ì€ í˜„ì¬ ë¹„í™œì„±í™” (OpenAI/Gemini ê¸°ë°˜ ì˜ìƒ RAG ì‚¬ìš©)
                st.session_state.virtual_human_enabled = False
                
                # ì„±ë³„ ë° ê°ì • ìƒíƒœë³„ ë¹„ë””ì˜¤ ì—…ë¡œë“œ
                st.markdown(f"**{L['video_gender_emotion_setting']}**")
                col_gender_video, col_emotion_video = st.columns(2)
                
                with col_gender_video:
                    video_gender = st.radio(L["video_gender_label"], [L["video_gender_male"], L["video_gender_female"]], key="video_gender_select", horizontal=True)
                    gender_key = "male" if video_gender == L["video_gender_male"] else "female"
                
                with col_emotion_video:
                    video_emotion = st.selectbox(
                        L["video_emotion_label"],
                        ["NEUTRAL", "HAPPY", "ANGRY", "ASKING", "SAD"],
                        key="video_emotion_select"
                    )
                    emotion_key = video_emotion.lower()
                
                # í•´ë‹¹ ì¡°í•©ì˜ ë¹„ë””ì˜¤ ì—…ë¡œë“œ
                video_key = f"video_{gender_key}_{emotion_key}"
                uploaded_video = st.file_uploader(
                    L["video_upload_label"].format(gender=video_gender, emotion=video_emotion),
                    type=["mp4", "webm", "ogg"],
                    key=f"customer_video_uploader_{gender_key}_{emotion_key}"
                )
                
                # â­ Gemini ì œì•ˆ: ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì§ì ‘ ì €ì¥ (íŒŒì¼ ì €ì¥ì€ ì˜µì…˜)
                upload_key = f"last_uploaded_video_{gender_key}_{emotion_key}"
                video_bytes_key = f"video_bytes_{gender_key}_{emotion_key}"  # ë°”ì´íŠ¸ ë°ì´í„° ì €ì¥ í‚¤
                
                if uploaded_video is not None:
                    # íŒŒì¼ì´ ìƒˆë¡œ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸ (íŒŒì¼ëª…ìœ¼ë¡œ ë¹„êµ)
                    current_upload_name = uploaded_video.name if hasattr(uploaded_video, 'name') else None
                    last_upload_info = st.session_state.get(upload_key, None)
                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° 'name' í‚¤ì—ì„œ íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
                    if isinstance(last_upload_info, dict):
                        last_upload_name = last_upload_info.get('name', None)
                    else:
                        last_upload_name = last_upload_info
                    
                    # ìƒˆ íŒŒì¼ì´ê±°ë‚˜ ì´ì „ê³¼ ë‹¤ë¥¸ íŒŒì¼ì¸ ê²½ìš°ì—ë§Œ ì €ì¥
                    if current_upload_name != last_upload_name:
                        try:
                            # ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ë¥¼ ì¦‰ì‹œ ì½ê¸° (rerun ì „ì— ì²˜ë¦¬)
                            video_bytes = uploaded_video.read()
                            current_upload_size = len(video_bytes)
                            
                            if not video_bytes or len(video_bytes) == 0:
                                st.error(L["video_empty_error"])
                            else:
                                # íŒŒì¼ëª… ë° í™•ì¥ì ê²°ì •
                                uploaded_filename = uploaded_video.name if hasattr(uploaded_video, 'name') else f"{gender_key}_{emotion_key}.mp4"
                                file_ext = os.path.splitext(uploaded_filename)[1].lower() if uploaded_filename else ".mp4"
                                if file_ext not in ['.mp4', '.webm', '.ogg', '.mpeg4']:
                                    file_ext = ".mp4"
                                
                                # MIME íƒ€ì… ê²°ì •
                                mime_type = uploaded_video.type if hasattr(uploaded_video, 'type') else f"video/{file_ext.lstrip('.')}"
                                if not mime_type or mime_type == "application/octet-stream":
                                    mime_type = f"video/{file_ext.lstrip('.')}"
                                
                                # â­ 1ì°¨ í•´ê²°ì±…: ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì§ì ‘ ì €ì¥ (ê°€ì¥ ì•ˆì •ì )
                                st.session_state[video_bytes_key] = video_bytes
                                st.session_state[video_key] = video_bytes_key  # ê²½ë¡œ ëŒ€ì‹  ë°”ì´íŠ¸ í‚¤ ì €ì¥
                                st.session_state[upload_key] = {
                                    'name': current_upload_name,
                                    'size': current_upload_size,
                                    'mime': mime_type,
                                    'ext': file_ext
                                }
                                
                                file_size_mb = current_upload_size / (1024 * 1024)
                                st.success(L["video_bytes_saved"].format(name=current_upload_name, size=f"{file_size_mb:.2f}"))
                                
                                # â­ ì¦‰ì‹œ ë¯¸ë¦¬ë³´ê¸° (ë°”ì´íŠ¸ ë°ì´í„° ì§ì ‘ ì‚¬ìš©)
                                try:
                                    st.video(video_bytes, format=mime_type, autoplay=False, loop=False, muted=False)
                                except Exception as video_error:
                                    st.warning(f"âš ï¸ {L.get('video_preview_error', 'ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜')}: {video_error}")
                                    # MIME íƒ€ì…ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì‹œë„
                                    try:
                                        st.video(video_bytes, format=f"video/{file_ext.lstrip('.')}", autoplay=False, loop=False, muted=False)
                                    except:
                                        st.error(L["video_playback_error"])
                                
                                # â­ ì˜µì…˜: íŒŒì¼ ì €ì¥ë„ ì‹œë„ (ë°±ì—…ìš©, ì‹¤íŒ¨í•´ë„ ë°”ì´íŠ¸ëŠ” ì´ë¯¸ ì €ì¥ë¨)
                                try:
                                    video_dir = os.path.join(DATA_DIR, "videos")
                                    os.makedirs(video_dir, exist_ok=True)
                                    video_filename = f"{gender_key}_{emotion_key}{file_ext}"
                                    video_path = os.path.join(video_dir, video_filename)
                                    
                                    # íŒŒì¼ ì €ì¥ ì‹œë„ (ê¶Œí•œ ë¬¸ì œê°€ ìˆì–´ë„ ë°”ì´íŠ¸ëŠ” ì´ë¯¸ ì €ì¥ë¨)
                                    try:
                                        with open(video_path, "wb") as f:
                                            f.write(video_bytes)
                                            f.flush()
                                        st.info(f"ğŸ“‚ íŒŒì¼ë„ ì €ì¥ë¨: {video_path}")
                                    except Exception as save_error:
                                        st.info(f"ğŸ’¡ íŒŒì¼ ì €ì¥ì€ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤ (ë°”ì´íŠ¸ ë°ì´í„°ëŠ” ë©”ëª¨ë¦¬ì— ì €ì¥ë¨): {save_error}")
                                except:
                                    pass  # íŒŒì¼ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë°”ì´íŠ¸ëŠ” ì´ë¯¸ ì €ì¥ë¨
                                
                        except Exception as e:
                            st.error(L["video_upload_error"].format(error=str(e)))
                            import traceback
                            st.code(traceback.format_exc())
                
                # ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ê°€ ìˆìœ¼ë©´ í˜„ì¬ ì„ íƒëœ ì¡°í•©ì˜ ë¹„ë””ì˜¤ í‘œì‹œ
                st.markdown("---")
                st.markdown(f"**{L['video_current_selection'].format(gender=video_gender, emotion=video_emotion)}**")
                
                # â­ Gemini ì œì•ˆ: ì„¸ì…˜ ìƒíƒœì—ì„œ ë°”ì´íŠ¸ ë°ì´í„° ì§ì ‘ ì¡°íšŒ
                video_bytes_key = f"video_bytes_{gender_key}_{emotion_key}"
                current_video_bytes = st.session_state.get(video_bytes_key, None)
                
                if current_video_bytes:
                    # ë°”ì´íŠ¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì§ì ‘ ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
                    upload_info = st.session_state.get(upload_key, {})
                    mime_type = upload_info.get('mime', 'video/mp4')
                    file_ext = upload_info.get('ext', '.mp4')
                    
                    st.success(f"âœ… ë¹„ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„° ë°œê²¬: {upload_info.get('name', 'ì—…ë¡œë“œëœ ë¹„ë””ì˜¤')}")
                    try:
                        st.video(current_video_bytes, format=mime_type, autoplay=False, loop=False, muted=False)
                        st.caption(L["video_auto_play_info"].format(gender=video_gender, emotion=video_emotion))
                    except Exception as e:
                        st.warning(f"ë¹„ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")
                        # MIME íƒ€ì…ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì‹œë„
                        try:
                            st.video(current_video_bytes, format=f"video/{file_ext.lstrip('.')}", autoplay=False, loop=False, muted=False)
                        except:
                            st.error(L["video_playback_error"])
                else:
                    # ë°”ì´íŠ¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ íŒŒì¼ ê²½ë¡œë¡œ ì‹œë„ (í•˜ìœ„ í˜¸í™˜ì„±)
                    current_video_path = get_video_path_by_avatar(
                        gender_key,
                        video_emotion,
                        is_speaking=False,
                        gesture="NONE"
                    )
                    
                    if current_video_path and os.path.exists(current_video_path):
                        st.success(f"âœ… ë¹„ë””ì˜¤ íŒŒì¼ ë°œê²¬: {os.path.basename(current_video_path)}")
                        try:
                            with open(current_video_path, "rb") as f:
                                existing_video_bytes = f.read()
                            st.video(existing_video_bytes, format="video/mp4", autoplay=False, loop=False, muted=False)
                            st.caption(L["video_auto_play_info"].format(gender=video_gender, emotion=video_emotion))
                        except Exception as e:
                            st.warning(f"ë¹„ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")
                    else:
                        st.info(L["video_upload_prompt"].format(filename=f"{gender_key}_{emotion_key}.mp4"))
                    
                    # ë””ë²„ê¹… ì •ë³´: ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ ëª©ë¡ í‘œì‹œ
                    video_dir = os.path.join(DATA_DIR, "videos")
                    st.caption(L["video_save_path"] + f" {video_dir}")
                    
                    if os.path.exists(video_dir):
                        all_videos = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.webm', '.ogg'))]
                        if all_videos:
                            st.caption(f"{L['video_uploaded_files']} ({len(all_videos)}ê°œ):")
                            for vid in all_videos:
                                st.caption(f"  - {vid}")
                            
                            # ë¹„ìŠ·í•œ ë¹„ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                            similar_videos = [
                                f for f in all_videos
                                if f.startswith(f"{gender_key}_") and f.endswith(('.mp4', '.webm', '.ogg'))
                            ]
                            if similar_videos:
                                st.caption(f"ğŸ“ {L.get('video_similar_gender', 'ê°™ì€ ì„±ë³„ì˜ ë‹¤ë¥¸ ë¹„ë””ì˜¤')}: {', '.join(similar_videos[:3])}")
                                st.caption(L.get("video_rename_hint", "ğŸ’¡ ìœ„ ë¹„ë””ì˜¤ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ íŒŒì¼ëª…ì„ ë³€ê²½í•˜ê±°ë‚˜ ìƒˆë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”."))
                        else:
                            st.caption(L["video_directory_empty"])
                    else:
                        st.caption(L["video_directory_not_exist"].format(path=video_dir))
                
                # ë˜ëŠ” ë¡œì»¬ íŒŒì¼ ê²½ë¡œ ì…ë ¥ ë° ë³µì‚¬
                video_path_input = st.text_input(
                    L["video_local_path_input"],
                    placeholder=L["video_local_path_placeholder"],
                    key="video_path_input"
                )
                
                if video_path_input:
                    try:
                        # â­ Gemini ì œì•ˆ: ì ˆëŒ€ ê²½ë¡œ ê²€ì¦ ê°•í™”
                        if not os.path.isabs(video_path_input):
                            st.error("âŒ ë¡œì»¬ ê²½ë¡œ ì…ë ¥ ì‹œ ë°˜ë“œì‹œ **ì ˆëŒ€ ê²½ë¡œ**ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš” (ì˜ˆ: C:\\Users\\...\\video.mp4).")
                            st.error("ğŸ’¡ Streamlit ì•±ì´ ì‹¤í–‰ë˜ëŠ” ì„œë²„ í™˜ê²½ê³¼ íŒŒì¼ ì‹œìŠ¤í…œì´ ë‹¤ë¥´ë©´ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()
                        
                        source_video_path = video_path_input
                        
                        if not os.path.exists(source_video_path):
                            st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_video_path}")
                            st.error("ğŸ’¡ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³ , Streamlit ì•±ì´ ì‹¤í–‰ë˜ëŠ” ì„œë²„ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            st.stop()
                        
                        # ì›ë³¸ íŒŒì¼ ì½ê¸°
                        with open(source_video_path, "rb") as f:
                            video_bytes = f.read()
                        
                        if len(video_bytes) == 0:
                            st.error("âŒ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                            st.stop()
                        
                        # íŒŒì¼ëª… ë° í™•ì¥ì ê²°ì •
                        source_filename = os.path.basename(source_video_path)
                        file_ext = os.path.splitext(source_filename)[1].lower()
                        if file_ext not in ['.mp4', '.webm', '.ogg', '.mpeg4']:
                            file_ext = ".mp4"
                        
                        mime_type = f"video/{file_ext.lstrip('.')}"
                        
                        # â­ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì§ì ‘ ì €ì¥ (íŒŒì¼ ë³µì‚¬ëŠ” ì˜µì…˜)
                        video_bytes_key = f"video_bytes_{gender_key}_{emotion_key}"
                        st.session_state[video_bytes_key] = video_bytes
                        st.session_state[video_key] = video_bytes_key
                        st.session_state[upload_key] = {
                            'name': source_filename,
                            'size': len(video_bytes),
                            'mime': mime_type,
                            'ext': file_ext
                        }
                        
                        file_size_mb = len(video_bytes) / (1024 * 1024)
                        st.success(f"âœ… ë¹„ë””ì˜¤ ë°”ì´íŠ¸ ë¡œë“œ ì™„ë£Œ: {source_filename} ({file_size_mb:.2f} MB)")
                        
                        # ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸° (ë°”ì´íŠ¸ ë°ì´í„° ì§ì ‘ ì‚¬ìš©)
                        try:
                            st.video(video_bytes, format=mime_type, autoplay=False, loop=False, muted=False)
                        except Exception as video_error:
                            st.warning(f"âš ï¸ ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {video_error}")
                        
                        # â­ ì˜µì…˜: íŒŒì¼ ë³µì‚¬ë„ ì‹œë„ (ë°±ì—…ìš©)
                        try:
                            video_dir = os.path.join(DATA_DIR, "videos")
                            os.makedirs(video_dir, exist_ok=True)
                            video_filename = f"{gender_key}_{emotion_key}{file_ext}"
                            target_video_path = os.path.join(video_dir, video_filename)
                            
                            with open(target_video_path, "wb") as f:
                                f.write(video_bytes)
                                f.flush()
                            st.info(f"ğŸ“‚ íŒŒì¼ë„ ë³µì‚¬ë¨: {target_video_path}")
                        except Exception as copy_error:
                            st.info(f"ğŸ’¡ íŒŒì¼ ë³µì‚¬ëŠ” ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤ (ë°”ì´íŠ¸ ë°ì´í„°ëŠ” ë©”ëª¨ë¦¬ì— ì €ì¥ë¨): {copy_error}")
                        
                        # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
                        st.session_state.video_path_input = ""
                        
                    except Exception as e:
                        st.error(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
            
            # ìƒíƒœ ì„ íƒ ë° ë¹„ë””ì˜¤ í‘œì‹œ
            st.markdown("---")
            st.markdown(f"**{L['video_current_avatar']}**")
            
            if st.session_state.is_on_hold:
                avatar_state = "HOLD"
            else:
                avatar_state = st.session_state.customer_avatar.get("state", "NEUTRAL")
            
            customer_gender = st.session_state.customer_avatar.get("gender", "male")
            
            # get_video_path_by_avatar í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ê²½ë¡œ ì°¾ê¸°
            video_path = get_video_path_by_avatar(
                customer_gender, 
                avatar_state, 
                is_speaking=False,  # ë¯¸ë¦¬ë³´ê¸°ëŠ” ìë™ ì¬ìƒí•˜ì§€ ì•ŠìŒ
                gesture="NONE"
            )
            
            # ë¹„ë””ì˜¤ í‘œì‹œ
            if video_path and os.path.exists(video_path):
                try:
                    with open(video_path, "rb") as f:
                        video_bytes = f.read()
                    
                    # ë¹„ë””ì˜¤ ì •ë³´ í‘œì‹œ
                    avatar_emoji = {
                        "NEUTRAL": "ğŸ˜",
                        "HAPPY": "ğŸ˜Š",
                        "ANGRY": "ğŸ˜ ",
                        "ASKING": "ğŸ¤”",
                        "SAD": "ğŸ˜¢",
                        "HOLD": "â¸ï¸"
                    }.get(avatar_state, "ğŸ˜")
                    
                    st.markdown(f"### {avatar_emoji} {customer_gender.upper()} - {avatar_state}")
                    st.caption(f"ë¹„ë””ì˜¤: {os.path.basename(video_path)}")
                    
                    # í˜„ì¬ ë§í•˜ëŠ” ì¤‘ì´ë©´ ìë™ ì¬ìƒ, ì•„ë‹ˆë©´ ìˆ˜ë™ ì¬ìƒ
                    is_speaking = bool(
                        st.session_state.get("customer_initial_audio_bytes") or 
                        st.session_state.get("current_customer_audio_text")
                    )
                    
                    autoplay_video = st.session_state.is_video_sync_enabled and is_speaking
                    st.video(video_bytes, format="video/mp4", autoplay=autoplay_video, loop=False, muted=False)
                    
                except Exception as e:
                    st.warning(f"ë¹„ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")
                    avatar_emoji = {
                        "NEUTRAL": "ğŸ˜",
                        "HAPPY": "ğŸ˜Š",
                        "ANGRY": "ğŸ˜ ",
                        "ASKING": "ğŸ¤”",
                        "SAD": "ğŸ˜¢",
                        "HOLD": "â¸ï¸"
                    }.get(avatar_state, "ğŸ˜")
                    st.markdown(f"### {avatar_emoji} {L['customer_avatar']}")
                    st.info(L.get("avatar_status_info", "ìƒíƒœ: {state} | ì„±ë³„: {gender}").format(state=avatar_state, gender=customer_gender))
            else:
                # ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì´ëª¨ì§€ë¡œ í‘œì‹œ
                avatar_emoji = {
                    "NEUTRAL": "ğŸ˜",
                    "HAPPY": "ğŸ˜Š",
                    "ANGRY": "ğŸ˜ ",
                    "ASKING": "ğŸ¤”",
                    "SAD": "ğŸ˜¢",
                    "HOLD": "â¸ï¸"
                }.get(avatar_state, "ğŸ˜")
                
                st.markdown(f"### {avatar_emoji} ê³ ê° ì•„ë°”íƒ€")
                st.info(L.get("avatar_status_info", "ìƒíƒœ: {state} | ì„±ë³„: {gender}").format(state=avatar_state, gender=customer_gender))
                st.warning(L["video_avatar_upload_prompt"].format(filename=f"{customer_gender}_{avatar_state.lower()}.mp4"))
                
                # ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ ëª©ë¡ í‘œì‹œ
                video_dir = os.path.join(DATA_DIR, "videos")
                if os.path.exists(video_dir):
                    uploaded_videos = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.webm', '.ogg'))]
                    if uploaded_videos:
                        st.caption(f"{L['video_uploaded_files']}: {', '.join(uploaded_videos[:5])}")
                        if len(uploaded_videos) > 5:
                            st.caption(L.get("video_more_files", f"... ì™¸ {len(uploaded_videos) - 5}ê°œ").format(count=len(uploaded_videos) - 5))

    with col_cc:
        # â­ ìˆ˜ì •: "ì „í™” ìˆ˜ì‹  ì¤‘" ë©”ì‹œì§€ëŠ” í†µí™” ì¤‘ì¼ ë•Œë§Œ í‘œì‹œ
        if st.session_state.call_sim_stage == "IN_CALL":
            if st.session_state.call_sim_mode == "INBOUND":
                st.markdown(
                    f"## {L['call_status_ringing'].format(number=st.session_state.incoming_phone_number)}"
                )
            else:
                st.markdown(
                    f"## {L['button_call_outbound']} ({st.session_state.incoming_phone_number})"
                )
        st.markdown("---")

    # ========================================
    # WAITING / RINGING ìƒíƒœ
    # ========================================
    if st.session_state.call_sim_stage in ["WAITING_CALL", "RINGING"]:

        if "call_sim_mode" not in st.session_state:
            st.session_state.call_sim_mode = "INBOUND"  # INBOUND or OUTBOUND

        if st.session_state.call_sim_mode == "INBOUND":
            st.subheader(L["call_status_waiting"])
        else:
            st.subheader(L["button_call_outbound"])

        # í™ˆí˜ì´ì§€ ì›¹ ì£¼ì†Œ ì…ë ¥ (ì„ íƒì‚¬í•­)
        st.session_state.call_website_url = st.text_input(
            L.get("website_url_label", "í™ˆí˜ì´ì§€ ì›¹ ì£¼ì†Œ (ì„ íƒì‚¬í•­)"),
            key="call_website_url_input",
            value=st.session_state.call_website_url,
            placeholder=L.get("website_url_placeholder", "https://example.com (í™ˆí˜ì´ì§€ ì£¼ì†Œê°€ ìˆìœ¼ë©´ ì…ë ¥í•˜ì„¸ìš”)"),
        )

        # ì´ˆê¸° ë¬¸ì˜ ì…ë ¥ (ê³ ê°ì´ ì „í™”ë¡œ ë§í•  ë‚´ìš©)
        st.session_state.call_initial_query = st.text_area(
            L["customer_query_label"],
            key="call_initial_query_text_area",
            height=100,
            placeholder=L["call_query_placeholder"],
        )

        # ê°€ìƒ ì „í™”ë²ˆí˜¸ í‘œì‹œ
        st.session_state.incoming_phone_number = st.text_input(
            "Incoming/Outgoing Phone Number",
            key="incoming_phone_number_input",
            value=st.session_state.incoming_phone_number,
            placeholder=L["call_number_placeholder"],
        )

        # ê³ ê° ìœ í˜• ì„ íƒ
        customer_type_options = L["customer_type_options"]
        default_idx = customer_type_options.index(
            st.session_state.customer_type_sim_select) if st.session_state.customer_type_sim_select in customer_type_options else 0

        st.session_state.customer_type_sim_select = st.selectbox(
            L["customer_type_label"],
            customer_type_options,
            index=default_idx,
            key="call_customer_type_sim_select_widget",
        )

        # â­ ì¶”ê°€: ê³ ê° ì„±ë³„ ë° ê°ì • ìƒíƒœ ì„¤ì •
        col_gender, col_emotion = st.columns(2)
        
        with col_gender:
            # ê³ ê° ì„±ë³„ ì„ íƒ
            if "customer_gender" not in st.session_state:
                st.session_state.customer_gender = "male"
            
            # â­ ìˆ˜ì •: ë²ˆì—­ í‚¤ ì‚¬ìš©
            gender_options = [L["gender_male"], L["gender_female"]]
            current_gender = st.session_state.customer_avatar.get("gender", "male")
            default_gender_idx = 0 if current_gender == "male" else 1
            
            selected_gender_display = st.radio(
                L["customer_gender_label"],
                gender_options,
                index=default_gender_idx,
                key="call_customer_gender_radio",
                horizontal=True
            )
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ì˜ì–´ë¡œ)
            st.session_state.customer_avatar["gender"] = "male" if selected_gender_display == L["gender_male"] else "female"
            st.session_state.customer_gender = st.session_state.customer_avatar["gender"]
        
        with col_emotion:
            # ê³ ê° ê°ì • ìƒíƒœ ì„ íƒ
            # â­ ìˆ˜ì •: ë²ˆì—­ í‚¤ ì‚¬ìš©
            emotion_options = [
                L["emotion_happy"],
                L["emotion_dissatisfied"],
                L["emotion_angry"],
                L["emotion_sad"],
                L["emotion_neutral"]
            ]
            emotion_mapping = {
                L["emotion_happy"]: "HAPPY",
                L["emotion_dissatisfied"]: "ASKING",
                L["emotion_angry"]: "ANGRY",
                L["emotion_sad"]: "SAD",
                L["emotion_neutral"]: "NEUTRAL"
            }
            
            current_emotion_state = st.session_state.customer_avatar.get("state", "NEUTRAL")
            default_emotion_idx = 4  # ê¸°ë³¸ê°’: ì¤‘ë¦½
            for i, (emotion_display, emotion_state) in enumerate(emotion_mapping.items()):
                if emotion_state == current_emotion_state:
                    default_emotion_idx = i
                    break
            
            selected_emotion = st.selectbox(
                L["customer_emotion_label"],
                emotion_options,
                index=default_emotion_idx,
                key="call_customer_emotion_select",
            )
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.customer_avatar["state"] = emotion_mapping.get(selected_emotion, "NEUTRAL")

        st.markdown("---")

        col_in, col_out = st.columns(2)

        # ì „í™” ì‘ë‹µ (ìˆ˜ì‹ )
        with col_in:
            if st.button(L["button_answer"], key=f"answer_call_btn_{st.session_state.sim_instance_id}"):
                # ì…ë ¥ ê²€ì¦
                if not st.session_state.call_initial_query.strip():
                    st.warning(L["simulation_warning_query"])
                    # st.stop()

                # â­ ìˆ˜ì •: OpenAI ë˜ëŠ” Gemini API í‚¤ ì²´í¬
                has_openai = st.session_state.openai_client is not None
                has_gemini = bool(get_api_key("gemini"))
                
                if not st.session_state.is_llm_ready or (not has_openai and not has_gemini):
                    st.error(L["simulation_no_key_warning"] + " (OpenAI ë˜ëŠ” Gemini API Key í•„ìš”)")
                    # st.stop()

                # INBOUND ëª¨ë“œ ì„¤ì •
                st.session_state.call_sim_mode = "INBOUND"

                # ì‹œë®¬ë ˆì´ì…˜ ì´ˆê¸°í™” ë° ì‹œì‘
                st.session_state.call_sim_stage = "IN_CALL"
                st.session_state.is_call_ended = False
                st.session_state.is_on_hold = False
                st.session_state.total_hold_duration = timedelta(0)
                st.session_state.hold_start_time = None
                st.session_state.start_time = datetime.now()  # í†µí™” ì‹œì‘ ì‹œê°„ (AHT ì‹œì‘)
                st.session_state.simulator_messages = []
                st.session_state.current_customer_audio_text = ""
                st.session_state.current_agent_audio_text = ""
                st.session_state.agent_response_input_box_widget_call = ""
                st.session_state.sim_instance_id = str(uuid.uuid4())
                st.session_state.call_summary_text = ""  # ìš”ì•½ ì´ˆê¸°í™”
                st.session_state.customer_initial_audio_bytes = None  # ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
                st.session_state.customer_history_summary = ""  # AI ìš”ì•½ ì´ˆê¸°í™” (ì¶”ê°€)
                st.session_state.sim_audio_bytes = None  # ë…¹ìŒ íŒŒì¼ ì´ˆê¸°í™” (ì¶”ê°€)

                # â­ ìˆ˜ì •: ìë™ ì¸ì‚¬ë§ ìƒì„± ì œê±° - ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ë…¹ìŒí•˜ë„ë¡ ë³€ê²½
                st.session_state.just_entered_call = False
                st.session_state.customer_turn_start = False  # ì—ì´ì „íŠ¸ ì¸ì‚¬ë§ ì™„ë£Œ ì „ê¹Œì§€ False

                # ê³ ê°ì˜ ì²« ë²ˆì§¸ ìŒì„± ë©”ì‹œì§€ (ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ë©”ì‹œì§€)
                initial_query_text = st.session_state.call_initial_query.strip()
                st.session_state.current_customer_audio_text = initial_query_text

                # â­ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ìë™ ê°ì§€ ë° ì–¸ì–´ ì„¤ì • ì—…ë°ì´íŠ¸
                try:
                    detected_lang = detect_text_language(initial_query_text)
                    if detected_lang in ["ko", "en", "ja"] and detected_lang != st.session_state.language:
                        st.session_state.language = detected_lang
                        st.info(f"ğŸŒ ì…ë ¥ ì–¸ì–´ê°€ ê°ì§€ë˜ì–´ ì–¸ì–´ ì„¤ì •ì´ '{detected_lang}'ë¡œ ìë™ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    print(f"Language detection failed in call: {e}")
                    detected_lang = st.session_state.language

                # â­ ê³ ê°ì˜ ì²« ë¬¸ì˜ TTS ìŒì„± ìƒì„± ë° ì €ì¥ (ê°ì§€ëœ ì–¸ì–´ ì‚¬ìš©)
                with st.spinner(L["tts_status_generating"] + " (Initial Customer Query)"):
                    audio_bytes, msg = synthesize_tts(initial_query_text, st.session_state.language, role="customer")
                    if audio_bytes:
                        st.session_state.customer_initial_audio_bytes = audio_bytes
                    else:
                        st.error(f"âŒ {msg}")
                        st.session_state.customer_initial_audio_bytes = None

                # âœ… ìƒíƒœ ë³€ê²½ í›„ ì¬ì‹¤í–‰í•˜ì—¬ IN_CALL ìƒíƒœë¡œ ì „í™˜
                # ì—ì´ì „íŠ¸ê°€ ì¸ì‚¬ë§ì„ ë…¹ìŒí•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´ ë©”ì‹œì§€ í‘œì‹œ
                st.info(L["call_started_message"])

        # ì „í™” ë°œì‹  (ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘)
        with col_out:
            st.markdown(f"### {L['button_call_outbound']}")
            call_targets = [
                L["call_target_customer"],
                L["call_target_partner"]
            ]

            call_target_selection = st.radio(
                L.get("call_target_select_label", "ë°œì‹  ëŒ€ìƒ ì„ íƒ"),
                call_targets,
                key="outbound_call_target_radio",
                horizontal=True
            )

            # ì„ íƒëœ ëŒ€ìƒì— ë”°ë¼ ë²„íŠ¼ í…ìŠ¤íŠ¸ ë³€ê²½
            if call_target_selection == L["call_target_customer"]:
                button_text = L["button_call_outbound_to_customer"]
            else:
                button_text = L["button_call_outbound_to_provider"]

            if st.button(button_text, key=f"outbound_call_start_btn_{st.session_state.sim_instance_id}", type="secondary", use_container_width=True):
                # ì…ë ¥ ê²€ì¦
                if not st.session_state.call_initial_query.strip():
                    st.warning("ì „í™” ë°œì‹  ëª©í‘œ (ê³ ê° ë¬¸ì˜ ë‚´ìš©)ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚")
                    # st.stop()

                # â­ ìˆ˜ì •: OpenAI ë˜ëŠ” Gemini API í‚¤ ì²´í¬
                has_openai = st.session_state.openai_client is not None
                has_gemini = bool(get_api_key("gemini"))
                
                if not st.session_state.is_llm_ready or (not has_openai and not has_gemini):
                    st.error(L["simulation_no_key_warning"] + " (OpenAI ë˜ëŠ” Gemini API Key í•„ìš”)")
                    # st.stop()

                # OUTBOUND ëª¨ë“œ ì„¤ì • ë° ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘
                st.session_state.call_sim_mode = "OUTBOUND"

                # ì‹œë®¬ë ˆì´ì…˜ ì´ˆê¸°í™” ë° ì‹œì‘
                st.session_state.call_sim_stage = "IN_CALL"
                st.session_state.is_call_ended = False
                st.session_state.is_on_hold = False
                st.session_state.total_hold_duration = timedelta(0)
                st.session_state.hold_start_time = None
                st.session_state.start_time = datetime.now()  # í†µí™” ì‹œì‘ ì‹œê°„ (AHT ì‹œì‘)
                st.session_state.simulator_messages = []

                # â­ ìˆ˜ì •: ìë™ ì¸ì‚¬ë§ ìƒì„± ì œê±° - ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ë…¹ìŒí•˜ë„ë¡ ë³€ê²½
                st.session_state.just_entered_call = False
                st.session_state.customer_turn_start = False

                initial_query_text = st.session_state.call_initial_query.strip()

                # ë°œì‹  ì‹œë®¬ë ˆì´ì…˜ì—ì„œëŠ” ì—ì´ì „íŠ¸ê°€ ë¨¼ì € ë§í•´ì•¼ í•˜ë¯€ë¡œ, ê³ ê° CC í…ìŠ¤íŠ¸ëŠ” ì•ˆë‚´ ë©”ì‹œì§€ë¡œ ì„¤ì •
                st.session_state.current_customer_audio_text = f"ğŸ“ {L['button_call_outbound']} ì„±ê³µ! {call_target_selection}ì´(ê°€) ë°›ì•˜ìŠµë‹ˆë‹¤ã€‚ ì ì‹œ í›„ ì‘ë‹µì´ ì‹œì‘ë©ë‹ˆë‹¤ã€‚ (ë¬¸ì˜ ëª©í‘œ: {initial_query_text[:50]}...)"
                st.session_state.current_agent_audio_text = ""  # Agent speaks first
                st.session_state.agent_response_input_box_widget_call = ""
                st.session_state.sim_instance_id = str(uuid.uuid4())
                st.session_state.call_summary_text = ""
                st.session_state.customer_initial_audio_bytes = None
                st.session_state.customer_history_summary = ""
                st.session_state.sim_audio_bytes = None

                st.success(f"'{call_target_selection}'ì—ê²Œ ì „í™” ë°œì‹  ì‹œë®¬ë ˆì´ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¸ì‚¬ë§ì„ ë…¹ìŒí•˜ì„¸ìš”ã€‚")

        # ------------------
        # IN_CALL ìƒíƒœ (í†µí™” ì¤‘)
        # ------------------
    elif st.session_state.call_sim_stage == "IN_CALL":
        # â­ ìˆ˜ì •: ìë™ ì¸ì‚¬ë§ ìƒì„± ë¡œì§ ì œê±° - ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ë…¹ìŒí•˜ë„ë¡ ë³€ê²½
        
        # ------------------------------
        # ì „í™” í†µí™” ì œëª© (í†µí™” ì¤‘ì¼ ë•Œë§Œ í‘œì‹œ)
        # ------------------------------
        # â­ ìˆ˜ì •: ì œëª©ì€ ì´ë¯¸ ìœ„ì—ì„œ í‘œì‹œë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°
        # st.markdown(f"## {title}")
        # st.markdown("---")

        # ------------------------------
        # Hangup / Hold ë²„íŠ¼
        # ------------------------------
        col_hangup, col_hold = st.columns(2)

        with col_hangup:
            if st.button(L["button_hangup"], key="hangup_call_btn"):

                # Hold ì •ì‚°
                if st.session_state.is_on_hold and st.session_state.hold_start_time:
                    st.session_state.total_hold_duration += datetime.now() - st.session_state.hold_start_time

                # ìš”ì•½ ìƒì„±
                with st.spinner("AI ìš”ì•½ ìƒì„± ì¤‘..."):
                    # â­ [ìˆ˜ì • 9] í•¨ìˆ˜ëª… í†µì¼: summarize_history_for_callë¡œ ë³€ê²½ ë° í˜¸ì¶œ
                    summary = summarize_history_for_call(
                        st.session_state.simulator_messages,
                        st.session_state.call_initial_query,
                        st.session_state.language
                    )
                    st.session_state.call_summary_text = summary

                # ì¢…ë£Œ
                st.session_state.call_sim_stage = "CALL_ENDED"
                st.session_state.is_call_ended = True

                # â­ [ìˆ˜ì • 10] Hangup í›„ UI ê°±ì‹ ì„ ìœ„í•´ rerun ì¶”ê°€
                st.rerun()

        # ------------------------------
        # Hold / Resume
        # ------------------------------
        with col_hold:
            if st.session_state.is_on_hold:
                if st.button(L["button_resume"], key="resume_call_btn"):
                    # Hold ìƒíƒœ í•´ì œ ë° ì‹œê°„ ì •ì‚°
                    st.session_state.is_on_hold = False
                    if st.session_state.hold_start_time:
                        st.session_state.total_hold_duration += datetime.now() - st.session_state.hold_start_time
                        st.session_state.hold_start_time = None
            else:
                if st.button(L["button_hold"], key="hold_call_btn"):
                    st.session_state.is_on_hold = True
                    st.session_state.hold_start_time = datetime.now()

        # ------------------------------
        # Hold í‘œì‹œ
        # ------------------------------
        if st.session_state.is_on_hold:
            if st.session_state.hold_start_time:
                current_hold = datetime.now() - st.session_state.hold_start_time
            else:
                current_hold = timedelta(0)

            total_hold = st.session_state.total_hold_duration + current_hold
            hold_str = str(total_hold).split('.')[0]

            st.warning(L["hold_status"].format(duration=hold_str))
            time.sleep(1)

        # ------------------------------
        # (ì¤‘ëµ) - **ì´ê´€, íŒíŠ¸, ìš”ì•½, CC, Whisper ì „ì‚¬, ê³ ê° ë°˜ì‘ ìƒì„±**
        # ------------------------------
        def transfer_session(target_lang: str, current_messages: List[Dict[str, str]]):
            """ì–¸ì–´ ì´ê´€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  ì„¸ì…˜ ì–¸ì–´ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤."""

            current_lang = st.session_state.language  # í˜„ì¬ ì–¸ì–´ í™•ì¸ (Source language)
            L = LANG[current_lang]

            # API í‚¤ ì²´í¬
            if not st.session_state.is_llm_ready:
                st.error(L["simulation_no_key_warning"].replace('API Key', 'LLM API Key'))
                return

            current_lang_at_start = st.session_state.language  # Source language

            # AHT íƒ€ì´ë¨¸ ì •ì§€ (ì‹¤ì œë¡œ í†µí™”ê°€ ì¢…ë£Œë˜ëŠ” ê²ƒì€ ì•„ë‹ˆë¯€ë¡œ, AHTëŠ” ê³„ì† íë¦„)
            # st.session_state.start_time = None

            # 1. ë¡œë”© ì‹œì‘ (ì‹œê°„ ì–‘í•´ ë©”ì‹œì§€ ì‹œë®¬ë ˆì´ì…˜)
            with st.spinner(L["transfer_loading"]):
                time.sleep(np.random.uniform(5, 10))

                # 2. ëŒ€í™” ê¸°ë¡ì„ ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¡œ ê°€ê³µ
                history_text = ""
                for msg in current_messages:
                    role = "Customer" if msg["role"].startswith("customer") or msg[
                        "role"] == "initial_query" else "Agent"
                    if msg["role"] in ["initial_query", "customer_rebuttal", "agent_response",
                                       "customer_closing_response", "phone_exchange"]:  # phone_exchange ì¶”ê°€
                        history_text += f"{role}: {msg['content']}\n"

                # â­ ìˆ˜ì •: ë¨¼ì € í•µì‹¬ í¬ì¸íŠ¸ë§Œ ìš”ì•½í•œ í›„ ë²ˆì—­
                # ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±
                lang_name_source = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(current_lang_at_start, "Korean")
                summary_prompt = f"""
You are an AI assistant that summarizes customer service conversations. 
Extract ONLY the key points from the conversation below. Keep it concise and focused on:
1. Customer's main inquiry/question
2. Key information provided by the agent
3. Important decisions or outcomes
4. Any unresolved issues

Write the summary in {lang_name_source}. Maximum 200 words. Be brief and to the point.

--- Conversation ---
{history_text}
---

Key Points Summary:
        # =========================
        # AI ìš”ì•½ ë²„íŠ¼ ë° í‘œì‹œ ë¡œì§ (ì¶”ê°€ëœ ê¸°ëŠ¥)
        # =========================
        st.markdown("---")
        # â­ history_expander_titleì—ì„œ ê´„í˜¸ ì•ˆ ë‚´ìš©ë§Œ ì œê±° (ì˜ˆ: (ìµœê·¼ 10ê±´))
        summary_title = L['history_expander_title'].split('(')[0].strip()
        st.markdown(f"### ğŸ“‘ {summary_title} ìš”ì•½")

        # 1. ìš”ì•½/ë²ˆì—­ ì¬ì‹œë„ ë²„íŠ¼ ì˜ì—­
        col_sum_btn, col_trans_btn = st.columns(2)

        with col_sum_btn:
            # â­ [ìˆ˜ì • FIX] í‚¤ ì¤‘ë³µ ì˜¤ë¥˜ í•´ê²°: ì„¸ì…˜ IDë¥¼ í‚¤ì— ì¶”ê°€
            if st.button(L["btn_request_phone_summary"], key=f"btn_request_phone_summary_{st.session_state.sim_instance_id}"):
                # ìš”ì•½ í•¨ìˆ˜ í˜¸ì¶œ
                st.session_state.customer_history_summary = summarize_history_with_ai(st.session_state.language)

        # 2. ì´ê´€ ë²ˆì—­ ì¬ì‹œë„ ë²„íŠ¼ (ì´ê´€ í›„ ë²ˆì—­ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš°)
        if st.session_state.language != st.session_state.language_at_transfer_start and not st.session_state.transfer_summary_text:
            with col_trans_btn:
                # â­ [ìˆ˜ì • FIX] í‚¤ ì¤‘ë³µ ì˜¤ë¥˜ í•´ê²°: ì„¸ì…˜ IDì™€ ì–¸ì–´ ì½”ë“œë¥¼ ì¡°í•©í•˜ì—¬ ê³ ìœ  í‚¤ ìƒì„±
                retry_key = f"btn_retry_translation_{st.session_state.language_at_transfer_start}_{st.session_state.language}_{st.session_state.sim_instance_id}"
                if st.button(L["button_retry_translation"], key=retry_key):
                    with st.spinner(L["transfer_loading"]):
                        # ì´ê´€ ë²ˆì—­ ë¡œì§ ì¬ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                        translated_summary, is_success = translate_text_with_llm(
                            get_chat_history_for_prompt(include_attachment=False),
                            st.session_state.language,
                            st.session_state.language_at_transfer_start
                        )
                        st.session_state.transfer_summary_text = translated_summary
                        st.session_state.translation_success = is_success

        # 3. ìš”ì•½ ë‚´ìš© í‘œì‹œ
        if st.session_state.transfer_summary_text:
            st.subheader(f"ğŸ” {L['transfer_summary_header']}")
            st.info(st.session_state.transfer_summary_text)
            # â­ ì´ê´€ ìš”ì•½ì— TTS ë²„íŠ¼ ì¶”ê°€
            render_tts_button(
                st.session_state.transfer_summary_text,
                st.session_state.language,
                role="agent",
                prefix="trans_summary_tts_call",
                index=-1  # ê³ ìœ  ì„¸ì…˜ ID ê¸°ë°˜ì˜ í‚¤ë¥¼ ìƒì„±í•˜ë„ë¡ ì§€ì‹œ
            )
        elif st.session_state.customer_history_summary:
            st.subheader("ğŸ’¡ AI ìš”ì•½")
            st.info(st.session_state.customer_history_summary)

        st.markdown("---")

        # --- ì‹¤ì‹œê°„ ì‘ëŒ€ íŒíŠ¸ ì˜ì—­ ---
        hint_cols = st.columns([4, 1])
        with hint_cols[0]:
            st.info(L["hint_placeholder"] + st.session_state.realtime_hint_text)

        with hint_cols[1]:
            # íŒíŠ¸ ìš”ì²­ ë²„íŠ¼
            if st.button(L["button_request_hint"], key=f"btn_request_hint_call_{st.session_state.sim_instance_id}"):
                with st.spinner(L["response_generating"]):
                    # ì „í™” íƒ­ì´ë¯€ë¡œ is_call=True
                    hint = generate_realtime_hint(current_lang, is_call=True)
                    st.session_state.realtime_hint_text = hint

        # =========================
        # CC ìë§‰ / ìŒì„± ì…ë ¥ ë° ì œì–´ ë¡œì§ (ê¸°ì¡´ ë¡œì§)
        # =========================================

        # --- ì‹¤ì‹œê°„ CC ìë§‰ / ì „ì‚¬ ì˜ì—­ ---
        st.subheader(L["cc_live_transcript"])

        if st.session_state.is_on_hold:
            st.text_area("Customer", value=L["customer_waiting_hold"], height=50, disabled=True, key="customer_live_cc_area")
            st.text_area("Agent", value=L["agent_hold_message"], height=50, disabled=True,
                         key="agent_live_cc_area")
        else:
            # ê³ ê° CC (LLM ìƒì„± í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ˆê¸° ë¬¸ì˜)
            # â­ ìˆ˜ì •: ê³ ê° ë¬¸ì˜ê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ì´ˆê¸° ë¬¸ì˜ë¥¼ í‘œì‹œ
            customer_cc_text = st.session_state.current_customer_audio_text
            if not customer_cc_text and st.session_state.call_initial_query:
                customer_cc_text = st.session_state.call_initial_query
            st.text_area(
                "Customer",
                value=customer_cc_text,
                height=50,
                disabled=True,
                key="customer_live_cc_area",
            )

            # ì—ì´ì „íŠ¸ CC (ë§ˆì´í¬ ì „ì‚¬)
            st.text_area(
                "Agent",
                value=st.session_state.current_agent_audio_text,
                height=50,
                disabled=True,
                key="agent_live_cc_area",
            )

        st.markdown("---")

        # --- ì—ì´ì „íŠ¸ ìŒì„± ì…ë ¥ / ë…¹ìŒ ---
        st.subheader(L["mic_input_status"])

        # ìŒì„± ì…ë ¥: ì§§ì€ ì²­í¬ë¡œ ëŠì–´ì„œ ì „ì‚¬í•´ì•¼ ì‹¤ì‹œê°„ CC ëª¨ë°© ê°€ëŠ¥
        if st.session_state.is_on_hold:
            st.info(L["call_on_hold_message"])
            mic_audio = None
        else:
            # âœ… ë§ˆì´í¬ ìœ„ì ¯ì„ í•­ìƒ ë Œë”ë§í•˜ì—¬ í™œì„±í™” ìƒíƒœë¥¼ ìœ ì§€
            mic_audio = mic_recorder(
                start_prompt=L["agent_response_prompt"],
                stop_prompt=L["agent_response_stop_and_send"],
                just_once=True,
                format="wav",
                use_container_width=True,
                key="call_sim_mic_recorder",
            )

            # ë…¹ìŒ ì™„ë£Œ (mic_audio.get("bytes")ê°€ ì±„ì›Œì§) ì‹œ, ë°”ì´íŠ¸ë¥¼ ì €ì¥í•˜ê³  ì¬ì‹¤í–‰
            # â­ ìˆ˜ì •: ì±„íŒ…/ì´ë©”ì¼ íƒ­ê³¼ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ìˆ˜ì • - ì¡°ê±´ ë‹¨ìˆœí™”
            if mic_audio and mic_audio.get("bytes"):
                # â­ ìˆ˜ì •: ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì¸ ê²½ìš° ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
                if "bytes_to_process" not in st.session_state or st.session_state.bytes_to_process is None:
                    st.session_state.bytes_to_process = mic_audio["bytes"]
                    st.session_state.current_agent_audio_text = L["recording_complete_transcribing"]
                    # âœ… ì¬ì‹¤í–‰í•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ì£¼ê¸°ì—ì„œ ì „ì‚¬ ë¡œì§ì„ ì²˜ë¦¬
                    st.rerun()

        # â­ ìˆ˜ì •: ì „ì‚¬ ë¡œì§ì„ ë§ˆì´í¬ ìœ„ì ¯ ë Œë”ë§ ë¸”ë¡ ë°–ìœ¼ë¡œ ì´ë™í•˜ì—¬ ì‹¤í–‰ ìˆœì„œ ë³´ì¥
        # ì „ì‚¬ ë¡œì§: bytes_to_processì— ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì‹¤í–‰
        if "bytes_to_process" in st.session_state and st.session_state.bytes_to_process is not None:
            # â­ ìˆ˜ì •: OpenAI ë˜ëŠ” Gemini API í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_openai = st.session_state.openai_client is not None
            has_gemini = bool(get_api_key("gemini"))
            
            if not has_openai and not has_gemini:
                st.error(L["openai_missing"] + " ë˜ëŠ” Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                st.session_state.bytes_to_process = None
                # â­ ìµœì í™”: ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ í›„ ë¶ˆí•„ìš”í•œ rerun ì œê±° (ì‚¬ìš©ìê°€ API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ìë™ìœ¼ë¡œ ì¬ì‹¤í–‰ë¨)
            else:
                # â­ ì „ì‚¬ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”
                agent_response_transcript = None

                # â­ [ìˆ˜ì •]: Whisper ì „ì‚¬ ë¡œì§ (ì±„íŒ…/ì´ë©”ì¼ íƒ­ê³¼ ë™ì¼í•œ íŒ¨í„´)
                # ì „ì‚¬ í›„ ë°”ì´íŠ¸ ë°ì´í„° ë°±ì—… (ì „ì‚¬ ì „ì— ë°±ì—…)
                audio_bytes_backup = st.session_state.bytes_to_process
                
                # ì „ì‚¬ í›„ ë°”ì´íŠ¸ ë°ì´í„° ì¦‰ì‹œ ì‚­ì œ (ì¡°ê±´ë¬¸ ì¬í‰ê°€ ë°©ì§€)
                st.session_state.bytes_to_process = None
                
                with st.spinner(L["whisper_processing"]):
                    try:
                        # 1) Whisper ì „ì‚¬ (ìë™ ì–¸ì–´ ê°ì§€ ì‚¬ìš©) - ì±„íŒ…/ì´ë©”ì¼ê³¼ ë™ì¼í•œ ë°©ì‹
                        agent_response_transcript = transcribe_bytes_with_whisper(
                            audio_bytes_backup,
                            "audio/wav",
                            lang_code=None,
                            auto_detect=True
                        )
                    except Exception as e:
                        agent_response_transcript = f"âŒ ì „ì‚¬ ì˜¤ë¥˜: {e}"

                # 2) ì „ì‚¬ ì‹¤íŒ¨ ì²˜ë¦¬ (ì±„íŒ…/ì´ë©”ì¼ê³¼ ë™ì¼í•œ íŒ¨í„´)
                if not agent_response_transcript or agent_response_transcript.startswith("âŒ"):
                    error_msg = agent_response_transcript if agent_response_transcript else L["transcription_no_result"]
                    st.error(error_msg)
                    st.session_state.current_agent_audio_text = L["transcription_error"]
                    # â­ ìµœì í™”: ì „ì‚¬ ì‹¤íŒ¨ ì‹œì—ë„ CCì— ë°˜ì˜ë˜ì§€ë§Œ ë¶ˆí•„ìš”í•œ rerun ì œê±° (Streamlitì´ ìë™ìœ¼ë¡œ ì¬ì‹¤í–‰)
                elif not agent_response_transcript.strip(): # â­ ìˆ˜ì •: ì „ì‚¬ ê²°ê³¼ê°€ ë¹„ì–´ ìˆê±°ë‚˜ (ê³µë°±ë§Œ ìˆëŠ” ê²½ìš°) ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œ í•´ê²°
                    st.warning(L["transcription_empty_warning"])
                    st.session_state.current_agent_audio_text = ""
                    # â­ ìµœì í™”: ë¶ˆí•„ìš”í•œ rerun ì œê±°
                elif agent_response_transcript.strip():
                    # 3) ì „ì‚¬ ì„±ê³µ - CCì— ë°˜ì˜ (ì „ì‚¬ ê²°ê³¼ë¥¼ ë¨¼ì € CC ì˜ì—­ì— í‘œì‹œ)
                    agent_response_transcript = agent_response_transcript.strip()
                    st.session_state.current_agent_audio_text = agent_response_transcript
                    
                    # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ (ì±„íŒ…/ì´ë©”ì¼ê³¼ ìœ ì‚¬)
                    snippet = agent_response_transcript[:50].replace("\n", " ")
                    if len(agent_response_transcript) > 50:
                        snippet += "..."
                    st.success(L["whisper_success"] + f" **ì¸ì‹ ë‚´ìš©:** *{snippet}*")

                    # â­ ìˆ˜ì •: ì²« ì¸ì‚¬ë§ì¸ì§€ í™•ì¸ (simulator_messagesì— phone_exchangeê°€ ì—†ìœ¼ë©´ ì²« ì¸ì‚¬ë§)
                    is_first_greeting = not any(
                        msg.get("role") == "phone_exchange" 
                        for msg in st.session_state.simulator_messages
                    )
                    
                    # â­ ìˆ˜ì •: ì „í™” ë°œì‹  ëª¨ë“œ í™•ì¸
                    is_outbound_call = st.session_state.get("call_sim_mode", "INBOUND") == "OUTBOUND"

                    if is_first_greeting:
                        # ì²« ì¸ì‚¬ë§ì¸ ê²½ìš°: ë¡œê·¸ì— ê¸°ë¡í•˜ê³  ê³ ê° ë¬¸ì˜ ì¬ìƒ ì¤€ë¹„
                        st.session_state.simulator_messages.append(
                            {"role": "agent", "content": agent_response_transcript}
                        )
                        # ì•„ë°”íƒ€ í‘œì • ì´ˆê¸°í™”
                        st.session_state.customer_avatar["state"] = "NEUTRAL"
                        
                        # â­ ìˆ˜ì •: ì „í™” ë°œì‹  ëª¨ë“œì—ì„œ customer_initial_audio_bytesê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ê³ ê° ì‘ë‹µ ìƒì„±
                        if is_outbound_call and not st.session_state.get("customer_initial_audio_bytes"):
                            # ì „í™” ë°œì‹  ëª¨ë“œì´ê³  ê³ ê° ë¬¸ì˜ ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ê³ ê° ì‘ë‹µ ìƒì„±
                            st.session_state.current_agent_audio_text = agent_response_transcript
                            st.session_state.process_customer_reaction = True
                            st.session_state.pending_agent_transcript = agent_response_transcript
                            st.rerun()
                        else:
                            # â­ ìˆ˜ì •: ê³ ê° ë¬¸ì˜ë¥¼ CC ìë§‰ì— ë¯¸ë¦¬ ë°˜ì˜ (ì¬ìƒ ì „ì— ë°˜ì˜)
                            if st.session_state.call_initial_query:
                                st.session_state.current_customer_audio_text = st.session_state.call_initial_query
                            # â­ ìˆ˜ì •: ê³ ê° ë¬¸ì˜ ì¬ìƒì„ ë°”ë¡œ ì‹¤í–‰ (ê°™ì€ ì‹¤í–‰ ì£¼ê¸°ì—ì„œ ì²˜ë¦¬)
                            # ê³ ê° ë¬¸ì˜ ì¬ìƒ ë¡œì§ì´ ì•„ë˜ì— ìˆìœ¼ë¯€ë¡œ í”Œë˜ê·¸ë§Œ ì„¤ì •
                            st.session_state.customer_turn_start = True
                            # â­ ìµœì í™”: í”Œë˜ê·¸ ì„¤ì • í›„ ì¬ì‹¤í–‰í•˜ì—¬ ê³ ê° ë¬¸ì˜ ì¬ìƒ ë¡œì§ ì‹¤í–‰
                            st.rerun()
                    else:
                        # ì´í›„ ì‘ë‹µì¸ ê²½ìš°: ê¸°ì¡´ ë¡œì§ëŒ€ë¡œ ê³ ê° ë°˜ì‘ ìƒì„±
                        # â­ ìˆ˜ì •: ì „í™” ë°œì‹  ëª¨ë“œì—ì„œë„ ê³ ê° ë°˜ì‘ì´ ìƒì„±ë˜ë„ë¡ ë³´ì¥
                        # â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­
                        # ğŸ¯ ì•„ë°”íƒ€ í‘œì • ì—…ë°ì´íŠ¸ (LLM ê¸°ë°˜ ì˜ìƒ RAG)
                        # LLMì´ ì—ì´ì „íŠ¸ ì‘ë‹µì„ ë¶„ì„í•˜ì—¬ ê³ ê°ì˜ ì˜ˆìƒ ë°˜ì‘(ê°ì •)ì„ íŒë‹¨
                        # ì´ëŠ” ê³ ê°ì´ ë‹¤ìŒì— ë§í•  ë•Œ ì–´ë–¤ ë¹„ë””ì˜¤ë¥¼ ë³´ì—¬ì¤„ì§€ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
                        try:
                            # LLM ê¸°ë°˜ ë¶„ì„ (ì—ì´ì „íŠ¸ ì‘ë‹µì— ëŒ€í•œ ê³ ê°ì˜ ì˜ˆìƒ ë°˜ì‘)
                            # ì—ì´ì „íŠ¸ê°€ "í™˜ë¶ˆ"ì„ ì–¸ê¸‰í•˜ë©´ ê³ ê°ì€ ê¸°ì  ê²ƒì´ê³ ,
                            # "ê¸°ë‹¤ë ¤"ë¥¼ ìš”ì²­í•˜ë©´ ê³ ê°ì€ ì§ˆë¬¸í•  ê²ƒì´ê³ ,
                            # "ë¶ˆê°€"ë¥¼ ë§í•˜ë©´ ê³ ê°ì€ í™”ë‚  ê²ƒì…ë‹ˆë‹¤.
                            # â­ Gemini ì œì•ˆ: ì—ì´ì „íŠ¸ ë‹µë³€ê³¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•˜ì—¬ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ
                            analysis_result = analyze_text_for_video_selection(
                                agent_response_transcript,
                                st.session_state.language,
                                agent_last_response=agent_response_transcript,
                                conversation_context=st.session_state.simulator_messages[-5:] if st.session_state.simulator_messages else None
                            )
                            # ê³ ê°ì˜ ì˜ˆìƒ ê°ì • ìƒíƒœ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ê³ ê° ë°˜ì‘ì— ì‚¬ìš©)
                            predicted_emotion = analysis_result.get("emotion", "NEUTRAL")
                            st.session_state.customer_avatar["state"] = predicted_emotion
                        except Exception as e:
                            # LLM ë¶„ì„ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±
                            print(f"LLM ë¶„ì„ ì‹¤íŒ¨, í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í´ë°±: {e}")
                            response_text = agent_response_transcript.lower()
                            if "refund" in response_text or "í™˜ë¶ˆ" in response_text:
                                st.session_state.customer_avatar["state"] = "HAPPY"
                            elif ("wait" in response_text or "ê¸°ë‹¤ë ¤" in response_text or "ì ì‹œë§Œ" in response_text):
                                st.session_state.customer_avatar["state"] = "ASKING"
                            elif ("no" in response_text or "ë¶ˆê°€" in response_text or "ì•ˆ ë©ë‹ˆë‹¤" in response_text or "cannot" in response_text):
                                st.session_state.customer_avatar["state"] = "ANGRY"
                            else:
                                st.session_state.customer_avatar["state"] = "NEUTRAL"
                        # â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­

                        # â­ ìˆ˜ì •: ì „ì‚¬ ê²°ê³¼ë¥¼ CCì— ë¨¼ì € ë°˜ì˜
                        st.session_state.current_agent_audio_text = agent_response_transcript

                        # â­ ìˆ˜ì •: ì „ì‚¬ ê²°ê³¼ê°€ CCì— ë°˜ì˜ë˜ë„ë¡ ë¨¼ì € ì¬ì‹¤í–‰
                        # ì±„íŒ…ê³¼ ë™ì¼í•˜ê²Œ ì „ì‚¬ ê²°ê³¼ë¥¼ ë¨¼ì € í™”ë©´ì— í‘œì‹œí•œ í›„ ê³ ê° ë°˜ì‘ ìƒì„±
                        # ë‹¤ìŒ ì‹¤í–‰ ì£¼ê¸°ì—ì„œ ê³ ê° ë°˜ì‘ì„ ìƒì„±í•˜ë„ë¡ í”Œë˜ê·¸ ì„¤ì •
                        st.session_state.process_customer_reaction = True
                        st.session_state.pending_agent_transcript = agent_response_transcript
                        # â­ ìˆ˜ì •: ì „ì‚¬ ì™„ë£Œ í›„ ì¦‰ì‹œ ì¬ì‹¤í–‰í•˜ì—¬ ê³ ê° ë°˜ì‘ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰
                        st.rerun()
                # â­ ìˆ˜ì •: else ë¸”ë¡ ì œê±° (ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨)

        # â­ ìˆ˜ì •: ì²« ì¸ì‚¬ë§ í›„ ê³ ê° ë¬¸ì˜ ì¬ìƒ ì²˜ë¦¬
        # customer_turn_start í”Œë˜ê·¸ê°€ Trueì¼ ë•Œ ê³ ê° ë¬¸ì˜ë¥¼ ì¬ìƒ
        if st.session_state.get("customer_turn_start", False) and st.session_state.customer_initial_audio_bytes:
            # â­ ìˆ˜ì •: ê³ ê° ë¬¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¦‰ì‹œ CC ì˜ì—­ì— ë°˜ì˜ (ì¬ìƒ ì‹œì‘ ì „, í™•ì‹¤íˆ ë°˜ì˜)
            st.session_state.current_customer_audio_text = st.session_state.call_initial_query
            
            # ê³ ê° ë¬¸ì˜ ì¬ìƒ (ë¹„ë””ì˜¤ì™€ ë™ê¸°í™”) - LLM ê¸°ë°˜ ì˜ìƒ RAG
            try:
                # ë¹„ë””ì˜¤ ë™ê¸°í™”ê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë¹„ë””ì˜¤ì™€ í•¨ê»˜ ì¬ìƒ
                if st.session_state.is_video_sync_enabled:
                    customer_gender = st.session_state.customer_avatar.get("gender", "male")
                    # â­ LLM ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ê°ì •/ì œìŠ¤ì²˜ íŒë‹¨
                    # â­ Gemini ì œì•ˆ: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                    agent_last_msg = None
                    if st.session_state.simulator_messages:
                        for msg in reversed(st.session_state.simulator_messages):
                            if msg.get("role") == "phone_exchange" and "Agent:" in msg.get("content", ""):
                                agent_last_msg = msg.get("content", "").split("Agent:")[-1].strip()
                                break
                    
                    analysis_result = analyze_text_for_video_selection(
                        st.session_state.call_initial_query,
                        st.session_state.language,
                        agent_last_response=agent_last_msg,
                        conversation_context=st.session_state.simulator_messages[-5:] if st.session_state.simulator_messages else None
                    )
                    avatar_state = analysis_result.get("emotion", st.session_state.customer_avatar.get("state", "NEUTRAL"))
                    gesture = analysis_result.get("gesture", "NONE")
                    context_keywords = analysis_result.get("context_keywords", [])  # â­ Gemini ì œì•ˆ
                    
                    # ë¶„ì„ ê²°ê³¼ë¥¼ ì•„ë°”íƒ€ ìƒíƒœì— ë°˜ì˜
                    st.session_state.customer_avatar["state"] = avatar_state
                    
                    # â­ Gemini ì œì•ˆ: ìƒí™©ë³„ í‚¤ì›Œë“œë¥¼ ê³ ë ¤í•œ ë¹„ë””ì˜¤ ì„ íƒ
                    video_path = get_video_path_by_avatar(
                        customer_gender, 
                        avatar_state, 
                        is_speaking=True,
                        gesture=gesture,
                        context_keywords=context_keywords
                    )
                    
                    if video_path and os.path.exists(video_path):
                        with open(video_path, "rb") as f:
                            video_bytes = f.read()
                        # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ë¥¼ í•¨ê»˜ ì¬ìƒ
                        st.video(video_bytes, format="video/mp4", autoplay=True, loop=False, muted=False)
                        st.audio(st.session_state.customer_initial_audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                    else:
                        # ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
                        st.audio(st.session_state.customer_initial_audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                else:
                    # ë¹„ë””ì˜¤ ë™ê¸°í™”ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
                    st.audio(st.session_state.customer_initial_audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                
                st.success(L["customer_query_playing"])
                st.info(f"{L['query_content_label']} {st.session_state.call_initial_query}")
                
                # â­ ìˆ˜ì •: ì¬ìƒ ì™„ë£Œ ëŒ€ê¸° ë¡œì§ ì™„ì „ ì œê±°
                # ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì¬ìƒë˜ë¯€ë¡œ ì„œë²„ì—ì„œ ê¸°ë‹¤ë¦´ í•„ìš” ì—†ìŒ
                # ì¬ìƒì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì† ì§„í–‰ë˜ë©°, CC ìë§‰ì€ ì´ë¯¸ ë°˜ì˜ë¨
                
            except Exception as e:
                st.warning(L["auto_play_failed"].format(error=str(e)))
                st.audio(st.session_state.customer_initial_audio_bytes, format="audio/mp3", autoplay=False)
                st.info(f"{L['query_content_label']} {st.session_state.call_initial_query}")
            
            # í”Œë˜ê·¸ ì´ˆê¸°í™”
            st.session_state.customer_turn_start = False
            
            # â­ ìˆ˜ì •: ë§ì¶¤í˜• ë°˜ì‘ ìƒì„±ì„ ê°™ì€ ì‹¤í–‰ ì£¼ê¸°ì—ì„œ ì²˜ë¦¬í•˜ë˜, ì¬ìƒì€ ê³„ì† ì§„í–‰ë˜ë„ë¡ í•¨
            # ì—ì´ì „íŠ¸ì˜ ì²« ì¸ì‚¬ë§ ê°€ì ¸ì˜¤ê¸°
            agent_greeting = ""
            for msg in reversed(st.session_state.simulator_messages):
                if msg.get("role") == "agent":
                    agent_greeting = msg.get("content", "")
                    break
            
            if agent_greeting:
                # ë§ì¶¤í˜• ê³ ê° ë°˜ì‘ ìƒì„± (ì¬ìƒê³¼ ë™ì‹œì— ì§„í–‰)
                with st.spinner(L["generating_customized_response"]):
                    customer_reaction = generate_customer_reaction_for_first_greeting(
                        st.session_state.language,
                        agent_greeting,
                        st.session_state.call_initial_query
                    )
                    
                    # ê³ ê° ë°˜ì‘ì„ TTSë¡œ ì¬ìƒ ë° CCì— ë°˜ì˜ (ë¹„ë””ì˜¤ì™€ ë™ê¸°í™”) - LLM ê¸°ë°˜ ì˜ìƒ RAG
                    if not customer_reaction.startswith("âŒ"):
                        audio_bytes, msg = synthesize_tts(customer_reaction, st.session_state.language, role="customer")
                        if audio_bytes:
                            try:
                                # ë¹„ë””ì˜¤ ë™ê¸°í™”ê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë¹„ë””ì˜¤ì™€ í•¨ê»˜ ì¬ìƒ
                                if st.session_state.is_video_sync_enabled:
                                    customer_gender = st.session_state.customer_avatar.get("gender", "male")
                                    # â­ LLM ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ê°ì •/ì œìŠ¤ì²˜ íŒë‹¨
                                    # â­ Gemini ì œì•ˆ: ì—ì´ì „íŠ¸ ë‹µë³€ê³¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                                    agent_last_msg = st.session_state.current_agent_audio_text if hasattr(st.session_state, 'current_agent_audio_text') else None
                                    analysis_result = analyze_text_for_video_selection(
                                        customer_reaction,
                                        st.session_state.language,
                                        agent_last_response=agent_last_msg,
                                        conversation_context=st.session_state.simulator_messages[-5:] if st.session_state.simulator_messages else None
                                    )
                                    avatar_state = analysis_result.get("emotion", st.session_state.customer_avatar.get("state", "NEUTRAL"))
                                    gesture = analysis_result.get("gesture", "NONE")
                                    context_keywords = analysis_result.get("context_keywords", [])  # â­ Gemini ì œì•ˆ
                                    
                                    # ë¶„ì„ ê²°ê³¼ë¥¼ ì•„ë°”íƒ€ ìƒíƒœì— ë°˜ì˜
                                    st.session_state.customer_avatar["state"] = avatar_state
                                    
                                    # â­ Gemini ì œì•ˆ: ìƒí™©ë³„ í‚¤ì›Œë“œë¥¼ ê³ ë ¤í•œ ë¹„ë””ì˜¤ ì„ íƒ
                                    video_path = get_video_path_by_avatar(
                                        customer_gender, 
                                        avatar_state, 
                                        is_speaking=True,
                                        gesture=gesture,
                                        context_keywords=context_keywords
                                    )
                                    
                                    if video_path and os.path.exists(video_path):
                                        with open(video_path, "rb") as f:
                                            video_bytes = f.read()
                                        # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ë¥¼ í•¨ê»˜ ì¬ìƒ
                                        st.video(video_bytes, format="video/mp4", autoplay=True, loop=False, muted=False)
                                        st.audio(audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                                        
                                        # â­ Gemini ì œì•ˆ: ì‚¬ìš©ì í”¼ë“œë°± í‰ê°€ UI ì¶”ê°€
                                        st.markdown("---")
                                        st.markdown("**ğŸ’¬ ë¹„ë””ì˜¤ ë§¤ì¹­ í‰ê°€**")
                                        st.caption("ì´ ë¹„ë””ì˜¤ê°€ ê³ ê°ì˜ í…ìŠ¤íŠ¸ì™€ ê°ì •ì— ìì—°ìŠ¤ëŸ½ê²Œ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆê¹Œ?")
                                        
                                        feedback_key = f"video_feedback_call_{st.session_state.sim_instance_id}_{len(st.session_state.simulator_messages)}"
                                        
                                        col_rating, col_comment = st.columns([2, 3])
                                        with col_rating:
                                            rating = st.slider(
                                                "í‰ê°€ ì ìˆ˜ (1-5ì )",
                                                min_value=1,
                                                max_value=5,
                                                value=3,
                                                key=f"{feedback_key}_rating",
                                                help="1ì : ë§¤ìš° ë¶€ìì—°ìŠ¤ëŸ¬ì›€, 5ì : ë§¤ìš° ìì—°ìŠ¤ëŸ¬ì›€"
                                            )
                                        
                                        with col_comment:
                                            comment = st.text_input(
                                                "ì˜ê²¬ (ì„ íƒì‚¬í•­)",
                                                key=f"{feedback_key}_comment",
                                                placeholder="ì˜ˆ: ë¹„ë””ì˜¤ê°€ í…ìŠ¤íŠ¸ì™€ ì˜ ë§ì•˜ìŠµë‹ˆë‹¤"
                                            )
                                        
                                        if st.button("í”¼ë“œë°± ì œì¶œ", key=f"{feedback_key}_submit"):
                                            # í”¼ë“œë°±ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                                            add_video_mapping_feedback(
                                                customer_text=customer_reaction,
                                                selected_video_path=video_path,
                                                emotion=avatar_state,
                                                gesture=gesture,
                                                context_keywords=context_keywords,
                                                user_rating=rating,
                                                user_comment=comment
                                            )
                                            st.success(f"âœ… í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ì ìˆ˜: {rating}/5)")
                                            st.info("ğŸ’¡ ì´ í”¼ë“œë°±ì€ í–¥í›„ ë¹„ë””ì˜¤ ì„ íƒ ì •í™•ë„ë¥¼ ê°œì„ í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.")
                                    else:
                                        # ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
                                        st.audio(audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                                else:
                                    # ë¹„ë””ì˜¤ ë™ê¸°í™”ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
                                    st.audio(audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                                
                                st.success(L["customer_responded"].format(reaction=customer_reaction.strip()[:50] + "..."))
                            except Exception as e:
                                st.warning(L["auto_play_failed"].format(error=str(e)))
                                st.audio(audio_bytes, format="audio/mp3", autoplay=False)
                                st.success(L["customer_responded"].format(reaction=customer_reaction.strip()[:50] + "..."))
                        else:
                            st.error(L["customer_voice_generation_error"].format(error=msg))
                        
                        # â­ ìˆ˜ì •: ê³ ê° ë°˜ì‘ì„ CC ì˜ì—­ì— ì¶”ê°€ (ê³ ê° ë¬¸ì˜ëŠ” ìœ ì§€)
                        # ê³ ê° ë¬¸ì˜ì™€ ë°˜ì‘ì„ ëª¨ë‘ í‘œì‹œ
                        if st.session_state.current_customer_audio_text == st.session_state.call_initial_query:
                            # ê³ ê° ë¬¸ì˜ë§Œ ìˆëŠ” ê²½ìš° ë°˜ì‘ ì¶”ê°€
                            st.session_state.current_customer_audio_text = f"{st.session_state.call_initial_query}\n\nâ†’ {customer_reaction.strip()}"
                        else:
                            # ì´ë¯¸ ë°˜ì‘ì´ ìˆëŠ” ê²½ìš° ì—…ë°ì´íŠ¸
                            st.session_state.current_customer_audio_text = customer_reaction.strip()
                        
                        # ì´ë ¥ ì €ì¥
                        log_entry = f"Agent: {agent_greeting} | Customer: {customer_reaction.strip()}"
                        st.session_state.simulator_messages.append(
                            {"role": "phone_exchange", "content": log_entry})
                    else:
                        st.error(customer_reaction)
            
            # â­ ìˆ˜ì •: rerun ì™„ì „ ì œê±° - ì¬ìƒì€ ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì§„í–‰ë˜ë¯€ë¡œ ì„œë²„ì—ì„œ ê¸°ë‹¤ë¦´ í•„ìš” ì—†ìŒ

        # â­ ìˆ˜ì •: ì „ì‚¬ í›„ ê³ ê° ë°˜ì‘ ìƒì„± ì²˜ë¦¬ (ë§ˆì´í¬ ìœ„ì ¯ ë Œë”ë§ ì´í›„ì— ìœ„ì¹˜)
        # ì „ì‚¬ ê²°ê³¼ê°€ CCì— ë¨¼ì € í‘œì‹œëœ í›„ ê³ ê° ë°˜ì‘ì„ ìƒì„±í•˜ë„ë¡ ë¶„ë¦¬
        if st.session_state.get("process_customer_reaction") and st.session_state.get("pending_agent_transcript"):
            pending_transcript = st.session_state.pending_agent_transcript
            # í”Œë˜ê·¸ ì´ˆê¸°í™”
            st.session_state.process_customer_reaction = False
            del st.session_state.pending_agent_transcript

            # â­ ìˆ˜ì •: ì—ì´ì „íŠ¸ ì‘ë‹µì„ ë¨¼ì € CCì— ë°˜ì˜
            if hasattr(st.session_state, 'current_agent_audio_text'):
                st.session_state.current_agent_audio_text = pending_transcript
            else:
                st.session_state.current_agent_audio_text = pending_transcript

            # ê³ ê° ë°˜ì‘ ìƒì„±
            with st.spinner(L["generating_customer_response"]):
                customer_reaction = generate_customer_reaction_for_call(
                    st.session_state.language,
                    pending_transcript
                )

                # ê³ ê° ë°˜ì‘ì„ TTSë¡œ ì¬ìƒ ë° CCì— ë°˜ì˜ (ë¹„ë””ì˜¤ì™€ ë™ê¸°í™”) - LLM ê¸°ë°˜ ì˜ìƒ RAG
                if not customer_reaction.startswith("âŒ"):
                    audio_bytes, msg = synthesize_tts(customer_reaction, st.session_state.language, role="customer")
                    if audio_bytes:
                        # Streamlit ë¬¸ì„œ: autoplayëŠ” ë¸Œë¼ìš°ì € ì •ì±…ìƒ ì œí•œë  ìˆ˜ ìˆìŒ
                        try:
                            # ë¹„ë””ì˜¤ ë™ê¸°í™”ê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë¹„ë””ì˜¤ì™€ í•¨ê»˜ ì¬ìƒ
                            if st.session_state.is_video_sync_enabled:
                                customer_gender = st.session_state.customer_avatar.get("gender", "male")
                                # â­ LLM ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ê°ì •/ì œìŠ¤ì²˜ íŒë‹¨
                                # â­ Gemini ì œì•ˆ: ì—ì´ì „íŠ¸ ë‹µë³€ê³¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
                                agent_last_msg = st.session_state.current_agent_audio_text if hasattr(st.session_state, 'current_agent_audio_text') else None
                                analysis_result = analyze_text_for_video_selection(
                                    customer_reaction,
                                    st.session_state.language,
                                    agent_last_response=agent_last_msg,
                                    conversation_context=st.session_state.simulator_messages[-5:] if st.session_state.simulator_messages else None
                                )
                                avatar_state = analysis_result.get("emotion", st.session_state.customer_avatar.get("state", "NEUTRAL"))
                                gesture = analysis_result.get("gesture", "NONE")
                                context_keywords = analysis_result.get("context_keywords", [])  # â­ Gemini ì œì•ˆ
                                
                                # ë¶„ì„ ê²°ê³¼ë¥¼ ì•„ë°”íƒ€ ìƒíƒœì— ë°˜ì˜
                                st.session_state.customer_avatar["state"] = avatar_state
                                
                                # â­ Gemini ì œì•ˆ: ìƒí™©ë³„ í‚¤ì›Œë“œë¥¼ ê³ ë ¤í•œ ë¹„ë””ì˜¤ ì„ íƒ
                                video_path = get_video_path_by_avatar(
                                    customer_gender, 
                                    avatar_state, 
                                    is_speaking=True,
                                    gesture=gesture,
                                    context_keywords=context_keywords
                                )
                                
                                if video_path and os.path.exists(video_path):
                                    with open(video_path, "rb") as f:
                                        video_bytes = f.read()
                                    # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ë¥¼ í•¨ê»˜ ì¬ìƒ
                                    st.video(video_bytes, format="video/mp4", autoplay=True, loop=False, muted=False)
                                    st.audio(audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                                    
                                    # â­ Gemini ì œì•ˆ: ì‚¬ìš©ì í”¼ë“œë°± í‰ê°€ UI ì¶”ê°€
                                    st.markdown("---")
                                    st.markdown("**ğŸ’¬ ë¹„ë””ì˜¤ ë§¤ì¹­ í‰ê°€**")
                                    st.caption("ì´ ë¹„ë””ì˜¤ê°€ ê³ ê°ì˜ í…ìŠ¤íŠ¸ì™€ ê°ì •ì— ìì—°ìŠ¤ëŸ½ê²Œ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆê¹Œ?")
                                    
                                    feedback_key = f"video_feedback_{st.session_state.sim_instance_id}_{len(st.session_state.simulator_messages)}"
                                    
                                    col_rating, col_comment = st.columns([2, 3])
                                    with col_rating:
                                        rating = st.slider(
                                            "í‰ê°€ ì ìˆ˜ (1-5ì )",
                                            min_value=1,
                                            max_value=5,
                                            value=3,
                                            key=f"{feedback_key}_rating",
                                            help="1ì : ë§¤ìš° ë¶€ìì—°ìŠ¤ëŸ¬ì›€, 5ì : ë§¤ìš° ìì—°ìŠ¤ëŸ¬ì›€"
                                        )
                                    
                                    with col_comment:
                                        comment = st.text_input(
                                            "ì˜ê²¬ (ì„ íƒì‚¬í•­)",
                                            key=f"{feedback_key}_comment",
                                            placeholder="ì˜ˆ: ë¹„ë””ì˜¤ê°€ í…ìŠ¤íŠ¸ì™€ ì˜ ë§ì•˜ìŠµë‹ˆë‹¤"
                                        )
                                    
                                    if st.button("í”¼ë“œë°± ì œì¶œ", key=f"{feedback_key}_submit"):
                                        # í”¼ë“œë°±ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                                        add_video_mapping_feedback(
                                            customer_text=customer_reaction,
                                            selected_video_path=video_path,
                                            emotion=avatar_state,
                                            gesture=gesture,
                                            context_keywords=context_keywords,
                                            user_rating=rating,
                                            user_comment=comment
                                        )
                                        st.success(f"âœ… í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ì ìˆ˜: {rating}/5)")
                                        st.info("ğŸ’¡ ì´ í”¼ë“œë°±ì€ í–¥í›„ ë¹„ë””ì˜¤ ì„ íƒ ì •í™•ë„ë¥¼ ê°œì„ í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.")
                                else:
                                    # ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
                                    st.audio(audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                            else:
                                # ë¹„ë””ì˜¤ ë™ê¸°í™”ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì˜¤ë””ì˜¤ë§Œ ì¬ìƒ
                                st.audio(audio_bytes, format="audio/mp3", autoplay=True, loop=False)
                            
                            st.success(L["customer_responded"].format(reaction=customer_reaction.strip()[:50] + "..."))
                            # â­ ìˆ˜ì •: ê³ ê° ë°˜ì‘ ì¬ìƒ ì‹œê°„ í™•ë³´ë¥¼ ìœ„í•´ ì§§ì€ ëŒ€ê¸°
                            time.sleep(0.5)
                        except Exception as e:
                            st.warning(L["auto_play_failed"].format(error=str(e)))
                            st.audio(audio_bytes, format="audio/mp3", autoplay=False)
                            st.success(L["customer_responded"].format(reaction=customer_reaction.strip()[:50] + "..."))
                    else:
                        st.error(L["customer_voice_generation_error"].format(error=msg))

                    # ê³ ê° ë°˜ì‘ í…ìŠ¤íŠ¸ë¥¼ CC ì˜ì—­ì— ë°˜ì˜
                    st.session_state.current_customer_audio_text = customer_reaction.strip()
                    
                    # â­ ìˆ˜ì •: ê³ ê° ë°˜ì‘ì„ ì´ë ¥ì— ì €ì¥ (ì „í™” ë°œì‹  ëª¨ë“œì—ì„œë„ ì‘ë™)
                    agent_response_text = st.session_state.get("current_agent_audio_text", pending_transcript)
                    log_entry = f"Agent: {agent_response_text} | Customer: {customer_reaction.strip()}"
                    st.session_state.simulator_messages.append(
                        {"role": "phone_exchange", "content": log_entry}
                    )

                    # â­ ìˆ˜ì •: "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤" ì‘ë‹µ ì²˜ë¦¬ - ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ í›„ ì¢…ë£Œ
                    if L['customer_no_more_inquiries'] in customer_reaction:
                        # â­ ìˆ˜ì •: ì´ë ¥ ì €ì¥ì€ ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì €ì¥ ë°©ì§€
                        
                        # â­ ì¶”ê°€: ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ ë©”ì‹œì§€ ì „ì†¡
                        agent_name = st.session_state.get("agent_name", "000")
                        current_lang_call = st.session_state.get("language", "ko")
                        if current_lang_call == "ko":
                            agent_closing_msg = f"ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› {agent_name}ì˜€ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì„¸ìš”."
                        elif current_lang_call == "en":
                            agent_closing_msg = f"Thank you for contacting us. This was {agent_name}. Have a great day!"
                        else:  # ja
                            agent_closing_msg = f"ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚æ‹…å½“ã¯{agent_name}ã§ã—ãŸã€‚è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚"
                        
                        st.session_state.simulator_messages.append(
                            {"role": "phone_exchange", "content": f"Agent: {agent_closing_msg}"}
                        )
                        
                        # í†µí™” ìš”ì•½ ìƒì„±
                        with st.spinner("AI ìš”ì•½ ìƒì„± ì¤‘..."):
                            summary = summarize_history_for_call(
                                st.session_state.simulator_messages,
                                st.session_state.call_initial_query,
                                st.session_state.language
                            )
                            st.session_state.call_summary_text = summary
                        
                        # í†µí™” ì¢…ë£Œ
                        st.session_state.call_sim_stage = "CALL_ENDED"
                        st.session_state.is_call_ended = True
                        
                        # ì—ì´ì „íŠ¸ ì…ë ¥ ì˜ì—­ ì´ˆê¸°í™”
                        st.session_state.current_agent_audio_text = ""
                        st.session_state.realtime_hint_text = ""
                        if "bytes_to_process" in st.session_state:
                            st.session_state.bytes_to_process = None
                        
                        st.success("âœ… ê³ ê°ì´ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ë‹¤ê³  í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ê°€ ê°ì‚¬ ì¸ì‚¬ë¥¼ ì „ì†¡í•œ í›„ í†µí™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    # â­ ì¶”ê°€: "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ë„ ìˆìŠµë‹ˆë‹¤" ì‘ë‹µ ì²˜ë¦¬ (í†µí™” ê³„ì†)
                    elif L['customer_has_additional_inquiries'] in customer_reaction:
                        # â­ ìˆ˜ì •: ì´ë ¥ ì €ì¥ì€ ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì €ì¥ ë°©ì§€
                        
                        # ì—ì´ì „íŠ¸ ì…ë ¥ ì˜ì—­ ì´ˆê¸°í™” (ë‹¤ìŒ ë…¹ìŒì„ ìœ„í•´)
                        st.session_state.current_agent_audio_text = ""
                        st.session_state.realtime_hint_text = ""
                        if "bytes_to_process" in st.session_state:
                            st.session_state.bytes_to_process = None
                        
                        st.info("ğŸ’¡ ê³ ê°ì´ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‘ë‹µì„ ë…¹ìŒí•˜ì„¸ìš”.")
                    else:
                        # ì¼ë°˜ ê³ ê° ë°˜ì‘ ì²˜ë¦¬
                        # â­ ìˆ˜ì •: ì´ë ¥ ì €ì¥ì€ ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ì €ì¥ ë°©ì§€

                        # ì—ì´ì „íŠ¸ ì…ë ¥ ì˜ì—­ ì´ˆê¸°í™” (ë‹¤ìŒ ë…¹ìŒì„ ìœ„í•´)
                        st.session_state.current_agent_audio_text = ""
                        st.session_state.realtime_hint_text = ""
                        # â­ ìµœì í™”: bytes_to_processë„ ì´ˆê¸°í™”í•˜ì—¬ ë‹¤ìŒ ë…¹ìŒì„ ì¤€ë¹„
                        if "bytes_to_process" in st.session_state:
                            st.session_state.bytes_to_process = None

                    # â­ ìˆ˜ì •: rerun ì œê±° - ì¬ìƒì€ ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì§„í–‰ë˜ë¯€ë¡œ ì„œë²„ì—ì„œ ê¸°ë‹¤ë¦´ í•„ìš” ì—†ìŒ
                    # ì²« ë¬¸ì˜ì™€ ë™ì¼í•˜ê²Œ rerunì„ ì œê±°í•˜ì—¬ ì¬ìƒì´ ëê¹Œì§€ ì§„í–‰ë˜ë„ë¡ í•¨


    # ========================================
    # CALL_ENDED ìƒíƒœ
    # ========================================
    elif st.session_state.call_sim_stage == "CALL_ENDED":
        st.success(L["call_end_message"])

        # AHT
        if st.session_state.start_time is not None:
            final_aht_seconds = max(0, (datetime.now() - st.session_state.start_time).total_seconds())
            final_aht_str = str(timedelta(seconds=final_aht_seconds)).split('.')[0]
            st.metric("Final AHT", final_aht_str)

            hold_str = str(st.session_state.total_hold_duration).split('.')[0]
            st.metric("Total Hold Time", hold_str)
        else:
            st.warning(L["aht_not_recorded"])

        st.markdown("---")

        # â­ ì¶”ê°€: í˜„ì¬ ì„¸ì…˜ ì´ë ¥ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ (ì±„íŒ…/ì´ë©”ì¼ê³¼ ë™ì¼)
        st.markdown("**ğŸ“¥ í˜„ì¬ ì„¸ì…˜ ì´ë ¥ ë‹¤ìš´ë¡œë“œ**")
        download_col1, download_col2, download_col3 = st.columns(3)
        
        # í˜„ì¬ ì„¸ì…˜ì˜ ì´ë ¥ì„ ìƒì„±
        current_session_history = None
        if st.session_state.simulator_messages:
            try:
                customer_type_display = st.session_state.get("customer_type_sim_select", "")
                # ì „í™” ìš”ì•½ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„±
                if st.session_state.call_summary_text:
                    # call_summary_textë¥¼ summary í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    summary_data = {
                        "main_inquiry": st.session_state.call_initial_query,
                        "key_responses": [],
                        "customer_sentiment_score": 50,  # ê¸°ë³¸ê°’
                        "customer_satisfaction_score": 50,  # ê¸°ë³¸ê°’
                        "customer_characteristics": {},
                        "privacy_info": {},
                        "summary": st.session_state.call_summary_text
                    }
                else:
                    # ìš”ì•½ ìƒì„±
                    summary_data = generate_chat_summary(
                        st.session_state.simulator_messages,
                        st.session_state.call_initial_query,
                        customer_type_display,
                        st.session_state.language
                    )
                
                current_session_history = [{
                    "id": f"call_session_{st.session_state.sim_instance_id}",
                    "timestamp": datetime.now().isoformat(),
                    "initial_query": st.session_state.call_initial_query,
                    "customer_type": customer_type_display,
                    "language_key": st.session_state.language,
                    "messages": st.session_state.simulator_messages,
                    "summary": summary_data,
                    "is_chat_ended": True,
                    "attachment_context": st.session_state.get("sim_attachment_context_for_llm", ""),
                    "is_call": True
                }]
            except Exception as e:
                st.warning(f"ì´ë ¥ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ì„ ì§ì ‘ í‘œì‹œ
        if current_session_history:
            # í˜„ì¬ ì–¸ì–´ ê°€ì ¸ì˜¤ê¸°
            current_lang = st.session_state.get("language", "ko")
            if current_lang not in ["ko", "en", "ja"]:
                current_lang = "ko"
            
            with download_col1:
                try:
                    filepath_word = export_history_to_word(current_session_history, lang=current_lang)
                    with open(filepath_word, "rb") as f:
                        st.download_button(
                            label=L.get("download_history_word", "ğŸ“¥ ì´ë ¥ ë‹¤ìš´ë¡œë“œ (Word)"),
                            data=f.read(),
                            file_name=os.path.basename(filepath_word),
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key="download_call_word_file"
                        )
                except Exception as e:
                    st.error(f"Word ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            
            with download_col2:
                try:
                    filepath_pptx = export_history_to_pptx(current_session_history, lang=current_lang)
                    with open(filepath_pptx, "rb") as f:
                        st.download_button(
                            label=L.get("download_history_pptx", "ğŸ“¥ ì´ë ¥ ë‹¤ìš´ë¡œë“œ (PPTX)"),
                            data=f.read(),
                            file_name=os.path.basename(filepath_pptx),
                            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                            key="download_call_pptx_file"
                        )
                except Exception as e:
                    st.error(f"PPTX ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            
            with download_col3:
                try:
                    filepath_pdf = export_history_to_pdf(current_session_history, lang=current_lang)
                    with open(filepath_pdf, "rb") as f:
                        st.download_button(
                            label=L.get("download_history_pdf", "ğŸ“¥ ì´ë ¥ ë‹¤ìš´ë¡œë“œ (PDF)"),
                            data=f.read(),
                            file_name=os.path.basename(filepath_pdf),
                            mime="application/pdf",
                            key="download_call_pdf_file"
                        )
                except Exception as e:
                    st.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        else:
            st.warning("ë‹¤ìš´ë¡œë“œí•  ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")

        with st.expander("í†µí™” ê¸°ë¡ ìš”ì•½"):
            st.subheader("AI í†µí™” ìš”ì•½")

            if st.session_state.call_summary_text:
                st.info(st.session_state.call_summary_text)
            else:
                st.error("âŒ í†µí™” ìš”ì•½ ìƒì„± ì‹¤íŒ¨")

            st.markdown("---")

            st.subheader("ê³ ê° ìµœì´ˆ ë¬¸ì˜ (ìŒì„±)")
            if st.session_state.customer_initial_audio_bytes:
                # Streamlit ë¬¸ì„œ: bytes ë°ì´í„°ë¥¼ ì§ì ‘ ì „ë‹¬ ê°€ëŠ¥
                try:
                    st.audio(st.session_state.customer_initial_audio_bytes, format="audio/mp3", autoplay=False)
                except Exception as e:
                    st.error(f"ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")
                st.caption(f"ì „ì‚¬: {st.session_state.call_initial_query}")
            else:
                st.info("ê³ ê° ìµœì´ˆ ìŒì„± ì—†ìŒ")

            st.markdown("---")
            st.subheader("ì „ì²´ êµí™˜ ë¡œê·¸")
            for log in st.session_state.simulator_messages:
                st.write(log["content"])

        # ìƒˆ ì‹œë®¬ë ˆì´ì…˜
        if st.button(L["new_simulation_button"]):
            st.session_state.call_sim_stage = "WAITING_CALL"
            st.session_state.call_sim_mode = "INBOUND"
            st.session_state.is_on_hold = False
            st.session_state.total_hold_duration = timedelta(0)
            st.session_state.hold_start_time = None
            st.session_state.start_time = None
            st.session_state.current_customer_audio_text = ""
            st.session_state.current_agent_audio_text = ""
            st.session_state.agent_response_input_box_widget_call = ""
            st.session_state.call_initial_query = ""
            st.session_state.call_website_url = ""  # í™ˆí˜ì´ì§€ ì£¼ì†Œ ì´ˆê¸°í™”
            st.session_state.simulator_messages = []
            st.session_state.call_summary_text = ""
            st.session_state.customer_initial_audio_bytes = None
            st.session_state.customer_history_summary = ""
            st.session_state.sim_audio_bytes = None


# -------------------- RAG Tab --------------------
elif feature_selection == L["rag_tab"]:
    st.header(L["rag_header"])
    st.markdown(L["rag_desc"])
    st.markdown("---")

    # â­ RAG ë°ì´í„° í•™ìŠµ ê¸°ëŠ¥ ì¶”ê°€ - AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„° ë°ì´í„°ë¥¼ ì¼ì¼ íŒŒì¼ë¡œ í•™ìŠµ
    st.subheader("ğŸ“š ê³ ê° ê°€ì´ë“œ ìë™ ìƒì„± (ì¼ì¼ í•™ìŠµ)")
    
    if st.button("ì˜¤ëŠ˜ ë‚ ì§œ ê³ ê° ê°€ì´ë“œ ìƒì„±", key="generate_daily_guide"):
        # ì˜¤ëŠ˜ ë‚ ì§œë¡œ íŒŒì¼ëª… ìƒì„± (ì˜ˆ: 251130_ê³ ê°ê°€ì´ë“œ.TXT)
        today_str = datetime.now().strftime("%y%m%d")
        guide_filename = f"{today_str}_ê³ ê°ê°€ì´ë“œ.TXT"
        guide_filepath = os.path.join(DATA_DIR, guide_filename)
        
        # ìµœê·¼ ì´ë ¥ ë¡œë“œ
        all_histories = load_simulation_histories_local(st.session_state.language)
        recent_histories = all_histories[:50]  # ìµœê·¼ 50ê°œ ì´ë ¥ ì‚¬ìš©
        
        if recent_histories:
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ê³ ê° ê°€ì´ë“œ ìƒì„±
            guide_prompt = f"""
ë‹¹ì‹ ì€ CS ì„¼í„° êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê³ ê° ì‘ëŒ€ ì´ë ¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¢…í•©ì ì¸ ê³ ê° ì‘ëŒ€ ê°€ì´ë“œë¼ì¸ì„ ì‘ì„±í•˜ì„¸ìš”.

ë¶„ì„í•  ì´ë ¥ ë°ì´í„°:
{json.dumps([h.get('summary', {}) for h in recent_histories if h.get('summary')], ensure_ascii=False, indent=2)}

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ê°€ì´ë“œë¼ì¸ì„ ì‘ì„±í•˜ì„¸ìš”:
1. ê³ ê° ìœ í˜•ë³„ ì‘ëŒ€ ì „ëµ (ì¼ë°˜/ê¹Œë‹¤ë¡œìš´/ë§¤ìš° ë¶ˆë§Œì¡±)
2. ë¬¸í™”ê¶Œë³„ ì‘ëŒ€ ê°€ì´ë“œ (ì–¸ì–´, ë¬¸í™”ì  ë°°ê²½ ê³ ë ¤)
3. ì£¼ìš” ë¬¸ì˜ ìœ í˜•ë³„ í•´ê²° ë°©ë²•
4. ê³ ê° ê°ì • ì ìˆ˜ì— ë”°ë¥¸ ì‘ëŒ€ ì „ëµ
5. ê°œì¸ì •ë³´ ì²˜ë¦¬ ê°€ì´ë“œ
6. íš¨ê³¼ì ì¸ ì†Œí†µ ìŠ¤íƒ€ì¼ ê¶Œì¥ì‚¬í•­

ê°€ì´ë“œë¼ì¸ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
            
            if st.session_state.is_llm_ready:
                with st.spinner("ê³ ê° ê°€ì´ë“œ ìƒì„± ì¤‘..."):
                    guide_content = run_llm(guide_prompt)
                    
                    # íŒŒì¼ ì €ì¥
                    with open(guide_filepath, "w", encoding="utf-8") as f:
                        f.write(f"ê³ ê° ì‘ëŒ€ ê°€ì´ë“œë¼ì¸\n")
                        f.write(f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write(f"ë¶„ì„ ì´ë ¥ ìˆ˜: {len(recent_histories)}\n")
                        f.write("=" * 80 + "\n\n")
                        f.write(guide_content)
                    
                    st.success(f"âœ… ê³ ê° ê°€ì´ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {guide_filename}")
                    st.info(f"íŒŒì¼ ìœ„ì¹˜: {guide_filepath}")
                    
                    # ìƒì„±ëœ íŒŒì¼ì„ ìë™ìœ¼ë¡œ RAGì— ì¶”ê°€í• ì§€ ì„ íƒ
                    if st.button("ìƒì„±ëœ ê°€ì´ë“œë¥¼ RAGì— ì¶”ê°€", key="add_guide_to_rag"):
                        # íŒŒì¼ì„ ì—…ë¡œë“œëœ íŒŒì¼ì²˜ëŸ¼ ì²˜ë¦¬í•˜ì—¬ RAGì— ì¶”ê°€
                        st.info("RAG ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")
                        # ì‹¤ì œë¡œëŠ” íŒŒì¼ì„ ì½ì–´ì„œ RAG ì¸ë±ìŠ¤ì— ì¶”ê°€í•˜ëŠ” ë¡œì§ í•„ìš”
            else:
                st.error("LLMì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API Keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        else:
            st.warning("ë¶„ì„í•  ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    st.markdown("---")

    # --- íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ---
    # â­ ìˆ˜ì •ëœ ë¶€ë¶„: RAG íƒ­ ì „ìš© í‚¤ ì‚¬ìš©
    uploaded_files = st.file_uploader(
        L["file_uploader"],
        type=["pdf", "txt", "html"],
        key="rag_file_uploader", # RAG ì „ìš© í‚¤
        accept_multiple_files=True
    )

    if uploaded_files:
        if uploaded_files != st.session_state.uploaded_files_state:
            # íŒŒì¼ì´ ë³€ê²½ë˜ë©´ RAG ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.is_rag_ready = False
            st.session_state.rag_vectorstore = None
            st.session_state.uploaded_files_state = uploaded_files

        if not st.session_state.is_rag_ready:
            if st.button(L["button_start_analysis"]):
                if not st.session_state.is_llm_ready:
                    st.error(L["simulation_no_key_warning"])
                else:
                    with st.spinner(L["data_analysis_progress"]):
                        vectorstore, count = build_rag_index(uploaded_files)

                    if vectorstore:
                        st.session_state.rag_vectorstore = vectorstore
                        st.session_state.is_rag_ready = True
                        st.success(L["embed_success"].format(count=count))
                        st.session_state.rag_messages = [
                            {"role": "assistant", "content": f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ ë¶„ì„ ì™„ë£Œ. ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."}
                        ]
                    else:
                        st.error(L["embed_fail"])
                        st.session_state.is_rag_ready = False
    else:
        st.info(L["warning_no_files"])
        st.session_state.is_rag_ready = False
        st.session_state.rag_vectorstore = None
        st.session_state.rag_messages = []

    st.markdown("---")

    # --- ì±—ë´‡ ì„¹ì…˜ ---
    if st.session_state.is_rag_ready and st.session_state.rag_vectorstore:
        if "rag_messages" not in st.session_state:
            st.session_state.rag_messages = [{"role": "assistant", "content": "ë¶„ì„ëœ ìë£Œì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."}]

        for message in st.session_state.rag_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input(L["rag_input_placeholder"]):
            st.session_state.rag_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner(L["response_generating"]):
                    response = rag_answer(
                        prompt,
                        st.session_state.rag_vectorstore,
                        st.session_state.language
                    )
                    st.markdown(response)

            st.session_state.rag_messages.append({"role": "assistant", "content": response})
    else:
        st.warning(L["warning_rag_not_ready"])

# -------------------- Content Tab --------------------
elif feature_selection == L["content_tab"]:
    st.header(L["content_header"])
    st.markdown(L["content_desc"])
    st.markdown("---")

    if not st.session_state.is_llm_ready:
        st.warning(L["simulation_no_key_warning"])
        st.info("ğŸ’¡ API Keyë¥¼ ì„¤ì •í•˜ë©´ ì½˜í…ì¸  ìƒì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        # st.stop() ì œê±°: UIëŠ” í‘œì‹œí•˜ë˜ ê¸°ëŠ¥ë§Œ ë¹„í™œì„±í™”

    # ë‹¤êµ­ì–´ ë§µí•‘ ë³€ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
    level_map = {
        "ì´ˆê¸‰": "Beginner",
        "ì¤‘ê¸‰": "Intermediate",
        "ê³ ê¸‰": "Advanced",
        "Beginner": "Beginner",
        "Intermediate": "Intermediate",
        "Advanced": "Advanced",
        "åˆç´š": "Beginner",
        "ä¸­ç´š": "Intermediate",
        "ä¸Šç´š": "Advanced",
    }
    content_map = {
        "í•µì‹¬ ìš”ì•½ ë…¸íŠ¸": "summary",
        "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­": "quiz",
        "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´": "example",
        "Key Summary Note": "summary",
        "10 MCQ Questions": "quiz",
        "Practical Example Idea": "example",
        "æ ¸å¿ƒè¦ç´„ãƒãƒ¼ãƒˆ": "summary",
        "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•": "quiz",
        "å®Ÿè·µä¾‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢": "example",
    }

    topic = st.text_input(L["topic_label"])
    level_display = st.selectbox(L["level_label"], L["level_options"])
    content_display = st.selectbox(L["content_type_label"], L["content_options"])

    level = level_map.get(level_display, "Beginner")
    content_type = content_map.get(content_display, "summary")

    if st.button(L["button_generate"]):
        if not topic.strip():
            st.warning(L["warning_topic"])
            # st.stop() ì œê±°: ê²½ê³ ë§Œ í‘œì‹œí•˜ê³  ê³„ì† ì§„í–‰
        elif not st.session_state.is_llm_ready:
            st.error("âŒ LLMì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API Keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            # st.stop() ì œê±°: ì—ëŸ¬ë§Œ í‘œì‹œí•˜ê³  ê³„ì† ì§„í–‰
        else:
            target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]

            # ê³µí†µ í”„ë¡¬í”„íŠ¸ ì„¤ì • (í€´ì¦ˆ í˜•ì‹ì„ í¬í•¨í•˜ì§€ ì•ŠëŠ” ê¸°ë³¸ í…œí”Œë¦¿)
            system_prompt = f"""
            You are a professional AI coach. Generate learning content in {target_lang} for the topic '{topic}' at the '{level}' difficulty.
            The content format requested is: {content_display}.
            Output ONLY the raw content.
            """

            if content_type == "quiz":
                # í€´ì¦ˆ ì „ìš© í”„ë¡¬í”„íŠ¸ ë° JSON êµ¬ì¡° ê°•ì œ (ë¡œì§ ìœ ì§€)
                lang_instruction = {"ko": "í•œêµ­ì–´ë¡œ", "en": "in English", "ja": "æ—¥æœ¬èªã§"}.get(st.session_state.language, "in Korean")
                quiz_prompt = f"""
                You are an expert quiz generator. Based on the topic '{topic}' and difficulty '{level}', generate 10 multiple-choice questions.
                IMPORTANT: All questions, options, and explanations must be written {lang_instruction}.
                Your output MUST be a **raw JSON object** containing a single key "quiz_questions" which holds an array of 10 questions.
                Each object in the array must strictly follow the required keys: 
                - "question" (string): The question text in {lang_instruction}
                - "options" (array of 4 strings): Four answer choices in {lang_instruction}
                - "answer" (integer): The correct answer index starting from 1 (1-4)
                - "explanation" (string): A DETAILED and COMPREHENSIVE explanation (at least 2-3 sentences, preferably 50-100 words) explaining:
                  * Why the correct answer is right
                  * Why other options are incorrect (briefly mention key differences)
                  * Additional context or background information that helps understanding
                  * Real-world examples or applications if relevant
                  Write the explanation in {lang_instruction} with clear, educational content.
                DO NOT include any explanation, introductory text, or markdown code blocks (e.g., ```json).
                Output ONLY the raw JSON object, starting with '{{' and ending with '}}'.
                Example structure:
                {{
                  "quiz_questions": [
                    {{
                      "question": "ì§ˆë¬¸ ë‚´ìš©",
                      "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
                      "answer": 1,
                      "explanation": "ì •ë‹µì¸ ì´ìœ ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ê³ , ë‹¤ë¥¸ ì„ íƒì§€ê°€ ì™œ í‹€ë ¸ëŠ”ì§€ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ë©°, ê´€ë ¨ ë°°ê²½ ì§€ì‹ì´ë‚˜ ì‹¤ì œ ì‚¬ë¡€ë¥¼ í¬í•¨í•œ ì¶©ë¶„íˆ ê¸´ í•´ì„¤ ë‚´ìš© (ìµœì†Œ 2-3ë¬¸ì¥, 50-100ë‹¨ì–´ ì •ë„)"
                    }}
                  ]
                }}
            def extract_json_from_text(text):
                """í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
                if not text:
                    return None
                
                text = text.strip()
                
                # 1. Markdown ì½”ë“œ ë¸”ë¡ ì œê±°
                if "```json" in text:
                    start = text.find("```json") + 7
                    end = text.find("```", start)
                    if end != -1:
                        text = text[start:end].strip()
                elif "```" in text:
                    start = text.find("```") + 3
                    end = text.find("```", start)
                    if end != -1:
                        text = text[start:end].strip()
                
                # 2. ì²« ë²ˆì§¸ '{' ë¶€í„° ë§ˆì§€ë§‰ '}' ê¹Œì§€ ì¶”ì¶œ
                first_brace = text.find('{')
                if first_brace == -1:
                    return None
                
                # ì¤‘ê´„í˜¸ ë§¤ì¹­ìœ¼ë¡œ JSON ê°ì²´ ë ì°¾ê¸°
                brace_count = 0
                last_brace = -1
                for i in range(first_brace, len(text)):
                    if text[i] == '{':
                        brace_count += 1
                    elif text[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            last_brace = i
                            break
                
                if last_brace != -1:
                    json_str = text[first_brace:last_brace + 1]
                    return json_str.strip()
                
                return None

            generated_json_text = None
            raw_response_text = None
            llm_attempts = []

            # 1ìˆœìœ„: OpenAI (JSON modeê°€ ê°€ì¥ ì•ˆì •ì )
            if get_api_key("openai"):
                llm_attempts.append(("openai", get_api_key("openai"), "gpt-4o"))
            # 2ìˆœìœ„: Gemini (Fallback)
            if get_api_key("gemini"):
                llm_attempts.append(("gemini", get_api_key("gemini"), "gemini-2.5-flash"))

            with st.spinner(L["response_generating"]):
                for provider, api_key, model_name in llm_attempts:
                    try:
                        if provider == "openai":
                            client = OpenAI(api_key=api_key)
                            response = client.chat.completions.create(
                                model=model_name,
                                messages=[{"role": "user", "content": quiz_prompt}],
                                # JSON Mode ê°•ì œ
                                response_format={"type": "json_object"},
                            )
                            raw_response_text = response.choices[0].message.content.strip()
                            # OpenAIëŠ” JSON ê°ì²´ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, ì§ì ‘ ì‚¬ìš© ì‹œë„
                            generated_json_text = extract_json_from_text(raw_response_text) or raw_response_text
                            break

                        elif provider == "gemini":
                            # GeminiëŠ” response_formatì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, run_llmì„ í†µí•´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ í˜¸ì¶œ
                            raw_response_text = run_llm(quiz_prompt)
                            generated_json_text = extract_json_from_text(raw_response_text)
                            
                            # JSON ì¶”ì¶œ ì„±ê³µ ì‹œ ì‹œë„ ì¢…ë£Œ
                            if generated_json_text:
                                break

                    except Exception as e:
                        print(f"JSON generation failed with {provider}: {e}")
                        continue

            # --- START: JSON Parsing and Error Handling Logic ---
            parsed_obj = None
            quiz_data = None
            
            if generated_json_text:
                try:
                    # JSON ê°ì²´ íŒŒì‹± ì‹œë„
                    parsed_obj = json.loads(generated_json_text)

                    # 'quiz_questions' í‚¤ì—ì„œ ë°°ì—´ ì¶”ì¶œ
                    quiz_data = parsed_obj.get("quiz_questions")

                    if not isinstance(quiz_data, list) or len(quiz_data) < 1:
                        raise ValueError("Missing 'quiz_questions' key or empty array.")

                    # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬: ê° ë¬¸ì œì— í•„ìˆ˜ í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                    for i, q in enumerate(quiz_data):
                        if not isinstance(q, dict):
                            raise ValueError(f"Question {i+1} is not a valid object.")
                        if "question" not in q or "options" not in q or "answer" not in q:
                            raise ValueError(f"Question {i+1} is missing required fields (question, options, or answer).")
                        if not isinstance(q["options"], list) or len(q["options"]) != 4:
                            raise ValueError(f"Question {i+1} must have exactly 4 options.")
                        if not isinstance(q["answer"], int) or q["answer"] < 1 or q["answer"] > 4:
                            raise ValueError(f"Question {i+1} answer must be an integer between 1 and 4.")

                    # íŒŒì‹± ì„±ê³µ ë° ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ í›„ ìƒíƒœ ì €ì¥
                    st.session_state.quiz_data = quiz_data
                    st.session_state.current_question_index = 0
                    st.session_state.quiz_score = 0
                    st.session_state.quiz_answers = [1] * len(quiz_data)
                    st.session_state.show_explanation = False
                    st.session_state.is_quiz_active = True
                    st.session_state.quiz_type_key = str(uuid.uuid4())

                    st.success(f"**{topic}** - {content_display} ìƒì„± ì™„ë£Œ")

                except json.JSONDecodeError as e:
                    # JSON íŒŒì‹± ì˜¤ë¥˜
                    st.error(L["quiz_error_llm"])
                    st.caption(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                    st.subheader(L["quiz_original_response"])
                    st.code(raw_response_text or generated_json_text, language="text")
                    if generated_json_text:
                        st.caption("ì¶”ì¶œëœ JSON í…ìŠ¤íŠ¸:")
                        st.code(generated_json_text, language="text")
                    
                except ValueError as e:
                    # ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜
                    st.error(L["quiz_error_llm"])
                    st.caption(f"ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜: {str(e)}")
                    st.subheader(L["quiz_original_response"])
                    st.code(raw_response_text or generated_json_text, language="text")
                    if parsed_obj:
                        st.caption("íŒŒì‹±ëœ ê°ì²´:")
                        st.json(parsed_obj)
                        
            else:
                # JSON ì¶”ì¶œ ì‹¤íŒ¨
                st.error(L["quiz_error_llm"])
                st.caption("LLM ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if raw_response_text:
                    st.subheader(L["quiz_original_response"])
                    st.text_area("", raw_response_text, height=300)
                elif generated_json_text:
                    st.subheader(L["quiz_original_response"])
                    st.text_area("", generated_json_text, height=300)
                # --- END: JSON Parsing and Error Handling Logic ---

                else:  # ì¼ë°˜ í…ìŠ¤íŠ¸ ìƒì„±
                    st.session_state.is_quiz_active = False
                with st.spinner(L["response_generating"]):
                    content = run_llm(system_prompt)
                st.session_state.generated_content = content

                st.markdown("---")
                st.markdown(f"### {content_display}")
                st.markdown(st.session_state.generated_content)

    # --- í€´ì¦ˆ/ì¼ë°˜ ì½˜í…ì¸  ì¶œë ¥ ë¡œì§ ---
    if st.session_state.get("is_quiz_active", False) and st.session_state.get("quiz_data"):
        # í€´ì¦ˆ ì§„í–‰ ë¡œì§ (ìƒëµ - ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        quiz_data = st.session_state.quiz_data
        idx = st.session_state.current_question_index

        # â­ í€´ì¦ˆ ì™„ë£Œ ì‹œ IndexError ë°©ì§€ ë¡œì§ (idx >= len(quiz_data))
        if idx >= len(quiz_data):
            # í€´ì¦ˆ ì™„ë£Œ ì‹œ ìµœì¢… ì ìˆ˜ í‘œì‹œ
            st.success(L["quiz_complete"])
            total_questions = len(quiz_data)
            score = st.session_state.quiz_score
            incorrect_count = total_questions - score
            st.subheader(f"{L['score']}: {score} / {total_questions} ({(score / total_questions) * 100:.1f}%)")

            # ì›í˜• ì°¨íŠ¸ë¡œ ë§ì€ ë¬¸ì œ/í‹€ë¦° ë¬¸ì œ í‘œì‹œ
            if IS_PLOTLY_AVAILABLE:
                col1, col2 = st.columns([1, 2])
                with col1:
                    # ì›í˜• ì°¨íŠ¸ ìƒì„±
                    fig = go.Figure(data=[go.Pie(
                        labels=[L["correct_questions"], L["incorrect_questions"]],
                        values=[score, incorrect_count],
                        hole=0.4,
                        marker_colors=['#28a745', '#dc3545'],
                        textinfo='label+percent',
                        textposition='outside'
                    )])
                    fig.update_layout(
                        title=L["question_result"],
                        showlegend=True,
                        height=300,
                        margin=dict(l=20, r=20, t=50, b=20)
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    st.markdown("### " + L["question_result"])
                    # ë¬¸ì œë³„ ì •ì˜¤ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
                    for i, question_item in enumerate(quiz_data):
                        user_answer = st.session_state.quiz_answers[i] if i < len(st.session_state.quiz_answers) else None
                        is_correct = user_answer == 'Correctly Scored'
                        correct_answer_idx = question_item.get('answer', 1)
                        correct_answer_text = question_item['options'][correct_answer_idx - 1] if 0 < correct_answer_idx <= len(question_item['options']) else "N/A"
                        
                        # ì‚¬ìš©ì ë‹µì•ˆ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                        if is_correct:
                            user_answer_text = correct_answer_text
                            status_icon = "âœ…"
                            status_color = "green"
                        else:
                            if isinstance(user_answer, int) and 0 < user_answer <= len(question_item['options']):
                                user_answer_text = question_item['options'][user_answer - 1]
                            else:
                                user_answer_text = "ë¯¸ì‘ë‹µ"
                            status_icon = "âŒ"
                            status_color = "red"
                        
                        # ë¬¸ì œë³„ ê²°ê³¼ í‘œì‹œ
                        with st.container():
                            st.markdown(f"""
                            <div style="border-left: 4px solid {status_color}; padding-left: 10px; margin-bottom: 15px;">
                                <strong>{status_icon} ë¬¸í•­ {i+1}:</strong> {question_item['question']}<br>
                                <span style="color: {status_color};">{L['your_answer']}: {user_answer_text}</span><br>
                                <span style="color: green;">{L['correct_answer_label']}: {correct_answer_text}</span>
                            </div>
                            """, unsafe_allow_html=True)
            else:
                # Plotlyê°€ ì—†ëŠ” ê²½ìš° í…ìŠ¤íŠ¸ë¡œë§Œ í‘œì‹œ
                st.markdown(f"**{L['correct_questions']}:** {score}ê°œ")
                st.markdown(f"**{L['incorrect_questions']}:** {incorrect_count}ê°œ")
                st.markdown("### " + L["question_result"])
                for i, question_item in enumerate(quiz_data):
                    user_answer = st.session_state.quiz_answers[i] if i < len(st.session_state.quiz_answers) else None
                    is_correct = user_answer == 'Correctly Scored'
                    correct_answer_idx = question_item.get('answer', 1)
                    correct_answer_text = question_item['options'][correct_answer_idx - 1] if 0 < correct_answer_idx <= len(question_item['options']) else "N/A"
                    
                    if is_correct:
                        user_answer_text = correct_answer_text
                        status_icon = "âœ…"
                    else:
                        if isinstance(user_answer, int) and 0 < user_answer <= len(question_item['options']):
                            user_answer_text = question_item['options'][user_answer - 1]
                        else:
                            user_answer_text = "ë¯¸ì‘ë‹µ"
                        status_icon = "âŒ"
                    
                    st.markdown(f"**{status_icon} ë¬¸í•­ {i+1}:** {question_item['question']}")
                    st.markdown(f"- {L['your_answer']}: {user_answer_text}")
                    st.markdown(f"- {L['correct_answer_label']}: {correct_answer_text}")
                    st.markdown("---")

            if st.button(L["retake_quiz"], key="retake_quiz_btn"):
                # í€´ì¦ˆ ìƒíƒœë§Œ ì´ˆê¸°í™” (í€´ì¦ˆ ë°ì´í„°ëŠ” ìœ ì§€í•˜ì—¬ ê°™ì€ í€´ì¦ˆë¥¼ ë‹¤ì‹œ í’€ ìˆ˜ ìˆë„ë¡)
                st.session_state.current_question_index = 0
                st.session_state.quiz_score = 0
                st.session_state.quiz_answers = [1] * len(quiz_data)  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
                st.session_state.show_explanation = False
                st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ì²« ë²ˆì§¸ ë¬¸ì œë¡œ ì´ë™
            # st.stop() ì œê±°: í€´ì¦ˆ ì™„ë£Œ í›„ì—ë„ UIëŠ” ê³„ì† í‘œì‹œ
        else:
            # í€´ì¦ˆ ì§„í–‰ (í˜„ì¬ ë¬¸í•­)
            question_data = quiz_data[idx]
            st.subheader(f"{L.get('question_label', 'ë¬¸í•­')} {idx + 1}/{len(quiz_data)}")
            st.markdown(f"**{question_data['question']}**")

            # ê¸°ì¡´ í€´ì¦ˆ ì§„í–‰ ë° ì±„ì  ë¡œì§ (ë³€í™” ì—†ìŒ)
            current_selection_index = st.session_state.quiz_answers[idx]

            options = question_data['options']
            current_answer = st.session_state.quiz_answers[idx]

            if current_answer is None or not isinstance(current_answer, int) or current_answer <= 0:
                radio_index = 0
            else:
                radio_index = min(current_answer - 1, len(options) - 1)

            selected_option = st.radio(
                L["select_answer"],
                options,
                index=radio_index,
                key=f"quiz_radio_{st.session_state.quiz_type_key}_{idx}"
            )

            selected_option_index = options.index(selected_option) + 1 if selected_option in options else None

            check_col, next_col = st.columns([1, 1])

            if check_col.button(L["check_answer"], key=f"check_answer_btn_{idx}"):
                if selected_option_index is None:
                    st.warning("ì„ íƒì§€ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                else:
                    # ì ìˆ˜ ê³„ì‚° ë¡œì§
                    if st.session_state.quiz_answers[idx] != 'Correctly Scored':
                        correct_answer = question_data.get('answer')  # answer í‚¤ê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„
                        if selected_option_index == correct_answer:
                            st.session_state.quiz_score += 1
                            st.session_state.quiz_answers[idx] = 'Correctly Scored'
                            st.success(L["correct_answer"])
                        else:
                            st.session_state.quiz_answers[idx] = selected_option_index  # ì˜¤ë‹µì€ ì„ íƒì§€ ì¸ë±ìŠ¤ ì €ì¥
                            st.error(L["incorrect_answer"])

                    st.session_state.show_explanation = True

            # ì •ë‹µ ë° í•´ì„¤ í‘œì‹œ
            if st.session_state.show_explanation:
                correct_index = question_data.get('answer', 1)
                correct_answer_text = question_data['options'][correct_index - 1] if 0 < correct_index <= len(
                    question_data['options']) else "N/A"

                st.markdown("---")
                st.markdown(f"**{L['correct_is']}:** {correct_answer_text}")
                with st.expander(f"**{L['explanation']}**", expanded=True):
                    st.info(question_data.get('explanation', 'í•´ì„¤ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'))

                # ë‹¤ìŒ ë¬¸í•­ ë²„íŠ¼
                if next_col.button(L["next_question"], key=f"next_question_btn_{idx}"):
                    st.session_state.current_question_index += 1
                    st.session_state.show_explanation = False

            else:
                # ì‚¬ìš©ìê°€ ì´ë¯¸ ì •ë‹µì„ ì²´í¬í–ˆê³  (ë‹¤ì‹œ ë¡œë“œëœ ê²½ìš°), ë‹¤ìŒ ë²„íŠ¼ì„ ë°”ë¡œ í‘œì‹œ
                if st.session_state.quiz_answers[idx] == 'Correctly Scored' or (
                        isinstance(st.session_state.quiz_answers[idx], int) and st.session_state.quiz_answers[idx] > 0):
                    if next_col.button(L["next_question"], key=f"next_question_btn_after_check_{idx}"):
                        st.session_state.current_question_index += 1
                        st.session_state.show_explanation = False

    else:
        # ì¼ë°˜ ì½˜í…ì¸  (í•µì‹¬ ìš”ì•½ ë…¸íŠ¸, ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´) ì¶œë ¥
        if st.session_state.get("generated_content"):
            content = st.session_state.generated_content  # Contentë¥¼ ë‹¤ì‹œ ê°€ì ¸ì˜´
            content_lines = content.split('\n')

            st.markdown("---")
            st.markdown(f"### {content_display}")

            # --- START: íš¨ìœ¨ì„± ê°œì„  (ìƒë‹¨ ë¶„ì„/í•˜ë‹¨ ë³¸ë¬¸) ---

            st.subheader("ğŸ’¡ ì½˜í…ì¸  ë¶„ì„ (Plotly ì‹œê°í™”)")

            if IS_PLOTLY_AVAILABLE:
                # 1. í‚¤ì›Œë“œ ë¹ˆë„ ì‹œê°í™” (ëª¨ì˜ ë°ì´í„°)

                # ì½˜í…ì¸ ë¥¼ í…ìŠ¤íŠ¸ ì¤„ë¡œ ë¶„í• í•˜ì—¬ ëª¨ì˜ í‚¤ì›Œë“œ ë° ì£¼ìš” ë¬¸ì¥ ìƒì„±
                content = st.session_state.generated_content
                content_lines = content.split('\n')
                all_words = ' '.join(content_lines).replace('.', '').replace(',', '').split()

                # ëª¨ì˜ í‚¤ì›Œë“œ ë¹ˆë„ ë°ì´í„° ìƒì„±
                words = ['AI', 'ê¸°ìˆ í˜ì‹ ', 'ê³ ê°ê²½í—˜', 'ë°ì´í„°ë¶„ì„', 'íš¨ìœ¨ì„±', 'ì—¬í–‰ì‚°ì—…']
                np.random.seed(42)
                counts = np.random.randint(5, 30, size=len(words))

                # ë‚œì´ë„ì— ë”°ë¼ ì ìˆ˜ ê°€ì¤‘ì¹˜ (ëª¨ì˜ ê°ì„± ì ìˆ˜ ë³€í™”)
                difficulty_score = {'Beginner': 60, 'Intermediate': 75, 'Advanced': 90}.get(level, 70)

                # --- ì°¨íŠ¸ 1: í‚¤ì›Œë“œ ë¹ˆë„ (Plotly Bar Chart) ---
                fig_bar = go.Figure(data=[
                    go.Bar(
                        x=words,
                        y=counts,
                        marker_color=px.colors.sequential.Plotly3,
                        name="í‚¤ì›Œë“œ ë¹ˆë„"
                    )
                ])
                fig_bar.update_layout(
                    title_text=f"ì£¼ìš” í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„",
                    height=300,
                    margin=dict(l=20, r=20, t=50, b=20)
                )
                st.plotly_chart(fig_bar, use_container_width=True)

                # --- ì°¨íŠ¸ 2: ì½˜í…ì¸  ê°ì„± ë° ë³µì¡ë„ ì¶”ì´ (Plotly Line Chart) ---
                # ëª¨ì˜ ê°ì„±/ë³µì¡ë„ ì ìˆ˜ ì¶”ì´ (5ê°œ ë¬¸ë‹¨ ëª¨ì˜)
                sections = ['ë„ì…ë¶€', 'í•µì‹¬1', 'í•µì‹¬2', 'í•´ê²°ì±…', 'ê²°ë¡ ']
                sentiment_scores = [difficulty_score - 10, difficulty_score + 5, difficulty_score,
                                    difficulty_score + 10, difficulty_score + 2]

                fig_line = go.Figure()
                fig_line.add_trace(go.Scatter(
                    x=sections,
                    y=sentiment_scores,
                    mode='lines+markers',
                    name='ê°ì„±/ë³µì¡ë„ ì ìˆ˜',
                    line=dict(color='orange', width=2),
                    marker=dict(size=8)
                ))
                fig_line.update_layout(
                    title_text="ì½˜í…ì¸  ì„¹ì…˜ë³„ ê°ì„± ë° ë³µì¡ë„ ì¶”ì´ (ëª¨ì˜)",
                    yaxis_range=[50, 100],
                    height=300,
                    margin=dict(l=20, r=20, t=50, b=20)
                )
                st.plotly_chart(fig_line, use_container_width=True)

            else:  # Plotlyê°€ ì—†ì„ ê²½ìš° ê¸°ì¡´ í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ì˜ ìœ ì§€
                st.info("Plotly ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ì˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
                all_words = ' '.join(content_lines).replace('.', '').replace(',', '').split()
                unique_words = sorted(set(all_words), key=len, reverse=True)[:5] if all_words else ["N/A"]
                key_sentences = [
                    content_lines[0].strip() if content_lines else "N/A",
                    content_lines[len(content_lines) // 2].strip() if len(content_lines) > 1 else "",
                    content_lines[-1].strip() if len(content_lines) > 1 else ""
                ]
                key_sentences = [s for s in key_sentences if s and s != "N/A"]

                col_keyword, col_sentences = st.columns([1, 1])

                with col_keyword:
                    st.markdown("**í•µì‹¬ í‚¤ì›Œë“œ/ê°œë… (ëª¨ì˜)**")
                    st.info(f"[{', '.join(unique_words)}...]")

                with col_sentences:
                    st.markdown("**ì£¼ìš” ë¬¸ì¥ ìš”ì•½ (ëª¨ì˜)**")
                    for sentence in key_sentences[:2]:
                        st.write(f"â€¢ {sentence[:50]}...")

            st.markdown("---")

            # 2. í•˜ë‹¨ ë³¸ë¬¸ ì¶œë ¥
            st.markdown(f"### ğŸ“ ì›ë³¸ ì½˜í…ì¸ ")
            st.markdown(content)

            # --- END: íš¨ìœ¨ì„± ê°œì„  ---

            # --- START: ì•„ì´ì½˜ ë²„íŠ¼ í™œì„±í™” ---
            st.markdown("---")

            # 1. ë³µì‚¬í•  ë‚´ìš© ì •ë¦¬ ë° ì´ìŠ¤ì¼€ì´í”„
            content_for_js = json.dumps(content)

            # JavaScript ì½”ë“œëŠ” ì´ìŠ¤ì¼€ì´í”„ëœ ì¤‘ê´„í˜¸ {{}}ë¥¼ ì‚¬ìš©
            js_copy_script = """
               function copyToClipboard(text) {{
                   navigator.clipboard.writeText(text).then(function() {{
                       // Streamlit toast í˜¸ì¶œ (ëª¨ì˜)
                       const elements = window.parent.document.querySelectorAll('[data-testid="stToast"]');
                       if (elements.length === 0) {{
                           // Fallback UI update (use Streamlit's native mechanism if possible, or simple alert)
                           console.log("ë³µì‚¬ ì™„ë£Œ: " + text.substring(0, 50) + "...");
                           }}
                       }}, function(err) {{
                           // Fallback: Copy via execCommand (deprecated but often works in Streamlit's iframe)
                           const textarea = document.createElement('textarea');
                           textarea.value = text;
                           document.body.appendChild(textarea);
                           textarea.select();
                           document.execCommand('copy');
                           document.body.removeChild(textarea);
                           alert("ë³µì‚¬ ì™„ë£Œ!"); 
                       }});
                   }}
                   // f-string ëŒ€ì‹  .formatì„ ì‚¬ìš©í•˜ì—¬ JavaScript ì½”ë“œì— ì£¼ì…
                   // content_for_jsëŠ” ì´ë¯¸ Pythonì—ì„œ JSON ë¬¸ìì—´ë¡œ ì•ˆì „í•˜ê²Œ ì´ìŠ¤ì¼€ì´í”„ë¨
                   copyToClipboard(JSON.parse('{content_json_safe}'));
               """.format(content_json_safe=content_for_js)

            # --- JavaScript for SHARE Menu (Messenger Mock) ---
            # Streamlitì€ í˜„ì¬ ì†Œì…œ ë¯¸ë””ì–´ APIë¥¼ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, URL ë³µì‚¬ë¥¼ ì‚¬ìš©í•˜ê³  UIì— ë©”ì‹œì§€ ì˜µì…˜ì„ ëª¨ì˜í•©ë‹ˆë‹¤.
            js_share_url_copy = """
               function copyShareUrl() {{
                   const url = window.location.href;
                   navigator.clipboard.writeText(url).then(function() {{
                       console.log('App URL copied');
                   }}, function(err) {{
                       // Fallback
                       const textarea = document.createElement('textarea');
                       textarea.value = url;
                       document.body.appendChild(textarea);
                       textarea.select();
                       document.execCommand('copy');
                       document.body.removeChild(textarea);
                   }});
               }}
            """

            # --- JavaScript for SHARE Menu (Messenger Mock) ---
            # Streamlitì€ í˜„ì¬ ì†Œì…œ ë¯¸ë””ì–´ APIë¥¼ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, URL ë³µì‚¬ë¥¼ ì‚¬ìš©í•˜ê³  UIì— ë©”ì‹œì§€ ì˜µì…˜ì„ ëª¨ì˜í•©ë‹ˆë‹¤.
            js_native_share = """
               function triggerNativeShare(title, text, url) {{
                   if (navigator.share) {{
                       // 1. ë„¤ì´í‹°ë¸Œ ê³µìœ  API ì§€ì› ì‹œ ì‚¬ìš©
                       navigator.share({{
                           title: title,
                           text: text,
                           url: url,
                       }}).then(() => {{
                           console.log('Successful share');
                       }}).catch((error) => {{
                           console.log('Error sharing', error);
                       }});
                       return true;
                   }} else {{
                      // 2. ë„¤ì´í‹°ë¸Œ ê³µìœ  API ë¯¸ì§€ì› ì‹œ (PC í™˜ê²½ ë“±)
                      return false;
                   }}
               }}
            def mock_download(file_type: str, file_name: str):
                """ëª¨ì˜ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥: íŒŒì¼ëª…ê³¼ í•¨ê»˜ ì„±ê³µ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
                st.toast(f"ğŸ“¥ {file_type} íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤: {file_name}")
                # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë¡œì§ì€ Streamlit ì»´í¬ë„ŒíŠ¸ í™˜ê²½ì—ì„œëŠ” ë³µì¡í•˜ì—¬ ìƒëµí•©ë‹ˆë‹¤.


            col_like, col_dislike, col_share, col_copy, col_more = st.columns([1, 1, 1, 1, 6])
            current_content_id = str(uuid.uuid4())  # ë™ì  ID ìƒì„±

            # 1. ì¢‹ì•„ìš” ë²„íŠ¼ (ê¸°ëŠ¥ í™œì„±í™”)
            if col_like.button("ğŸ‘", key=f"content_like_{current_content_id}"):
                st.toast(L["toast_like"])

            # 2. ì‹«ì–´ìš” ë²„íŠ¼ (ê¸°ëŠ¥ í™œì„±í™”)
            if col_dislike.button("ğŸ‘", key=f"content_dislike_{current_content_id}"):
                st.toast(L["toast_dislike"])

            # 3. ê³µìœ  ë²„íŠ¼ (Web Share API í˜¸ì¶œ í†µí•©)
            with col_share:
                share_clicked = st.button("ğŸ”—", key=f"content_share_{current_content_id}")

            if share_clicked:
                # 1ë‹¨ê³„: ë„¤ì´í‹°ë¸Œ ê³µìœ  API í˜¸ì¶œ ì‹œë„ (ëª¨ë°”ì¼ í™˜ê²½ ëŒ€ìƒ)
                share_title = f"{content_display} ({topic})"
                share_text = content[:150] + "..."
                share_url = "https://utility-convenience-salmonyeonwoo.streamlit.app/"  # ì‹¤ì œ ë°°í¬ URLë¡œ ê°€ì •

                # JavaScript ì‹¤í–‰: ë„¤ì´í‹°ë¸Œ ê³µìœ  í˜¸ì¶œ
                st.components.v1.html(
                    f"""
                    <script>{js_native_share}
                        const shared = triggerNativeShare('{share_title}', '{share_text}', '{share_url}');
                        if (shared) {{
                           // ë„¤ì´í‹°ë¸Œ ê³µìœ  ì„±ê³µ ì‹œ (í† ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ë¸Œë¼ìš°ì €ê°€ ê´€ë¦¬)
                            console.log("Native Share Attempted.");
                        }} else {{
                           // ë„¤ì´í‹°ë¸Œ ê³µìœ  ë¯¸ì§€ì› ì‹œ, ëŒ€ì‹  URL ë³µì‚¬
                           const url = window.location.href;
                           const textarea = document.createElement('textarea');
                           textarea.value = url;
                           document.body.appendChild(textarea);
                           textarea.select();
                           document.execCommand('copy');
                           document.body.removeChild(textarea);
                           // PC í™˜ê²½ì—ì„œ URL ë³µì‚¬ ì™„ë£Œ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ ì¶œë ¥
                           const toastElement = window.parent.document.querySelector('[data-testid="stToast"]');
                           if (toastElement) {{
                               // ì´ë¯¸ í† ìŠ¤íŠ¸ ë©”ì‹œì§€ê°€ ì—´ë ¤ ìˆë‹¤ë©´ ê°±ì‹  (Streamlitì˜ toast ê¸°ëŠ¥ì„ ê°€ì •)
                           }} else {{
                              alert('URLì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.');
                           }}
                        }}
                    </script>
                    """,
                    height=0,
                )

                # Streamlitì˜ toast ë©”ì‹œì§€ëŠ” ë„¤ì´í‹°ë¸Œ ê³µìœ  ì„±ê³µ ì—¬ë¶€ë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ URL ë³µì‚¬ ì™„ë£Œë¥¼ ì•Œë¦¼
                st.toast(L["toast_share"])


            # 4. ë³µì‚¬ ë²„íŠ¼ (ê¸°ëŠ¥ í™œì„±í™” - ì½˜í…ì¸  í…ìŠ¤íŠ¸ ë³µì‚¬)
            if col_copy.button("ğŸ“‹", key=f"content_copy_{current_content_id}"):
                # JavaScriptë¥¼ ì‹¤í–‰í•˜ì—¬ ë³µì‚¬ (execCommand ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •í™”)
                st.components.v1.html(
