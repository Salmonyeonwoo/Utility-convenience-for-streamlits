# ========================================
# streamlit_app_last_correction.py
# Î°úÏª¨ Ï†ÑÏö©: RAG + ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ + ÏùåÏÑ± Í∏∞Î°ù + LSTM + ÏΩòÌÖêÏ∏†
# Firebase/GCS Ï†úÍ±∞, local_db(JSON/ÌååÏùº)Îßå ÏÇ¨Ïö©
# Python 3.9 / langchain>=1.0 / streamlit-mic-recorder 0.0.8 Í∏∞Ï§Ä
# ========================================

import os
import io
import json
import time
import uuid
import base64
import tempfile
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any

import numpy as np
import streamlit as st
from matplotlib import pyplot as plt

from openai import OpenAI

# mic_recorder (0.0.8) - returns dict with key "bytes"
from streamlit_mic_recorder import mic_recorder

# LangChain / RAG Í¥ÄÎ†®
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, TextLoader

# ========================================
# 0. Í∏∞Î≥∏ Í≤ΩÎ°ú/Î°úÏª¨ DB ÏÑ§Ï†ï
# ========================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "local_db")
AUDIO_DIR = os.path.join(DATA_DIR, "audio")
RAG_INDEX_DIR = os.path.join(DATA_DIR, "rag_index")

VOICE_META_FILE = os.path.join(DATA_DIR, "voice_records.json")
SIM_META_FILE = os.path.join(DATA_DIR, "simulation_histories.json")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(RAG_INDEX_DIR, exist_ok=True)

# ----------------------------------------
# JSON Helper
# ----------------------------------------
def _load_json(path: str, default: Any):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return default


def _save_json(path: str, data: Any):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# ========================================
# 1. Îã§Íµ≠Ïñ¥ ÏÑ§Ï†ï
# ========================================
DEFAULT_LANG = "ko"

LANG: Dict[str, Dict[str, str]] = {
    "ko": {
        "title": "Í∞úÏù∏ ÎßûÏ∂§Ìòï AI ÌïôÏäµ ÏΩîÏπò (ÏùåÏÑ± Î∞è DB ÌÜµÌï©)",
        "sidebar_title": "üìö AI Study Coach ÏÑ§Ï†ï",
        "file_uploader": "ÌïôÏäµ ÏûêÎ£å ÏóÖÎ°úÎìú (PDF, TXT, HTML)",
        "button_start_analysis": "ÏûêÎ£å Î∂ÑÏÑù ÏãúÏûë (RAG Indexing)",
        "rag_tab": "RAG ÏßÄÏãù Ï±óÎ¥á",
        "content_tab": "ÎßûÏ∂§Ìòï ÌïôÏäµ ÏΩòÌÖêÏ∏† ÏÉùÏÑ±",
        "lstm_tab": "LSTM ÏÑ±Ï∑®ÎèÑ ÏòàÏ∏° ÎåÄÏãúÎ≥¥Îìú",
        "simulator_tab": "AI Í≥†Í∞ù ÏùëÎåÄ ÏãúÎÆ¨Î†àÏù¥ÌÑ∞",
        "rag_header": "RAG ÏßÄÏãù Ï±óÎ¥á (Î¨∏ÏÑú Í∏∞Î∞ò Q&A)",
        "rag_desc": "ÏóÖÎ°úÎìúÎêú Î¨∏ÏÑú Í∏∞Î∞òÏúºÎ°ú ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌï©ÎãàÎã§„ÄÇ",
        "rag_input_placeholder": "ÌïôÏäµ ÏûêÎ£åÏóê ÎåÄÌï¥ ÏßàÎ¨∏Ìï¥ Î≥¥ÏÑ∏Ïöî",
        "llm_error_key": "‚ö†Ô∏è Í≤ΩÍ≥†: GEMINI API ÌÇ§Í∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Streamlit SecretsÏóê 'GEMINI_API_KEY'Î•º ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî„ÄÇ",
        "llm_error_init": "LLM Ï¥àÍ∏∞Ìôî Ïò§Î•ò: API ÌÇ§Î•º ÌôïÏù∏Ìï¥ Ï£ºÏÑ∏Ïöî„ÄÇ",
        "content_header": "ÎßûÏ∂§Ìòï ÌïôÏäµ ÏΩòÌÖêÏ∏† ÏÉùÏÑ±",
        "content_desc": "ÌïôÏäµ Ï£ºÏ†úÏôÄ ÎÇúÏù¥ÎèÑÏóê ÎßûÏ∂∞ ÏΩòÌÖêÏ∏† ÏÉùÏÑ±",
        "topic_label": "ÌïôÏäµ Ï£ºÏ†ú",
        "level_label": "ÎÇúÏù¥ÎèÑ",
        "content_type_label": "ÏΩòÌÖêÏ∏† ÌòïÏãù",
        "level_options": ["Ï¥àÍ∏â", "Ï§ëÍ∏â", "Í≥†Í∏â"],
        "content_options": ["ÌïµÏã¨ ÏöîÏïΩ ÎÖ∏Ìä∏", "Í∞ùÍ¥ÄÏãù ÌÄ¥Ï¶à 10Î¨∏Ìï≠", "Ïã§Ïäµ ÏòàÏ†ú ÏïÑÏù¥ÎîîÏñ¥"],
        "button_generate": "ÏΩòÌÖêÏ∏† ÏÉùÏÑ±",
        "warning_topic": "ÌïôÏäµ Ï£ºÏ†úÎ•º ÏûÖÎ†•Ìï¥ Ï£ºÏÑ∏Ïöî„ÄÇ",
        "lstm_header": "LSTM Í∏∞Î∞ò ÌïôÏäµ ÏÑ±Ï∑®ÎèÑ ÏòàÏ∏° ÎåÄÏãúÎ≥¥Îìú",
        "lstm_desc": "Í∞ÄÏÉÅÏùò Í≥ºÍ±∞ ÌÄ¥Ï¶à Ï†êÏàò Îç∞Ïù¥ÌÑ∞Î•º Î∞îÌÉïÏúºÎ°ú LSTM Î™®Îç∏ÏùÑ ÌõàÎ†®ÌïòÍ≥† ÎØ∏Îûò ÏÑ±Ï∑®ÎèÑÎ•º ÏòàÏ∏°ÌïòÏó¨ Î≥¥Ïó¨Ï§çÎãàÎã§„ÄÇ",
        "lang_select": "Ïñ∏Ïñ¥ ÏÑ†ÌÉù",
        "embed_success": "Ï¥ù {count}Í∞ú Ï≤≠ÌÅ¨Î°ú ÌïôÏäµ DB Íµ¨Ï∂ï ÏôÑÎ£å!",
        "embed_fail": "ÏûÑÎ≤†Îî© Ïã§Ìå®: Î¨¥Î£å Ìã∞Ïñ¥ ÌïúÎèÑ Ï¥àÍ≥º ÎòêÎäî ÎÑ§Ìä∏ÏõåÌÅ¨ Î¨∏Ï†ú„ÄÇ",
        "warning_no_files": "Î®ºÏ†Ä ÌïôÏäµ ÏûêÎ£åÎ•º ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî„ÄÇ",
        "warning_rag_not_ready": "RAGÍ∞Ä Ï§ÄÎπÑÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. ÌïôÏäµ ÏûêÎ£åÎ•º ÏóÖÎ°úÎìúÌïòÍ≥† Î∂ÑÏÑùÌïòÏÑ∏Ïöî„ÄÇ",
        "quiz_fail_structure": "ÌÄ¥Ï¶à Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞Í∞Ä Ïò¨Î∞îÎ•¥ÏßÄ ÏïäÏäµÎãàÎã§„ÄÇ",
        "select_answer": "Ï†ïÎãµÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
        "check_answer": "Ï†ïÎãµ ÌôïÏù∏",
        "next_question": "Îã§Ïùå Î¨∏Ìï≠",
        "correct_answer": "Ï†ïÎãµÏûÖÎãàÎã§! üéâ",
        "incorrect_answer": "Ïò§ÎãµÏûÖÎãàÎã§. üòû",
        "correct_is": "Ï†ïÎãµ",
        "explanation": "Ìï¥ÏÑ§",
        "quiz_complete": "ÌÄ¥Ï¶à ÏôÑÎ£å!",
        "score": "Ï†êÏàò",
        "retake_quiz": "ÌÄ¥Ï¶à Îã§Ïãú ÌíÄÍ∏∞",
        "quiz_error_llm": "ÌÄ¥Ï¶à ÏÉùÏÑ± Ïã§Ìå®: LLMÏù¥ Ïò¨Î∞îÎ•∏ JSON ÌòïÏãùÏùÑ Î∞òÌôòÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§„ÄÇ",
        "quiz_original_response": "LLM ÏõêÎ≥∏ ÏùëÎãµ",
        "firestore_loading": "Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú RAG Ïù∏Îç±Ïä§ Î°úÎìú Ï§ë...",
        "firestore_no_index": "Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú Í∏∞Ï°¥ RAG Ïù∏Îç±Ïä§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌïòÏó¨ ÏÉàÎ°ú ÎßåÎìúÏÑ∏Ïöî„ÄÇ",
        "db_save_complete": "(DB Ï†ÄÏû• ÏôÑÎ£å)",
        "data_analysis_progress": "ÏûêÎ£å Î∂ÑÏÑù Î∞è ÌïôÏäµ DB Íµ¨Ï∂ï Ï§ë...",
        "response_generating": "ÎãµÎ≥Ä ÏÉùÏÑ± Ï§ë...",
        "lstm_result_header": "ÌïôÏäµ ÏÑ±Ï∑®ÎèÑ ÏòàÏ∏° Í≤∞Í≥º",
        "lstm_score_metric": "ÌòÑÏû¨ ÏòàÏ∏° ÏÑ±Ï∑®ÎèÑ",
        "lstm_score_info": "Îã§Ïùå ÌÄ¥Ï¶à ÏòàÏÉÅ Ï†êÏàòÎäî ÏïΩ **{predicted_score:.1f}Ï†ê**ÏûÖÎãàÎã§. ÌïôÏäµ ÏÑ±Í≥ºÎ•º Ïú†ÏßÄÌïòÍ±∞ÎÇò Í∞úÏÑ†ÌïòÏÑ∏Ïöî!",
        "lstm_rerun_button": "ÏÉàÎ°úÏö¥ Í∞ÄÏÉÅ Îç∞Ïù¥ÌÑ∞Î°ú ÏòàÏ∏°",

        # --- ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ ---
        "simulator_header": "AI Í≥†Í∞ù ÏùëÎåÄ ÏãúÎÆ¨Î†àÏù¥ÌÑ∞",
        "simulator_desc": "ÍπåÎã§Î°úÏö¥ Í≥†Í∞ù Î¨∏ÏùòÏóê AIÏùò ÏùëÎåÄ Ï¥àÏïà Î∞è Í∞ÄÏù¥ÎìúÎùºÏù∏ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§„ÄÇ",
        "customer_query_label": "Í≥†Í∞ù Î¨∏Ïùò ÎÇ¥Ïö© (ÎßÅÌÅ¨ Ìè¨Ìï® Í∞ÄÎä•)",
        "customer_type_label": "Í≥†Í∞ù ÏÑ±Ìñ•",
        "customer_type_options": ["ÏùºÎ∞òÏ†ÅÏù∏ Î¨∏Ïùò", "ÍπåÎã§Î°úÏö¥ Í≥†Í∞ù", "Îß§Ïö∞ Î∂àÎßåÏ°±Ïä§Îü¨Ïö¥ Í≥†Í∞ù"],
        "button_simulate": "ÏùëÎåÄ Ï°∞Ïñ∏ ÏöîÏ≤≠",
        "customer_generate_response_button": "Í≥†Í∞ù Î∞òÏùë ÏÉùÏÑ±",
        "send_closing_confirm_button": "Ï∂îÍ∞Ä Î¨∏Ïùò Ïó¨Î∂Ä ÌôïÏù∏ Î©îÏãúÏßÄ Î≥¥ÎÇ¥Í∏∞",
        "simulation_warning_query": "Í≥†Í∞ù Î¨∏Ïùò ÎÇ¥Ïö©ÏùÑ ÏûÖÎ†•Ìï¥ Ï£ºÏÑ∏Ïöî„ÄÇ",
        "simulation_no_key_warning": "‚ö†Ô∏è API KeyÍ∞Ä ÏóÜÍ∏∞ ÎïåÎ¨∏Ïóê ÏùëÎãµ ÏÉùÏÑ±ÏùÄ Ïã§ÌñâÎêòÏßÄ ÏïäÏäµÎãàÎã§„ÄÇ",
        "simulation_advice_header": "AIÏùò ÏùëÎåÄ Í∞ÄÏù¥ÎìúÎùºÏù∏",
        "simulation_draft_header": "Ï∂îÏ≤ú ÏùëÎåÄ Ï¥àÏïà",
        "button_listen_audio": "ÏùåÏÑ±ÏúºÎ°ú Îì£Í∏∞",
        "tts_status_ready": "ÏùåÏÑ±ÏúºÎ°ú Îì£Í∏∞ Ï§ÄÎπÑÎê®",
        "tts_status_generating": "Ïò§ÎîîÏò§ ÏÉùÏÑ± Ï§ë...",
        "tts_status_success": "‚úÖ Ïò§ÎîîÏò§ Ïû¨ÏÉù ÏôÑÎ£å!",
        "tts_status_error": "‚ùå TTS Ïò§Î•ò Î∞úÏÉù",
        "history_expander_title": "üìù Ïù¥Ï†Ñ ÏÉÅÎã¥ Ïù¥Î†• Î°úÎìú (ÏµúÍ∑º 10Í∞ú)",
        "initial_query_sample": "ÌîÑÎûëÏä§ ÌååÎ¶¨Ïóê ÎèÑÏ∞©ÌñàÎäîÎç∞, ÌÅ¥Î£©ÏóêÏÑú Íµ¨Îß§Ìïú eSIMÏù¥ ÌôúÏÑ±ÌôîÍ∞Ä Ïïà Îê©ÎãàÎã§...",
        "button_mic_input": "üéô ÏùåÏÑ± ÏûÖÎ†•",
        "prompt_customer_end": "Í≥†Í∞ùÎãòÏùò Ï∂îÍ∞Ä Î¨∏Ïùò ÏÇ¨Ìï≠Ïù¥ ÏóÜÏñ¥, Ïù¥ ÏÉÅÎã¥ÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§„ÄÇ",
        "prompt_survey": "Î¨∏ÏùòÌï¥ Ï£ºÏÖîÏÑú Í∞êÏÇ¨Ìï©ÎãàÎã§. ÌïÑÏöîÌïòÏãúÎ©¥ Ïñ∏Ï†úÎì†ÏßÄ Ïó∞ÎùΩÏ£ºÏÑ∏Ïöî„ÄÇ",
        "customer_closing_confirm": "Îòê Îã§Î•∏ Î¨∏Ïùò ÏÇ¨Ìï≠ÏùÄ ÏóÜÏúºÏã†Í∞ÄÏöî?",
        "customer_positive_response": "ÏπúÏ†àÌïú ÏÉÅÎã¥ Í∞êÏÇ¨ÎìúÎ¶ΩÎãàÎã§„ÄÇ",
        "button_end_chat": "ÏùëÎåÄ Ï¢ÖÎ£å (ÏÑ§Î¨∏ ÏöîÏ≤≠)",
        "survey_sent_confirm": "üì® ÏÑ§Î¨∏Ï°∞ÏÇ¨ ÎßÅÌÅ¨Í∞Ä Ï†ÑÏÜ°ÎêòÏóàÏúºÎ©∞, Ïù¥ ÏÉÅÎã¥ÏùÄ Ï¢ÖÎ£åÎêòÏóàÏäµÎãàÎã§.",
        "new_simulation_ready": "ÏÉà ÏãúÎÆ¨Î†àÏù¥ÏÖòÏùÑ ÏãúÏûëÌï† Ïàò ÏûàÏäµÎãàÎã§.",
        "agent_response_header": "‚úçÔ∏è ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµ",
        "agent_response_placeholder": "Í≥†Í∞ùÏóêÍ≤å ÏùëÎãµÌïòÏÑ∏Ïöî...",
        "send_response_button": "ÏùëÎãµ Ï†ÑÏÜ°",
        "request_rebuttal_button": "Í≥†Í∞ùÏùò Îã§Ïùå Î∞òÏùë ÏöîÏ≤≠",
        "new_simulation_button": "ÏÉà ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏãúÏûë",
        "history_selectbox_label": "Î°úÎìúÌï† Ïù¥Î†•ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî:",
        "history_load_button": "ÏÑ†ÌÉùÎêú Ïù¥Î†• Î°úÎìú",
        "delete_history_button": "‚ùå Î™®Îì† Ïù¥Î†• ÏÇ≠Ï†ú",
        "delete_confirm_message": "Ï†ïÎßêÎ°ú Î™®Îì† ÏÉÅÎã¥ Ïù¥Î†•ÏùÑ ÏÇ≠Ï†úÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
        "delete_confirm_yes": "Ïòà, ÏÇ≠Ï†úÌï©ÎãàÎã§",
        "delete_confirm_no": "ÏïÑÎãàÏò§, Ïú†ÏßÄÌï©ÎãàÎã§",
        "delete_success": "‚úÖ ÏÇ≠Ï†ú ÏôÑÎ£å!",
        "deleting_history_progress": "Ïù¥Î†• ÏÇ≠Ï†ú Ï§ë...",
        "search_history_label": "Ïù¥Î†• Í≤ÄÏÉâ",
        "date_range_label": "ÎÇ†Ïßú Î≤îÏúÑ ÌïÑÌÑ∞",
        "no_history_found": "Í≤ÄÏÉâ Ï°∞Í±¥Ïóê ÎßûÎäî Ïù¥Î†•Ïù¥ ÏóÜÏäµÎãàÎã§„ÄÇ",
        "customer_email_label": "Í≥†Í∞ù Ïù¥Î©îÏùº (ÏÑ†ÌÉù)",
        "customer_phone_label": "Í≥†Í∞ù Ïó∞ÎùΩÏ≤ò / Ï†ÑÌôîÎ≤àÌò∏ (ÏÑ†ÌÉù)",

        # --- ÏùåÏÑ± Í∏∞Î°ù ---
        "voice_rec_header": "ÏùåÏÑ± Í∏∞Î°ù & Í¥ÄÎ¶¨",
        "record_help": "ÎßàÏù¥ÌÅ¨ Î≤ÑÌäºÏùÑ ÎàåÎü¨ ÎÖπÏùåÌïòÍ±∞ÎÇò ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî„ÄÇ",
        "uploaded_file": "Ïò§ÎîîÏò§ ÌååÏùº ÏóÖÎ°úÎìú",
        "rec_list_title": "Ï†ÄÏû•Îêú ÏùåÏÑ± Í∏∞Î°ù",
        "transcribe_btn": "Ï†ÑÏÇ¨(Whisper)",
        "save_btn": "ÏùåÏÑ± Í∏∞Î°ù Ï†ÄÏû•",
        "transcribing": "ÏùåÏÑ± Ï†ÑÏÇ¨ Ï§ë...",
        "transcript_result": "Ï†ÑÏÇ¨ Í≤∞Í≥º:",
        "transcript_text": "Ï†ÑÏÇ¨ ÌÖçÏä§Ìä∏",
        "openai_missing": "OpenAI API KeyÍ∞Ä ÏóÜÏäµÎãàÎã§.",
        "whisper_client_error": "‚ùå Whisper API Client Ï¥àÍ∏∞Ìôî Ïã§Ìå®",
        "whisper_auth_error": "‚ùå Whisper API Ïù∏Ï¶ù Ïã§Ìå®",
        "whisper_format_error": "‚ùå ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Ïò§ÎîîÏò§ ÌòïÏãùÏûÖÎãàÎã§„ÄÇ",
        "whisper_success": "‚úÖ ÏùåÏÑ± Ï†ÑÏÇ¨ ÏôÑÎ£å!",
        "playback": "ÎÖπÏùå Ïû¨ÏÉù",
        "retranscribe": "Ïû¨Ï†ÑÏÇ¨",
        "delete": "ÏÇ≠Ï†ú",
        "no_records": "Ï†ÄÏû•Îêú ÏùåÏÑ± Í∏∞Î°ùÏù¥ ÏóÜÏäµÎãàÎã§„ÄÇ",
        "saved_success": "Ï†ÄÏû• ÏôÑÎ£å!",
        "delete_confirm_rec": "Ï†ïÎßê ÏÇ≠Ï†úÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
        "gcs_not_conf": "GCS ÎØ∏ÏÑ§Ï†ï",
        "gcs_playback_fail": "Ïò§ÎîîÏò§ Ïû¨ÏÉù Ïã§Ìå®",
        "gcs_no_audio": "Ïò§ÎîîÏò§ ÏóÜÏùå",
        "error": "Ïò§Î•ò:",
        "firestore_no_db_connect": "DB Ïó∞Í≤∞ Ïã§Ìå®",
        "save_history_success": "ÏÉÅÎã¥ Ïù¥Î†•Ïù¥ Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§„ÄÇ",
        "save_history_fail": "ÏÉÅÎã¥ Ïù¥Î†• Ï†ÄÏû• Ïã§Ìå®",
        "delete_fail": "ÏÇ≠Ï†ú Ïã§Ìå®",
        "rec_header": "ÏùåÏÑ± ÏûÖÎ†• Î∞è Ï†ÑÏÇ¨",
        "whisper_processing": "ÏùåÏÑ± Ï†ÑÏÇ¨ Ï≤òÎ¶¨ Ï§ë",
        "empty_response_warning": "ÏùëÎãµÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî„ÄÇ",
    },

    # --- ‚≠ê ÏòÅÏñ¥ Î≤ÑÏ†Ñ (ÌïúÍµ≠Ïñ¥ 100% Îß§Ïπ≠) ---
    "en": {
        "title": "Personalized AI Study Coach (Voice & Local DB)",
        "sidebar_title": "üìö AI Study Coach Settings",
        "file_uploader": "Upload Study Materials (PDF, TXT, HTML)",
        "button_start_analysis": "Start Analysis (RAG Indexing)",
        "rag_tab": "RAG Knowledge Chatbot",
        "content_tab": "Custom Content Generation",
        "lstm_tab": "LSTM Achievement Prediction Dashboard",
        "simulator_tab": "AI Customer Support Simulator",
        "rag_header": "RAG Knowledge Chatbot (Document Q&A)",
        "rag_desc": "Answer questions based on uploaded documents.",
        "rag_input_placeholder": "Ask a question about your study materials",
        "llm_error_key": "‚ö†Ô∏è Warning: GEMINI_API_KEY is not set.",
        "llm_error_init": "LLM initialization error. Please check your API key.",
        "content_header": "Custom Learning Content Generation",
        "content_desc": "Generate content based on the topic and difficulty.",
        "topic_label": "Learning Topic",
        "level_label": "Difficulty",
        "content_type_label": "Content Type",
        "level_options": ["Beginner", "Intermediate", "Advanced"],
        "content_options": ["Key Summary Note", "10 MCQ Questions", "Practical Example Idea"],
        "button_generate": "Generate Content",
        "warning_topic": "Please enter a learning topic.",
        "lstm_header": "LSTM Achievement Prediction Dashboard",
        "lstm_desc": "Train an LSTM model on hypothetical quiz scores and predict performance.",
        "lang_select": "Select Language",
        "embed_success": "Learning DB built with {count} chunks!",
        "embed_fail": "Embedding failed: quota exceeded or network issue.",
        "warning_no_files": "Please upload study materials first.",
        "warning_rag_not_ready": "RAG is not ready. Upload materials and analyze.",
        "quiz_fail_structure": "Quiz data structure is invalid.",
        "select_answer": "Select answer",
        "check_answer": "Check answer",
        "next_question": "Next question",
        "correct_answer": "Correct! üéâ",
        "incorrect_answer": "Incorrect üòû",
        "correct_is": "Correct answer",
        "explanation": "Explanation",
        "quiz_complete": "Quiz Complete!",
        "score": "Score",
        "retake_quiz": "Retake Quiz",
        "quiz_error_llm": "Quiz generation failed: invalid JSON.",
        "quiz_original_response": "Original LLM Response",
        "firestore_loading": "Loading RAG index...",
        "firestore_no_index": "No existing RAG index found.",
        "db_save_complete": "(DB Save Complete)",
        "data_analysis_progress": "Analyzing materials and building DB...",
        "response_generating": "Generating response...",
        "lstm_result_header": "Achievement Prediction",
        "lstm_score_metric": "Predicted Achievement",
        "lstm_score_info": "Estimated next quiz score: **{predicted_score:.1f}**.",
        "lstm_rerun_button": "Predict with New Data",

        # Simulator
        "simulator_header": "AI Customer Response Simulator",
        "simulator_desc": "AI generates draft responses and guidelines for customer inquiries.",
        "customer_query_label": "Customer Message (links allowed)",
        "customer_type_label": "Customer Type",
        "customer_type_options": ["General Inquiry", "Difficult Customer", "Highly Dissatisfied Customer"],
        "button_simulate": "Generate Response",
        "customer_generate_response_button": "Generate Customer Response",
        "send_closing_confirm_button": "Send Closing Confirmation",
        "simulation_warning_query": "Please enter the customer‚Äôs message.",
        "simulation_no_key_warning": "‚ö†Ô∏è API Key missing. Simulation cannot proceed.",
        "simulation_advice_header": "AI Response Guidelines",
        "simulation_draft_header": "Recommended Response Draft",
        "button_listen_audio": "Play as Audio",
        "tts_status_ready": "Ready to generate audio",
        "tts_status_generating": "Generating audio...",
        "tts_status_success": "Audio ready!",
        "tts_status_error": "TTS error occurred",
        "history_expander_title": "üìù Load Previous Sessions (Last 10)",
        "initial_query_sample": "I arrived in Paris but my Klook eSIM won't activate‚Ä¶",
        "button_mic_input": "üéô Voice Input",
        "prompt_customer_end": "No further inquiries. Ending chat.",
        "prompt_survey": "Thank you for contacting support.",
        "customer_closing_confirm": "Anything else I can help you with?",
        "customer_positive_response": "Thank you for your kind support.",
        "button_end_chat": "End Chat (Survey Request)",
        "survey_sent_confirm": "üì® The survey link has been sent. This chat session is now closed.",
        "new_simulation_ready": "You can now start a new simulation.",
        "agent_response_header": "‚úçÔ∏è Agent Response",
        "agent_response_placeholder": "Write a response...",
        "send_response_button": "Send Response",
        "request_rebuttal_button": "Request Customer Reaction",
        "new_simulation_button": "Start New Simulation",
        "history_selectbox_label": "Choose a record to load:",
        "history_load_button": "Load Selected Record",
        "delete_history_button": "‚ùå Delete All History",
        "delete_confirm_message": "Are you sure you want to delete all records?",
        "delete_confirm_yes": "Yes, Delete",
        "delete_confirm_no": "Cancel",
        "delete_success": "Deleted successfully!",
        "deleting_history_progress": "Deleting history...",
        "search_history_label": "Search History",
        "date_range_label": "Date Filter",
        "no_history_found": "No matching history found.",
        "customer_email_label": "Customer Email (optional)",
        "customer_phone_label": "Customer Phone / WhatsApp (optional)",

        # Voice
        "voice_rec_header": "Voice Record & Management",
        "record_help": "Record using the microphone or upload a file.",
        "uploaded_file": "Upload Audio File",
        "rec_list_title": "Saved Voice Records",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Record",
        "transcribing": "Transcribing...",
        "transcript_result": "Transcription:",
        "transcript_text": "Transcribed Text",
        "openai_missing": "Missing OPENAI_API_KEY",
        "whisper_client_error": "Whisper client initialization failed.",
        "whisper_auth_error": "Whisper authentication failed.",
        "whisper_format_error": "Unsupported audio format.",
        "whisper_success": "Transcription complete!",
        "playback": "Play Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Voice Record",
        "transcribing": "Transcribing voice...",
        "transcript_result": "Transcription Result:",
        "transcript_text": "Transcribed Text",
        "whisper_processing": "Processing voice transcription...",
        "whisper_success": "‚úÖ Transcription complete! Please check the text below.",
        "openai_missing": "OpenAI API Key is missing. Please set OPENAI_API_KEY.",
        "whisper_client_error": "‚ùå Error: Whisper API client not initialized.",
        "whisper_auth_error": "‚ùå Whisper API authentication failed. Check your API Key.",
        "whisper_format_error": "‚ùå Error: Unsupported audio format.",
        "playback": "Playback Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "no_records": "No saved voice records.",
        "saved_success": "Saved successfully!",
        "delete_confirm_rec": "Are you sure you want to delete this voice record?",
        "gcs_not_conf": "GCS not configured or no audio available",
        "gcs_playback_fail": "Failed to play audio",
        "gcs_no_audio": "No audio file found",
        "error": "Error:",
        "firestore_no_db_connect": "DB connection failed",
        "save_history_success": "Saved successfully.",
        "save_history_fail": "Save failed.",
        "delete_fail": "Delete failed",
        "rec_header": "Voice Input & Transcription",
        "whisper_processing": "Processing...",
        "empty_response_warning": "Please enter a response."
    },

    # --- ‚≠ê ÏùºÎ≥∏Ïñ¥ Î≤ÑÏ†Ñ (ÌïúÍµ≠Ïñ¥ 100% Îß§Ïπ≠) ---
    "ja": {
        "title": "„Éë„Éº„ÇΩ„Éä„É©„Ç§„Ç∫AIÂ≠¶Áøí„Ç≥„Éº„ÉÅ (Èü≥Â£∞„Éª„É≠„Éº„Ç´„É´DB)",
        "sidebar_title": "üìö AIÂ≠¶Áøí„Ç≥„Éº„ÉÅË®≠ÂÆö",
        "file_uploader": "Â≠¶ÁøíË≥áÊñô„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ (PDF, TXT, HTML)",
        "button_start_analysis": "Ë≥áÊñôÂàÜÊûêÈñãÂßã (RAG„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ‰ΩúÊàê)",
        "rag_tab": "RAGÁü•Ë≠ò„ÉÅ„É£„ÉÉ„Éà„Éú„ÉÉ„Éà",
        "content_tab": "„Ç´„Çπ„Çø„É†Â≠¶Áøí„Ç≥„É≥„ÉÜ„É≥„ÉÑÁîüÊàê",
        "lstm_tab": "LSTMÈÅîÊàêÂ∫¶‰∫àÊ∏¨„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ",
        "simulator_tab": "AIÈ°ßÂÆ¢ÂØæÂøú„Ç∑„Éü„É•„É¨„Éº„Çø„Éº",
        "rag_header": "RAGÁü•Ë≠ò„ÉÅ„É£„ÉÉ„Éà„Éú„ÉÉ„Éà („Éâ„Ç≠„É•„É°„É≥„ÉàQ&A)",
        "rag_desc": "„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„ÅüË≥áÊñô„Å´Âü∫„Å•„ÅÑ„Å¶Ë≥™Âïè„Å´ÂõûÁ≠î„Åó„Åæ„Åô„ÄÇ",
        "rag_input_placeholder": "Ë≥áÊñô„Å´„Å§„ÅÑ„Å¶Ë≥™Âïè„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
        "llm_error_key": "‚ö†Ô∏è Ê≥®ÊÑè: GEMINI_API_KEY „ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ",
        "llm_error_init": "LLM ÂàùÊúüÂåñ„Ç®„É©„ÉºÔºöAPI„Ç≠„Éº„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "content_header": "„Ç´„Çπ„Çø„É†Â≠¶Áøí„Ç≥„É≥„ÉÜ„É≥„ÉÑÁîüÊàê",
        "content_desc": "Â≠¶Áøí„ÉÜ„Éº„Éû„Å®Èõ£ÊòìÂ∫¶„Å´Âøú„Åò„Å¶„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÇíÁîüÊàê„Åó„Åæ„Åô„ÄÇ",
        "topic_label": "Â≠¶Áøí„ÉÜ„Éº„Éû",
        "level_label": "Èõ£ÊòìÂ∫¶",
        "content_type_label": "„Ç≥„É≥„ÉÜ„É≥„ÉÑÁ®ÆÈ°û",
        "level_options": ["ÂàùÁ¥ö", "‰∏≠Á¥ö", "‰∏äÁ¥ö"],
        "content_options": ["Ë¶ÅÁÇπ„Çµ„Éû„É™„Éº", "ÈÅ∏ÊäûÂºè„ÇØ„Ç§„Ç∫10Âïè", "ÂÆüË∑µ‰æã„Ç¢„Ç§„Éá„Ç¢"],
        "button_generate": "ÁîüÊàê„Åô„Çã",
        "warning_topic": "Â≠¶Áøí„ÉÜ„Éº„Éû„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "lstm_header": "LSTMÈÅîÊàêÂ∫¶‰∫àÊ∏¨„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ",
        "lstm_desc": "‰ªÆÊÉ≥„ÇØ„Ç§„Ç∫„Çπ„Ç≥„Ç¢„Çí‰ΩøÁî®„Åó„Å¶ÈÅîÊàêÂ∫¶„Çí‰∫àÊ∏¨„Åó„Åæ„Åô„ÄÇ",
        "lang_select": "Ë®ÄË™ûÈÅ∏Êäû",
        "embed_success": "{count}ÂÄã„ÅÆ„ÉÅ„É£„É≥„ÇØ„ÅßDBÊßãÁØâÂÆå‰∫Ü!",
        "embed_fail": "Âüã„ÇÅËæº„ÅøÂ§±ÊïóÔºö„ÇØ„Ç©„Éº„ÇøË∂ÖÈÅé„Åæ„Åü„ÅØ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂïèÈ°å„ÄÇ",
        "warning_no_files": "Ë≥áÊñô„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "warning_rag_not_ready": "RAG„ÅåÊ∫ñÂÇô„Åß„Åç„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ",
        "quiz_fail_structure": "„ÇØ„Ç§„Ç∫„Éá„Éº„Çø„ÅÆÂΩ¢Âºè„ÅåÊ≠£„Åó„Åè„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
        "select_answer": "ÂõûÁ≠î„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
        "check_answer": "ÂõûÁ≠î„ÇíÁ¢∫Ë™ç",
        "next_question": "Ê¨°„ÅÆË≥™Âïè",
        "correct_answer": "Ê≠£Ëß£ÔºÅ üéâ",
        "incorrect_answer": "‰∏çÊ≠£Ëß£ üòû",
        "correct_is": "Ê≠£Ëß£",
        "explanation": "Ëß£Ë™¨",
        "quiz_complete": "„ÇØ„Ç§„Ç∫ÂÆå‰∫Ü!",
        "score": "„Çπ„Ç≥„Ç¢",
        "retake_quiz": "ÂÜçÊåëÊà¶",
        "quiz_error_llm": "„ÇØ„Ç§„Ç∫ÁîüÊàêÂ§±ÊïóÔºöJSONÂΩ¢Âºè„ÅåÊ≠£„Åó„Åè„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
        "quiz_original_response": "LLM ÂéüÊú¨ÂõûÁ≠î",
        "firestore_loading": "RAG„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπË™≠„ÅøËæº„Åø‰∏≠...",
        "firestore_no_index": "‰øùÂ≠ò„Åï„Çå„ÅüRAG„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ",
        "db_save_complete": "(DB‰øùÂ≠òÂÆå‰∫Ü)",
        "data_analysis_progress": "Ë≥áÊñôÂàÜÊûê‰∏≠...",
        "response_generating": "ÂøúÁ≠îÁîüÊàê‰∏≠...",
        "lstm_result_header": "ÈÅîÊàêÂ∫¶‰∫àÊ∏¨ÁµêÊûú",
        "lstm_score_metric": "‰∫àÊ∏¨ÈÅîÊàêÂ∫¶",
        "lstm_score_info": "Ê¨°„ÅÆ„Çπ„Ç≥„Ç¢‰∫àÊ∏¨: **{predicted_score:.1f}ÁÇπ**",
        "lstm_rerun_button": "Êñ∞„Åó„ÅÑ„Éá„Éº„Çø„ÅßÂÜç‰∫àÊ∏¨",

        # --- Simulator ---
        "simulator_header": "AIÈ°ßÂÆ¢ÂØæÂøú„Ç∑„Éü„É•„É¨„Éº„Çø„Éº",
        "simulator_desc": "Èõ£„Åó„ÅÑÈ°ßÂÆ¢Âïè„ÅÑÂêà„Çè„Åõ„Å´ÂØæ„Åô„ÇãAI„ÅÆ„Ç¨„Ç§„Éâ„É©„Ç§„É≥„Å®ËçâÊ°à„ÇíÁîüÊàê„Åó„Åæ„Åô„ÄÇ",
        "customer_query_label": "È°ßÂÆ¢„Åã„Çâ„ÅÆÂïè„ÅÑÂêà„Çè„ÅõÂÜÖÂÆπ („É™„É≥„ÇØÂèØ)",
        "customer_type_label": "È°ßÂÆ¢„Çø„Ç§„Éó",
        "customer_type_options": ["‰∏ÄËà¨ÁöÑ„Å™Âïè„ÅÑÂêà„Çè„Åõ", "Èõ£„Åó„ÅÑÈ°ßÂÆ¢", "ÈùûÂ∏∏„Å´‰∏çÊ∫Ä„Å™È°ßÂÆ¢"],
        "button_simulate": "ÂøúÂØæ„Ç¨„Ç§„ÉâÁîüÊàê",
        "customer_generate_response_button": "È°ßÂÆ¢„ÅÆËøî‰ø°„ÇíÁîüÊàê",
        "send_closing_confirm_button": "ËøΩÂä†„ÅÆ„ÅîË≥™ÂïèÊúâÁÑ°„ÇíÁ¢∫Ë™ç„Åô„Çã„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÈÄÅ‰ø°",
        "simulation_warning_query": "„ÅäÂïè„ÅÑÂêà„Çè„ÅõÂÜÖÂÆπ„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "simulation_no_key_warning": "‚ö†Ô∏è API„Ç≠„Éº‰∏çË∂≥„ÅÆ„Åü„ÇÅÂøúÂØæÁîüÊàê‰∏çÂèØ„ÄÇ",
        "simulation_advice_header": "AIÂØæÂøú„Ç¨„Ç§„Éâ„É©„Ç§„É≥",
        "simulation_draft_header": "Êé®Â•®ÂøúÂØæËçâÊ°à",
        "button_listen_audio": "Èü≥Â£∞„ÅßËÅû„Åè",
        "tts_status_ready": "Èü≥Â£∞ÁîüÊàêÊ∫ñÂÇôÂÆå‰∫Ü",
        "tts_status_generating": "Èü≥Â£∞ÁîüÊàê‰∏≠...",
        "tts_status_success": "Èü≥Â£∞Ê∫ñÂÇôÂÆå‰∫ÜÔºÅ",
        "tts_status_error": "TTS „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü",
        "history_expander_title": "üìù ÈÅéÂéª„ÅÆÂØæÂøúÂ±•Ê≠¥„ÇíË™≠„ÅøËæº„ÇÄ (ÊúÄÊñ∞10‰ª∂)",
        "initial_query_sample": "„Éë„É™„Å´Âà∞ÁùÄ„Åó„Åæ„Åó„Åü„Åå„ÄÅKlook„ÅÆeSIM„Åå‰Ωø„Åà„Åæ„Åõ„Çì‚Ä¶",
        "button_mic_input": "üéô Èü≥Â£∞ÂÖ•Âäõ",
        "prompt_customer_end": "ËøΩÂä†„ÅÆË≥™Âïè„Åå„Å™„ÅÑ„Åü„ÇÅ„ÉÅ„É£„ÉÉ„Éà„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ",
        "prompt_survey": "„ÅäÂïè„ÅÑÂêà„Çè„Åõ„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åó„Åü„ÄÇ",
        "customer_closing_confirm": "‰ªñ„ÅÆ„ÅäÂïèÂêà„Åõ„ÅØ„Åî„Åñ„ÅÑ„Åæ„Åõ„Çì„Åß„Åó„Çá„ÅÜ„Åã„ÄÇ",
        "customer_positive_response": "„Åî‰∏ÅÂØß„Å™ÂØæÂøú„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åó„Åü„ÄÇ",
        "button_end_chat": "„ÉÅ„É£„ÉÉ„ÉàÁµÇ‰∫ÜÔºà„Ç¢„É≥„Ç±„Éº„ÉàÔºâ",
        "new_simulation_ready": "Êñ∞„Åó„ÅÑ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„ÇíÈñãÂßã„Åß„Åç„Åæ„Åô„ÄÇ",
        "survey_sent_confirm": "üì® „Ç¢„É≥„Ç±„Éº„Éà„É™„É≥„ÇØ„ÇíÈÄÅ‰ø°„Åó„Åæ„Åó„Åü„ÄÇ„Åì„ÅÆ„ÉÅ„É£„ÉÉ„Éà„ÅØÁµÇ‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ",
        "agent_response_header": "‚úçÔ∏è „Ç®„Éº„Ç∏„Çß„É≥„ÉàÂøúÁ≠î",
        "agent_response_placeholder": "È°ßÂÆ¢„Å∏Ëøî‰ø°ÂÜÖÂÆπ„ÇíÂÖ•Âäõ‚Ä¶",
        "send_response_button": "Ëøî‰ø°ÈÄÅ‰ø°",
        "request_rebuttal_button": "È°ßÂÆ¢„ÅÆÂèçÂøú„ÇíÁîüÊàê",
        "new_simulation_button": "Êñ∞Ë¶è„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥",
        "history_selectbox_label": "Â±•Ê≠¥„ÇíÈÅ∏Êäû:",
        "history_load_button": "Â±•Ê≠¥„ÇíË™≠„ÅøËæº„ÇÄ",
        "delete_history_button": "‚ùå ÂÖ®Â±•Ê≠¥ÂâäÈô§",
        "delete_confirm_message": "„Åô„Åπ„Å¶„ÅÆÂ±•Ê≠¥„ÇíÂâäÈô§„Åó„Åæ„Åô„ÅãÔºü",
        "delete_confirm_yes": "„ÅØ„ÅÑ„ÄÅÂâäÈô§„Åô„Çã",
        "delete_confirm_no": "„Ç≠„É£„É≥„Çª„É´",
        "delete_success": "ÂâäÈô§ÂÆå‰∫ÜÔºÅ",
        "deleting_history_progress": "ÂâäÈô§‰∏≠...",
        "search_history_label": "Â±•Ê≠¥Ê§úÁ¥¢",
        "date_range_label": "Êó•‰ªò„Éï„Ç£„É´„Çø„Éº",
        "no_history_found": "Ë©≤ÂΩì„Åô„ÇãÂ±•Ê≠¥„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
        "customer_email_label": "È°ßÂÆ¢„É°„Éº„É´„Ç¢„Éâ„É¨„ÇπÔºà‰ªªÊÑèÔºâ",
        "customer_phone_label": "È°ßÂÆ¢ÈÄ£Áµ°ÂÖà / ÈõªË©±Áï™Âè∑Ôºà‰ªªÊÑèÔºâ",

        # --- Voice ---
        "voice_rec_header": "Èü≥Â£∞Ë®òÈå≤ÔºÜÁÆ°ÁêÜ",
        "record_help": "Èå≤Èü≥„Åô„Çã„ÅãÈü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Åæ„Åô„ÄÇ",
        "uploaded_file": "Èü≥Â£∞„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ",
        "rec_list_title": "‰øùÂ≠ò„Åï„Çå„ÅüÈü≥Â£∞Ë®òÈå≤",
        "transcribe_btn": "Ëª¢ÂÜô (Whisper)",
        "save_btn": "Èü≥Â£∞Ë®òÈå≤„Çí‰øùÂ≠ò",
        "transcribing": "Èü≥Â£∞„ÇíËª¢ÂÜô‰∏≠...",
        "transcript_result": "Ëª¢ÂÜôÁµêÊûú:",
        "transcript_text": "Ëª¢ÂÜô„ÉÜ„Ç≠„Çπ„Éà",
        "whisper_processing": "Èü≥Â£∞Ëª¢ÂÜô„ÇíÂá¶ÁêÜ‰∏≠...",
        "whisper_success": "‚úÖ Ëª¢ÂÜô„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ ‰ª•‰∏ã„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„Çí„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "openai_missing": "OpenAI API„Ç≠„Éº„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇOPENAI_API_KEY„ÇíË®≠ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "whisper_client_error": "‚ùå „Ç®„É©„Éº: Whisper API„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÅåÂàùÊúüÂåñ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ",
        "whisper_auth_error": "‚ùå Whisper APIË™çË®º„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇAPI„Ç≠„Éº„Çí„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ",
        "whisper_format_error": "‚ùå „Ç®„É©„Éº: „Åì„ÅÆÈü≥Â£∞ÂΩ¢Âºè„ÅØ„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ",
        "playback": "Èå≤Èü≥ÂÜçÁîü",
        "retranscribe": "ÂÜçËª¢ÂÜô",
        "delete": "ÂâäÈô§",
        "no_records": "‰øùÂ≠ò„Åï„Çå„ÅüÈü≥Â£∞Ë®òÈå≤„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
        "saved_success": "‰øùÂ≠ò„Åó„Åæ„Åó„ÅüÔºÅ",
        "delete_confirm_rec": "„Åì„ÅÆÈü≥Â£∞Ë®òÈå≤„ÇíÂâäÈô§„Åó„Åæ„Åô„ÅãÔºü",
        "gcs_not_conf": "GCS„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åã„ÄÅÈü≥Â£∞„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
        "gcs_playback_fail": "Èü≥Â£∞„ÅÆÂÜçÁîü„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ",
        "gcs_no_audio": "Èü≥Â£∞„Éï„Ç°„Ç§„É´„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
        "error": "„Ç®„É©„Éº:",
        "firestore_no_db_connect": "DBÊé•Á∂öÂ§±Êïó",
        "save_history_success": "‰øùÂ≠òÂÆå‰∫Ü„ÄÇ",
        "save_history_fail": "‰øùÂ≠òÂ§±Êïó„ÄÇ",
        "delete_fail": "ÂâäÈô§Â§±Êïó",
        "rec_header": "Èü≥Â£∞ÂÖ•ÂäõÔºÜËª¢ÂÜô",
        "whisper_processing": "Âá¶ÁêÜ‰∏≠...",
        "empty_response_warning": "ÂøúÁ≠î„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
    }
}



# ========================================
# 1-1. Session State Ï¥àÍ∏∞Ìôî
# ========================================

if "language" not in st.session_state:
    st.session_state.language = DEFAULT_LANG
if "is_llm_ready" not in st.session_state:
    st.session_state.is_llm_ready = False
if "llm_init_error_msg" not in st.session_state:
    st.session_state.llm_init_error_msg = ""
if "uploaded_files_state" not in st.session_state:
    st.session_state.uploaded_files_state = None
if "is_rag_ready" not in st.session_state:
    st.session_state.is_rag_ready = False
if "rag_vectorstore" not in st.session_state:
    st.session_state.rag_vectorstore = None
if "rag_messages" not in st.session_state:
    st.session_state.rag_messages = []

if "simulator_messages" not in st.session_state:
    st.session_state.simulator_messages = []
if "simulator_memory" not in st.session_state:
    st.session_state.simulator_memory = ConversationBufferMemory(memory_key="chat_history")
if "simulator_chain" not in st.session_state:
    st.session_state.simulator_chain = None
if "initial_advice_provided" not in st.session_state:
    st.session_state.initial_advice_provided = False
if "is_chat_ended" not in st.session_state:
    st.session_state.is_chat_ended = False
if "show_delete_confirm" not in st.session_state:
    st.session_state.show_delete_confirm = False
if "customer_query_text_area" not in st.session_state:
    st.session_state.customer_query_text_area = ""
if "agent_response_area_text" not in st.session_state:
    st.session_state.agent_response_area_text = ""
if "last_transcript" not in st.session_state:
    st.session_state.last_transcript = ""
if "sim_audio_bytes" not in st.session_state:
    st.session_state.sim_audio_bytes = None

if "openai_client" not in st.session_state:
    st.session_state.openai_client = None
if "openai_init_msg" not in st.session_state:
    st.session_state.openai_init_msg = ""

L = LANG[st.session_state.language]

# ========================================
# 2. OpenAI Client Ï¥àÍ∏∞Ìôî (secrets ÏÇ¨Ïö© Ïïà Ìï®)
# ========================================

# @st.cache_resource
# ========================================
# 0-A. API Key ÏïàÏ†Ñ Íµ¨Ï°∞ (Secrets + User Input)
# ========================================

# 1) Streamlit Cloud SecretsÏóêÏÑú Ïö∞ÏÑ† Í∞ÄÏ†∏Ïò§Í∏∞


secret_key = None

try:
    if hasattr(st, "secrets") and "OPENAI_API_KEY" in st.secrets:
        secret_key = st.secrets["OPENAI_API_KEY"]
except Exception:
    secret_key = None

# 2) ÏÇ¨Ïö©Ïûê ÏûÖÎ†• ÌÇ§ (ÏÑ∏ÏÖòÏóê Ï†ÄÏû•)
if "user_api_key" not in st.session_state:
    st.session_state.user_api_key = ""


# 3) UI Ï†úÍ≥µ: ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÅÏ†ë ÏûÖÎ†•ÌïòÎäî Î∞±ÏóÖ API Key
# ========================================
# 0. Î©ÄÌã∞ Î™®Îç∏ API Key ÏïàÏ†Ñ Íµ¨Ï°∞ (Secrets + User Input)
# ========================================


# --- Ï†ïÏùò: ÏßÄÏõêÌïòÎäî API Î™©Î°ù ---
L = LANG[st.session_state.language]

# ========================================
# 0. Î©ÄÌã∞ Î™®Îç∏ API Key ÏïàÏ†Ñ Íµ¨Ï°∞ (Secrets + User Input)
# ========================================

# 1) ÏßÄÏõêÌïòÎäî API Î™©Î°ù Ï†ïÏùò
SUPPORTED_APIS = {
    "openai": {
        "label": "OpenAI API Key",
        "secret_key": "OPENAI_API_KEY",
        "session_key": "user_openai_key",
    },
    "gemini": {
        "label": "Google Gemini API Key",
        "secret_key": "GEMINI_API_KEY",
        "session_key": "user_gemini_key",
    },
    "nvidia": {
        "label": "NVIDIA NIM API Key",
        "secret_key": "NVIDIA_API_KEY",
        "session_key": "user_nvidia_key",
    },
    "claude": {
        "label": "Anthropic Claude API Key",
        "secret_key": "CLAUDE_API_KEY",
        "session_key": "user_claude_key",
    },
    "groq": {
        "label": "Groq API Key",
        "secret_key": "GROQ_API_KEY",
        "session_key": "user_groq_key",
    },
}

# 2) ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî
for api, cfg in SUPPORTED_APIS.items():
    if cfg["session_key"] not in st.session_state:
        st.session_state[cfg["session_key"]] = ""

if "selected_llm" not in st.session_state:
    st.session_state.selected_llm = "openai_gpt4"  # Í∏∞Î≥∏Í∞í


def get_api_key(api_name: str):
    """1) Streamlit secrets ‚Üí 2) user ÏûÖÎ†• ÏàúÏúºÎ°ú API Key Î∞òÌôò"""
    cfg = SUPPORTED_APIS[api_name]

    # 1. Streamlit Secrets Ïö∞ÏÑ†
    try:
        if hasattr(st, "secrets") and cfg["secret_key"] in st.secrets:
            return st.secrets[cfg["secret_key"]]
    except Exception:
        pass

    # 2. ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Key
    if st.session_state.get(cfg["session_key"]):
        return st.session_state[cfg["session_key"]]

    # 3. ÏóÜÎäî Í≤ΩÏö∞
    return None


# ========================================
# 1. Sidebar UI: Î©ÄÌã∞ API Key ÏûÖÎ†• + Î™®Îç∏ ÏÑ†ÌÉù
# ========================================
with st.sidebar:
    st.markdown("### üîê API Keys ÏÑ§Ï†ï")

    for api, cfg in SUPPORTED_APIS.items():
        st.markdown(f"**{cfg['label']}**")
        key_input = st.text_input(
            cfg["label"],
            type="password",
            key=f"input_{api}",
            placeholder="sk-**************************",
        )

        if st.button(f"{cfg['label']} Ï†ÅÏö©", key=f"apply_{api}"):
            if key_input.strip():
                st.session_state[cfg["session_key"]] = key_input.strip()
                st.success(f"{cfg['label']} Ï†ÄÏû•Îê®")
            else:
                st.warning("API KeyÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî.")

    st.divider()
    st.markdown("### ü§ñ ÏÇ¨Ïö©Ìï† LLM Î™®Îç∏ ÏÑ†ÌÉù")

    MODEL_CHOICES = {
        "openai_gpt4": "OpenAI GPT-4.1",
        "openai_gpt35": "OpenAI GPT-3.5 Turbo",
        "gemini_flash": "Gemini 2.0 Flash",
        "gemini_pro": "Gemini 2.0 Pro",
        "nvidia_llama3": "NVIDIA NIM Llama-3-70B",
        "claude_sonnet": "Claude 3.5 Sonnet",
        "groq_llama3": "Groq Llama-3-70B",
        "groq_mixtral": "Groq Mixtral-8x7B",
    }

    st.session_state.selected_llm = st.selectbox(
        "LLM Î™®Îç∏ ÏÑ†ÌÉù",
        options=list(MODEL_CHOICES.keys()),
        format_func=lambda x: MODEL_CHOICES[x],
        key="selected_llm_box",
        index=list(MODEL_CHOICES.keys()).index(st.session_state.selected_llm)
        if st.session_state.selected_llm in MODEL_CHOICES
        else 0,
    )


# ========================================
# 2. LLM ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÎùºÏö∞ÌåÖ
# ========================================
def get_llm_client():
    """ÏÑ†ÌÉùÎêú Î™®Îç∏Ïóê ÎßûÎäî ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ + Î™®Îç∏ÏΩîÎìú Î∞òÌôò"""
    model_key = st.session_state.get("selected_llm", "openai_gpt4")

    # --- OpenAI ---
    if model_key.startswith("openai"):
        from openai import OpenAI

        key = get_api_key("openai")
        if not key:
            return None, None

        client = OpenAI(api_key=key)
        model_name = "gpt-4.1" if model_key == "openai_gpt4" else "gpt-3.5-turbo"
        return client, ("openai", model_name)

    # --- Gemini ---
    if model_key.startswith("gemini"):
        import google.generativeai as genai

        key = get_api_key("gemini")
        if not key:
            return None, None

        genai.configure(api_key=key)
        model_name = (
            "gemini-2.0-flash" if model_key == "gemini_flash" else "gemini-2.0-pro"
        )
        return genai, ("gemini", model_name)

    # --- NVIDIA NIM ---
    if model_key.startswith("nvidia"):
        import requests  # Ï†ÑÏó≠ÏóêÏÑú run_llmÏù¥ Îã§Ïãú ÏÇ¨Ïö©

        key = get_api_key("nvidia")
        if not key:
            return None, None

        model_name = "meta/llama3-70b-instruct"
        return ("nvidia", key), ("nvidia", model_name)

    # --- Claude ---
    if model_key.startswith("claude"):
        from anthropic import Anthropic

        key = get_api_key("claude")
        if not key:
            return None, None

        client = Anthropic(api_key=key)
        model_name = "claude-3-5-sonnet-latest"
        return client, ("claude", model_name)

    # --- Groq ---
    if model_key.startswith("groq"):
        from groq import Groq

        key = get_api_key("groq")
        if not key:
            return None, None

        client = Groq(api_key=key)
        model_name = (
            "llama3-70b-8192"
            if "llama3" in model_key
            else "mixtral-8x7b-32768"
        )
        return client, ("groq", model_name)

    return None, None


def run_llm(prompt: str) -> str:
    """ÏÑ†ÌÉùÎêú LLMÏúºÎ°ú ÌîÑÎ°¨ÌîÑÌä∏ Ïã§Ìñâ"""
    client, info = get_llm_client()

    if client is None or info is None:
        return "‚ùå No API key for selected model."

    provider, model_name = info

    # --- OpenAI Chat ---
    if provider == "openai":
        resp = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
        )
        return resp.choices[0].message.content

    # --- Gemini ---
    if provider == "gemini":
        gen_model = client.GenerativeModel(model_name)
        resp = gen_model.generate_content(prompt)
        return resp.text

    # --- Claude ---
    if provider == "claude":
        resp = client.messages.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
        )
        return resp.content[0].text

    # --- Groq ---
    if provider == "groq":
        resp = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
        )
        return resp.choices[0].message.content

    # --- NVIDIA NIM ---
    if provider == "nvidia":
        import requests  # get_llm_clientÏóêÏÑú Ïù¥ÎØ∏ ÏûÑÌè¨Ìä∏ÎêòÏßÄÎßå, ÏïàÏ†ÑÌïòÍ≤å Ìïú Î≤à Îçî

        api_key = client[1]
        r = requests.post(
            "https://integrate.api.nvidia.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            json={
                "model": model_name,
                "messages": [{"role": "user", "content": prompt}],
            },
            timeout=60,
        )
        data = r.json()
        return data["choices"][0]["message"]["content"]

    return "‚ùå Unsupported provider."


# ========================================
# 2-A. Whisper / TTS Ïö© OpenAI Client Î≥ÑÎèÑÎ°ú Ï¥àÍ∏∞Ìôî
#      (ÏÑ†ÌÉù Î™®Îç∏Í≥º Î¨¥Í¥ÄÌïòÍ≤å, OpenAI KeyÎßå ÏûàÏúºÎ©¥ ÏÇ¨Ïö©)
# ========================================
if "openai_client" not in st.session_state:
    st.session_state.openai_client = None
if "openai_init_msg" not in st.session_state:
    st.session_state.openai_init_msg = ""


def init_openai_client_for_audio():
    """Whisper/TTS Ï†ÑÏö© OpenAI ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî"""
    from openai import OpenAI

    openai_key = get_api_key("openai")
    if not openai_key:
        st.session_state.openai_client = None
        st.session_state.openai_init_msg = LANG[DEFAULT_LANG]["openai_missing"]
        return

    try:
        st.session_state.openai_client = OpenAI(api_key=openai_key)
        st.session_state.openai_init_msg = "‚úÖ OpenAI TTS/Whisper client ready."
    except Exception as e:
        st.session_state.openai_client = None
        st.session_state.openai_init_msg = f"OpenAI client init error: {e}"


init_openai_client_for_audio()

# LLM ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌîåÎûòÍ∑∏ (ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ Îì±ÏóêÏÑú ÏÇ¨Ïö©)
probe_client, _ = get_llm_client()
st.session_state.is_llm_ready = probe_client is not None
if not st.session_state.is_llm_ready:
    st.session_state.llm_init_error_msg = LANG[st.session_state.language][
        "simulation_no_key_warning"
    ]
else:
    st.session_state.llm_init_error_msg = ""

# ========================================
# 3. Whisper / TTS Helper
# ========================================

def transcribe_bytes_with_whisper(audio_bytes: bytes, mime_type: str = "audio/webm", lang_code: str = "ko") -> str:
    L = LANG[st.session_state.language]
    client = st.session_state.openai_client
    if client is None:
        return f"‚ùå {L['openai_missing']}"

    # Ïñ∏Ïñ¥ ÏΩîÎìú Îß§Ìïë
    whisper_lang = {"ko": "ko", "en": "en", "ja": "ja"}.get(lang_code, "en")

    ext = "webm"
    if "/" in mime_type:
        ext = mime_type.split("/")[-1].lower()

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=f".{ext}")
    tmp.write(audio_bytes)
    tmp.flush()
    tmp.close()

    try:
        with open(tmp.name, "rb") as f:
            res = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="text",
                language=whisper_lang,
            )
        return res.strip() if isinstance(res, str) else str(res)
    except Exception as e:
        return f"‚ùå {L['error']} Whisper: {e}"
    finally:
        try:
            os.remove(tmp.name)
        except OSError:
            pass

# ========================================
# Ïó≠Ìï†Î≥Ñ TTS ÏùåÏÑ± Ïä§ÌÉÄÏùº ÏÑ§Ï†ï
# ========================================

TTS_VOICES = {
    "customer": {
        "gender": "male",
        "voice": "verse"      # ÎÇ®ÏÑ± Î™©ÏÜåÎ¶¨
    },
    "agent": {
        "gender": "female",
        "voice": "coral"      # Îî∞ÎúªÌïú Ïó¨ÏÑ± Î™©ÏÜåÎ¶¨
    }
}

def synthesize_tts(text: str, lang_key: str, role: str = "customer"):
    client = st.session_state.openai_client
    if not client:
        return None, LANG[lang_key]["openai_missing"]

    voice_cfg = TTS_VOICES.get(role, TTS_VOICES["customer"])
    voice_name = voice_cfg["voice"]

    try:
        response = client.audio.speech.create(
            model="gpt-4o-mini-tts",
            voice=voice_name,
            input=text
        )
        return response.read(), LANG[lang_key]["tts_status_success"]

    except Exception as e:
        return None, f"TTS Error: {str(e)}"



def render_tts_button(text, lang_key, role="customer", prefix=""):
    L = LANG[lang_key]
    safe_key = prefix + f"tts_{role}_" + hashlib.md5(text.encode()).hexdigest()

    if st.button(L["button_listen_audio"], key=safe_key):
        audio_bytes, msg = synthesize_tts(text, lang_key, role=role)
        if audio_bytes:
            st.audio(audio_bytes, format="audio/mp3")
        else:
            st.error(msg)



# ========================================
# 4. Î°úÏª¨ ÏùåÏÑ± Í∏∞Î°ù Helper
# ========================================

def load_voice_records() -> List[Dict[str, Any]]:
    return _load_json(VOICE_META_FILE, [])


def save_voice_records(records: List[Dict[str, Any]]):
    _save_json(VOICE_META_FILE, records)


def save_audio_record_local(
    audio_bytes: bytes,
    filename: str,
    transcript_text: str,
    mime_type: str = "audio/webm",
    meta: Dict[str, Any] = None,
) -> str:
    records = load_voice_records()
    rec_id = str(uuid.uuid4())
    ts = datetime.utcnow().isoformat()

    ext = filename.split(".")[-1] if "." in filename else "webm"
    audio_filename = f"{rec_id}.{ext}"
    audio_path = os.path.join(AUDIO_DIR, audio_filename)
    with open(audio_path, "wb") as f:
        f.write(audio_bytes)

    rec = {
        "id": rec_id,
        "created_at": ts,
        "filename": filename,
        "audio_filename": audio_filename,
        "size": len(audio_bytes),
        "transcript": transcript_text,
        "mime_type": mime_type,
        "language": st.session_state.language,
        "meta": meta or {},
    }
    records.insert(0, rec)
    save_voice_records(records)
    return rec_id


def delete_audio_record_local(rec_id: str) -> bool:
    records = load_voice_records()
    idx = next((i for i, r in enumerate(records) if r.get("id") == rec_id), None)
    if idx is None:
        return False
    rec = records.pop(idx)
    audio_filename = rec.get("audio_filename")
    if audio_filename:
        audio_path = os.path.join(AUDIO_DIR, audio_filename)
        try:
            os.remove(audio_path)
        except FileNotFoundError:
            pass
    save_voice_records(records)
    return True


def get_audio_bytes_local(rec_id: str):
    records = load_voice_records()
    rec = next((r for r in records if r.get("id") == rec_id), None)
    if not rec:
        raise FileNotFoundError("record not found")
    audio_filename = rec["audio_filename"]
    audio_path = os.path.join(AUDIO_DIR, audio_filename)
    with open(audio_path, "rb") as f:
        b = f.read()
    return b, rec

# ========================================
# 5. Î°úÏª¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïù¥Î†• Helper
# ========================================

def load_simulation_histories_local(lang_key: str) -> List[Dict[str, Any]]:
    histories = _load_json(SIM_META_FILE, [])
    return [
        h for h in histories
        if h.get("language_key") == lang_key and isinstance(h.get("messages"), list)
    ]


def save_simulation_history_local(initial_query: str, customer_type: str, messages: List[Dict[str, Any]], is_chat_ended: bool):
    histories = _load_json(SIM_META_FILE, [])
    doc_id = str(uuid.uuid4())
    ts = datetime.utcnow().isoformat()
    data = {
        "id": doc_id,
        "initial_query": initial_query,
        "customer_type": customer_type,
        "messages": messages,
        "language_key": st.session_state.language,
        "timestamp": ts,
        "is_chat_ended": is_chat_ended,
    }
    histories.insert(0, data)
    _save_json(SIM_META_FILE, histories)
    return True


def delete_all_history_local():
    _save_json(SIM_META_FILE, [])

# ========================================
# 6. RAG Helper (FAISS)
# ========================================

def load_documents(files) -> List[Document]:
    docs: List[Document] = []
    for f in files:
        name = f.name
        lower = name.lower()
        if lower.endswith(".pdf"):
            # UploadedFile -> temp ÌååÏùºÎ°ú
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
            tmp.write(f.read())
            tmp.flush()
            tmp.close()
            loader = PyPDFLoader(tmp.name)
            file_docs = loader.load()
            for d in file_docs:
                d.metadata["source"] = name
            docs.extend(file_docs)
            try:
                os.remove(tmp.name)
            except OSError:
                pass
        elif lower.endswith(".txt"):
            text = f.read().decode("utf-8", errors="ignore")
            docs.append(Document(page_content=text, metadata={"source": name}))
        elif lower.endswith(".html") or lower.endswith(".htm"):
            text = f.read().decode("utf-8", errors="ignore")
            docs.append(Document(page_content=text, metadata={"source": name}))
    return docs


def split_documents(docs: List[Document]) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=["\n\n", "\n", ".", " ", ""],
    )
    return splitter.split_documents(docs)


def build_rag_index(files, embeddings):
    if not files:
        st.warning(L["warning_no_files"])
        return None, 0

    docs = load_documents(files)
    if not docs:
        st.warning("Î¨∏ÏÑúÎ•º Î∂àÎü¨Ïò§ÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
        return None, 0

    chunks = split_documents(docs)
    if not chunks:
        st.warning("Î¨∏ÏÑú Ï≤≠ÌÅ¨ Î∂ÑÌï†Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.")
        return None, 0

    try:
        vectorstore = FAISS.from_documents(chunks, embeddings)
        # Ï†ÄÏû•
        vectorstore.save_local(RAG_INDEX_DIR)
    except Exception as e:
        st.error(f"RAG Ïù∏Îç±Ïä§ ÏÉùÏÑ± Ï§ë Ïò§Î•ò: {e}")
        return None, 0

    return vectorstore, len(chunks)


def load_rag_index(embeddings):
    try:
        vs = FAISS.load_local(RAG_INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
        return vs
    except Exception:
        return None


def rag_answer(question: str, vectorstore: FAISS, lang_key: str) -> str:
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return LANG[lang_key]["openai_missing"]

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
        openai_api_key=api_key,
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

    docs = retriever.get_relevant_documents(question)
    context = "\n\n".join(d.page_content[:1500] for d in docs)

    prompt_tmpl = PromptTemplate(
        template=(
            "You are a helpful AI tutor. Answer the question using ONLY the provided context.\n"
            "If you cannot find the answer in the context, say you don't know.\n\n"
            "Question:\n{question}\n\n"
            "Context:\n{context}\n\n"
            "Answer:"
        ),
        input_variables=["question", "context"],
    )
    prompt = prompt_tmpl.format(question=question, context=context)
    resp = llm.invoke(prompt)
    return resp.content if hasattr(resp, "content") else str(resp)

# ========================================
# 7. LSTM Helper (Í∞ÑÎã® Mock + ÏãúÍ∞ÅÌôî)
# ========================================

def load_or_train_lstm():
    # Ïã§Ï†ú LSTM ÎåÄÏã† ÎûúÎç§ + sin ÌååÌòï Í∏∞Î∞ò Mock
    np.random.seed(42)
    n_points = 50
    ts = 60 + 20 * np.sin(np.linspace(0, 4 * np.pi, n_points)) + np.random.normal(0, 5, n_points)
    ts = np.clip(ts, 50, 100).astype(np.float32)
    return ts

# ========================================
# 8. LLM (ChatOpenAI) for Simulator / Content
# ========================================

LLM_API_KEY = os.environ.get("OPENAI_API_KEY")
LLM_MODEL = "gpt-4o-mini"

if "llm" not in st.session_state:
    if LLM_API_KEY:
        try:
            st.session_state.llm = ChatOpenAI(
                model=LLM_MODEL,
                temperature=0.7,
                openai_api_key=LLM_API_KEY,
            )
            st.session_state.embeddings = OpenAIEmbeddings(openai_api_key=LLM_API_KEY)
            st.session_state.is_llm_ready = True

            sim_prompt = PromptTemplate(
                template=(
                    "You are an AI customer who responds ONLY as the customer in the scenario.\n"
                    "Do NOT greet unless the agent greets first.\n"
                    "Do NOT repeat your initial message.\n"
                    "Always answer in the language used by the agent.\n\n"
                    "Rules:\n"
                    "- If the agent requests specific information, provide ONLY ONE detail.\n"
                    "- If the agent provides a solution, respond politely.\n"
                    "- If the conversation is nearing completion, optionally add a closing remark.\n"
                    "- DO NOT generate long formal greetings like 'Good morning'.\n"
                    "- DO NOT reset context.\n\n"
                    "{chat_history}\nHuman agent: {input}\nCustomer:"
                ),
                input_variables=["input", "chat_history"],
            )

            st.session_state.simulator_chain = ConversationChain(
                llm=st.session_state.llm,
                memory=st.session_state.simulator_memory,
                prompt=sim_prompt,
                input_key="input",
            )
        except Exception as e:
            st.session_state.llm_init_error_msg = f"{L['llm_error_init']} (OpenAI): {e}"
            st.session_state.is_llm_ready = False
    else:
        st.session_state.llm_init_error_msg = LANG[DEFAULT_LANG]["openai_missing"]
        st.session_state.is_llm_ready = False

# ========================================
# 9. ÏÇ¨Ïù¥ÎìúÎ∞î (Ïñ∏Ïñ¥ ÏÑ†ÌÉù + ÌååÏùº ÏóÖÎ°úÎìú + Î∂ÑÏÑù Î≤ÑÌäº)
# ========================================

with st.sidebar:
    selected_lang_key = st.selectbox(
        L["lang_select"],
        options=["ko", "en", "ja"],
        index=["ko", "en", "ja"].index(st.session_state.language),
        format_func=lambda x: {"ko": "ÌïúÍµ≠Ïñ¥", "en": "English", "ja": "Êó•Êú¨Ë™û"}[x],
    )

    # üîπ Ïñ∏Ïñ¥ Î≥ÄÍ≤Ω Í∞êÏßÄ
    if selected_lang_key != st.session_state.language:
        old_lang = st.session_state.language
        st.session_state.language = selected_lang_key
        L = LANG[st.session_state.language]

        # üîπ ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ Í¥ÄÎ†® ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî
        st.session_state.simulator_messages = []
        st.session_state.simulator_memory.clear()
        st.session_state.initial_advice_provided = False
        st.session_state.is_chat_ended = False
        st.session_state.agent_response_area_text = ""
        st.session_state.last_transcript = ""
        st.session_state.sim_audio_bytes = None
        st.session_state.sim_audio_bytes_raw = None

        # (ÏõêÌïòÎ©¥ RAG Ï±ÑÌåÖ Ïù¥Î†•ÎèÑ Ïñ∏Ïñ¥Î≥ÑÎ°ú Î∂ÑÎ¶¨ÌïòÍ≥† Ïã∂ÏùÑ Îïå)
        # st.session_state.messages = []

        # st.rerun()


    L = LANG[st.session_state.language]

    st.title(L["sidebar_title"])
    st.markdown("---")

    st.subheader("ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî ÏÉÅÌÉú")
    if st.session_state.llm_init_error_msg:
        st.error(st.session_state.llm_init_error_msg)
    elif st.session_state.is_llm_ready:
        st.success("‚úÖ LLM Î∞è ÏûÑÎ≤†Îî© ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï§ÄÎπÑ ÏôÑÎ£å")

    if "‚úÖ" in st.session_state.openai_init_msg:
        st.success(st.session_state.openai_init_msg)
    else:
        st.warning(st.session_state.openai_init_msg)

    st.markdown("---")

    uploaded_files_widget = st.file_uploader(
        L["file_uploader"], type=["pdf", "txt", "html"], accept_multiple_files=True
    )
    if uploaded_files_widget:
        st.session_state.uploaded_files_state = uploaded_files_widget

    files_to_process = st.session_state.uploaded_files_state or []

    if files_to_process and st.session_state.is_llm_ready:
        if st.button(L["button_start_analysis"]):
            with st.spinner(L["data_analysis_progress"]):
                vs, count = build_rag_index(files_to_process, st.session_state.embeddings)
                if vs is not None:
                    st.session_state.rag_vectorstore = vs
                    st.session_state.is_rag_ready = True
                    st.success(L["embed_success"].format(count=count))
                else:
                    st.session_state.is_rag_ready = False
    elif not files_to_process:
        st.info(L["warning_no_files"])

    st.markdown("---")

    feature_selection = st.radio(
        "Í∏∞Îä• ÏÑ†ÌÉù",
        [L["rag_tab"], L["content_tab"], L["lstm_tab"], L["simulator_tab"], L["voice_rec_header"]],
    )

# Î©îÏù∏ ÌÉÄÏù¥ÌãÄ
st.title(L["title"])

# ========================================
# 10. Í∏∞Îä•Î≥Ñ ÌéòÏù¥ÏßÄ
# ========================================

# -------------------- Voice Record Tab --------------------
if feature_selection == L["voice_rec_header"]:
    st.header(L["voice_rec_header"])
    st.caption(L["record_help"])

    col_rec, col_list = st.columns([1, 1])

    # ÎÖπÏùå/ÏóÖÎ°úÎìú + Ï†ÑÏÇ¨ + Ï†ÄÏû•
    with col_rec:
        st.subheader(L["rec_header"])
        audio_file = st.file_uploader(
            L["uploaded_file"],
            type=["wav", "mp3", "m4a", "webm", "ogg"],
            key="voice_rec_uploader",
        )
        audio_bytes = None
        audio_mime = "audio/webm"

        if audio_file is not None:
            audio_bytes = audio_file.getvalue()
            audio_mime = audio_file.type or "audio/webm"

        # Ïû¨ÏÉù
        if audio_bytes:
            st.audio(audio_bytes, format=audio_mime)

        # Ï†ÑÏÇ¨ Î≤ÑÌäº
        if audio_bytes and st.button(L["transcribe_btn"]):
            if st.session_state.openai_client is None:
                st.error(L["openai_missing"])
            else:
                with st.spinner(L["transcribing"]):
                    text = transcribe_bytes_with_whisper(
                        audio_bytes, audio_mime, lang_code=st.session_state.language
                    )
                    st.session_state.last_transcript = text
                    snippet = text[:50].replace("\n", " ")
                    if len(text) > 50:
                        snippet += "..."
                    if text.startswith("‚ùå"):
                        st.error(text)
                    else:
                        st.success(f"{L['transcript_result']} **{snippet}**")

        st.text_area(
            L["transcript_text"],
            value=st.session_state.last_transcript,
            height=150,
            key="voice_rec_transcript_area",
        )

        if audio_bytes and st.button(L["save_btn"]):
            try:
                ext = audio_mime.split("/")[-1] if "/" in audio_mime else "webm"
                filename = f"record_{int(time.time())}.{ext}"
                save_audio_record_local(
                    audio_bytes,
                    filename,
                    st.session_state.last_transcript,
                    mime_type=audio_mime,
                )
                st.success(L["saved_success"])
                st.session_state.last_transcript = ""
                # st.rerun()
            except Exception as e:
                st.error(f"{L['error']} {e}")

    # Ï†ÄÏû•Îêú Í∏∞Î°ù Î¶¨Ïä§Ìä∏
    with col_list:
        st.subheader(L["rec_list_title"])
        try:
            records = load_voice_records()
        except Exception as e:
            st.error(f"read error: {e}")
            records = []

        if not records:
            st.info(L["no_records"])
        else:
            for rec in records:
                rec_id = rec["id"]
                created_at = rec.get("created_at")
                try:
                    dt = datetime.fromisoformat(created_at)
                    created_str = dt.strftime("%Y-%m-%d %H:%M")
                except Exception:
                    created_str = str(created_at)

                transcript_snippet = (rec.get("transcript") or "")[:50].replace("\n", " ")
                if len(rec.get("transcript") or "") > 50:
                    transcript_snippet += "..."

                with st.expander(f"[{created_str}] {transcript_snippet}"):
                    st.write(f"**{L['transcript_text']}:** {rec.get('transcript') or 'N/A'}")
                    st.caption(
                        f"**Size:** {rec.get('size')} bytes | **File:** {rec.get('audio_filename')}"
                    )

                    col_p, col_r, col_d = st.columns([2, 1, 1])

                    if col_p.button(L["playback"], key=f"play_{rec_id}"):
                        try:
                            b, info = get_audio_bytes_local(rec_id)
                            mime = info.get("mime_type", "audio/webm")
                            st.audio(b, format=mime)
                        except Exception as e:
                            st.error(f"{L['gcs_playback_fail']}: {e}")

                    if col_r.button(L["retranscribe"], key=f"re_{rec_id}"):
                        if st.session_state.openai_client is None:
                            st.error(L["openai_missing"])
                        else:
                            with st.spinner(L["transcribing"]):
                                try:
                                    b, info = get_audio_bytes_local(rec_id)
                                    mime = info.get("mime_type", "audio/webm")
                                    new_text = transcribe_bytes_with_whisper(
                                        b, mime, lang_code=st.session_state.language
                                    )
                                    records = load_voice_records()
                                    for r in records:
                                        if r["id"] == rec_id:
                                            r["transcript"] = new_text
                                            break
                                    save_voice_records(records)
                                    st.success(L["retranscribe"] + " " + L["saved_success"])
                                    # st.rerun()
                                except Exception as e:
                                    st.error(f"{L['error']} {e}")

                    if col_d.button(L["delete"], key=f"del_{rec_id}"):
                        if st.session_state.get(f"confirm_del_{rec_id}", False):
                            ok = delete_audio_record_local(rec_id)
                            if ok:
                                st.success(L["delete_success"])
                            else:
                                st.error(L["delete_fail"])
                            st.session_state[f"confirm_del_{rec_id}"] = False
                            # st.rerun()
                        else:
                            st.session_state[f"confirm_del_{rec_id}"] = True
                            st.warning(L["delete_confirm_rec"])

# -------------------- Simulator Tab --------------------
elif feature_selection == L["simulator_tab"]:
    st.header(L["simulator_header"])
    st.markdown(L["simulator_desc"])

    st.markdown(
        f'<div style="padding:5px;text-align:center;border-radius:5px;background-color:#f0f0f0;margin-bottom:10px;">{L["tts_status_ready"]}</div>',
        unsafe_allow_html=True,
    )

    # Ï†ÑÏ≤¥ Ïù¥Î†• ÏÇ≠Ï†ú
    col_del, _ = st.columns([1, 4])
    with col_del:
        if st.button(L["delete_history_button"], key="trigger_delete_hist"):
            st.session_state.show_delete_confirm = True

    if st.session_state.show_delete_confirm:
        with st.container():
            st.warning(L["delete_confirm_message"])
            c_yes, c_no = st.columns(2)
            if c_yes.button(L["delete_confirm_yes"], key="confirm_del_yes"):
                with st.spinner(L["deleting_history_progress"]):
                    delete_all_history_local()
                    st.session_state.simulator_messages = []
                    st.session_state.simulator_memory.clear()
                    st.session_state.show_delete_confirm = False
                    st.success(L["delete_success"])
                    # st.rerun()
            if c_no.button(L["delete_confirm_no"], key="confirm_del_no"):
                st.session_state.show_delete_confirm = False
                # st.rerun()

    current_lang = st.session_state.language

    # Ïù¥Î†• Î°úÎìú
    with st.expander(L["history_expander_title"]):
        histories = load_simulation_histories_local(current_lang)
        search_query = st.text_input(L["search_history_label"], key="sim_hist_search")

        today = datetime.now().date()
        dr = st.date_input(
            L["date_range_label"],
            value=[today - timedelta(days=7), today],
            key="sim_hist_date_range",
        )

        filtered = []
        if histories:
            if isinstance(dr, list) and len(dr) == 2:
                start_date = min(dr)
                end_date = max(dr)
            else:
                start_date = datetime.min.date()
                end_date = datetime.max.date()

            for h in histories:
                ok_search = True
                if search_query:
                    q = search_query.lower()
                    text = (h["initial_query"] + " " + h["customer_type"]).lower()
                    if q not in text:
                        ok_search = False

                ok_date = True
                ts = h.get("timestamp")
                if ts:
                    try:
                        d = datetime.fromisoformat(ts).date()
                        if not (start_date <= d <= end_date):
                            ok_date = False
                    except Exception:
                        pass

                if ok_search and ok_date:
                    filtered.append(h)

        if filtered:
            def _label(h):
                try:
                    t = datetime.fromisoformat(h["timestamp"])
                    t_str = t.strftime("%m-%d %H:%M")
                except Exception:
                    t_str = h.get("timestamp", "")
                q = h["initial_query"][:30].replace("\n", " ")
                return f"[{t_str}] {h['customer_type']} - {q}..."

            options_map = { _label(h): h for h in filtered }
            sel_key = st.selectbox(L["history_selectbox_label"], options=list(options_map.keys()))
            if st.button(L["history_load_button"], key="load_hist_btn"):
                h = options_map[sel_key]
                st.session_state.customer_query_text_area = h["initial_query"]
                st.session_state.simulator_messages = h["messages"]
                st.session_state.initial_advice_provided = True
                st.session_state.is_chat_ended = h.get("is_chat_ended", False)

                st.session_state.simulator_memory.clear()
                for msg in h["messages"]:
                    role = msg["role"]
                    if role in ["customer", "agent_response"]:
                        st.session_state.simulator_memory.chat_memory.add_user_message(msg["content"])
                    else:
                        st.session_state.simulator_memory.chat_memory.add_ai_message(msg["content"])

                st.rerun()
        else:
            st.info(L["no_history_found"])

    # LLM ÏóÜÏúºÎ©¥ ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ Ï†úÌïú
    if not st.session_state.is_llm_ready and not LLM_API_KEY:
        st.warning(L["simulation_no_key_warning"])

    if st.session_state.is_chat_ended:
        st.success(L["prompt_customer_end"] + " " + L["prompt_survey"])
        if st.button(L["new_simulation_button"], key="new_simulation_btn"):
            st.session_state.is_chat_ended = False
            st.session_state.initial_advice_provided = False
            st.session_state.simulator_messages = []
            st.session_state.simulator_memory.clear()
            st.session_state.last_transcript = ""
            st.session_state.agent_response_area_text = ""
            st.session_state.customer_query_text_area = ""
            # st.rerun()
        st.stop()

    # Ï¥àÍ∏∞ Î¨∏Ïùò ÏûÖÎ†•
    customer_query = st.text_area(
        L["customer_query_label"],
        key="customer_query_text_area",
        height=150,
        placeholder=L["initial_query_sample"],
        value=st.session_state.agent_response_area_text,
        disabled=st.session_state.initial_advice_provided,
    )

    # üîπ ÏÉàÎ°ú Ï∂îÍ∞Ä: Í≥†Í∞ù Ïó∞ÎùΩÏ≤ò (ÏÑ†ÌÉù)
    customer_email = st.text_input(
        L.get("customer_email_label", "Customer email (optional)"),
        key="customer_email",
        disabled=st.session_state.initial_advice_provided,
    )
    customer_phone = st.text_input(
        L.get("customer_phone_label", "Customer phone / WhatsApp (optional)"),
        key="customer_phone",
        disabled=st.session_state.initial_advice_provided,
    )

    customer_type_options = L["customer_type_options"]
    default_idx = 1 if len(customer_type_options) > 1 else 0
    customer_type_display = st.selectbox(
        L["customer_type_label"],
        customer_type_options,
        index=default_idx,
        disabled=st.session_state.initial_advice_provided,
        key="customer_type_sim_select",
    )

    if st.button(L["button_simulate"], disabled=st.session_state.initial_advice_provided):
        if not customer_query.strip():
            st.warning(L["simulation_warning_query"])
            st.stop()

        st.session_state.simulator_memory.clear()
        st.session_state.simulator_messages = []
        st.session_state.is_chat_ended = False

        st.session_state.simulator_messages.append({"role": "customer", "content": customer_query})
        st.session_state.simulator_memory.chat_memory.add_user_message(customer_query)

        contact_info_block = ""
        if customer_email or customer_phone:
            contact_info_block = (
                f"\n\n[Customer contact info for your reference]"
                f"\n- Email: {customer_email or 'N/A'}"
                f"\n- Phone: {customer_phone or 'N/A'}"
            )

        current_lang_key = st.session_state.language

        initial_prompt = f"""
        You are an AI Customer Support Supervisor. Your role is to analyze the following customer inquiry
        from a **{customer_type_display}** and provide:

        1) A detailed **response guideline for the human agent** (step-by-step).
        2) A **ready-to-send draft reply** in {LANG[current_lang_key]['lang_select']}.


        [CRITICAL RULE 1: LANGUAGE]
        - All content (guideline AND draft) MUST be written strictly in {LANG[current_lang_key]['lang_select']}.

        [CRITICAL RULE 2: FORMAT]
        - Use the exact markdown headers:
          - "### {L['simulation_advice_header']}"
          - "### {L['simulation_draft_header']}"

        [CRITICAL RULE 3: INFORMATION YOU MUST ASK FIRST]
        Before solving the problem, list the essential details the agent must collect from the customer.
        In the guideline, always include a section like "1. Ï†ïÎ≥¥ ÏàòÏßë / Information to collect" with bullet points such as:
        - For eSIM / connectivity issues:
          - Device model (e.g. iPhone 12, Galaxy S22)
          - OS version
          - Whether the device supports eSIM
          - Current location / country and whether the customer has already arrived
          - Exact activation steps already tried and at which step it failed
        - For tickets with children:
          - Number of children
          - Each child's date of birth or age range
          - Whether the ticket type changes with age (free / child / youth / adult)
        - Any booking ID, voucher number, or reservation code
        - Customer's preferred contact channel if follow-up is needed.

        [CRITICAL RULE 4: DRAFT STYLE]
        - The draft reply should:
          - Politely thank the customer.
          - Clearly ask for the missing information listed above (but not all in one long sentence).
          - Explain the next troubleshooting steps in simple language.
          - For eSIM cases, mention important checks (airplane mode, roaming settings, APN, profile installation, etc.) if relevant.
          - For child ticket cases, clearly explain how the pricing works by age.

        [CRITICAL RULE 5: ROLEPLAY FOR FUTURE MESSAGES]
        When the Agent subsequently asks for information in later rounds,
        **ROLEPLAY as the customer** who is frustrated but **HIGHLY COOPERATIVE** and
        provide the requested details piece by piece (not all at once).
        The customer MUST NOT argue about why the information is needed.
        
        [CRITICAL RULE 6: ASK FOR ALL REQUIRED DETAILS AT ONCE]
        When composing the draft reply:
        - Do NOT ask one-by-one questions.
        - Instead, request ALL required details in a neatly formatted multi-bullet list.
        - Each bullet point must contain only ONE information category.

        Customer Inquiry:
        {customer_query}
        {contact_info_block}
        """

        if not st.session_state.is_llm_ready or not LLM_API_KEY:
            mock_text = (
                f"### {L['simulation_advice_header']}\n\n"
                f"- (Mock) {customer_type_display} Ïú†Ìòï Í≥†Í∞ùÏóê ÎåÄÌïú ÏùëÎåÄ Í∞ÄÏù¥ÎìúÎùºÏù∏ÏûÖÎãàÎã§.\n\n"
                f"### {L['simulation_draft_header']}\n\n"
                f"(Mock) Ïó¨Í∏∞ÏóêÎäî Ïã§Ï†ú AI ÏùëÎåÄ Ï¥àÏïàÏù¥ Îì§Ïñ¥Í∞ëÎãàÎã§.\n\n"
            )
            st.session_state.simulator_messages.append({"role": "supervisor", "content": mock_text})
            st.session_state.simulator_memory.chat_memory.add_ai_message(mock_text)
            st.session_state.initial_advice_provided = True
            save_simulation_history_local(
                customer_query,
                customer_type_display,
                st.session_state.simulator_messages,
                is_chat_ended=False,
            )
            st.warning(L["simulation_no_key_warning"])
            # st.rerun()
        else:
            with st.spinner(L["response_generating"]):
                try:
                    text = st.session_state.simulator_chain.predict(input=initial_prompt)
                    st.session_state.simulator_messages.append({"role": "supervisor", "content": text})
                    st.session_state.initial_advice_provided = True
                    save_simulation_history_local(
                        customer_query,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=False,
                    )
                    # st.rerun()
                except Exception as e:
                    st.error(f"AI Ï°∞Ïñ∏ ÏÉùÏÑ± Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")

    # ÎåÄÌôî Î°úÍ∑∏ ÌëúÏãú
    # ÎåÄÌôî Î°úÍ∑∏ ÌëúÏãú
    for msg in st.session_state.simulator_messages:
        role = msg["role"]
        content = msg["content"]

        if role == "customer":
            with st.chat_message("user", avatar="üôã"):
                st.markdown(content)
                render_tts_button(customer_message, st.session_state.language, role="customer", prefix="cust_")

        elif role == "supervisor":
            with st.chat_message("assistant", avatar="ü§ñ"):
                st.markdown(content)
                render_tts_button(content, st.session_state.language, prefix="supervisor_")

        elif role == "agent_response":
            with st.chat_message("user", avatar="üßë‚Äçüíª"):
                st.markdown(content)
                render_tts_button(agent_reply, st.session_state.language, role="agent", prefix="agt_")

        elif role in ["customer_rebuttal", "customer_end", "system_end"]:
            with st.chat_message("assistant", avatar="‚ú®"):
                st.markdown(content)
                render_tts_button(content, st.session_state.language, prefix=f"{role}_")

    # ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµ / ÎßàÏù¥ÌÅ¨ ÏûÖÎ†•
    # ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµ / ÎßàÏù¥ÌÅ¨ ÏûÖÎ†•
    if st.session_state.initial_advice_provided and not st.session_state.is_chat_ended:

        last_role = (
            st.session_state.simulator_messages[-1]["role"]
            if st.session_state.simulator_messages else None
        )

        if last_role in ["customer", "supervisor", "customer_rebuttal", "customer_end"]:
            st.markdown(f"### {L['agent_response_header']}")
            col_mic, col_text = st.columns([1, 2])

            # ÎßàÏù¥ÌÅ¨ ÎÖπÏùå
            with col_mic:
                mic_audio = mic_recorder(
                    start_prompt=L["button_mic_input"],
                    stop_prompt="‚èπÔ∏è ÎÖπÏùå Ï¢ÖÎ£å",
                    just_once=False,
                    format="wav",
                    use_container_width=True,
                    key="sim_mic_recorder",
                )

            new_audio_bytes = mic_audio["bytes"] if mic_audio else None

            if new_audio_bytes is not None:
                st.session_state.sim_audio_bytes = new_audio_bytes
                st.info("‚úÖ ÎÖπÏùå ÏôÑÎ£å! ÏïÑÎûò Ï†ÑÏÇ¨ Î≤ÑÌäºÏùÑ ÎàåÎü¨ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôòÌïòÏÑ∏Ïöî.")

            if st.session_state.sim_audio_bytes:
                st.audio(st.session_state.sim_audio_bytes, format="audio/wav")

            # Ï†ÑÏÇ¨ Î≤ÑÌäº
            col_tr, _ = st.columns([1, 2])
            if col_tr.button(L["transcribe_btn"], key="sim_transcribe_btn"):
                if st.session_state.sim_audio_bytes is None:
                    st.warning("Î®ºÏ†Ä ÎßàÏù¥ÌÅ¨Î°ú ÎÖπÏùåÏùÑ ÏôÑÎ£åÌïòÏÑ∏Ïöî.")
                elif st.session_state.openai_client is None:
                    st.error(L["whisper_client_error"])
                else:
                    # üîπ Ïó¨Í∏∞ÏÑú Ïã§Ï†ú Ï†ÑÏÇ¨ ÎåÄÏÉÅ Ïò§ÎîîÏò§/Ìè¨Îß∑ÏùÑ Ï†ïÏùò
                    audio_bytes_to_transcribe = st.session_state.sim_audio_bytes
                    audio_mime_to_transcribe = "audio/wav"  # mic_recorder(format="wav") Ïù¥ÎùºÏÑú Í≥†Ï†ï

                    with st.spinner(
                            L.get("whisper_processing", "ÏùåÏÑ± ÌååÏùºÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò Ï§ë...")
                    ):
                        try:
                            transcribed_text = transcribe_bytes_with_whisper(
                                audio_bytes_to_transcribe,
                                audio_mime_to_transcribe,
                                # Ïñ∏Ïñ¥ÌÇ§Îäî ÏÑ∏ÏÖòÏóêÏÑú ÏßÅÏ†ë Í∞ÄÏ†∏Ïò§Îäî Í≤å Îçî ÏïàÏ†Ñ
                                lang_code=st.session_state.language,
                            )

                            if transcribed_text.startswith("‚ùå"):
                                st.error(transcribed_text)
                                st.session_state.last_transcript = ""
                            else:
                                # ÎßàÏßÄÎßâ Ï†ÑÏÇ¨ ÎÇ¥Ïö©Í≥º ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµÏ∞ΩÏóê ÎèôÏãúÏóê Î∞òÏòÅ
                                st.session_state.last_transcript = transcribed_text
                                st.session_state.agent_response_area_text = transcribed_text.strip()
                                st.session_state.last_transcript = transcribed_text.strip()

                                snippet = transcribed_text[:50].replace("\n", " ") + (
                                    "..." if len(transcribed_text) > 50 else ""
                                )

                                success_msg = L.get(
                                    "whisper_success",
                                    "‚úÖ ÏùåÏÑ± Ï†ÑÏÇ¨ ÏôÑÎ£å! ÌÖçÏä§Ìä∏ Ï∞ΩÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî."
                                ) + f"\n\n**Ïù∏Ïãù ÎÇ¥Ïö©:** *{snippet}*"

                                st.success(success_msg)

                        except Exception as e:
                            st.error(f"Whisper Error: {e}")

                            if transcribed_text.startswith("‚ùå"):
                                st.error(transcribed_text)
                                st.session_state.last_transcript = ""
                            else:
                                st.session_state.last_transcript = transcribed_text
                                st.session_state.agent_response_area_text = transcribed_text

                                snippet = (
                                        transcribed_text[:50].replace("\n", " ")
                                        + ("..." if len(transcribed_text) > 50 else "")
                                )

                                success_msg = (
                                        L.get("whisper_success",
                                              "‚úÖ ÏùåÏÑ± Ï†ÑÏÇ¨ ÏôÑÎ£å! ÌÖçÏä§Ìä∏ Ï∞ΩÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.")
                                        + f"\n\n**Ïù∏Ïãù ÎÇ¥Ïö©:** *{snippet}*"
                                )
                        except Exception as e:
                            st.error(f"Whisper Error: {e}")

            # ‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì
            # Ïó¨Í∏∞ÏÑúÎ∂ÄÌÑ∞Í∞Ä Î¨∏Ï†úÏòÄÎçò Î∂ÄÎ∂Ñ ‚Äî Ï†ïÎ†¨ ÏôÑÏ†Ñ ÏàòÏ†ï
            # ‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì

            col_text, col_button = st.columns([4, 1])

            with col_text:
                agent_response = st.text_area(
                    L["agent_response_placeholder"],
                    value=st.session_state.agent_response_area_text,
                    height=150,
                    key="agent_response_text_area"
                )

            with col_button:
                send_clicked = st.button(L["send_response_button"], key="send_response_btn")

            if send_clicked:
                if not agent_response.strip():
                    st.warning(L["empty_response_warning"])
                else:
                    st.session_state.last_transcript = agent_response
                    st.session_state.agent_response_area_text = ""
                    st.session_state.sim_audio_bytes = None

                    st.session_state.simulator_messages.append(
                        {"role": "agent_response", "content": agent_response}
                    )
                    st.session_state.simulator_memory.chat_memory.add_user_message(agent_response)

                    save_simulation_history_local(
                        st.session_state.customer_query_text_area,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=False,
                    )

                    # st.rerun()

        # ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµ Ïù¥ÌõÑ: Ï¢ÖÎ£å/Îã§Ïùå Î∞òÏùë
        last_role = st.session_state.simulator_messages[-1]["role"] if st.session_state.simulator_messages else None

        if last_role == "agent_response":

            st.markdown("### ü§ñ Í≥†Í∞ù Î∞òÏùë ÏÉùÏÑ±")

            if st.button(L["customer_generate_response_button"], key="btn_generate_customer"):
                next_prompt = f"""
                You are the CUSTOMER. Respond naturally to the agent's latest message.

                RULES:
                1. If the agent requested information ‚Üí provide exactly ONE missing detail.
                2. If the agent provided a solution ‚Üí respond with appreciation.
                3. Appreciation must include a positive phrase like:
                   "{L['customer_positive_response']}"
                4. After appreciation, customer MUST wait for the agent to ask:
                   "{L['customer_closing_confirm']}"
                5. Language must be {LANG[st.session_state.language]['lang_select']}.
                """

                with st.spinner(L["response_generating"]):
                    reaction = run_llm(next_prompt)

                st.session_state.simulator_messages.append(
                    {"role": "customer", "content": reaction}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                st.stop()

        if last_role == "customer":
            customer_text = st.session_state.simulator_messages[-1]["content"].strip().lower()

            appreciation_patterns = ["Í∞êÏÇ¨", "thank", "„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô", "„ÅÇ„Çä„Åå„Å®„ÅÜ", "Í∞êÏÇ¨Ìï©ÎãàÎã§"]
            closing_patterns = ["ÏóÜÏäµÎãàÎã§", "ÏóÜÏñ¥Ïöî", "ÏóÜÏñ¥", "no more", "nothing else", "ÁµêÊßã„Åß„Åô", "Â§ß‰∏àÂ§´„Åß„Åô"]

            # 1) Í≥†Í∞ùÏù¥ Í∞êÏÇ¨ Ïù∏ÏÇ¨Î•º Ìïú Í≤ΩÏö∞
            if any(p in customer_text for p in appreciation_patterns):

                st.info("Í≥†Í∞ùÏù¥ Í∞êÏÇ¨ Ïù∏ÏÇ¨Î•º ÌñàÏäµÎãàÎã§. ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï∂îÍ∞Ä Î¨∏Ïùò Ïó¨Î∂ÄÎ•º ÌôïÏù∏Ìï¥Ïïº Ìï©ÎãàÎã§.")

                if st.button(L["send_closing_confirm_button"], key="btn_send_closing_confirm"):
                    closing_msg = L["customer_closing_confirm"]

                    st.session_state.simulator_messages.append(
                        {"role": "supervisor", "content": closing_msg}
                    )
                    st.session_state.simulator_memory.chat_memory.add_ai_message(closing_msg)

                    st.success("Ï∂îÍ∞Ä Î¨∏Ïùò Ïó¨Î∂Ä ÌôïÏù∏ Î©îÏãúÏßÄÍ∞Ä Ï†ÑÏÜ°ÎêòÏóàÏäµÎãàÎã§. Í≥†Í∞ùÏùò ÏùëÎãµÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§...")

                    st.session_state.trigger_customer_reaction = True

                if st.session_state.get("sim_next_rebuttal", False):
                    st.session_state.sim_next_rebuttal = False

            # 2) Í≥†Í∞ùÏù¥ ‚ÄúÏ∂îÍ∞Ä Î¨∏Ïùò ÏóÜÏùå‚ÄùÏùÑ ÌëúÌòÑÌïú Í≤ΩÏö∞
            elif any(p in customer_text for p in closing_patterns):

                st.success("Í≥†Í∞ùÏù¥ Îçî Ïù¥ÏÉÅ Î¨∏ÏùòÍ∞Ä ÏóÜÎã§Í≥† ÎßêÌñàÏäµÎãàÎã§.")

                end_msg = L["prompt_survey"]
                st.session_state.simulator_messages.append({"role": "system_end", "content": end_msg})
                st.session_state.is_chat_ended = True

                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.simulator_messages,
                    is_chat_ended=True,
                )

                st.info("üìå ÏÉÅÎã¥ Ï¢ÖÎ£å Îã®Í≥ÑÏûÖÎãàÎã§. ÏÑ§Î¨∏Ï°∞ÏÇ¨ Î©îÏãúÏßÄÎ•º Ï†ÑÏÜ°Ìï† Ïàò ÏûàÏäµÎãàÎã§.")
                st.stop()

            # 3) Í∑∏ Ïô∏Ïùò Í≤ΩÏö∞ ‚Üí ÏùºÎ∞òÏ†ÅÏù∏ Ï∂îÍ∞Ä ÏßàÎ¨∏
            else:
                pass  # ÏóêÏù¥Ï†ÑÌä∏ ÏùëÎãµ UI Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÎê®

        if last_role == "agent_response":
            col_end, col_next = st.columns([1, 2])

            if col_end.button(L["button_end_chat"], key="sim_end_chat_btn"):
                # ÏÑ§Î¨∏ Ï°∞ÏÇ¨ Î©îÏãúÏßÄ Ï†ÑÏÜ°
                survey_msg = L["prompt_survey"]

                st.session_state.simulator_messages.append(
                    {"role": "system_end", "content": survey_msg}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(survey_msg)

                # ÏÉÅÎã¥ Ï¢ÖÎ£å ÏÉÅÌÉú Ï†ÄÏû•
                st.session_state.is_chat_ended = True

                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.simulator_messages,
                    is_chat_ended=True,
                )

                # UI ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî
                st.success(L["survey_sent_confirm"])  # ÏïÑÎûòÏóêÏÑú Ï∂îÍ∞ÄÌï¥Ï§Ñ Lang Î¨∏ÏûêÏó¥
                st.session_state.simulation_finished = True

                st.rerun()

                if st.session_state.get("simulation_finished", False):
                    st.session_state.simulation_finished = False

                    # Î™®Îì† ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî
                    st.session_state.simulator_messages = []
                    st.session_state.agent_response_area_text = ""
                    st.session_state.customer_query_text_area = ""
                    st.session_state.initial_advice_provided = False
                    st.session_state.is_chat_ended = False

                    st.success(L["new_simulation_ready"])

                if col_next.button(L["request_rebuttal_button"], key="sim_next_rebuttal_btn"):
                    next_prompt = """ ... (LLMÏóêÍ≤å customer role ÏöîÏ≤≠) ... """

                    with st.spinner(L["response_generating"]):
                        reaction = st.session_state.simulator_chain.predict(input=next_prompt)

                    st.session_state.simulator_messages.append(
                        {"role": "customer_rebuttal", "content": reaction}
                    )
                    st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                    save_simulation_history_local(
                        st.session_state.customer_query_text_area,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=False,
                    )

                    st.stop()

                if not st.session_state.is_llm_ready or not LLM_API_KEY:
                    st.warning("API KeyÍ∞Ä ÏóÜÏñ¥ ÎåÄÌôîÌòï ÏãúÎÆ¨Î†àÏù¥ÏÖòÏùÄ Î∂àÍ∞ÄÎä•Ìï©ÎãàÎã§.")
                    st.stop()

                # -----------------------------
                # 1) supervisor ‚Üí customer Ïó≠Ìï†Î°ú Î≥ÄÌôò (LLM)
                # -----------------------------
                next_prompt = f"""
            You are now ROLEPLAYING as the CUSTOMER.

            Analyze the dialogue so far and respond naturally.

            RULES:
            1. If the agent requested information ‚Üí provide EXACTLY ONE missing detail.
            2. If the agent provided a solution ‚Üí respond with appreciation.
            3. If appreciation is given ‚Üí ALWAYS respond with:
               "{L['customer_closing_confirm']}"
            4. If the agent already asked:
               "{L['customer_closing_confirm']}"
               AND the customer has no further questions:
               ‚Üí Respond with "{L['customer_positive_response']}"
               ‚Üí THEN the chat MUST END.
            5. Language MUST be {LANG[st.session_state.language]['lang_select']}.
                """


                # LLM Ïã§Ìñâ
                with st.spinner(L["response_generating"]):
                    reaction = st.session_state.simulator_chain.predict(input=next_prompt)

                reaction_lower = reaction.lower()

                # Ìå®ÌÑ¥ Ï†ïÏùò
                closing_user_signals = [
                    "ÏóÜÏäµÎãàÎã§", "ÏóÜÏñ¥Ïöî", "ÏóÜÏñ¥",
                    "no more", "nothing else",
                    "ÁµêÊßã„Åß„Åô", "Â§ß‰∏àÂ§´„Åß„Åô"
                ]

                appreciation_signals = [
                    "Í∞êÏÇ¨", "thank", "„ÅÇ„Çä„Åå„Å®„ÅÜ"
                ]

                # -----------------------------
                # 2) Í≥†Í∞ùÏù¥ "Ï¢ÖÎ£å ÏùòÏÇ¨" Ï†ÑÎã¨
                # -----------------------------
                if any(k in reaction_lower for k in closing_user_signals):
                    st.session_state.simulator_messages.append(
                        {"role": "customer_end", "content": reaction}
                    )
                    st.session_state.simulator_messages.append(
                        {"role": "system_end", "content": L["prompt_survey"]}
                    )

                    st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)
                    st.session_state.simulator_memory.chat_memory.add_ai_message(L["prompt_survey"])

                    st.session_state.is_chat_ended = True

                    save_simulation_history_local(
                        st.session_state.customer_query_text_area,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=True,
                    )
                    st.stop()

                # -----------------------------
                # 3) Í≥†Í∞ùÏù¥ Í∞êÏÇ¨ Î©îÏãúÏßÄ Î≥¥ÎÇ¥Ïò¥ ‚Üí supervisorÍ∞Ä closing ÏßàÎ¨∏ ÏûêÎèô Î∞úÏÜ°
                # -----------------------------
                # if any(k in reaction_lower for k in appreciation_signals):
                #     # Í≥†Í∞ù Í∞êÏÇ¨ Î©îÏãúÏßÄ
                #     st.session_state.simulator_messages.append(
                #         {"role": "customer_rebuttal", "content": reaction}
                #     )
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)
                #
                #     follow_up = L["customer_closing_confirm"]
                #
                #     # supervisorÍ∞Ä Ï∂îÍ∞Ä Î¨∏Ïùò Ïó¨Î∂Ä ÏßàÎ¨∏
                #     st.session_state.simulator_messages.append(
                #         {"role": "supervisor", "content": follow_up}
                #     )
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(follow_up)
                #
                #     save_simulation_history_local(
                #         st.session_state.customer_query_text_area,
                #         customer_type_display,
                #         st.session_state.simulator_messages,
                #         is_chat_ended=False,
                #     )
                #     st.stop()

                # -----------------------------
                # 4) Í∏∞ÌÉÄ ÏùºÎ∞ò Î∞òÏùë
                # -----------------------------
                st.session_state.simulator_messages.append(
                    {"role": "customer_rebuttal", "content": reaction}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.simulator_messages,
                    is_chat_ended=False,
                )
                st.stop()

                # 2) Í≥†Í∞ùÏù¥ Í∞êÏÇ¨ Ïù∏ÏÇ¨ ‚Üí Î∞òÎìúÏãú ‚ÄúÏ∂îÍ∞Ä Î¨∏Ïùò Ïó¨Î∂Ä‚Äù ÌôïÏù∏ Î©îÏãúÏßÄ Î∞úÏÜ°
                # if any(k in reaction_lower for k in appreciation_signals):
                #     follow_up = L["customer_closing_confirm"]
                #
                #     st.session_state.simulator_messages.append(
                #         {"role": "customer_rebuttal", "content": reaction}
                #     )
                #     st.session_state.simulator_messages.append(
                #         {"role": "supervisor", "content": follow_up}
                #     )
                #
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(follow_up)
                #
                #     save_simulation_history_local(
                #         st.session_state.customer_query_text_area,
                #         customer_type_display,
                #         st.session_state.simulator_messages,
                #         is_chat_ended=False,
                #     )
                #     st.stop()

                # 3) Í∑∏ Ïô∏ ÏùºÎ∞òÏ†Å Î∞òÏùë
                st.session_state.simulator_messages.append(
                    {"role": "customer_rebuttal", "content": reaction}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.simulator_messages,
                    is_chat_ended=False,
                )

                if is_positive:
                            st.session_state.is_chat_ended = True
                        # st.rerun()

# -------------------- RAG Tab --------------------
elif feature_selection == L["rag_tab"]:
    st.header(L["rag_header"])
    st.markdown(L["rag_desc"])

    if not st.session_state.is_rag_ready or st.session_state.rag_vectorstore is None:
        # Ïù¥ÎØ∏ Ï†ÄÏû•Îêú Ïù∏Îç±Ïä§Í∞Ä ÏûàÏúºÎ©¥ Î°úÎìú ÏãúÎèÑ
        if st.session_state.is_llm_ready:
            vs = load_rag_index(st.session_state.embeddings)
            if vs is not None:
                st.session_state.rag_vectorstore = vs
                st.session_state.is_rag_ready = True
            else:
                st.info(L["warning_rag_not_ready"])
        else:
            st.info(L["warning_rag_not_ready"])

    if st.session_state.is_rag_ready and st.session_state.rag_vectorstore is not None:
        # Í∏∞Ï°¥ ÎåÄÌôî Î°úÍ∑∏ ÌëúÏãú
        for m in st.session_state.rag_messages:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        user_q = st.chat_input(L["rag_input_placeholder"])
        if user_q:
            st.session_state.rag_messages.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)
            with st.chat_message("assistant"):
                with st.spinner(L["response_generating"]):
                    try:
                        ans = rag_answer(user_q, st.session_state.rag_vectorstore, st.session_state.language)
                        st.markdown(ans)
                        st.session_state.rag_messages.append({"role": "assistant", "content": ans})
                    except Exception as e:
                        st.error(f"Ï±óÎ¥á Ïò§Î•ò: {e}")
                        msg = "Ïò§Î•ò Î∞úÏÉù" if st.session_state.language == "ko" else "An error occurred"
                        st.session_state.rag_messages.append({"role": "assistant", "content": msg})
    else:
        st.warning(L["warning_rag_not_ready"])

# -------------------- Content Tab --------------------
elif feature_selection == L["content_tab"]:
    st.header(L["content_header"])
    st.markdown(L["content_desc"])

    if not st.session_state.is_llm_ready:
        st.error(L["llm_error_init"])
    else:
        topic = st.text_input(L["topic_label"])
        level_display = st.selectbox(L["level_label"], L["level_options"])
        content_display = st.selectbox(L["content_type_label"], L["content_options"])

        level_map = {
            "Ï¥àÍ∏â": "Beginner",
            "Ï§ëÍ∏â": "Intermediate",
            "Í≥†Í∏â": "Advanced",
            "Beginner": "Beginner",
            "Intermediate": "Intermediate",
            "Advanced": "Advanced",
            "ÂàùÁ¥ö": "Beginner",
            "‰∏≠Á¥ö": "Intermediate",
            "‰∏äÁ¥ö": "Advanced",
        }
        content_map = {
            "ÌïµÏã¨ ÏöîÏïΩ ÎÖ∏Ìä∏": "summary",
            "Í∞ùÍ¥ÄÏãù ÌÄ¥Ï¶à 10Î¨∏Ìï≠": "quiz",
            "Ïã§Ïäµ ÏòàÏ†ú ÏïÑÏù¥ÎîîÏñ¥": "example",
            "Key Summary Note": "summary",
            "10 Multiple-Choice Questions": "quiz",
            "Practical Example Idea": "example",
            "Ê†∏ÂøÉË¶ÅÁ¥Ñ„Éé„Éº„Éà": "summary",
            "ÈÅ∏ÊäûÂºè„ÇØ„Ç§„Ç∫10Âïè": "quiz",
            "ÂÆüË∑µ‰æã„ÅÆ„Ç¢„Ç§„Éá„Ç¢": "example",
        }

        level = level_map.get(level_display, "Beginner")
        content_type = content_map.get(content_display, "summary")

        if st.button(L["button_generate"]):
            if not topic.strip():
                st.warning(L["warning_topic"])
            else:
                target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]

                if content_type == "quiz":
                    system_prompt = (
                        "You are an expert quiz creator.\n"
                        "Generate EXACTLY 10 multiple-choice questions.\n"
                        "Return ONLY valid JSON wrapped inside ```json ... ```.\n"
                        "JSON structure:\n"
                        "{\n"
                        '  \"quiz_questions\": [\n'
                        "    {\n"
                        '      \"question\": \"...\",\n'
                        '      \"options\": [\"A\", \"B\", \"C\", \"D\"],\n'
                        '      \"correct_index\": 0,\n'
                        '      \"explanation\": \"...\"\n'
                        "    }\n"
                        "  ]\n"
                        "}\n"
                        f"The language of questions MUST be {target_lang}.\n"
                    )
                    user_msg = f"Topic: {topic} (level: {level})"
                    with st.spinner("ÌÄ¥Ï¶à ÏÉùÏÑ± Ï§ë..."):
                        try:
                            resp = st.session_state.llm.invoke(system_prompt + "\n\n" + user_msg)
                            raw = resp.content if hasattr(resp, "content") else str(resp)
                            # Îã®Ïàú Ï∂úÎ†•
                            st.success(f"**{topic}** - {content_display}")
                            st.code(raw, language="json")
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")
                else:
                    content_prompt = (
                        f"You are a professional AI coach at the {level} level.\n"
                        f"Generate clear and educational content in {target_lang}.\n"
                        f"Content type: {content_display}.\n"
                        f"Topic: {topic}\n"
                    )
                    with st.spinner("ÏΩòÌÖêÏ∏† ÏÉùÏÑ± Ï§ë..."):
                        try:
                            resp = st.session_state.llm.invoke(content_prompt)
                            txt = resp.content if hasattr(resp, "content") else str(resp)
                            st.success(f"**{topic}** - {content_display}")
                            st.markdown(txt)
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")

# -------------------- LSTM Tab --------------------
elif feature_selection == L["lstm_tab"]:
    st.header(L["lstm_header"])
    st.markdown(L["lstm_desc"])

    if st.button(L["lstm_rerun_button"]):
        st.rerun()

    try:
        data = load_or_train_lstm()
        predicted_score = float(np.clip(data[-1] + np.random.uniform(-3, 5), 50, 100))

        st.markdown("---")
        st.subheader(L["lstm_result_header"])

        col_score, col_chart = st.columns([1, 2])

        with col_score:
            suffix = "Ï†ê" if st.session_state.language == "ko" else ""
            st.metric(L["lstm_score_metric"], f"{predicted_score:.1f}{suffix}")
            st.info(L["lstm_score_info"].format(predicted_score=predicted_score))

        with col_chart:
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(data, label="Past Scores", marker="o")
            ax.plot(len(data), predicted_score, marker="*", markersize=10)
            ax.set_title(L["lstm_header"])
            ax.set_xlabel("Time (attempts)")
            ax.set_ylabel("Score (0-100)")
            ax.legend()
            st.pyplot(fig)
    except Exception as e:
        st.info(f"LSTM Í∏∞Îä• ÏóêÎü¨: {e}")
