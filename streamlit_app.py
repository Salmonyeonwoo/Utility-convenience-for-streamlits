# ========================================
# streamlit_app_last_correction.py
# ë¡œì»¬ ì „ìš©: RAG + ì‹œë®¬ë ˆì´í„° + ìŒì„± ê¸°ë¡ + LSTM + ì½˜í…ì¸ 
# Firebase/GCS ì œê±°, local_db(JSON/íŒŒì¼)ë§Œ ì‚¬ìš©
# Python 3.9 / langchain>=1.0 / streamlit-mic-recorder 0.0.8 ê¸°ì¤€
# ========================================

import os
import io
import json
import time
import uuid
import base64
import tempfile
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any

import numpy as np
import streamlit as st
from matplotlib import pyplot as plt

from openai import OpenAI

# mic_recorder (0.0.8) - returns dict with key "bytes"
from streamlit_mic_recorder import mic_recorder

# LangChain / RAG ê´€ë ¨
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, TextLoader

# ========================================
# 0. ê¸°ë³¸ ê²½ë¡œ/ë¡œì»¬ DB ì„¤ì •
# ========================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "local_db")
AUDIO_DIR = os.path.join(DATA_DIR, "audio")
RAG_INDEX_DIR = os.path.join(DATA_DIR, "rag_index")

VOICE_META_FILE = os.path.join(DATA_DIR, "voice_records.json")
SIM_META_FILE = os.path.join(DATA_DIR, "simulation_histories.json")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(RAG_INDEX_DIR, exist_ok=True)

# ----------------------------------------
# JSON Helper
# ----------------------------------------
def _load_json(path: str, default: Any):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return default


def _save_json(path: str, data: Any):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# ========================================
# 1. ë‹¤êµ­ì–´ ì„¤ì •
# ========================================
DEFAULT_LANG = "ko"

LANG: Dict[str, Dict[str, str]] = {
    "ko": {
        "title": "ê°œì¸ ë§ì¶¤í˜• AI í•™ìŠµ ì½”ì¹˜ (ìŒì„± ë° DB í†µí•©)",
        "sidebar_title": "ğŸ“š AI Study Coach ì„¤ì •",
        "file_uploader": "í•™ìŠµ ìë£Œ ì—…ë¡œë“œ (PDF, TXT, HTML)",
        "button_start_analysis": "ìë£Œ ë¶„ì„ ì‹œì‘ (RAG Indexing)",
        "rag_tab": "RAG ì§€ì‹ ì±—ë´‡",
        "content_tab": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "lstm_tab": "LSTM ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "simulator_tab": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°",
        "rag_header": "RAG ì§€ì‹ ì±—ë´‡ (ë¬¸ì„œ ê¸°ë°˜ Q&A)",
        "rag_desc": "ì—…ë¡œë“œëœ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ã€‚",
        "rag_input_placeholder": "í•™ìŠµ ìë£Œì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”",
        "llm_error_key": "âš ï¸ ê²½ê³ : GEMINI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì— 'GEMINI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”ã€‚",
        "llm_error_init": "LLM ì´ˆê¸°í™” ì˜¤ë¥˜: API í‚¤ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”ã€‚",
        "content_header": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "content_desc": "í•™ìŠµ ì£¼ì œì™€ ë‚œì´ë„ì— ë§ì¶° ì½˜í…ì¸  ìƒì„±",
        "topic_label": "í•™ìŠµ ì£¼ì œ",
        "level_label": "ë‚œì´ë„",
        "content_type_label": "ì½˜í…ì¸  í˜•ì‹",
        "level_options": ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"],
        "content_options": ["í•µì‹¬ ìš”ì•½ ë…¸íŠ¸", "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­", "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´"],
        "button_generate": "ì½˜í…ì¸  ìƒì„±",
        "warning_topic": "í•™ìŠµ ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚",
        "lstm_header": "LSTM ê¸°ë°˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "lstm_desc": "ê°€ìƒì˜ ê³¼ê±° í€´ì¦ˆ ì ìˆ˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ LSTM ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë¯¸ë˜ ì„±ì·¨ë„ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤ã€‚",
        "lang_select": "ì–¸ì–´ ì„ íƒ",
        "embed_success": "ì´ {count}ê°œ ì²­í¬ë¡œ í•™ìŠµ DB êµ¬ì¶• ì™„ë£Œ!",
        "embed_fail": "ì„ë² ë”© ì‹¤íŒ¨: ë¬´ë£Œ í‹°ì–´ í•œë„ ì´ˆê³¼ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œã€‚",
        "warning_no_files": "ë¨¼ì € í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
        "warning_rag_not_ready": "RAGê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•˜ì„¸ìš”ã€‚",
        "quiz_fail_structure": "í€´ì¦ˆ ë°ì´í„° êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚",
        "select_answer": "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”",
        "check_answer": "ì •ë‹µ í™•ì¸",
        "next_question": "ë‹¤ìŒ ë¬¸í•­",
        "correct_answer": "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰",
        "incorrect_answer": "ì˜¤ë‹µì…ë‹ˆë‹¤. ğŸ˜",
        "correct_is": "ì •ë‹µ",
        "explanation": "í•´ì„¤",
        "quiz_complete": "í€´ì¦ˆ ì™„ë£Œ!",
        "score": "ì ìˆ˜",
        "retake_quiz": "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°",
        "quiz_error_llm": "í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: LLMì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ã€‚",
        "quiz_original_response": "LLM ì›ë³¸ ì‘ë‹µ",
        "firestore_loading": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...",
        "firestore_no_index": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ RAG ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìƒˆë¡œ ë§Œë“œì„¸ìš”ã€‚",
        "db_save_complete": "(DB ì €ì¥ ì™„ë£Œ)",
        "data_analysis_progress": "ìë£Œ ë¶„ì„ ë° í•™ìŠµ DB êµ¬ì¶• ì¤‘...",
        "response_generating": "ë‹µë³€ ìƒì„± ì¤‘...",
        "lstm_result_header": "í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ ê²°ê³¼",
        "lstm_score_metric": "í˜„ì¬ ì˜ˆì¸¡ ì„±ì·¨ë„",
        "lstm_score_info": "ë‹¤ìŒ í€´ì¦ˆ ì˜ˆìƒ ì ìˆ˜ëŠ” ì•½ **{predicted_score:.1f}ì **ì…ë‹ˆë‹¤. í•™ìŠµ ì„±ê³¼ë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ê°œì„ í•˜ì„¸ìš”!",
        "lstm_rerun_button": "ìƒˆë¡œìš´ ê°€ìƒ ë°ì´í„°ë¡œ ì˜ˆì¸¡",

        # --- ì‹œë®¬ë ˆì´í„° ---
        "simulator_header": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°",
        "simulator_desc": "ê¹Œë‹¤ë¡œìš´ ê³ ê° ë¬¸ì˜ì— AIì˜ ì‘ëŒ€ ì´ˆì•ˆ ë° ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤ã€‚",
        "customer_query_label": "ê³ ê° ë¬¸ì˜ ë‚´ìš© (ë§í¬ í¬í•¨ ê°€ëŠ¥)",
        "customer_type_label": "ê³ ê° ì„±í–¥",
        "customer_type_options": ["ì¼ë°˜ì ì¸ ë¬¸ì˜", "ê¹Œë‹¤ë¡œìš´ ê³ ê°", "ë§¤ìš° ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ìš´ ê³ ê°"],
        "button_simulate": "ì‘ëŒ€ ì¡°ì–¸ ìš”ì²­",
        "customer_generate_response_button": "ê³ ê° ë°˜ì‘ ìƒì„±",
        "send_closing_confirm_button": "ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸°",
        "simulation_warning_query": "ê³ ê° ë¬¸ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚",
        "simulation_no_key_warning": "âš ï¸ API Keyê°€ ì—†ê¸° ë•Œë¬¸ì— ì‘ë‹µ ìƒì„±ì€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚",
        "simulation_advice_header": "AIì˜ ì‘ëŒ€ ê°€ì´ë“œë¼ì¸",
        "simulation_draft_header": "ì¶”ì²œ ì‘ëŒ€ ì´ˆì•ˆ",
        "button_listen_audio": "ìŒì„±ìœ¼ë¡œ ë“£ê¸°",
        "tts_status_ready": "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨",
        "tts_status_generating": "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...",
        "tts_status_success": "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!",
        "tts_status_error": "âŒ TTS ì˜¤ë¥˜ ë°œìƒ",
        "history_expander_title": "ğŸ“ ì´ì „ ìƒë‹´ ì´ë ¥ ë¡œë“œ (ìµœê·¼ 10ê°œ)",
        "initial_query_sample": "í”„ë‘ìŠ¤ íŒŒë¦¬ì— ë„ì°©í–ˆëŠ”ë°, í´ë£©ì—ì„œ êµ¬ë§¤í•œ eSIMì´ í™œì„±í™”ê°€ ì•ˆ ë©ë‹ˆë‹¤...",
        "button_mic_input": "ğŸ™ ìŒì„± ì…ë ¥",
        "prompt_customer_end": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ì„ ì¢…ë£Œí•©ë‹ˆë‹¤ã€‚",
        "prompt_survey": "ë¬¸ì˜í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ì£¼ì„¸ìš”ã€‚",
        "customer_closing_confirm": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
        "customer_positive_response": "ì¹œì ˆí•œ ìƒë‹´ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤ã€‚",
        "button_end_chat": "ì‘ëŒ€ ì¢…ë£Œ (ì„¤ë¬¸ ìš”ì²­)",
        "agent_response_header": "âœï¸ ì—ì´ì „íŠ¸ ì‘ë‹µ",
        "agent_response_placeholder": "ê³ ê°ì—ê²Œ ì‘ë‹µí•˜ì„¸ìš”...",
        "send_response_button": "ì‘ë‹µ ì „ì†¡",
        "request_rebuttal_button": "ê³ ê°ì˜ ë‹¤ìŒ ë°˜ì‘ ìš”ì²­",
        "new_simulation_button": "ìƒˆ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘",
        "history_selectbox_label": "ë¡œë“œí•  ì´ë ¥ì„ ì„ íƒí•˜ì„¸ìš”:",
        "history_load_button": "ì„ íƒëœ ì´ë ¥ ë¡œë“œ",
        "delete_history_button": "âŒ ëª¨ë“  ì´ë ¥ ì‚­ì œ",
        "delete_confirm_message": "ì •ë§ë¡œ ëª¨ë“  ìƒë‹´ ì´ë ¥ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "delete_confirm_yes": "ì˜ˆ, ì‚­ì œí•©ë‹ˆë‹¤",
        "delete_confirm_no": "ì•„ë‹ˆì˜¤, ìœ ì§€í•©ë‹ˆë‹¤",
        "delete_success": "âœ… ì‚­ì œ ì™„ë£Œ!",
        "deleting_history_progress": "ì´ë ¥ ì‚­ì œ ì¤‘...",
        "search_history_label": "ì´ë ¥ ê²€ìƒ‰",
        "date_range_label": "ë‚ ì§œ ë²”ìœ„ í•„í„°",
        "no_history_found": "ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "customer_email_label": "ê³ ê° ì´ë©”ì¼ (ì„ íƒ)",
        "customer_phone_label": "ê³ ê° ì—°ë½ì²˜ / ì „í™”ë²ˆí˜¸ (ì„ íƒ)",

        # --- ìŒì„± ê¸°ë¡ ---
        "voice_rec_header": "ìŒì„± ê¸°ë¡ & ê´€ë¦¬",
        "record_help": "ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒí•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
        "uploaded_file": "ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ",
        "rec_list_title": "ì €ì¥ëœ ìŒì„± ê¸°ë¡",
        "transcribe_btn": "ì „ì‚¬(Whisper)",
        "save_btn": "ìŒì„± ê¸°ë¡ ì €ì¥",
        "transcribing": "ìŒì„± ì „ì‚¬ ì¤‘...",
        "transcript_result": "ì „ì‚¬ ê²°ê³¼:",
        "transcript_text": "ì „ì‚¬ í…ìŠ¤íŠ¸",
        "openai_missing": "OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤.",
        "whisper_client_error": "âŒ Whisper API Client ì´ˆê¸°í™” ì‹¤íŒ¨",
        "whisper_auth_error": "âŒ Whisper API ì¸ì¦ ì‹¤íŒ¨",
        "whisper_format_error": "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤ã€‚",
        "whisper_success": "âœ… ìŒì„± ì „ì‚¬ ì™„ë£Œ!",
        "playback": "ë…¹ìŒ ì¬ìƒ",
        "retranscribe": "ì¬ì „ì‚¬",
        "delete": "ì‚­ì œ",
        "no_records": "ì €ì¥ëœ ìŒì„± ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "saved_success": "ì €ì¥ ì™„ë£Œ!",
        "delete_confirm_rec": "ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "gcs_not_conf": "GCS ë¯¸ì„¤ì •",
        "gcs_playback_fail": "ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨",
        "gcs_no_audio": "ì˜¤ë””ì˜¤ ì—†ìŒ",
        "error": "ì˜¤ë¥˜:",
        "firestore_no_db_connect": "DB ì—°ê²° ì‹¤íŒ¨",
        "save_history_success": "ìƒë‹´ ì´ë ¥ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ã€‚",
        "save_history_fail": "ìƒë‹´ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨",
        "delete_fail": "ì‚­ì œ ì‹¤íŒ¨",
        "rec_header": "ìŒì„± ì…ë ¥ ë° ì „ì‚¬",
        "whisper_processing": "ìŒì„± ì „ì‚¬ ì²˜ë¦¬ ì¤‘",
        "empty_response_warning": "ì‘ë‹µì„ ì…ë ¥í•˜ì„¸ìš”ã€‚",
    },

    # --- â­ ì˜ì–´ ë²„ì „ (í•œêµ­ì–´ 100% ë§¤ì¹­) ---
    "en": {
        "title": "Personalized AI Study Coach (Voice & Local DB)",
        "sidebar_title": "ğŸ“š AI Study Coach Settings",
        "file_uploader": "Upload Study Materials (PDF, TXT, HTML)",
        "button_start_analysis": "Start Analysis (RAG Indexing)",
        "rag_tab": "RAG Knowledge Chatbot",
        "content_tab": "Custom Content Generation",
        "lstm_tab": "LSTM Achievement Prediction Dashboard",
        "simulator_tab": "AI Customer Response Simulator",
        "rag_header": "RAG Knowledge Chatbot (Document Q&A)",
        "rag_desc": "Answer questions based on uploaded documents.",
        "rag_input_placeholder": "Ask a question about your study materials",
        "llm_error_key": "âš ï¸ Warning: GEMINI_API_KEY is not set.",
        "llm_error_init": "LLM initialization error. Please check your API key.",
        "content_header": "Custom Learning Content Generation",
        "content_desc": "Generate content based on the topic and difficulty.",
        "topic_label": "Learning Topic",
        "level_label": "Difficulty",
        "content_type_label": "Content Type",
        "level_options": ["Beginner", "Intermediate", "Advanced"],
        "content_options": ["Key Summary Note", "10 MCQ Questions", "Practical Example Idea"],
        "button_generate": "Generate Content",
        "warning_topic": "Please enter a learning topic.",
        "lstm_header": "LSTM Achievement Prediction Dashboard",
        "lstm_desc": "Train an LSTM model on hypothetical quiz scores and predict performance.",
        "lang_select": "Select Language",
        "embed_success": "Learning DB built with {count} chunks!",
        "embed_fail": "Embedding failed: quota exceeded or network issue.",
        "warning_no_files": "Please upload study materials first.",
        "warning_rag_not_ready": "RAG is not ready. Upload materials and analyze.",
        "quiz_fail_structure": "Quiz data structure is invalid.",
        "select_answer": "Select answer",
        "check_answer": "Check answer",
        "next_question": "Next question",
        "correct_answer": "Correct! ğŸ‰",
        "incorrect_answer": "Incorrect ğŸ˜",
        "correct_is": "Correct answer",
        "explanation": "Explanation",
        "quiz_complete": "Quiz Complete!",
        "score": "Score",
        "retake_quiz": "Retake Quiz",
        "quiz_error_llm": "Quiz generation failed: invalid JSON.",
        "quiz_original_response": "Original LLM Response",
        "firestore_loading": "Loading RAG index...",
        "firestore_no_index": "No existing RAG index found.",
        "db_save_complete": "(DB Save Complete)",
        "data_analysis_progress": "Analyzing materials and building DB...",
        "response_generating": "Generating response...",
        "lstm_result_header": "Achievement Prediction",
        "lstm_score_metric": "Predicted Achievement",
        "lstm_score_info": "Estimated next quiz score: **{predicted_score:.1f}**.",
        "lstm_rerun_button": "Predict with New Data",

        # Simulator
        "simulator_header": "AI Customer Response Simulator",
        "simulator_desc": "AI generates draft responses and guidelines for customer inquiries.",
        "customer_query_label": "Customer Message (links allowed)",
        "customer_type_label": "Customer Type",
        "customer_type_options": ["General Inquiry", "Difficult Customer", "Highly Dissatisfied Customer"],
        "button_simulate": "Generate Response",
        "customer_generate_response_button": "Generate Customer Response",
        "send_closing_confirm_button": "Send Closing Confirmation",
        "simulation_warning_query": "Please enter the customerâ€™s message.",
        "simulation_no_key_warning": "âš ï¸ API Key missing. Simulation cannot proceed.",
        "simulation_advice_header": "AI Response Guidelines",
        "simulation_draft_header": "Recommended Response Draft",
        "button_listen_audio": "Play as Audio",
        "tts_status_ready": "Ready to generate audio",
        "tts_status_generating": "Generating audio...",
        "tts_status_success": "Audio ready!",
        "tts_status_error": "TTS error occurred",
        "history_expander_title": "ğŸ“ Load Previous Sessions (Last 10)",
        "initial_query_sample": "I arrived in Paris but my Klook eSIM won't activateâ€¦",
        "button_mic_input": "ğŸ™ Voice Input",
        "prompt_customer_end": "No further inquiries. Ending chat.",
        "prompt_survey": "Thank you for contacting support.",
        "customer_closing_confirm": "Anything else I can help you with?",
        "customer_positive_response": "Thank you for your kind support.",
        "button_end_chat": "End Chat (Survey Request)",
        "agent_response_header": "âœï¸ Agent Response",
        "agent_response_placeholder": "Write a response...",
        "send_response_button": "Send Response",
        "request_rebuttal_button": "Request Customer Reaction",
        "new_simulation_button": "Start New Simulation",
        "history_selectbox_label": "Choose a record to load:",
        "history_load_button": "Load Selected Record",
        "delete_history_button": "âŒ Delete All History",
        "delete_confirm_message": "Are you sure you want to delete all records?",
        "delete_confirm_yes": "Yes, Delete",
        "delete_confirm_no": "Cancel",
        "delete_success": "Deleted successfully!",
        "deleting_history_progress": "Deleting history...",
        "search_history_label": "Search History",
        "date_range_label": "Date Filter",
        "no_history_found": "No matching history found.",
        "customer_email_label": "Customer Email (optional)",
        "customer_phone_label": "Customer Phone / WhatsApp (optional)",

        # Voice
        "voice_rec_header": "Voice Record & Management",
        "record_help": "Record using the microphone or upload a file.",
        "uploaded_file": "Upload Audio File",
        "rec_list_title": "Saved Voice Records",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Record",
        "transcribing": "Transcribing...",
        "transcript_result": "Transcription:",
        "transcript_text": "Transcribed Text",
        "openai_missing": "Missing OPENAI_API_KEY",
        "whisper_client_error": "Whisper client initialization failed.",
        "whisper_auth_error": "Whisper authentication failed.",
        "whisper_format_error": "Unsupported audio format.",
        "whisper_success": "Transcription complete!",
        "playback": "Play Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Voice Record",
        "transcribing": "Transcribing voice...",
        "transcript_result": "Transcription Result:",
        "transcript_text": "Transcribed Text",
        "whisper_processing": "Processing voice transcription...",
        "whisper_success": "âœ… Transcription complete! Please check the text below.",
        "openai_missing": "OpenAI API Key is missing. Please set OPENAI_API_KEY.",
        "whisper_client_error": "âŒ Error: Whisper API client not initialized.",
        "whisper_auth_error": "âŒ Whisper API authentication failed. Check your API Key.",
        "whisper_format_error": "âŒ Error: Unsupported audio format.",
        "playback": "Playback Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "no_records": "No saved voice records.",
        "saved_success": "Saved successfully!",
        "delete_confirm_rec": "Are you sure you want to delete this voice record?",
        "gcs_not_conf": "GCS not configured or no audio available",
        "gcs_playback_fail": "Failed to play audio",
        "gcs_no_audio": "No audio file found",
        "error": "Error:",
        "firestore_no_db_connect": "DB connection failed",
        "save_history_success": "Saved successfully.",
        "save_history_fail": "Save failed.",
        "delete_fail": "Delete failed",
        "rec_header": "Voice Input & Transcription",
        "whisper_processing": "Processing...",
        "empty_response_warning": "Please enter a response."
    },

    # --- â­ ì¼ë³¸ì–´ ë²„ì „ (í•œêµ­ì–´ 100% ë§¤ì¹­) ---
    "ja": {
        "title": "ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºAIå­¦ç¿’ã‚³ãƒ¼ãƒ (éŸ³å£°ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«DB)",
        "sidebar_title": "ğŸ“š AIå­¦ç¿’ã‚³ãƒ¼ãƒè¨­å®š",
        "file_uploader": "å­¦ç¿’è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PDF, TXT, HTML)",
        "button_start_analysis": "è³‡æ–™åˆ†æé–‹å§‹ (RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ)",
        "rag_tab": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
        "content_tab": "ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "lstm_tab": "LSTMé”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "simulator_tab": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
        "rag_header": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆQ&A)",
        "rag_desc": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè³‡æ–™ã«åŸºã¥ã„ã¦è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚",
        "rag_input_placeholder": "è³‡æ–™ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
        "llm_error_key": "âš ï¸ æ³¨æ„: GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "llm_error_init": "LLM åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ï¼šAPIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        "content_header": "ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "content_desc": "å­¦ç¿’ãƒ†ãƒ¼ãƒã¨é›£æ˜“åº¦ã«å¿œã˜ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "topic_label": "å­¦ç¿’ãƒ†ãƒ¼ãƒ",
        "level_label": "é›£æ˜“åº¦",
        "content_type_label": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç¨®é¡",
        "level_options": ["åˆç´š", "ä¸­ç´š", "ä¸Šç´š"],
        "content_options": ["è¦ç‚¹ã‚µãƒãƒªãƒ¼", "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•", "å®Ÿè·µä¾‹ã‚¢ã‚¤ãƒ‡ã‚¢"],
        "button_generate": "ç”Ÿæˆã™ã‚‹",
        "warning_topic": "å­¦ç¿’ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "lstm_header": "LSTMé”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "lstm_desc": "ä»®æƒ³ã‚¯ã‚¤ã‚ºã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã—ã¦é”æˆåº¦ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚",
        "lang_select": "è¨€èªé¸æŠ",
        "embed_success": "{count}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã§DBæ§‹ç¯‰å®Œäº†!",
        "embed_fail": "åŸ‹ã‚è¾¼ã¿å¤±æ•—ï¼šã‚¯ã‚©ãƒ¼ã‚¿è¶…éã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã€‚",
        "warning_no_files": "è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
        "warning_rag_not_ready": "RAGãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“ã€‚",
        "quiz_fail_structure": "ã‚¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚",
        "select_answer": "å›ç­”ã‚’é¸æŠã—ã¦ãã ã•ã„",
        "check_answer": "å›ç­”ã‚’ç¢ºèª",
        "next_question": "æ¬¡ã®è³ªå•",
        "correct_answer": "æ­£è§£ï¼ ğŸ‰",
        "incorrect_answer": "ä¸æ­£è§£ ğŸ˜",
        "correct_is": "æ­£è§£",
        "explanation": "è§£èª¬",
        "quiz_complete": "ã‚¯ã‚¤ã‚ºå®Œäº†!",
        "score": "ã‚¹ã‚³ã‚¢",
        "retake_quiz": "å†æŒ‘æˆ¦",
        "quiz_error_llm": "ã‚¯ã‚¤ã‚ºç”Ÿæˆå¤±æ•—ï¼šJSONå½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚",
        "quiz_original_response": "LLM åŸæœ¬å›ç­”",
        "firestore_loading": "RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ä¸­...",
        "firestore_no_index": "ä¿å­˜ã•ã‚ŒãŸRAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
        "db_save_complete": "(DBä¿å­˜å®Œäº†)",
        "data_analysis_progress": "è³‡æ–™åˆ†æä¸­...",
        "response_generating": "å¿œç­”ç”Ÿæˆä¸­...",
        "lstm_result_header": "é”æˆåº¦äºˆæ¸¬çµæœ",
        "lstm_score_metric": "äºˆæ¸¬é”æˆåº¦",
        "lstm_score_info": "æ¬¡ã®ã‚¹ã‚³ã‚¢äºˆæ¸¬: **{predicted_score:.1f}ç‚¹**",
        "lstm_rerun_button": "æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§å†äºˆæ¸¬",

        # --- Simulator ---
        "simulator_header": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
        "simulator_desc": "é›£ã—ã„é¡§å®¢å•ã„åˆã‚ã›ã«å¯¾ã™ã‚‹AIã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¨è‰æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "customer_query_label": "é¡§å®¢ã‹ã‚‰ã®å•ã„åˆã‚ã›å†…å®¹ (ãƒªãƒ³ã‚¯å¯)",
        "customer_type_label": "é¡§å®¢ã‚¿ã‚¤ãƒ—",
        "customer_type_options": ["ä¸€èˆ¬çš„ãªå•ã„åˆã‚ã›", "é›£ã—ã„é¡§å®¢", "éå¸¸ã«ä¸æº€ãªé¡§å®¢"],
        "button_simulate": "å¿œå¯¾ã‚¬ã‚¤ãƒ‰ç”Ÿæˆ",
        "customer_generate_response_button": "é¡§å®¢ã®è¿”ä¿¡ã‚’ç”Ÿæˆ",
        "send_closing_confirm_button": "è¿½åŠ ã®ã”è³ªå•æœ‰ç„¡ã‚’ç¢ºèªã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡",
        "simulation_warning_query": "ãŠå•ã„åˆã‚ã›å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "simulation_no_key_warning": "âš ï¸ APIã‚­ãƒ¼ä¸è¶³ã®ãŸã‚å¿œå¯¾ç”Ÿæˆä¸å¯ã€‚",
        "simulation_advice_header": "AIå¯¾å¿œã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
        "simulation_draft_header": "æ¨å¥¨å¿œå¯¾è‰æ¡ˆ",
        "button_listen_audio": "éŸ³å£°ã§èã",
        "tts_status_ready": "éŸ³å£°ç”Ÿæˆæº–å‚™å®Œäº†",
        "tts_status_generating": "éŸ³å£°ç”Ÿæˆä¸­...",
        "tts_status_success": "éŸ³å£°æº–å‚™å®Œäº†ï¼",
        "tts_status_error": "TTS ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
        "history_expander_title": "ğŸ“ éå»ã®å¯¾å¿œå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ (æœ€æ–°10ä»¶)",
        "initial_query_sample": "ãƒ‘ãƒªã«åˆ°ç€ã—ã¾ã—ãŸãŒã€Klookã®eSIMãŒä½¿ãˆã¾ã›ã‚“â€¦",
        "button_mic_input": "ğŸ™ éŸ³å£°å…¥åŠ›",
        "prompt_customer_end": "è¿½åŠ ã®è³ªå•ãŒãªã„ãŸã‚ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚",
        "prompt_survey": "ãŠå•ã„åˆã‚ã›ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
        "customer_closing_confirm": "ä»–ã®ãŠå•åˆã›ã¯ã”ã–ã„ã¾ã›ã‚“ã§ã—ã‚‡ã†ã‹ã€‚",
        "customer_positive_response": "ã”ä¸å¯§ãªå¯¾å¿œã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
        "button_end_chat": "ãƒãƒ£ãƒƒãƒˆçµ‚äº†ï¼ˆã‚¢ãƒ³ã‚±ãƒ¼ãƒˆï¼‰",
        "agent_response_header": "âœï¸ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”",
        "agent_response_placeholder": "é¡§å®¢ã¸è¿”ä¿¡å†…å®¹ã‚’å…¥åŠ›â€¦",
        "send_response_button": "è¿”ä¿¡é€ä¿¡",
        "request_rebuttal_button": "é¡§å®¢ã®åå¿œã‚’ç”Ÿæˆ",
        "new_simulation_button": "æ–°è¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
        "history_selectbox_label": "å±¥æ­´ã‚’é¸æŠ:",
        "history_load_button": "å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€",
        "delete_history_button": "âŒ å…¨å±¥æ­´å‰Šé™¤",
        "delete_confirm_message": "ã™ã¹ã¦ã®å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ",
        "delete_confirm_yes": "ã¯ã„ã€å‰Šé™¤ã™ã‚‹",
        "delete_confirm_no": "ã‚­ãƒ£ãƒ³ã‚»ãƒ«",
        "delete_success": "å‰Šé™¤å®Œäº†ï¼",
        "deleting_history_progress": "å‰Šé™¤ä¸­...",
        "search_history_label": "å±¥æ­´æ¤œç´¢",
        "date_range_label": "æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
        "no_history_found": "è©²å½“ã™ã‚‹å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        "customer_email_label": "é¡§å®¢ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆä»»æ„ï¼‰",
        "customer_phone_label": "é¡§å®¢é€£çµ¡å…ˆ / é›»è©±ç•ªå·ï¼ˆä»»æ„ï¼‰",

        # --- Voice ---
        "voice_rec_header": "éŸ³å£°è¨˜éŒ²ï¼†ç®¡ç†",
        "record_help": "éŒ²éŸ³ã™ã‚‹ã‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚",
        "uploaded_file": "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "rec_list_title": "ä¿å­˜ã•ã‚ŒãŸéŸ³å£°è¨˜éŒ²",
        "transcribe_btn": "è»¢å†™ (Whisper)",
        "save_btn": "éŸ³å£°è¨˜éŒ²ã‚’ä¿å­˜",
        "transcribing": "éŸ³å£°ã‚’è»¢å†™ä¸­...",
        "transcript_result": "è»¢å†™çµæœ:",
        "transcript_text": "è»¢å†™ãƒ†ã‚­ã‚¹ãƒˆ",
        "whisper_processing": "éŸ³å£°è»¢å†™ã‚’å‡¦ç†ä¸­...",
        "whisper_success": "âœ… è»¢å†™ãŒå®Œäº†ã—ã¾ã—ãŸï¼ ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
        "openai_missing": "OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚",
        "whisper_client_error": "âŒ ã‚¨ãƒ©ãƒ¼: Whisper APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "whisper_auth_error": "âŒ Whisper APIèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
        "whisper_format_error": "âŒ ã‚¨ãƒ©ãƒ¼: ã“ã®éŸ³å£°å½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "playback": "éŒ²éŸ³å†ç”Ÿ",
        "retranscribe": "å†è»¢å†™",
        "delete": "å‰Šé™¤",
        "no_records": "ä¿å­˜ã•ã‚ŒãŸéŸ³å£°è¨˜éŒ²ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        "saved_success": "ä¿å­˜ã—ã¾ã—ãŸï¼",
        "delete_confirm_rec": "ã“ã®éŸ³å£°è¨˜éŒ²ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ",
        "gcs_not_conf": "GCSãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€éŸ³å£°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "gcs_playback_fail": "éŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
        "gcs_no_audio": "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "error": "ã‚¨ãƒ©ãƒ¼:",
        "firestore_no_db_connect": "DBæ¥ç¶šå¤±æ•—",
        "save_history_success": "ä¿å­˜å®Œäº†ã€‚",
        "save_history_fail": "ä¿å­˜å¤±æ•—ã€‚",
        "delete_fail": "å‰Šé™¤å¤±æ•—",
        "rec_header": "éŸ³å£°å…¥åŠ›ï¼†è»¢å†™",
        "whisper_processing": "å‡¦ç†ä¸­...",
        "empty_response_warning": "å¿œç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    }
}



# ========================================
# 1-1. Session State ì´ˆê¸°í™”
# ========================================

if "language" not in st.session_state:
    st.session_state.language = DEFAULT_LANG
if "is_llm_ready" not in st.session_state:
    st.session_state.is_llm_ready = False
if "llm_init_error_msg" not in st.session_state:
    st.session_state.llm_init_error_msg = ""
if "uploaded_files_state" not in st.session_state:
    st.session_state.uploaded_files_state = None
if "is_rag_ready" not in st.session_state:
    st.session_state.is_rag_ready = False
if "rag_vectorstore" not in st.session_state:
    st.session_state.rag_vectorstore = None
if "rag_messages" not in st.session_state:
    st.session_state.rag_messages = []

if "simulator_messages" not in st.session_state:
    st.session_state.simulator_messages = []
if "simulator_memory" not in st.session_state:
    st.session_state.simulator_memory = ConversationBufferMemory(memory_key="chat_history")
if "simulator_chain" not in st.session_state:
    st.session_state.simulator_chain = None
if "initial_advice_provided" not in st.session_state:
    st.session_state.initial_advice_provided = False
if "is_chat_ended" not in st.session_state:
    st.session_state.is_chat_ended = False
if "show_delete_confirm" not in st.session_state:
    st.session_state.show_delete_confirm = False
if "customer_query_text_area" not in st.session_state:
    st.session_state.customer_query_text_area = ""
if "agent_response_area_text" not in st.session_state:
    st.session_state.agent_response_area_text = ""
if "last_transcript" not in st.session_state:
    st.session_state.last_transcript = ""
if "sim_audio_bytes" not in st.session_state:
    st.session_state.sim_audio_bytes = None

if "openai_client" not in st.session_state:
    st.session_state.openai_client = None
if "openai_init_msg" not in st.session_state:
    st.session_state.openai_init_msg = ""

L = LANG[st.session_state.language]

# ========================================
# 2. OpenAI Client ì´ˆê¸°í™” (secrets ì‚¬ìš© ì•ˆ í•¨)
# ========================================

# @st.cache_resource
# ========================================
# 0-A. API Key ì•ˆì „ êµ¬ì¡° (Secrets + User Input)
# ========================================

# 1) Streamlit Cloud Secretsì—ì„œ ìš°ì„  ê°€ì ¸ì˜¤ê¸°


secret_key = None

try:
    if hasattr(st, "secrets") and "OPENAI_API_KEY" in st.secrets:
        secret_key = st.secrets["OPENAI_API_KEY"]
except Exception:
    secret_key = None

# 2) ì‚¬ìš©ì ì…ë ¥ í‚¤ (ì„¸ì…˜ì— ì €ì¥)
if "user_api_key" not in st.session_state:
    st.session_state.user_api_key = ""

# 3) UI ì œê³µ: ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ëŠ” ë°±ì—… API Key
with st.sidebar:
    st.markdown("### ğŸ” OpenAI API Key ì„¤ì •")

    if secret_key:
        st.success("âœ” Streamlit Secrets API Key ê°ì§€ë¨ (ìë™ ì ìš©)")
    else:
        st.warning("âš  Streamlit Secretsì— API Key ì—†ìŒ â€” ì§ì ‘ ì…ë ¥ í•„ìš”")

    user_key_input = st.text_input(
        "ì§ì ‘ OpenAI API Key ì…ë ¥ (ì„ íƒ)",
        type="password",
        key="user_key_input_box",
        placeholder="sk-************************"
    )

    if st.button("API Key ì ìš©"):
        if user_key_input.strip():
            st.session_state.user_api_key = user_key_input.strip()
            st.success("ğŸ”‘ ì‚¬ìš©ì API Key ë“±ë¡ ì™„ë£Œ! (ì„¸ì…˜ ë‚´ ì„ì‹œ ì €ì¥)")
        else:
            st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


# 4) ìµœì¢… API Key ì„ íƒ ìš°ì„ ìˆœìœ„
def get_active_api_key():
    """
    1) Streamlit Cloud Secrets
    2) ì‚¬ìš©ì ì…ë ¥ í‚¤
    3) ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ None
    """
    if secret_key:
        return secret_key
    if st.session_state.user_api_key:
        return st.session_state.user_api_key
    return None


def init_openai_client():
    openai_key = get_active_api_key()
    if not openai_key:
        return None, LANG[DEFAULT_LANG]["openai_missing"]
    try:
        client = OpenAI(api_key=openai_key)
        return client, "âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ"
    except Exception as e:
        return None, f"OpenAI client init error: {e}"


openai_client_obj, openai_msg = init_openai_client()
st.session_state.openai_client = openai_client_obj
st.session_state.openai_init_msg = openai_msg

# ========================================
# 3. Whisper / TTS Helper
# ========================================

def transcribe_bytes_with_whisper(audio_bytes: bytes, mime_type: str = "audio/webm", lang_code: str = "ko") -> str:
    L = LANG[st.session_state.language]
    client = st.session_state.openai_client
    if client is None:
        return f"âŒ {L['openai_missing']}"

    # ì–¸ì–´ ì½”ë“œ ë§¤í•‘
    whisper_lang = {"ko": "ko", "en": "en", "ja": "ja"}.get(lang_code, "en")

    ext = "webm"
    if "/" in mime_type:
        ext = mime_type.split("/")[-1].lower()

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=f".{ext}")
    tmp.write(audio_bytes)
    tmp.flush()
    tmp.close()

    try:
        with open(tmp.name, "rb") as f:
            res = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="text",
                language=whisper_lang,
            )
        return res.strip() if isinstance(res, str) else str(res)
    except Exception as e:
        return f"âŒ {L['error']} Whisper: {e}"
    finally:
        try:
            os.remove(tmp.name)
        except OSError:
            pass


def synthesize_tts(text: str, lang_key: str):
    L = LANG[lang_key]
    client = st.session_state.openai_client

    if client is None:
        return None, f"âŒ {L['tts_status_error']} (Client Missing)"

    try:
        # TTS ìƒì„±: format íŒŒë¼ë¯¸í„° ì ˆëŒ€ ë„£ì§€ ë§ ê²ƒ
        response = client.audio.speech.create(
            model="tts-1",
            voice="nova",
            input=text,
        )

        # ëª¨ë“  SDK ë²„ì „ì—ì„œ ì‘ë™í•˜ëŠ” ì•ˆì „í•œ ë°©ì‹
        audio_bytes = response.read()

        return audio_bytes, f"âœ… {L['tts_status_success']}"

    except Exception as e:
        return None, f"âŒ {L['tts_status_error']} (OpenAI TTS Error: {e})"


def render_tts_button(text: str, lang_key: str, prefix: str = ""):
    L = LANG[lang_key]

    # ì™„ì „ ê³ ìœ  key ìƒì„± (message, prefix, time ì¡°í•©)
    unique_key = prefix + "_tts_" + hashlib.md5(
        (text + prefix + str(time.time())).encode("utf-8")
    ).hexdigest()

    if st.button(L["button_listen_audio"], key=unique_key):
        audio_bytes, msg = synthesize_tts(text, lang_key)
        if audio_bytes:
            st.audio(audio_bytes, format="audio/wav")
        else:
            st.error(msg)


# ========================================
# 4. ë¡œì»¬ ìŒì„± ê¸°ë¡ Helper
# ========================================

def load_voice_records() -> List[Dict[str, Any]]:
    return _load_json(VOICE_META_FILE, [])


def save_voice_records(records: List[Dict[str, Any]]):
    _save_json(VOICE_META_FILE, records)


def save_audio_record_local(
    audio_bytes: bytes,
    filename: str,
    transcript_text: str,
    mime_type: str = "audio/webm",
    meta: Dict[str, Any] = None,
) -> str:
    records = load_voice_records()
    rec_id = str(uuid.uuid4())
    ts = datetime.utcnow().isoformat()

    ext = filename.split(".")[-1] if "." in filename else "webm"
    audio_filename = f"{rec_id}.{ext}"
    audio_path = os.path.join(AUDIO_DIR, audio_filename)
    with open(audio_path, "wb") as f:
        f.write(audio_bytes)

    rec = {
        "id": rec_id,
        "created_at": ts,
        "filename": filename,
        "audio_filename": audio_filename,
        "size": len(audio_bytes),
        "transcript": transcript_text,
        "mime_type": mime_type,
        "language": st.session_state.language,
        "meta": meta or {},
    }
    records.insert(0, rec)
    save_voice_records(records)
    return rec_id


def delete_audio_record_local(rec_id: str) -> bool:
    records = load_voice_records()
    idx = next((i for i, r in enumerate(records) if r.get("id") == rec_id), None)
    if idx is None:
        return False
    rec = records.pop(idx)
    audio_filename = rec.get("audio_filename")
    if audio_filename:
        audio_path = os.path.join(AUDIO_DIR, audio_filename)
        try:
            os.remove(audio_path)
        except FileNotFoundError:
            pass
    save_voice_records(records)
    return True


def get_audio_bytes_local(rec_id: str):
    records = load_voice_records()
    rec = next((r for r in records if r.get("id") == rec_id), None)
    if not rec:
        raise FileNotFoundError("record not found")
    audio_filename = rec["audio_filename"]
    audio_path = os.path.join(AUDIO_DIR, audio_filename)
    with open(audio_path, "rb") as f:
        b = f.read()
    return b, rec

# ========================================
# 5. ë¡œì»¬ ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ Helper
# ========================================

def load_simulation_histories_local(lang_key: str) -> List[Dict[str, Any]]:
    histories = _load_json(SIM_META_FILE, [])
    return [
        h for h in histories
        if h.get("language_key") == lang_key and isinstance(h.get("messages"), list)
    ]


def save_simulation_history_local(initial_query: str, customer_type: str, messages: List[Dict[str, Any]], is_chat_ended: bool):
    histories = _load_json(SIM_META_FILE, [])
    doc_id = str(uuid.uuid4())
    ts = datetime.utcnow().isoformat()
    data = {
        "id": doc_id,
        "initial_query": initial_query,
        "customer_type": customer_type,
        "messages": messages,
        "language_key": st.session_state.language,
        "timestamp": ts,
        "is_chat_ended": is_chat_ended,
    }
    histories.insert(0, data)
    _save_json(SIM_META_FILE, histories)
    return True


def delete_all_history_local():
    _save_json(SIM_META_FILE, [])

# ========================================
# 6. RAG Helper (FAISS)
# ========================================

def load_documents(files) -> List[Document]:
    docs: List[Document] = []
    for f in files:
        name = f.name
        lower = name.lower()
        if lower.endswith(".pdf"):
            # UploadedFile -> temp íŒŒì¼ë¡œ
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
            tmp.write(f.read())
            tmp.flush()
            tmp.close()
            loader = PyPDFLoader(tmp.name)
            file_docs = loader.load()
            for d in file_docs:
                d.metadata["source"] = name
            docs.extend(file_docs)
            try:
                os.remove(tmp.name)
            except OSError:
                pass
        elif lower.endswith(".txt"):
            text = f.read().decode("utf-8", errors="ignore")
            docs.append(Document(page_content=text, metadata={"source": name}))
        elif lower.endswith(".html") or lower.endswith(".htm"):
            text = f.read().decode("utf-8", errors="ignore")
            docs.append(Document(page_content=text, metadata={"source": name}))
    return docs


def split_documents(docs: List[Document]) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=["\n\n", "\n", ".", " ", ""],
    )
    return splitter.split_documents(docs)


def build_rag_index(files, embeddings):
    if not files:
        st.warning(L["warning_no_files"])
        return None, 0

    docs = load_documents(files)
    if not docs:
        st.warning("ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None, 0

    chunks = split_documents(docs)
    if not chunks:
        st.warning("ë¬¸ì„œ ì²­í¬ ë¶„í• ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return None, 0

    try:
        vectorstore = FAISS.from_documents(chunks, embeddings)
        # ì €ì¥
        vectorstore.save_local(RAG_INDEX_DIR)
    except Exception as e:
        st.error(f"RAG ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None, 0

    return vectorstore, len(chunks)


def load_rag_index(embeddings):
    try:
        vs = FAISS.load_local(RAG_INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
        return vs
    except Exception:
        return None


def rag_answer(question: str, vectorstore: FAISS, lang_key: str) -> str:
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return LANG[lang_key]["openai_missing"]

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
        openai_api_key=api_key,
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

    docs = retriever.get_relevant_documents(question)
    context = "\n\n".join(d.page_content[:1500] for d in docs)

    prompt_tmpl = PromptTemplate(
        template=(
            "You are a helpful AI tutor. Answer the question using ONLY the provided context.\n"
            "If you cannot find the answer in the context, say you don't know.\n\n"
            "Question:\n{question}\n\n"
            "Context:\n{context}\n\n"
            "Answer:"
        ),
        input_variables=["question", "context"],
    )
    prompt = prompt_tmpl.format(question=question, context=context)
    resp = llm.invoke(prompt)
    return resp.content if hasattr(resp, "content") else str(resp)

# ========================================
# 7. LSTM Helper (ê°„ë‹¨ Mock + ì‹œê°í™”)
# ========================================

def load_or_train_lstm():
    # ì‹¤ì œ LSTM ëŒ€ì‹  ëœë¤ + sin íŒŒí˜• ê¸°ë°˜ Mock
    np.random.seed(42)
    n_points = 50
    ts = 60 + 20 * np.sin(np.linspace(0, 4 * np.pi, n_points)) + np.random.normal(0, 5, n_points)
    ts = np.clip(ts, 50, 100).astype(np.float32)
    return ts

# ========================================
# 8. LLM (ChatOpenAI) for Simulator / Content
# ========================================

LLM_API_KEY = os.environ.get("OPENAI_API_KEY")
LLM_MODEL = "gpt-4o-mini"

if "llm" not in st.session_state:
    if LLM_API_KEY:
        try:
            st.session_state.llm = ChatOpenAI(
                model=LLM_MODEL,
                temperature=0.7,
                openai_api_key=LLM_API_KEY,
            )
            st.session_state.embeddings = OpenAIEmbeddings(openai_api_key=LLM_API_KEY)
            st.session_state.is_llm_ready = True

            sim_prompt = PromptTemplate(
                template=(
                    "You are an AI customer who responds ONLY as the customer in the scenario.\n"
                    "Do NOT greet unless the agent greets first.\n"
                    "Do NOT repeat your initial message.\n"
                    "Always answer in the language used by the agent.\n\n"
                    "Rules:\n"
                    "- If the agent requests specific information, provide ONLY ONE detail.\n"
                    "- If the agent provides a solution, respond politely.\n"
                    "- If the conversation is nearing completion, optionally add a closing remark.\n"
                    "- DO NOT generate long formal greetings like 'Good morning'.\n"
                    "- DO NOT reset context.\n\n"
                    "{chat_history}\nHuman agent: {input}\nCustomer:"
                ),
                input_variables=["input", "chat_history"],
            )

            st.session_state.simulator_chain = ConversationChain(
                llm=st.session_state.llm,
                memory=st.session_state.simulator_memory,
                prompt=sim_prompt,
                input_key="input",
            )
        except Exception as e:
            st.session_state.llm_init_error_msg = f"{L['llm_error_init']} (OpenAI): {e}"
            st.session_state.is_llm_ready = False
    else:
        st.session_state.llm_init_error_msg = LANG[DEFAULT_LANG]["openai_missing"]
        st.session_state.is_llm_ready = False

# ========================================
# 9. ì‚¬ì´ë“œë°” (ì–¸ì–´ ì„ íƒ + íŒŒì¼ ì—…ë¡œë“œ + ë¶„ì„ ë²„íŠ¼)
# ========================================

with st.sidebar:
    selected_lang_key = st.selectbox(
        L["lang_select"],
        options=["ko", "en", "ja"],
        index=["ko", "en", "ja"].index(st.session_state.language),
        format_func=lambda x: {"ko": "í•œêµ­ì–´", "en": "English", "ja": "æ—¥æœ¬èª"}[x],
    )

    # ğŸ”¹ ì–¸ì–´ ë³€ê²½ ê°ì§€
    if selected_lang_key != st.session_state.language:
        old_lang = st.session_state.language
        st.session_state.language = selected_lang_key
        L = LANG[st.session_state.language]

        # ğŸ”¹ ì‹œë®¬ë ˆì´í„° ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.simulator_messages = []
        st.session_state.simulator_memory.clear()
        st.session_state.initial_advice_provided = False
        st.session_state.is_chat_ended = False
        st.session_state.agent_response_area_text = ""
        st.session_state.last_transcript = ""
        st.session_state.sim_audio_bytes = None
        st.session_state.sim_audio_bytes_raw = None

        # (ì›í•˜ë©´ RAG ì±„íŒ… ì´ë ¥ë„ ì–¸ì–´ë³„ë¡œ ë¶„ë¦¬í•˜ê³  ì‹¶ì„ ë•Œ)
        # st.session_state.messages = []

        # st.rerun()


    L = LANG[st.session_state.language]

    st.title(L["sidebar_title"])
    st.markdown("---")

    st.subheader("í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ìƒíƒœ")
    if st.session_state.llm_init_error_msg:
        st.error(st.session_state.llm_init_error_msg)
    elif st.session_state.is_llm_ready:
        st.success("âœ… LLM ë° ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ")

    if "âœ…" in st.session_state.openai_init_msg:
        st.success(st.session_state.openai_init_msg)
    else:
        st.warning(st.session_state.openai_init_msg)

    st.markdown("---")

    uploaded_files_widget = st.file_uploader(
        L["file_uploader"], type=["pdf", "txt", "html"], accept_multiple_files=True
    )
    if uploaded_files_widget:
        st.session_state.uploaded_files_state = uploaded_files_widget

    files_to_process = st.session_state.uploaded_files_state or []

    if files_to_process and st.session_state.is_llm_ready:
        if st.button(L["button_start_analysis"]):
            with st.spinner(L["data_analysis_progress"]):
                vs, count = build_rag_index(files_to_process, st.session_state.embeddings)
                if vs is not None:
                    st.session_state.rag_vectorstore = vs
                    st.session_state.is_rag_ready = True
                    st.success(L["embed_success"].format(count=count))
                else:
                    st.session_state.is_rag_ready = False
    elif not files_to_process:
        st.info(L["warning_no_files"])

    st.markdown("---")

    feature_selection = st.radio(
        "ê¸°ëŠ¥ ì„ íƒ",
        [L["rag_tab"], L["content_tab"], L["lstm_tab"], L["simulator_tab"], L["voice_rec_header"]],
    )

# ë©”ì¸ íƒ€ì´í‹€
st.title(L["title"])

# ========================================
# 10. ê¸°ëŠ¥ë³„ í˜ì´ì§€
# ========================================

# -------------------- Voice Record Tab --------------------
if feature_selection == L["voice_rec_header"]:
    st.header(L["voice_rec_header"])
    st.caption(L["record_help"])

    col_rec, col_list = st.columns([1, 1])

    # ë…¹ìŒ/ì—…ë¡œë“œ + ì „ì‚¬ + ì €ì¥
    with col_rec:
        st.subheader(L["rec_header"])
        audio_file = st.file_uploader(
            L["uploaded_file"],
            type=["wav", "mp3", "m4a", "webm", "ogg"],
            key="voice_rec_uploader",
        )
        audio_bytes = None
        audio_mime = "audio/webm"

        if audio_file is not None:
            audio_bytes = audio_file.getvalue()
            audio_mime = audio_file.type or "audio/webm"

        # ì¬ìƒ
        if audio_bytes:
            st.audio(audio_bytes, format=audio_mime)

        # ì „ì‚¬ ë²„íŠ¼
        if audio_bytes and st.button(L["transcribe_btn"]):
            if st.session_state.openai_client is None:
                st.error(L["openai_missing"])
            else:
                with st.spinner(L["transcribing"]):
                    text = transcribe_bytes_with_whisper(
                        audio_bytes, audio_mime, lang_code=st.session_state.language
                    )
                    st.session_state.last_transcript = text
                    snippet = text[:50].replace("\n", " ")
                    if len(text) > 50:
                        snippet += "..."
                    if text.startswith("âŒ"):
                        st.error(text)
                    else:
                        st.success(f"{L['transcript_result']} **{snippet}**")

        st.text_area(
            L["transcript_text"],
            value=st.session_state.last_transcript,
            height=150,
            key="voice_rec_transcript_area",
        )

        if audio_bytes and st.button(L["save_btn"]):
            try:
                ext = audio_mime.split("/")[-1] if "/" in audio_mime else "webm"
                filename = f"record_{int(time.time())}.{ext}"
                save_audio_record_local(
                    audio_bytes,
                    filename,
                    st.session_state.last_transcript,
                    mime_type=audio_mime,
                )
                st.success(L["saved_success"])
                st.session_state.last_transcript = ""
                # st.rerun()
            except Exception as e:
                st.error(f"{L['error']} {e}")

    # ì €ì¥ëœ ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
    with col_list:
        st.subheader(L["rec_list_title"])
        try:
            records = load_voice_records()
        except Exception as e:
            st.error(f"read error: {e}")
            records = []

        if not records:
            st.info(L["no_records"])
        else:
            for rec in records:
                rec_id = rec["id"]
                created_at = rec.get("created_at")
                try:
                    dt = datetime.fromisoformat(created_at)
                    created_str = dt.strftime("%Y-%m-%d %H:%M")
                except Exception:
                    created_str = str(created_at)

                transcript_snippet = (rec.get("transcript") or "")[:50].replace("\n", " ")
                if len(rec.get("transcript") or "") > 50:
                    transcript_snippet += "..."

                with st.expander(f"[{created_str}] {transcript_snippet}"):
                    st.write(f"**{L['transcript_text']}:** {rec.get('transcript') or 'N/A'}")
                    st.caption(
                        f"**Size:** {rec.get('size')} bytes | **File:** {rec.get('audio_filename')}"
                    )

                    col_p, col_r, col_d = st.columns([2, 1, 1])

                    if col_p.button(L["playback"], key=f"play_{rec_id}"):
                        try:
                            b, info = get_audio_bytes_local(rec_id)
                            mime = info.get("mime_type", "audio/webm")
                            st.audio(b, format=mime)
                        except Exception as e:
                            st.error(f"{L['gcs_playback_fail']}: {e}")

                    if col_r.button(L["retranscribe"], key=f"re_{rec_id}"):
                        if st.session_state.openai_client is None:
                            st.error(L["openai_missing"])
                        else:
                            with st.spinner(L["transcribing"]):
                                try:
                                    b, info = get_audio_bytes_local(rec_id)
                                    mime = info.get("mime_type", "audio/webm")
                                    new_text = transcribe_bytes_with_whisper(
                                        b, mime, lang_code=st.session_state.language
                                    )
                                    records = load_voice_records()
                                    for r in records:
                                        if r["id"] == rec_id:
                                            r["transcript"] = new_text
                                            break
                                    save_voice_records(records)
                                    st.success(L["retranscribe"] + " " + L["saved_success"])
                                    # st.rerun()
                                except Exception as e:
                                    st.error(f"{L['error']} {e}")

                    if col_d.button(L["delete"], key=f"del_{rec_id}"):
                        if st.session_state.get(f"confirm_del_{rec_id}", False):
                            ok = delete_audio_record_local(rec_id)
                            if ok:
                                st.success(L["delete_success"])
                            else:
                                st.error(L["delete_fail"])
                            st.session_state[f"confirm_del_{rec_id}"] = False
                            # st.rerun()
                        else:
                            st.session_state[f"confirm_del_{rec_id}"] = True
                            st.warning(L["delete_confirm_rec"])

# -------------------- Simulator Tab --------------------
elif feature_selection == L["simulator_tab"]:
    st.header(L["simulator_header"])
    st.markdown(L["simulator_desc"])

    st.markdown(
        f'<div style="padding:5px;text-align:center;border-radius:5px;background-color:#f0f0f0;margin-bottom:10px;">{L["tts_status_ready"]}</div>',
        unsafe_allow_html=True,
    )

    # ì „ì²´ ì´ë ¥ ì‚­ì œ
    col_del, _ = st.columns([1, 4])
    with col_del:
        if st.button(L["delete_history_button"], key="trigger_delete_hist"):
            st.session_state.show_delete_confirm = True

    if st.session_state.show_delete_confirm:
        with st.container():
            st.warning(L["delete_confirm_message"])
            c_yes, c_no = st.columns(2)
            if c_yes.button(L["delete_confirm_yes"], key="confirm_del_yes"):
                with st.spinner(L["deleting_history_progress"]):
                    delete_all_history_local()
                    st.session_state.simulator_messages = []
                    st.session_state.simulator_memory.clear()
                    st.session_state.show_delete_confirm = False
                    st.success(L["delete_success"])
                    # st.rerun()
            if c_no.button(L["delete_confirm_no"], key="confirm_del_no"):
                st.session_state.show_delete_confirm = False
                # st.rerun()

    current_lang = st.session_state.language

    # ì´ë ¥ ë¡œë“œ
    with st.expander(L["history_expander_title"]):
        histories = load_simulation_histories_local(current_lang)
        search_query = st.text_input(L["search_history_label"], key="sim_hist_search")

        today = datetime.now().date()
        dr = st.date_input(
            L["date_range_label"],
            value=[today - timedelta(days=7), today],
            key="sim_hist_date_range",
        )

        filtered = []
        if histories:
            if isinstance(dr, list) and len(dr) == 2:
                start_date = min(dr)
                end_date = max(dr)
            else:
                start_date = datetime.min.date()
                end_date = datetime.max.date()

            for h in histories:
                ok_search = True
                if search_query:
                    q = search_query.lower()
                    text = (h["initial_query"] + " " + h["customer_type"]).lower()
                    if q not in text:
                        ok_search = False

                ok_date = True
                ts = h.get("timestamp")
                if ts:
                    try:
                        d = datetime.fromisoformat(ts).date()
                        if not (start_date <= d <= end_date):
                            ok_date = False
                    except Exception:
                        pass

                if ok_search and ok_date:
                    filtered.append(h)

        if filtered:
            def _label(h):
                try:
                    t = datetime.fromisoformat(h["timestamp"])
                    t_str = t.strftime("%m-%d %H:%M")
                except Exception:
                    t_str = h.get("timestamp", "")
                q = h["initial_query"][:30].replace("\n", " ")
                return f"[{t_str}] {h['customer_type']} - {q}..."

            options_map = { _label(h): h for h in filtered }
            sel_key = st.selectbox(L["history_selectbox_label"], options=list(options_map.keys()))
            if st.button(L["history_load_button"], key="load_hist_btn"):
                h = options_map[sel_key]
                st.session_state.customer_query_text_area = h["initial_query"]
                st.session_state.simulator_messages = h["messages"]
                st.session_state.initial_advice_provided = True
                st.session_state.is_chat_ended = h.get("is_chat_ended", False)

                st.session_state.simulator_memory.clear()
                for msg in h["messages"]:
                    role = msg["role"]
                    if role in ["customer", "agent_response"]:
                        st.session_state.simulator_memory.chat_memory.add_user_message(msg["content"])
                    else:
                        st.session_state.simulator_memory.chat_memory.add_ai_message(msg["content"])

                st.rerun()
        else:
            st.info(L["no_history_found"])

    # LLM ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´í„° ì œí•œ
    if not st.session_state.is_llm_ready and not LLM_API_KEY:
        st.warning(L["simulation_no_key_warning"])

    if st.session_state.is_chat_ended:
        st.success(L["prompt_customer_end"] + " " + L["prompt_survey"])
        if st.button(L["new_simulation_button"], key="new_simulation_btn"):
            st.session_state.is_chat_ended = False
            st.session_state.initial_advice_provided = False
            st.session_state.simulator_messages = []
            st.session_state.simulator_memory.clear()
            st.session_state.last_transcript = ""
            st.session_state.agent_response_area_text = ""
            st.session_state.customer_query_text_area = ""
            # st.rerun()
        st.stop()

    # ì´ˆê¸° ë¬¸ì˜ ì…ë ¥
    customer_query = st.text_area(
        L["customer_query_label"],
        key="customer_query_text_area",
        height=150,
        placeholder=L["initial_query_sample"],
        value=st.session_state.agent_response_area_text,
        disabled=st.session_state.initial_advice_provided,
    )

    # ğŸ”¹ ìƒˆë¡œ ì¶”ê°€: ê³ ê° ì—°ë½ì²˜ (ì„ íƒ)
    customer_email = st.text_input(
        L.get("customer_email_label", "Customer email (optional)"),
        key="customer_email",
        disabled=st.session_state.initial_advice_provided,
    )
    customer_phone = st.text_input(
        L.get("customer_phone_label", "Customer phone / WhatsApp (optional)"),
        key="customer_phone",
        disabled=st.session_state.initial_advice_provided,
    )

    customer_type_options = L["customer_type_options"]
    default_idx = 1 if len(customer_type_options) > 1 else 0
    customer_type_display = st.selectbox(
        L["customer_type_label"],
        customer_type_options,
        index=default_idx,
        disabled=st.session_state.initial_advice_provided,
        key="customer_type_sim_select",
    )

    if st.button(L["button_simulate"], disabled=st.session_state.initial_advice_provided):
        if not customer_query.strip():
            st.warning(L["simulation_warning_query"])
            st.stop()

        st.session_state.simulator_memory.clear()
        st.session_state.simulator_messages = []
        st.session_state.is_chat_ended = False

        st.session_state.simulator_messages.append({"role": "customer", "content": customer_query})
        st.session_state.simulator_memory.chat_memory.add_user_message(customer_query)

        contact_info_block = ""
        if customer_email or customer_phone:
            contact_info_block = (
                f"\n\n[Customer contact info for your reference]"
                f"\n- Email: {customer_email or 'N/A'}"
                f"\n- Phone: {customer_phone or 'N/A'}"
            )

        current_lang_key = st.session_state.language

        initial_prompt = f"""
        You are an AI Customer Support Supervisor. Your role is to analyze the following customer inquiry
        from a **{customer_type_display}** and provide:

        1) A detailed **response guideline for the human agent** (step-by-step).
        2) A **ready-to-send draft reply** in {LANG[current_lang_key]['lang_select']}.


        [CRITICAL RULE 1: LANGUAGE]
        - All content (guideline AND draft) MUST be written strictly in {LANG[current_lang_key]['lang_select']}.

        [CRITICAL RULE 2: FORMAT]
        - Use the exact markdown headers:
          - "### {L['simulation_advice_header']}"
          - "### {L['simulation_draft_header']}"

        [CRITICAL RULE 3: INFORMATION YOU MUST ASK FIRST]
        Before solving the problem, list the essential details the agent must collect from the customer.
        In the guideline, always include a section like "1. ì •ë³´ ìˆ˜ì§‘ / Information to collect" with bullet points such as:
        - For eSIM / connectivity issues:
          - Device model (e.g. iPhone 12, Galaxy S22)
          - OS version
          - Whether the device supports eSIM
          - Current location / country and whether the customer has already arrived
          - Exact activation steps already tried and at which step it failed
        - For tickets with children:
          - Number of children
          - Each child's date of birth or age range
          - Whether the ticket type changes with age (free / child / youth / adult)
        - Any booking ID, voucher number, or reservation code
        - Customer's preferred contact channel if follow-up is needed.

        [CRITICAL RULE 4: DRAFT STYLE]
        - The draft reply should:
          - Politely thank the customer.
          - Clearly ask for the missing information listed above (but not all in one long sentence).
          - Explain the next troubleshooting steps in simple language.
          - For eSIM cases, mention important checks (airplane mode, roaming settings, APN, profile installation, etc.) if relevant.
          - For child ticket cases, clearly explain how the pricing works by age.

        [CRITICAL RULE 5: ROLEPLAY FOR FUTURE MESSAGES]
        When the Agent subsequently asks for information in later rounds,
        **ROLEPLAY as the customer** who is frustrated but **HIGHLY COOPERATIVE** and
        provide the requested details piece by piece (not all at once).
        The customer MUST NOT argue about why the information is needed.
        
        [CRITICAL RULE 6: ASK FOR ALL REQUIRED DETAILS AT ONCE]
        When composing the draft reply:
        - Do NOT ask one-by-one questions.
        - Instead, request ALL required details in a neatly formatted multi-bullet list.
        - Each bullet point must contain only ONE information category.

        Customer Inquiry:
        {customer_query}
        {contact_info_block}
        """

        if not st.session_state.is_llm_ready or not LLM_API_KEY:
            mock_text = (
                f"### {L['simulation_advice_header']}\n\n"
                f"- (Mock) {customer_type_display} ìœ í˜• ê³ ê°ì— ëŒ€í•œ ì‘ëŒ€ ê°€ì´ë“œë¼ì¸ì…ë‹ˆë‹¤.\n\n"
                f"### {L['simulation_draft_header']}\n\n"
                f"(Mock) ì—¬ê¸°ì—ëŠ” ì‹¤ì œ AI ì‘ëŒ€ ì´ˆì•ˆì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n\n"
            )
            st.session_state.simulator_messages.append({"role": "supervisor", "content": mock_text})
            st.session_state.simulator_memory.chat_memory.add_ai_message(mock_text)
            st.session_state.initial_advice_provided = True
            save_simulation_history_local(
                customer_query,
                customer_type_display,
                st.session_state.simulator_messages,
                is_chat_ended=False,
            )
            st.warning(L["simulation_no_key_warning"])
            # st.rerun()
        else:
            with st.spinner(L["response_generating"]):
                try:
                    text = st.session_state.simulator_chain.predict(input=initial_prompt)
                    st.session_state.simulator_messages.append({"role": "supervisor", "content": text})
                    st.session_state.initial_advice_provided = True
                    save_simulation_history_local(
                        customer_query,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=False,
                    )
                    # st.rerun()
                except Exception as e:
                    st.error(f"AI ì¡°ì–¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ëŒ€í™” ë¡œê·¸ í‘œì‹œ
    # ëŒ€í™” ë¡œê·¸ í‘œì‹œ
    for msg in st.session_state.simulator_messages:
        role = msg["role"]
        content = msg["content"]

        if role == "customer":
            with st.chat_message("user", avatar="ğŸ™‹"):
                st.markdown(content)
                render_tts_button(content, st.session_state.language, prefix="customer_")

        elif role == "supervisor":
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown(content)
                render_tts_button(content, st.session_state.language, prefix="supervisor_")

        elif role == "agent_response":
            with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
                st.markdown(content)
                render_tts_button(content, st.session_state.language, prefix="agent_")

        elif role in ["customer_rebuttal", "customer_end", "system_end"]:
            with st.chat_message("assistant", avatar="âœ¨"):
                st.markdown(content)
                render_tts_button(content, st.session_state.language, prefix=f"{role}_")

    # ì—ì´ì „íŠ¸ ì‘ë‹µ / ë§ˆì´í¬ ì…ë ¥
    # ì—ì´ì „íŠ¸ ì‘ë‹µ / ë§ˆì´í¬ ì…ë ¥
    if st.session_state.initial_advice_provided and not st.session_state.is_chat_ended:

        last_role = (
            st.session_state.simulator_messages[-1]["role"]
            if st.session_state.simulator_messages else None
        )

        if last_role in ["customer", "supervisor", "customer_rebuttal", "customer_end"]:
            st.markdown(f"### {L['agent_response_header']}")
            col_mic, col_text = st.columns([1, 2])

            # ë§ˆì´í¬ ë…¹ìŒ
            with col_mic:
                mic_audio = mic_recorder(
                    start_prompt=L["button_mic_input"],
                    stop_prompt="â¹ï¸ ë…¹ìŒ ì¢…ë£Œ",
                    just_once=False,
                    format="wav",
                    use_container_width=True,
                    key="sim_mic_recorder",
                )

            new_audio_bytes = mic_audio["bytes"] if mic_audio else None

            if new_audio_bytes is not None:
                st.session_state.sim_audio_bytes = new_audio_bytes
                st.info("âœ… ë…¹ìŒ ì™„ë£Œ! ì•„ë˜ ì „ì‚¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”.")

            if st.session_state.sim_audio_bytes:
                st.audio(st.session_state.sim_audio_bytes, format="audio/wav")

            # ì „ì‚¬ ë²„íŠ¼
            col_tr, _ = st.columns([1, 2])
            if col_tr.button(L["transcribe_btn"], key="sim_transcribe_btn"):
                if st.session_state.sim_audio_bytes is None:
                    st.warning("ë¨¼ì € ë§ˆì´í¬ë¡œ ë…¹ìŒì„ ì™„ë£Œí•˜ì„¸ìš”.")
                elif st.session_state.openai_client is None:
                    st.error(L["whisper_client_error"])
                else:
                    # ğŸ”¹ ì—¬ê¸°ì„œ ì‹¤ì œ ì „ì‚¬ ëŒ€ìƒ ì˜¤ë””ì˜¤/í¬ë§·ì„ ì •ì˜
                    audio_bytes_to_transcribe = st.session_state.sim_audio_bytes
                    audio_mime_to_transcribe = "audio/wav"  # mic_recorder(format="wav") ì´ë¼ì„œ ê³ ì •

                    with st.spinner(
                            L.get("whisper_processing", "ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
                    ):
                        try:
                            transcribed_text = transcribe_bytes_with_whisper(
                                audio_bytes_to_transcribe,
                                audio_mime_to_transcribe,
                                # ì–¸ì–´í‚¤ëŠ” ì„¸ì…˜ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ëŠ” ê²Œ ë” ì•ˆì „
                                lang_code=st.session_state.language,
                            )

                            if transcribed_text.startswith("âŒ"):
                                st.error(transcribed_text)
                                st.session_state.last_transcript = ""
                            else:
                                # ë§ˆì§€ë§‰ ì „ì‚¬ ë‚´ìš©ê³¼ ì—ì´ì „íŠ¸ ì‘ë‹µì°½ì— ë™ì‹œì— ë°˜ì˜
                                st.session_state.last_transcript = transcribed_text
                                st.session_state.agent_response_area_text = transcribed_text.strip()
                                st.session_state.last_transcript = transcribed_text.strip()

                                snippet = transcribed_text[:50].replace("\n", " ") + (
                                    "..." if len(transcribed_text) > 50 else ""
                                )

                                success_msg = L.get(
                                    "whisper_success",
                                    "âœ… ìŒì„± ì „ì‚¬ ì™„ë£Œ! í…ìŠ¤íŠ¸ ì°½ì„ í™•ì¸í•˜ì„¸ìš”."
                                ) + f"\n\n**ì¸ì‹ ë‚´ìš©:** *{snippet}*"

                                st.success(success_msg)

                        except Exception as e:
                            st.error(f"Whisper Error: {e}")

                            if transcribed_text.startswith("âŒ"):
                                st.error(transcribed_text)
                                st.session_state.last_transcript = ""
                            else:
                                st.session_state.last_transcript = transcribed_text
                                st.session_state.agent_response_area_text = transcribed_text

                                snippet = (
                                        transcribed_text[:50].replace("\n", " ")
                                        + ("..." if len(transcribed_text) > 50 else "")
                                )

                                success_msg = (
                                        L.get("whisper_success",
                                              "âœ… ìŒì„± ì „ì‚¬ ì™„ë£Œ! í…ìŠ¤íŠ¸ ì°½ì„ í™•ì¸í•˜ì„¸ìš”.")
                                        + f"\n\n**ì¸ì‹ ë‚´ìš©:** *{snippet}*"
                                )
                        except Exception as e:
                            st.error(f"Whisper Error: {e}")

            # â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“
            # ì—¬ê¸°ì„œë¶€í„°ê°€ ë¬¸ì œì˜€ë˜ ë¶€ë¶„ â€” ì •ë ¬ ì™„ì „ ìˆ˜ì •
            # â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“

            col_text, col_button = st.columns([4, 1])

            with col_text:
                agent_response = st.text_area(
                    L["agent_response_placeholder"],
                    value=st.session_state.agent_response_area_text,
                    height=150,
                    key="agent_response_text_area"
                )

            with col_button:
                send_clicked = st.button(L["send_response_button"], key="send_response_btn")

            if send_clicked:
                if not agent_response.strip():
                    st.warning(L["empty_response_warning"])
                else:
                    st.session_state.last_transcript = agent_response
                    st.session_state.agent_response_area_text = ""
                    st.session_state.sim_audio_bytes = None

                    st.session_state.simulator_messages.append(
                        {"role": "agent_response", "content": agent_response}
                    )
                    st.session_state.simulator_memory.chat_memory.add_user_message(agent_response)

                    save_simulation_history_local(
                        st.session_state.customer_query_text_area,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=False,
                    )

                    # st.rerun()

        # ì—ì´ì „íŠ¸ ì‘ë‹µ ì´í›„: ì¢…ë£Œ/ë‹¤ìŒ ë°˜ì‘
        last_role = st.session_state.simulator_messages[-1]["role"] if st.session_state.simulator_messages else None

        if last_role == "agent_response":

            st.markdown("### ğŸ¤– ê³ ê° ë°˜ì‘ ìƒì„±")

            if st.button(L["customer_generate_response_button"], key="btn_generate_customer"):
                next_prompt = f"""
                You are the CUSTOMER. Respond naturally to the agent's latest message.

                RULES:
                1. If the agent requested information â†’ provide exactly ONE missing detail.
                2. If the agent provided a solution â†’ respond with appreciation.
                3. Appreciation must include a positive phrase like:
                   "{L['customer_positive_response']}"
                4. After appreciation, customer MUST wait for the agent to ask:
                   "{L['customer_closing_confirm']}"
                5. Language must be {LANG[st.session_state.language]['lang_select']}.
                """

                with st.spinner(L["response_generating"]):
                    reaction = st.session_state.simulator_chain.predict(input=next_prompt)

                st.session_state.simulator_messages.append(
                    {"role": "customer", "content": reaction}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                st.stop()

        if last_role == "customer":
            customer_text = st.session_state.simulator_messages[-1]["content"].strip().lower()

            appreciation_patterns = ["ê°ì‚¬", "thank", "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™", "ã‚ã‚ŠãŒã¨ã†", "ê°ì‚¬í•©ë‹ˆë‹¤"]
            closing_patterns = ["ì—†ìŠµë‹ˆë‹¤", "ì—†ì–´ìš”", "ì—†ì–´", "no more", "nothing else", "çµæ§‹ã§ã™", "å¤§ä¸ˆå¤«ã§ã™"]

            # 1) ê³ ê°ì´ ê°ì‚¬ ì¸ì‚¬ë¥¼ í•œ ê²½ìš°
            if any(p in customer_text for p in appreciation_patterns):

                st.info("ê³ ê°ì´ ê°ì‚¬ ì¸ì‚¬ë¥¼ í–ˆìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ê°€ ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.")

                if st.button(L["send_closing_confirm_button"], key="btn_send_closing_confirm"):
                    closing_msg = L["customer_closing_confirm"]

                    st.session_state.simulator_messages.append(
                        {"role": "supervisor", "content": closing_msg}
                    )
                    st.session_state.simulator_memory.chat_memory.add_ai_message(closing_msg)

                    st.success("ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë©”ì‹œì§€ê°€ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.stop()

            # 2) ê³ ê°ì´ â€œì¶”ê°€ ë¬¸ì˜ ì—†ìŒâ€ì„ í‘œí˜„í•œ ê²½ìš°
            elif any(p in customer_text for p in closing_patterns):

                st.success("ê³ ê°ì´ ë” ì´ìƒ ë¬¸ì˜ê°€ ì—†ë‹¤ê³  ë§í–ˆìŠµë‹ˆë‹¤.")

                end_msg = L["prompt_survey"]
                st.session_state.simulator_messages.append({"role": "system_end", "content": end_msg})
                st.session_state.is_chat_ended = True

                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.simulator_messages,
                    is_chat_ended=True,
                )

                st.info("ğŸ“Œ ìƒë‹´ ì¢…ë£Œ ë‹¨ê³„ì…ë‹ˆë‹¤. ì„¤ë¬¸ì¡°ì‚¬ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                st.stop()

            # 3) ê·¸ ì™¸ì˜ ê²½ìš° â†’ ì¼ë°˜ì ì¸ ì¶”ê°€ ì§ˆë¬¸
            else:
                pass  # ì—ì´ì „íŠ¸ ì‘ë‹µ UI ê·¸ëŒ€ë¡œ ìœ ì§€ë¨

        if last_role == "agent_response":
            col_end, col_next = st.columns([1, 2])

            if col_end.button(L["button_end_chat"], key="sim_end_chat_btn"):
                # ê³ ê°ì—ê²Œ "ì¶”ê°€ ë¬¸ì˜ í™•ì¸" ë¨¼ì € ë³´ë‚´ê¸°
                closing_query = L["customer_closing_confirm"]

                st.session_state.simulator_messages.append(
                    {"role": "supervisor", "content": closing_query}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(closing_query)

                # ì„¤ë¬¸ ë©”ì‹œì§€ëŠ” ê³ ê°ì´ â€œì—†ìŠµë‹ˆë‹¤â€ë¼ê³  í•œ ë’¤ì—ë§Œ ì „ì†¡
                st.stop()
                # st.rerun()

                if col_next.button(L["request_rebuttal_button"], key="sim_next_rebuttal_btn"):
                    next_prompt = """ ... (LLMì—ê²Œ customer role ìš”ì²­) ... """

                    with st.spinner(L["response_generating"]):
                        reaction = st.session_state.simulator_chain.predict(input=next_prompt)

                    st.session_state.simulator_messages.append(
                        {"role": "customer_rebuttal", "content": reaction}
                    )
                    st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                    save_simulation_history_local(
                        st.session_state.customer_query_text_area,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=False,
                    )

                    st.stop()

                if not st.session_state.is_llm_ready or not LLM_API_KEY:
                    st.warning("API Keyê°€ ì—†ì–´ ëŒ€í™”í˜• ì‹œë®¬ë ˆì´ì…˜ì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    st.stop()

                # -----------------------------
                # 1) supervisor â†’ customer ì—­í• ë¡œ ë³€í™˜ (LLM)
                # -----------------------------
                next_prompt = f"""
            You are now ROLEPLAYING as the CUSTOMER.

            Analyze the dialogue so far and respond naturally.

            RULES:
            1. If the agent requested information â†’ provide EXACTLY ONE missing detail.
            2. If the agent provided a solution â†’ respond with appreciation.
            3. If appreciation is given â†’ ALWAYS respond with:
               "{L['customer_closing_confirm']}"
            4. If the agent already asked:
               "{L['customer_closing_confirm']}"
               AND the customer has no further questions:
               â†’ Respond with "{L['customer_positive_response']}"
               â†’ THEN the chat MUST END.
            5. Language MUST be {LANG[st.session_state.language]['lang_select']}.
                """

                # LLM ì‹¤í–‰
                with st.spinner(L["response_generating"]):
                    reaction = st.session_state.simulator_chain.predict(input=next_prompt)

                reaction_lower = reaction.lower()

                # íŒ¨í„´ ì •ì˜
                closing_user_signals = [
                    "ì—†ìŠµë‹ˆë‹¤", "ì—†ì–´ìš”", "ì—†ì–´",
                    "no more", "nothing else",
                    "çµæ§‹ã§ã™", "å¤§ä¸ˆå¤«ã§ã™"
                ]

                appreciation_signals = [
                    "ê°ì‚¬", "thank", "ã‚ã‚ŠãŒã¨ã†"
                ]

                # -----------------------------
                # 2) ê³ ê°ì´ "ì¢…ë£Œ ì˜ì‚¬" ì „ë‹¬
                # -----------------------------
                if any(k in reaction_lower for k in closing_user_signals):
                    st.session_state.simulator_messages.append(
                        {"role": "customer_end", "content": reaction}
                    )
                    st.session_state.simulator_messages.append(
                        {"role": "system_end", "content": L["prompt_survey"]}
                    )

                    st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)
                    st.session_state.simulator_memory.chat_memory.add_ai_message(L["prompt_survey"])

                    st.session_state.is_chat_ended = True

                    save_simulation_history_local(
                        st.session_state.customer_query_text_area,
                        customer_type_display,
                        st.session_state.simulator_messages,
                        is_chat_ended=True,
                    )
                    st.stop()

                # -----------------------------
                # 3) ê³ ê°ì´ ê°ì‚¬ ë©”ì‹œì§€ ë³´ë‚´ì˜´ â†’ supervisorê°€ closing ì§ˆë¬¸ ìë™ ë°œì†¡
                # -----------------------------
                # if any(k in reaction_lower for k in appreciation_signals):
                #     # ê³ ê° ê°ì‚¬ ë©”ì‹œì§€
                #     st.session_state.simulator_messages.append(
                #         {"role": "customer_rebuttal", "content": reaction}
                #     )
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)
                #
                #     follow_up = L["customer_closing_confirm"]
                #
                #     # supervisorê°€ ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ ì§ˆë¬¸
                #     st.session_state.simulator_messages.append(
                #         {"role": "supervisor", "content": follow_up}
                #     )
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(follow_up)
                #
                #     save_simulation_history_local(
                #         st.session_state.customer_query_text_area,
                #         customer_type_display,
                #         st.session_state.simulator_messages,
                #         is_chat_ended=False,
                #     )
                #     st.stop()

                # -----------------------------
                # 4) ê¸°íƒ€ ì¼ë°˜ ë°˜ì‘
                # -----------------------------
                st.session_state.simulator_messages.append(
                    {"role": "customer_rebuttal", "content": reaction}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.simulator_messages,
                    is_chat_ended=False,
                )
                st.stop()

                # 2) ê³ ê°ì´ ê°ì‚¬ ì¸ì‚¬ â†’ ë°˜ë“œì‹œ â€œì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€â€ í™•ì¸ ë©”ì‹œì§€ ë°œì†¡
                # if any(k in reaction_lower for k in appreciation_signals):
                #     follow_up = L["customer_closing_confirm"]
                #
                #     st.session_state.simulator_messages.append(
                #         {"role": "customer_rebuttal", "content": reaction}
                #     )
                #     st.session_state.simulator_messages.append(
                #         {"role": "supervisor", "content": follow_up}
                #     )
                #
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)
                #     st.session_state.simulator_memory.chat_memory.add_ai_message(follow_up)
                #
                #     save_simulation_history_local(
                #         st.session_state.customer_query_text_area,
                #         customer_type_display,
                #         st.session_state.simulator_messages,
                #         is_chat_ended=False,
                #     )
                #     st.stop()

                # 3) ê·¸ ì™¸ ì¼ë°˜ì  ë°˜ì‘
                st.session_state.simulator_messages.append(
                    {"role": "customer_rebuttal", "content": reaction}
                )
                st.session_state.simulator_memory.chat_memory.add_ai_message(reaction)

                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display,
                    st.session_state.simulator_messages,
                    is_chat_ended=False,
                )

                if is_positive:
                            st.session_state.is_chat_ended = True
                        # st.rerun()

# -------------------- RAG Tab --------------------
elif feature_selection == L["rag_tab"]:
    st.header(L["rag_header"])
    st.markdown(L["rag_desc"])

    if not st.session_state.is_rag_ready or st.session_state.rag_vectorstore is None:
        # ì´ë¯¸ ì €ì¥ëœ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ë¡œë“œ ì‹œë„
        if st.session_state.is_llm_ready:
            vs = load_rag_index(st.session_state.embeddings)
            if vs is not None:
                st.session_state.rag_vectorstore = vs
                st.session_state.is_rag_ready = True
            else:
                st.info(L["warning_rag_not_ready"])
        else:
            st.info(L["warning_rag_not_ready"])

    if st.session_state.is_rag_ready and st.session_state.rag_vectorstore is not None:
        # ê¸°ì¡´ ëŒ€í™” ë¡œê·¸ í‘œì‹œ
        for m in st.session_state.rag_messages:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        user_q = st.chat_input(L["rag_input_placeholder"])
        if user_q:
            st.session_state.rag_messages.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)
            with st.chat_message("assistant"):
                with st.spinner(L["response_generating"]):
                    try:
                        ans = rag_answer(user_q, st.session_state.rag_vectorstore, st.session_state.language)
                        st.markdown(ans)
                        st.session_state.rag_messages.append({"role": "assistant", "content": ans})
                    except Exception as e:
                        st.error(f"ì±—ë´‡ ì˜¤ë¥˜: {e}")
                        msg = "ì˜¤ë¥˜ ë°œìƒ" if st.session_state.language == "ko" else "An error occurred"
                        st.session_state.rag_messages.append({"role": "assistant", "content": msg})
    else:
        st.warning(L["warning_rag_not_ready"])

# -------------------- Content Tab --------------------
elif feature_selection == L["content_tab"]:
    st.header(L["content_header"])
    st.markdown(L["content_desc"])

    if not st.session_state.is_llm_ready:
        st.error(L["llm_error_init"])
    else:
        topic = st.text_input(L["topic_label"])
        level_display = st.selectbox(L["level_label"], L["level_options"])
        content_display = st.selectbox(L["content_type_label"], L["content_options"])

        level_map = {
            "ì´ˆê¸‰": "Beginner",
            "ì¤‘ê¸‰": "Intermediate",
            "ê³ ê¸‰": "Advanced",
            "Beginner": "Beginner",
            "Intermediate": "Intermediate",
            "Advanced": "Advanced",
            "åˆç´š": "Beginner",
            "ä¸­ç´š": "Intermediate",
            "ä¸Šç´š": "Advanced",
        }
        content_map = {
            "í•µì‹¬ ìš”ì•½ ë…¸íŠ¸": "summary",
            "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­": "quiz",
            "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´": "example",
            "Key Summary Note": "summary",
            "10 Multiple-Choice Questions": "quiz",
            "Practical Example Idea": "example",
            "æ ¸å¿ƒè¦ç´„ãƒãƒ¼ãƒˆ": "summary",
            "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•": "quiz",
            "å®Ÿè·µä¾‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢": "example",
        }

        level = level_map.get(level_display, "Beginner")
        content_type = content_map.get(content_display, "summary")

        if st.button(L["button_generate"]):
            if not topic.strip():
                st.warning(L["warning_topic"])
            else:
                target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]

                if content_type == "quiz":
                    system_prompt = (
                        "You are an expert quiz creator.\n"
                        "Generate EXACTLY 10 multiple-choice questions.\n"
                        "Return ONLY valid JSON wrapped inside ```json ... ```.\n"
                        "JSON structure:\n"
                        "{\n"
                        '  \"quiz_questions\": [\n'
                        "    {\n"
                        '      \"question\": \"...\",\n'
                        '      \"options\": [\"A\", \"B\", \"C\", \"D\"],\n'
                        '      \"correct_index\": 0,\n'
                        '      \"explanation\": \"...\"\n'
                        "    }\n"
                        "  ]\n"
                        "}\n"
                        f"The language of questions MUST be {target_lang}.\n"
                    )
                    user_msg = f"Topic: {topic} (level: {level})"
                    with st.spinner("í€´ì¦ˆ ìƒì„± ì¤‘..."):
                        try:
                            resp = st.session_state.llm.invoke(system_prompt + "\n\n" + user_msg)
                            raw = resp.content if hasattr(resp, "content") else str(resp)
                            # ë‹¨ìˆœ ì¶œë ¥
                            st.success(f"**{topic}** - {content_display}")
                            st.code(raw, language="json")
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")
                else:
                    content_prompt = (
                        f"You are a professional AI coach at the {level} level.\n"
                        f"Generate clear and educational content in {target_lang}.\n"
                        f"Content type: {content_display}.\n"
                        f"Topic: {topic}\n"
                    )
                    with st.spinner("ì½˜í…ì¸  ìƒì„± ì¤‘..."):
                        try:
                            resp = st.session_state.llm.invoke(content_prompt)
                            txt = resp.content if hasattr(resp, "content") else str(resp)
                            st.success(f"**{topic}** - {content_display}")
                            st.markdown(txt)
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")

# -------------------- LSTM Tab --------------------
elif feature_selection == L["lstm_tab"]:
    st.header(L["lstm_header"])
    st.markdown(L["lstm_desc"])

    if st.button(L["lstm_rerun_button"]):
        st.rerun()

    try:
        data = load_or_train_lstm()
        predicted_score = float(np.clip(data[-1] + np.random.uniform(-3, 5), 50, 100))

        st.markdown("---")
        st.subheader(L["lstm_result_header"])

        col_score, col_chart = st.columns([1, 2])

        with col_score:
            suffix = "ì " if st.session_state.language == "ko" else ""
            st.metric(L["lstm_score_metric"], f"{predicted_score:.1f}{suffix}")
            st.info(L["lstm_score_info"].format(predicted_score=predicted_score))

        with col_chart:
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(data, label="Past Scores", marker="o")
            ax.plot(len(data), predicted_score, marker="*", markersize=10)
            ax.set_title(L["lstm_header"])
            ax.set_xlabel("Time (attempts)")
            ax.set_ylabel("Score (0-100)")
            ax.legend()
            st.pyplot(fig)
    except Exception as e:
        st.info(f"LSTM ê¸°ëŠ¥ ì—ëŸ¬: {e}")
