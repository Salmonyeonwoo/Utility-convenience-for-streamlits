# ========================================
# Streamlit AI í•™ìŠµ ì½”ì¹˜ (ìµœì¢… Firebase ì˜êµ¬ ì €ì¥ì†Œ í†µí•© ë° ì‹œë®¬ë ˆì´í„° í™•ì¥)
# ========================================
import streamlit as st
import os
import tempfile
import time
import json
import re
import base64
import io

# â­ Admin SDK ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from firebase_admin import credentials, firestore, initialize_app, get_app
# Admin SDKì˜ firestoreì™€ Google Cloud SDKì˜ firestoreë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ alias ì‚¬ìš©
from google.cloud import firestore as gcp_firestore
from google.cloud.firestore import Query # Firestore ì¿¼ë¦¬ìš© import ì¶”ê°€

# ConversationChain ì‚¬ìš©ì„ ìœ„í•´ import ì¶”ê°€
from langchain.chains import ConversationalRetrievalChain, ConversationChain
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.memory import ConversationBufferMemory
from langchain.schema.document import Document
from langchain.prompts import PromptTemplate # â­ PromptTemplate ì„í¬íŠ¸
import numpy as np
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense


# ================================
# 1. Firebase Admin SDK ì´ˆê¸°í™” ë° Secrets ì²˜ë¦¬ í•¨ìˆ˜
# ================================

def _get_admin_credentials():
    """Secretsì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œí•˜ê³  ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if "FIREBASE_SERVICE_ACCOUNT_JSON" not in st.secrets:
        return None, "FIREBASE_SERVICE_ACCOUNT_JSON Secretì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    service_account_data = st.secrets["FIREBASE_SERVICE_ACCOUNT_JSON"]
    sa_info = None

    if isinstance(service_account_data, str):
        try:
            sa_info = json.loads(service_account_data.strip())
        except json.JSONDecodeError as e:
            return None, f"FIREBASE_SERVICE_ACCOUNT_JSONì˜ JSON êµ¬ë¬¸ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ê°’ì„ í™•ì¸í•˜ì„¸ìš”. ìƒì„¸ ì˜¤ë¥˜: {e}"
    elif hasattr(service_account_data, 'get'):
        try:
            sa_info = dict(service_account_data) # AttrDictë¥¼ í‘œì¤€ dictë¡œ ë³€í™˜
        except Exception:
             return None, f"FIREBASE_SERVICE_ACCOUNT_JSONì˜ ë”•ì…”ë„ˆë¦¬ ë³€í™˜ ì‹¤íŒ¨. íƒ€ì…: {type(service_account_data)}"
    else:
        return None, f"FIREBASE_SERVICE_ACCOUNT_JSONì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (Type: {type(service_account_data)})"
    
    if not sa_info.get("project_id") or not sa_info.get("private_key"):
        return None, "JSON ë‚´ 'project_id' ë˜ëŠ” 'private_key' í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."

    return sa_info, None

@st.cache_resource(ttl=None)
def initialize_firestore_admin():
    """Secretsì—ì„œ ë¡œë“œëœ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ Firebase Admin SDKë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    sa_info, error_message = _get_admin_credentials()

    if error_message:
        st.error(f"âŒ Firebase Secret ì˜¤ë¥˜: {error_message}")
        return None

    try:
        get_app()
    except ValueError:
        pass 
    else:
        try:
            return firestore.client()
        except Exception as e:
            st.error(f"ğŸ”¥ Firebase í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    try:
        cred = credentials.Certificate(sa_info) 
        initialize_app(cred)
        
        db_client = firestore.client()
        st.session_state["db"] = db_client
        st.success("âœ… Firebase Admin SDK ì´ˆê¸°í™” ì™„ë£Œ! (Secrets ê¸°ë°˜)")
        return db_client
    except Exception as e:
        st.error(f"ğŸ”¥ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ ë¬¸ì œ. ì˜¤ë¥˜: {e}")
        return None


def save_index_to_firestore(db, vector_store, index_id="user_portfolio_rag"):
    """FAISS ì¸ë±ìŠ¤ë¥¼ Firestoreì— Base64 í˜•íƒœë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤."""
    if not db: return False
    temp_dir = tempfile.mkdtemp()
    
    try:
        vector_store.save_local(folder_path=temp_dir, index_name="index")
        
        with open(f"{temp_dir}/index.faiss", "rb") as f: faiss_bytes = f.read()
        with open(f"{temp_dir}/index.pkl", "rb") as f: metadata_bytes = f.read()
        
        encoded_data = {
            "faiss_data": base64.b64encode(faiss_bytes).decode('utf-8'),
            "metadata_data": base64.b64encode(metadata_bytes).decode('utf-8'),
            "timestamp": gcp_firestore.SERVER_TIMESTAMP 
        }
        
        db.collection("rag_indices").document(index_id).set(encoded_data)
        return True
    
    except Exception as e:
        st.error(f"DB ì €ì¥ ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"Error saving index to Firestore: {e}")
        return False

def load_index_from_firestore(db, embeddings, index_id="user_portfolio_rag"):
    """Firestoreì—ì„œ Base64 ë¬¸ìì—´ì„ ë¡œë“œí•˜ì—¬ FAISS ì¸ë±ìŠ¤ë¡œ ì—­ì§ë ¬í™”í•©ë‹ˆë‹¤."""
    if not db: return False

    try:
        doc = db.collection("rag_indices").document(index_id).get()
        if not doc.exists:
            return None 

        encoded_data = doc.to_dict()
        
        faiss_bytes = base64.b64decode(encoded_data["faiss_data"])
        metadata_bytes = base64.b64decode(encoded_data["metadata_data"])
        
        temp_dir = tempfile.mkdtemp()
        with open(f"{temp_dir}/index.faiss", "wb") as f: f.write(faiss_bytes)
        with open(f"{temp_dir}/index.pkl", "wb") as f: f.write(metadata_bytes)
        
        vector_store = FAISS.load_local(folder_path=temp_dir, embeddings=embeddings, index_name="index")
        return vector_store
        
    except Exception as e:
        print(f"Error loading index from Firestore: {e}")
        return None

# â­ ìƒë‹´ ì´ë ¥ ì €ì¥ í•¨ìˆ˜ ì¶”ê°€
def save_simulation_history(db, initial_query, customer_type, messages):
    """Firestoreì— ìƒë‹´ ì´ë ¥ì„ ì €ì¥í•©ë‹ˆë‹¤."""
    if not db: 
        st.sidebar.warning("âŒ DB ì—°ê²° ì‹¤íŒ¨: ìƒë‹´ ì´ë ¥ ì €ì¥ ë¶ˆê°€")
        return False
    
    # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    history_data = [{k: v for k, v in msg.items()} for msg in messages]

    data = {
        "initial_query": initial_query,
        "customer_type": customer_type,
        "messages": history_data,
        "timestamp": firestore.SERVER_TIMESTAMP
    }
    
    try:
        db.collection("simulation_histories").add(data)
        st.sidebar.success("âœ… ìƒë‹´ ì´ë ¥ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
    except Exception as e:
        st.sidebar.error(f"âŒ ìƒë‹´ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

# â­ ìƒë‹´ ì´ë ¥ ë¡œë“œ í•¨ìˆ˜ ì¶”ê°€
def load_simulation_histories(db):
    """Firestoreì—ì„œ ìµœê·¼ ìƒë‹´ ì´ë ¥ì„ ë¡œë“œí•©ë‹ˆë‹¤ (ìµœëŒ€ 10ê°œ)."""
    if not db: return []
    
    try:
        # ìµœê·¼ 10ê°œ ì´ë ¥ì„ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì ¸ì˜´
        histories = (
            db.collection("simulation_histories")
            .order_by("timestamp", direction=Query.DESCENDING)
            .limit(10)
            .stream()
        )
        
        results = []
        for doc in histories:
            data = doc.to_dict()
            data['id'] = doc.id
            
            # ë©”ì‹œì§€ ë°ì´í„°ê°€ ì§ë ¬í™”ëœ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if 'messages' in data and isinstance(data['messages'], list) and data['messages']:
                results.append(data)

        return results
    except Exception as e:
        st.error(f"âŒ ì´ë ¥ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

# ================================
# 2. JSON/RAG/LSTM/TTS í•¨ìˆ˜ ì •ì˜
# ================================
def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # TTS ë²„íŠ¼ì€ LLM ì‘ë‹µ ì‹œì ì—ë§Œ ë‚˜íƒ€ë‚˜ë„ë¡ render_tts_button ì™¸ë¶€ì—ì„œ ì œì–´ë©ë‹ˆë‹¤.
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def render_interactive_quiz(quiz_data, current_lang):
    """ìƒì„±ëœ í€´ì¦ˆ ë°ì´í„°ë¥¼ Streamlit UIë¡œ ë Œë”ë§í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    L = LANG[current_lang]
    if not quiz_data or 'quiz_questions' not in quiz_data: return

    questions = quiz_data['quiz_questions']
    num_questions = len(questions)

    if "current_question" not in st.session_state or st.session_state.current_question >= num_questions:
        st.session_state.current_question = 0
        st.session_state.quiz_results = [None] * num_questions
        st.session_state.quiz_submitted = False
        
    q_index = st.session_state.current_question
    q_data = questions[q_index]
    
    st.subheader(f"{q_index + 1}. {q_data['question']}")
    
    options_dict = {}
    try:
        options_dict = {f"{opt['option']}": f"{opt['option']}) {opt['text']}" for opt in q_data['options']}
    except KeyError:
        st.error(L["quiz_fail_structure"])
        if 'quiz_data_raw' in st.session_state: st.code(st.session_state.quiz_data_raw, language="json")
        return

    options_list = list(options_dict.values())
    
    selected_answer = st.radio(
        L.get("select_answer", "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”"),
        options=options_list,
        key=f"q_radio_{q_index}"
    )

    col1, col2 = st.columns(2)

    if col1.button(L.get("check_answer", "ì •ë‹µ í™•ì¸"), key=f"check_btn_{q_index}", disabled=st.session_state.quiz_submitted):
        user_choice_letter = selected_answer.split(')')[0] if selected_answer else None
        correct_answer_letter = q_data['correct_answer']

        is_correct = (user_choice_letter == correct_answer_letter)
        
        st.session_state.quiz_results[q_index] = is_correct
        st.session_state.quiz_submitted = True
        
        if is_correct:
            st.success(L.get("correct_answer", "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰"))
        else:
            st.error(L.get("incorrect_answer", "ì˜¤ë‹µì…ë‹ˆë‹¤.ğŸ˜"))
        
        st.markdown(f"**{L.get('correct_is', 'ì •ë‹µ')}: {correct_answer_letter}**")
        st.info(f"**{L.get('explanation', 'í•´ì„¤')}:** {q_data['explanation']}")

    if st.session_state.quiz_submitted:
        if q_index < num_questions - 1:
            if col2.button(L.get("next_question", "ë‹¤ìŒ ë¬¸í•­"), key=f"next_btn_{q_index}"):
                st.session_state.current_question += 1
                st.session_state.quiz_submitted = False
                st.rerun()
        else:
            total_correct = st.session_state.quiz_results.count(True)
            total_questions = len(st.session_state.quiz_results)
            st.success(f"**{L.get('quiz_complete', 'í€´ì¦ˆ ì™„ë£Œ!')}** {L.get('score', 'ì ìˆ˜')}: {total_correct}/{total_questions}")
            if st.button(L.get("retake_quiz", "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°"), key="retake"):
                st.session_state.current_question = 0
                st.session_state.quiz_results = [None] * num_questions
                st.session_state.quiz_submitted = False
                st.rerun()

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def render_interactive_quiz(quiz_data, current_lang):
    """ìƒì„±ëœ í€´ì¦ˆ ë°ì´í„°ë¥¼ Streamlit UIë¡œ ë Œë”ë§í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    L = LANG[current_lang]
    if not quiz_data or 'quiz_questions' not in quiz_data: return

    questions = quiz_data['quiz_questions']
    num_questions = len(questions)

    if "current_question" not in st.session_state or st.session_state.current_question >= num_questions:
        st.session_state.current_question = 0
        st.session_state.quiz_results = [None] * num_questions
        st.session_state.quiz_submitted = False
        
    q_index = st.session_state.current_question
    q_data = questions[q_index]
    
    st.subheader(f"{q_index + 1}. {q_data['question']}")
    
    options_dict = {}
    try:
        options_dict = {f"{opt['option']}": f"{opt['option']}) {opt['text']}" for opt in q_data['options']}
    except KeyError:
        st.error(L["quiz_fail_structure"])
        if 'quiz_data_raw' in st.session_state: st.code(st.session_state.quiz_data_raw, language="json")
        return

    options_list = list(options_dict.values())
    
    selected_answer = st.radio(
        L.get("select_answer", "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”"),
        options=options_list,
        key=f"q_radio_{q_index}"
    )

    col1, col2 = st.columns(2)

    if col1.button(L.get("check_answer", "ì •ë‹µ í™•ì¸"), key=f"check_btn_{q_index}", disabled=st.session_state.quiz_submitted):
        user_choice_letter = selected_answer.split(')')[0] if selected_answer else None
        correct_answer_letter = q_data['correct_answer']

        is_correct = (user_choice_letter == correct_answer_letter)
        
        st.session_state.quiz_results[q_index] = is_correct
        st.session_state.quiz_submitted = True
        
        if is_correct:
            st.success(L.get("correct_answer", "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰"))
        else:
            st.error(L.get("incorrect_answer", "ì˜¤ë‹µì…ë‹ˆë‹¤.ğŸ˜"))
        
        st.markdown(f"**{L.get('correct_is', 'ì •ë‹µ')}: {correct_answer_letter}**")
        st.info(f"**{L.get('explanation', 'í•´ì„¤')}:** {q_data['explanation']}")

    if st.session_state.quiz_submitted:
        if q_index < num_questions - 1:
            if col2.button(L.get("next_question", "ë‹¤ìŒ ë¬¸í•­"), key=f"next_btn_{q_index}"):
                st.session_state.current_question += 1
                st.session_state.quiz_submitted = False
                st.rerun()
        else:
            total_correct = st.session_state.quiz_results.count(True)
            total_questions = len(st.session_state.quiz_results)
            st.success(f"**{L.get('quiz_complete', 'í€´ì¦ˆ ì™„ë£Œ!')}** {L.get('score', 'ì ìˆ˜')}: {total_correct}/{total_questions}")
            if st.button(L.get("retake_quiz", "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°"), key="retake"):
                st.session_state.current_question = 0
                st.session_state.quiz_results = [None] * num_questions
                st.session_state.quiz_submitted = False
                st.rerun()

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def render_interactive_quiz(quiz_data, current_lang):
    """ìƒì„±ëœ í€´ì¦ˆ ë°ì´í„°ë¥¼ Streamlit UIë¡œ ë Œë”ë§í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    L = LANG[current_lang]
    if not quiz_data or 'quiz_questions' not in quiz_data: return

    questions = quiz_data['quiz_questions']
    num_questions = len(questions)

    if "current_question" not in st.session_state or st.session_state.current_question >= num_questions:
        st.session_state.current_question = 0
        st.session_state.quiz_results = [None] * num_questions
        st.session_state.quiz_submitted = False
        
    q_index = st.session_state.current_question
    q_data = questions[q_index]
    
    st.subheader(f"{q_index + 1}. {q_data['question']}")
    
    options_dict = {}
    try:
        options_dict = {f"{opt['option']}": f"{opt['option']}) {opt['text']}" for opt in q_data['options']}
    except KeyError:
        st.error(L["quiz_fail_structure"])
        if 'quiz_data_raw' in st.session_state: st.code(st.session_state.quiz_data_raw, language="json")
        return

    options_list = list(options_dict.values())
    
    selected_answer = st.radio(
        L.get("select_answer", "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”"),
        options=options_list,
        key=f"q_radio_{q_index}"
    )

    col1, col2 = st.columns(2)

    if col1.button(L.get("check_answer", "ì •ë‹µ í™•ì¸"), key=f"check_btn_{q_index}", disabled=st.session_state.quiz_submitted):
        user_choice_letter = selected_answer.split(')')[0] if selected_answer else None
        correct_answer_letter = q_data['correct_answer']

        is_correct = (user_choice_letter == correct_answer_letter)
        
        st.session_state.quiz_results[q_index] = is_correct
        st.session_state.quiz_submitted = True
        
        if is_correct:
            st.success(L.get("correct_answer", "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰"))
        else:
            st.error(L.get("incorrect_answer", "ì˜¤ë‹µì…ë‹ˆë‹¤.ğŸ˜"))
        
        st.markdown(f"**{L.get('correct_is', 'ì •ë‹µ')}: {correct_answer_letter}**")
        st.info(f"**{L.get('explanation', 'í•´ì„¤')}:** {q_data['explanation']}")

    if st.session_state.quiz_submitted:
        if q_index < num_questions - 1:
            if col2.button(L.get("next_question", "ë‹¤ìŒ ë¬¸í•­"), key=f"next_btn_{q_index}"):
                st.session_state.current_question += 1
                st.session_state.quiz_submitted = False
                st.rerun()
        else:
            total_correct = st.session_state.quiz_results.count(True)
            total_questions = len(st.session_state.quiz_results)
            st.success(f"**{L.get('quiz_complete', 'í€´ì¦ˆ ì™„ë£Œ!')}** {L.get('score', 'ì ìˆ˜')}: {total_correct}/{total_questions}")
            if st.button(L.get("retake_quiz", "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°"), key="retake"):
                st.session_state.current_question = 0
                st.session_state.quiz_results = [None] * num_questions
                st.session_state.quiz_submitted = False
                st.rerun()

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def render_interactive_quiz(quiz_data, current_lang):
    """ìƒì„±ëœ í€´ì¦ˆ ë°ì´í„°ë¥¼ Streamlit UIë¡œ ë Œë”ë§í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    L = LANG[current_lang]
    if not quiz_data or 'quiz_questions' not in quiz_data: return

    questions = quiz_data['quiz_questions']
    num_questions = len(questions)

    if "current_question" not in st.session_state or st.session_state.current_question >= num_questions:
        st.session_state.current_question = 0
        st.session_state.quiz_results = [None] * num_questions
        st.session_state.quiz_submitted = False
        
    q_index = st.session_state.current_question
    q_data = questions[q_index]
    
    st.subheader(f"{q_index + 1}. {q_data['question']}")
    
    options_dict = {}
    try:
        options_dict = {f"{opt['option']}": f"{opt['option']}) {opt['text']}" for opt in q_data['options']}
    except KeyError:
        st.error(L["quiz_fail_structure"])
        if 'quiz_data_raw' in st.session_state: st.code(st.session_state.quiz_data_raw, language="json")
        return

    options_list = list(options_dict.values())
    
    selected_answer = st.radio(
        L.get("select_answer", "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”"),
        options=options_list,
        key=f"q_radio_{q_index}"
    )

    col1, col2 = st.columns(2)

    if col1.button(L.get("check_answer", "ì •ë‹µ í™•ì¸"), key=f"check_btn_{q_index}", disabled=st.session_state.quiz_submitted):
        user_choice_letter = selected_answer.split(')')[0] if selected_answer else None
        correct_answer_letter = q_data['correct_answer']

        is_correct = (user_choice_letter == correct_answer_letter)
        
        st.session_state.quiz_results[q_index] = is_correct
        st.session_state.quiz_submitted = True
        
        if is_correct:
            st.success(L.get("correct_answer", "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰"))
        else:
            st.error(L.get("incorrect_answer", "ì˜¤ë‹µì…ë‹ˆë‹¤.ğŸ˜"))
        
        st.markdown(f"**{L.get('correct_is', 'ì •ë‹µ')}: {correct_answer_letter}**")
        st.info(f"**{L.get('explanation', 'í•´ì„¤')}:** {q_data['explanation']}")

    if st.session_state.quiz_submitted:
        if q_index < num_questions - 1:
            if col2.button(L.get("next_question", "ë‹¤ìŒ ë¬¸í•­"), key=f"next_btn_{q_index}"):
                st.session_state.current_question += 1
                st.session_state.quiz_submitted = False
                st.rerun()
        else:
            total_correct = st.session_state.quiz_results.count(True)
            total_questions = len(st.session_state.quiz_results)
            st.success(f"**{L.get('quiz_complete', 'í€´ì¦ˆ ì™„ë£Œ!')}** {L.get('score', 'ì ìˆ˜')}: {total_correct}/{total_questions}")
            if st.button(L.get("retake_quiz", "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°"), key="retake"):
                st.session_state.current_question = 0
                st.session_state.quiz_results = [None] * num_questions
                st.session_state.quiz_submitted = False
                st.rerun()

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def render_interactive_quiz(quiz_data, current_lang):
    """ìƒì„±ëœ í€´ì¦ˆ ë°ì´í„°ë¥¼ Streamlit UIë¡œ ë Œë”ë§í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    L = LANG[current_lang]
    if not quiz_data or 'quiz_questions' not in quiz_data: return

    questions = quiz_data['quiz_questions']
    num_questions = len(questions)

    if "current_question" not in st.session_state or st.session_state.current_question >= num_questions:
        st.session_state.current_question = 0
        st.session_state.quiz_results = [None] * num_questions
        st.session_state.quiz_submitted = False
        
    q_index = st.session_state.current_question
    q_data = questions[q_index]
    
    st.subheader(f"{q_index + 1}. {q_data['question']}")
    
    options_dict = {}
    try:
        options_dict = {f"{opt['option']}": f"{opt['option']}) {opt['text']}" for opt in q_data['options']}
    except KeyError:
        st.error(L["quiz_fail_structure"])
        if 'quiz_data_raw' in st.session_state: st.code(st.session_state.quiz_data_raw, language="json")
        return

    options_list = list(options_dict.values())
    
    selected_answer = st.radio(
        L.get("select_answer", "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”"),
        options=options_list,
        key=f"q_radio_{q_index}"
    )

    col1, col2 = st.columns(2)

    if col1.button(L.get("check_answer", "ì •ë‹µ í™•ì¸"), key=f"check_btn_{q_index}", disabled=st.session_state.quiz_submitted):
        user_choice_letter = selected_answer.split(')')[0] if selected_answer else None
        correct_answer_letter = q_data['correct_answer']

        is_correct = (user_choice_letter == correct_answer_letter)
        
        st.session_state.quiz_results[q_index] = is_correct
        st.session_state.quiz_submitted = True
        
        if is_correct:
            st.success(L.get("correct_answer", "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰"))
        else:
            st.error(L.get("incorrect_answer", "ì˜¤ë‹µì…ë‹ˆë‹¤.ğŸ˜"))
        
        st.markdown(f"**{L.get('correct_is', 'ì •ë‹µ')}: {correct_answer_letter}**")
        st.info(f"**{L.get('explanation', 'í•´ì„¤')}:** {q_data['explanation']}")

    if st.session_state.quiz_submitted:
        if q_index < num_questions - 1:
            if col2.button(L.get("next_question", "ë‹¤ìŒ ë¬¸í•­"), key=f"next_btn_{q_index}"):
                st.session_state.current_question += 1
                st.session_state.quiz_submitted = False
                st.rerun()
        else:
            total_correct = st.session_state.quiz_results.count(True)
            total_questions = len(st.session_state.quiz_results)
            st.success(f"**{L.get('quiz_complete', 'í€´ì¦ˆ ì™„ë£Œ!')}** {L.get('score', 'ì ìˆ˜')}: {total_correct}/{total_questions}")
            if st.button(L.get("retake_quiz", "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°"), key="retake"):
                st.session_state.current_question = 0
                st.session_state.quiz_results = [None] * num_questions
                st.session_state.quiz_submitted = False
                st.rerun()

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def render_interactive_quiz(quiz_data, current_lang):
    """ìƒì„±ëœ í€´ì¦ˆ ë°ì´í„°ë¥¼ Streamlit UIë¡œ ë Œë”ë§í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    L = LANG[current_lang]
    if not quiz_data or 'quiz_questions' not in quiz_data: return

    questions = quiz_data['quiz_questions']
    num_questions = len(questions)

    if "current_question" not in st.session_state or st.session_state.current_question >= num_questions:
        st.session_state.current_question = 0
        st.session_state.quiz_results = [None] * num_questions
        st.session_state.quiz_submitted = False
        
    q_index = st.session_state.current_question
    q_data = questions[q_index]
    
    st.subheader(f"{q_index + 1}. {q_data['question']}")
    
    options_dict = {}
    try:
        options_dict = {f"{opt['option']}": f"{opt['option']}) {opt['text']}" for opt in q_data['options']}
    except KeyError:
        st.error(L["quiz_fail_structure"])
        if 'quiz_data_raw' in st.session_state: st.code(st.session_state.quiz_data_raw, language="json")
        return

    options_list = list(options_dict.values())
    
    selected_answer = st.radio(
        L.get("select_answer", "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”"),
        options=options_list,
        key=f"q_radio_{q_index}"
    )

    col1, col2 = st.columns(2)

    if col1.button(L.get("check_answer", "ì •ë‹µ í™•ì¸"), key=f"check_btn_{q_index}", disabled=st.session_state.quiz_submitted):
        user_choice_letter = selected_answer.split(')')[0] if selected_answer else None
        correct_answer_letter = q_data['correct_answer']

        is_correct = (user_choice_letter == correct_answer_letter)
        
        st.session_state.quiz_results[q_index] = is_correct
        st.session_state.quiz_submitted = True
        
        if is_correct:
            st.success(L.get("correct_answer", "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰"))
        else:
            st.error(L.get("incorrect_answer", "ì˜¤ë‹µì…ë‹ˆë‹¤.ğŸ˜"))
        
        st.markdown(f"**{L.get('correct_is', 'ì •ë‹µ')}: {correct_answer_letter}**")
        st.info(f"**{L.get('explanation', 'í•´ì„¤')}:** {q_data['explanation']}")

    if st.session_state.quiz_submitted:
        if q_index < num_questions - 1:
            if col2.button(L.get("next_question", "ë‹¤ìŒ ë¬¸í•­"), key=f"next_btn_{q_index}"):
                st.session_state.current_question += 1
                st.session_state.quiz_submitted = False
                st.rerun()
        else:
            total_correct = st.session_state.quiz_results.count(True)
            total_questions = len(st.session_state.quiz_results)
            st.success(f"**{L.get('quiz_complete', 'í€´ì¦ˆ ì™„ë£Œ!')}** {L.get('score', 'ì ìˆ˜')}: {total_correct}/{total_questions}")
            if st.button(L.get("retake_quiz", "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°"), key="retake"):
                st.session_state.current_question = 0
                st.session_state.quiz_results = [None] * num_questions
                st.session_state.quiz_submitted = False
                st.rerun()

def synthesize_and_play_audio(current_lang_key):
    """TTS API ëŒ€ì‹  Web Speech APIë¥¼ ìœ„í•œ JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlitì— ì‚½ì…í•©ë‹ˆë‹¤."""
    
    # í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë‚´ë¶€ì—ì„œ L ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
    ko_ready = "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨"
    en_ready = "Ready to listen"
    ja_ready = "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ"

    tts_js_code = f"""
    <script>
    if (!window.speechSynthesis) {{
        document.getElementById('tts_status').innerText = 'âŒ TTS Not Supported';
    }}

    window.speakText = function(text, langKey) {{
        if (!window.speechSynthesis || !text) return;

        const statusElement = document.getElementById('tts_status');
        const utterance = new SpeechSynthesisUtterance(text);
        
        // ë™ì ìœ¼ë¡œ ì–¸ì–´ ì½”ë“œ ì„¤ì •
        const langCode = {{ "ko": "ko-KR", "en": "en-US", "ja": "ja-JP" }}[langKey] || "en-US";
        utterance.lang = langCode; 

        // ë™ì ìœ¼ë¡œ ì¤€ë¹„ ìƒíƒœ ë©”ì‹œì§€ ì„¤ì • (L ë”•ì…”ë„ˆë¦¬ ê°’ì„ ì§ì ‘ ì‚¬ìš©)
        const getReadyText = (key) => {{
            if (key === 'ko') return '{ko_ready}';
            if (key === 'en') return '{en_ready}';
            if (key === 'ja') return '{ja_ready}';
            return '{en_ready}';
        }};

        let voicesLoaded = false;
        const setVoiceAndSpeak = () => {{
            const voices = window.speechSynthesis.getVoices();
            if (voices.length > 0) {{
                // í˜„ì¬ ì–¸ì–´ ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ìŒì„±ì„ ì°¾ê±°ë‚˜, ì²« ë²ˆì§¸ ìŒì„±ì„ ì‚¬ìš©
                utterance.voice = voices.find(v => v.lang.startsWith(langCode.substring(0, 2))) || voices[0];
                voicesLoaded = true;
                window.speechSynthesis.speak(utterance);
            }} else if (!voicesLoaded) {{
                // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°, ì ì‹œ í›„ ì¬ì‹œë„ (ë¹„ë™ê¸° ë¡œë“œ ë¬¸ì œ í•´ê²°)
                setTimeout(setVoiceAndSpeak, 100);
            }}
        }};
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        utterance.onstart = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_generating", "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")}';
            statusElement.style.backgroundColor = '#fff3e0';
        }};
        
        utterance.onend = () => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_success", "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!")}';
            statusElement.style.backgroundColor = '#e8f5e9';
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3000);
        }};
        
        utterance.onerror = (event) => {{
            statusElement.innerText = '{LANG[current_lang_key].get("tts_status_error", "âŒ TTS ì˜¤ë¥˜ ë°œìƒ")}';
            statusElement.style.backgroundColor = '#ffebee';
            console.error("SpeechSynthesis Error:", event);
             setTimeout(() => {{ 
                 statusElement.innerText = getReadyText(langKey);
                 statusElement.style.backgroundColor = '#f0f0f0';
             }}, 3999);
        }};

        window.speechSynthesis.cancel(); // Stop any current speech
        setVoiceAndSpeak(); // ì¬ìƒ ì‹œì‘

    }};
    </script>
    """
    # JS ìœ í‹¸ë¦¬í‹°ë¥¼ Streamlit ì•±ì— ì»´í¬ë„ŒíŠ¸ë¡œ ì‚½ì… (ë†’ì´ ì¡°ì •í•˜ì—¬ ìƒíƒœì°½ë§Œ ë³´ì´ë„ë¡)
    st.components.v1.html(tts_js_code, height=5, width=0)

def render_tts_button(text_to_speak, current_lang_key):
    """TTS ë²„íŠ¼ UIë¥¼ ë Œë”ë§í•˜ê³  í´ë¦­ ì‹œ JS í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    # ì¤„ ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë”°ì˜´í‘œë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    safe_text = text_to_speak.replace('\n', ' ').replace('"', '\\"').replace("'", "\\'")
    
    # â­ JS í•¨ìˆ˜ì— ì–¸ì–´ í‚¤ë„ í•¨ê»˜ ì „ë‹¬
    js_call = f"window.speakText('{safe_text}', '{current_lang_key}')"

    st.markdown(f"""
        <button onclick="{js_call}"
                style="background-color: #4338CA; color: white; padding: 10px 20px; border-radius: 5px; cursor: pointer; border: none; width: 100%; font-weight: bold; margin-bottom: 10px;">
            {LANG[current_lang_key].get("button_listen_audio", "ìŒì„±ìœ¼ë¡œ ë“£ê¸°")} ğŸ§
        </button>
    """, unsafe_allow_html=True)


def get_mock_response_data(lang_key, customer_type):
    """API Keyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê°€ìƒ ì‘ëŒ€ ë°ì´í„° (ë‹¤êµ­ì–´ ì§€ì›)"""
    
    if lang_key == 'ko':
        initial_check = "ê³ ê°ë‹˜ì˜ ì„±í•¨, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“± ì •í™•í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
        tone = "ê³µê° ë° ì§„ì •"
        advice = "ì´ ê³ ê°ì€ ë§¤ìš° ê¹Œë‹¤ë¡œìš´ ì„±í–¥ì´ë¯€ë¡œ, ê°ì •ì— ê³µê°í•˜ë©´ì„œë„ ì •í•´ì§„ ì •ì±… ë‚´ì—ì„œ í•´ê²°ì±…ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ì„±ê¸‰í•œ í™•ë‹µì€ í”¼í•˜ì„¸ìš”."
        draft = f"""
{initial_check}

> ê³ ê°ë‹˜, ë¨¼ì € ì£¼ë¬¸í•˜ì‹  ìƒí’ˆ ë°°ì†¡ì´ ëŠ¦ì–´ì ¸ ë§ì´ ë¶ˆí¸í•˜ì…¨ì„ ì  ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> í˜„ì¬ ì‹œìŠ¤í…œ ìƒ í™•ì¸ëœ ë°”ë¡œëŠ” [ë°°ì†¡ ì§€ì—° ì‚¬ìœ  ì„¤ëª…]. 
> ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €í¬ê°€ [êµ¬ì²´ì ì¸ í•´ê²°ì±… 1: ì˜ˆ: ë‹´ë‹¹ íŒ€ì— ì§ì ‘ ì—°ë½] ë° [êµ¬ì²´ì ì¸ í•´ê²°ì±… 2: ì˜ˆ: ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¬í™•ì¸]ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.
> ì²˜ë¦¬ë˜ëŠ” ëŒ€ë¡œ ì˜¤ëŠ˜ ì˜¤í›„ [ì‹œê°„]ê¹Œì§€ ê³ ê°ë‹˜ê»˜ ê°œë³„ì ìœ¼ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
"""
    elif lang_key == 'en':
        initial_check = "Could you please confirm your accurate contact details, such as your full name, phone number, and email address?"
        tone = "Empathy and Calming Tone"
        advice = "This customer is highly dissatisfied. You must apologize sincerely, explain the status transparently, and provide concrete next steps to solve the problem within policy boundaries. Avoid making hasty promises."
        draft = f"""
{initial_check}

> Dear Customer, I sincerely apologize for the inconvenience caused by the delay in delivering your order. I completely understand your frustration.
> Our system indicates [Reason for delay]. 
> To resolve this, we will proceed with [Specific Solution 1: e.g., contacting the dedicated team immediately] and [Specific Solution 2: e.g., re-confirming the status update by end of day].
> We will contact you personally by [Time] this afternoon with an update.
"""
    elif lang_key == 'ja':
        initial_check = "ãŠå®¢æ§˜ã®æ°åã€ãŠé›»è©±ç•ªå·ã€Eãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€æ­£ç¢ºãªé€£çµ¡å…ˆæƒ…å ±ã‚’ç¢ºèªã•ã›ã¦ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ã€‚"
        tone = "å…±æ„Ÿã¨é®é™ãƒˆãƒ¼ãƒ³"
        advice = "ã“ã®ãŠå®¢æ§˜ã¯éå¸¸ã«é›£ã—ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã«å…±æ„Ÿã—ã¤ã¤ã‚‚ã€å®šã‚ã‚‰ã‚ŒãŸãƒãƒªã‚·ãƒ¼å†…ã§è§£æ±ºç­–ã‚’æ®µéšçš„ã«æç¤ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®‰æ˜“ãªç¢ºç´„ã¯é¿ã‘ã¦ãã ã•ã„ã€‚"
        draft = f"""
{initial_check}

> ãŠå®¢æ§˜ã€ã”æ³¨æ–‡å•†å“ã®é…é€ãŒé…ã‚Œã¦ã—ã¾ã„ã€å¤§å¤‰ã”è¿·æƒ‘ã‚’ãŠã‹ã‘ã—ã¦ãŠã‚Šã¾ã™ã“ã¨ã‚’å¿ƒã‚ˆã‚ŠãŠè©«ã³ç”³ã—ä¸Šã’ã¾ã™ã€‚ãŠå®¢æ§˜ã®ãŠæ°—æŒã¡ã€ååˆ†ç†è§£ã—ã¦ãŠã‚Šã¾ã™ã€‚
> ç¾åœ¨ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ãŸã¨ã“ã‚ã€[é…å»¶ã®ç†ç”±ã‚’èª¬æ˜]ã€‚
> ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å¼Šç¤¾ã«ã¦[å…·ä½“çš„ãªè§£æ±ºç­–1ï¼šä¾‹ï¼šæ‹…å½“ãƒãƒ¼ãƒ ã«ç›´æ¥é€£çµ¡]ãŠã‚ˆã³[å…·ä½“çš„ãªè§£æ±ºç­–2ï¼šä¾‹ï¼šæœ¬æ—¥ä¸­ã«å†åº¦çŠ¶æ³ã‚’ç¢ºèª]ã‚’ã„ãŸã—ã¾ã™ã€‚
> é€²æ—ãŒã‚ã‚Šæ¬¡ç¬¬ã€æœ¬æ—¥åˆå¾Œ[æ™‚é–“]ã¾ã§ã«å€‹åˆ¥ã«ã”é€£çµ¡å·®ã—ä¸Šã’ã¾ã™ã€‚
"""
    
    return {
        "advice_header": f"{LANG[lang_key]['simulation_advice_header']}",
        "advice": advice,
        "draft_header": f"{LANG[lang_key]['simulation_draft_header']} ({tone})",
        "draft": draft
    }

def get_closing_messages(lang_key):
    """ê³ ê° ì‘ëŒ€ ì¢…ë£Œ ì‹œ ì‚¬ìš©í•˜ëŠ” ë‹¤êµ­ì–´ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if lang_key == 'ko':
        return {
            "additional_query": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
            "chat_closing": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤. ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤."
        }
    elif lang_key == 'en':
        return {
            "additional_query": "Is there anything else we can assist you with today?",
            "chat_closing": "As there are no further inquiries, we will now end this chat session. Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions."
        }
    elif lang_key == 'ja':
        return {
            "additional_query": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
            "chat_closing": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚"
        }
    return get_closing_messages('ko') # ê¸°ë³¸ê°’


def get_document_chunks(files):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤."""
    documents = []
    temp_dir = tempfile.mkdtemp()
    for uploaded_file in files:
        temp_filepath = os.path.join(temp_dir, uploaded_file.name)
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension == "pdf":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = PyPDFLoader(temp_filepath)
            documents.extend(loader.load())
        elif file_extension == "html":
            raw_html = uploaded_file.getvalue().decode('utf-8')
            soup = BeautifulSoup(raw_html, 'html.parser')
            text_content = soup.get_text(separator=' ', strip=True)
            documents.append(Document(page_content=text_content, metadata={"source": uploaded_file.name}))
        elif file_extension == "txt":
            with open(temp_filepath, "wb") as f: f.write(uploaded_file.getvalue())
            loader = TextLoader(temp_filepath, encoding="utf-8")
            documents.extend(loader.load())
        else:
            print(f"File '{uploaded_file.name}' not supported.")
            continue
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return text_splitter.split_documents(documents)

def get_vector_store(text_chunks):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Vector Storeë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(doc.page_content for doc in text_chunks)
    if cache_key in st.session_state.embedding_cache: return st.session_state.embedding_cache[cache_key]
    if not st.session_state.is_llm_ready: return None
    try:
        vector_store = FAISS.from_documents(text_chunks, embedding=st.session_state.embeddings)
        st.session_state.embedding_cache[cache_key] = vector_store
        return vector_store
    except Exception as e:
        if "429" in str(e): return None
        else:
            print(f"Vector Store creation failed: {e}") 
            return None

def get_rag_chain(vector_store):
    """ê²€ìƒ‰ ì²´ì¸(ConversationalRetrievalChain)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if vector_store is None: return None
    # â­ RAG ì²´ì¸ì— memory_keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    return ConversationalRetrievalChain.from_llm(
        llm=st.session_state.llm,
        retriever=vector_store.as_retriever(),
        memory=st.session_state.memory
    )

@st.cache_resource
def load_or_train_lstm():
    """ê°€ìƒì˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ì„ ìœ„í•œ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."""
    np.random.seed(42)
    data = np.cumsum(np.random.normal(loc=5, scale=5, size=50)) + 60
    data = np.clip(data, 50, 95)
    def create_dataset(dataset, look_back=3):
        X, Y = [], []
        for i in range(len(dataset) - look_back):
            X.append(dataset[i:(i + look_back)])
            Y.append(dataset[i + look_back])
        return np.array(X), np.array(Y)
    look_back = 5
    X, Y = create_dataset(data, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, epochs=10, batch_size=1, verbose=0)
    return model, data


def clean_and_load_json(text):
    """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ë§Œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¡œë“œ"""
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        json_str = match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            return None
    return None

def render_interactive_quiz(quiz_data, current_lang):
    """ìƒì„±ëœ í€´ì¦ˆ ë°ì´í„°ë¥¼ Streamlit UIë¡œ ë Œë”ë§í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤."""
    L = LANG[current_lang]
    if not quiz_data or 'quiz_questions' not in quiz_data: return

    questions = quiz_data['quiz_questions']
    num_questions = len(questions)

    if "current_question" not in st.session_state or st.session_state.current_question >= num_questions:
        st.session_state.current_question = 0
        st.session_state.quiz_results = [None] * num_questions
        st.session_state.quiz_submitted = False
        
    q_index = st.session_state.current_question
    q_data = questions[q_index]
    
    st.subheader(f"{q_index + 1}. {q_data['question']}")
    
    options_dict = {}
    try:
        options_dict = {f"{opt['option']}": f"{opt['option']}) {opt['text']}" for opt in q_data['options']}
    except KeyError:
        st.error(L["quiz_fail_structure"])
        if 'quiz_data_raw' in st.session_state: st.code(st.session_state.quiz_data_raw, language="json")
        return

    options_list = list(options_dict.values())
    
    selected_answer = st.radio(
        L.get("select_answer", "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”"),
        options=options_list,
        key=f"q_radio_{q_index}"
    )

    col1, col2 = st.columns(2)

    if col1.button(L.get("check_answer", "ì •ë‹µ í™•ì¸"), key=f"check_btn_{q_index}", disabled=st.session_state.quiz_submitted):
        user_choice_letter = selected_answer.split(')')[0] if selected_answer else None
        correct_answer_letter = q_data['correct_answer']

        is_correct = (user_choice_letter == correct_answer_letter)
        
        st.session_state.quiz_results[q_index] = is_correct
        st.session_state.quiz_submitted = True
        
        if is_correct:
            st.success(L.get("correct_answer", "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰"))
        else:
            st.error(L.get("incorrect_answer", "ì˜¤ë‹µì…ë‹ˆë‹¤.ğŸ˜"))
        
        st.markdown(f"**{L.get('correct_is', 'ì •ë‹µ')}: {correct_answer_letter}**")
        st.info(f"**{L.get('explanation', 'í•´ì„¤')}:** {q_data['explanation']}")

    if st.session_state.quiz_submitted:
        if q_index < num_questions - 1:
            if col2.button(L.get("next_question", "ë‹¤ìŒ ë¬¸í•­"), key=f"next_btn_{q_index}"):
                st.session_state.current_question += 1
                st.session_state.quiz_submitted = False
                st.rerun()
        else:
            total_correct = st.session_state.quiz_results.count(True)
            total_questions = len(st.session_state.quiz_results)
            st.success(f"**{L.get('quiz_complete', 'í€´ì¦ˆ ì™„ë£Œ!')}** {L.get('score', 'ì ìˆ˜')}: {total_correct}/{total_questions}")
            if st.button(L.get("retake_quiz", "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°"), key="retake"):
                st.session_state.current_question = 0
                st.session_state.quiz_results = [None] * num_questions
                st.session_state.quiz_submitted = False
                st.rerun()

# ================================
# 3. ë‹¤êµ­ì–´ ì§€ì› ë”•ì…”ë„ˆë¦¬ (Language Dictionary)
# ================================
LANG = {
    "ko": {
        "title": "ê°œì¸ ë§ì¶¤í˜• AI í•™ìŠµ ì½”ì¹˜",
        "sidebar_title": "ğŸ“š AI Study Coach ì„¤ì •",
        "file_uploader": "í•™ìŠµ ìë£Œ ì—…ë¡œë“œ (PDF, TXT, HTML)",
        "button_start_analysis": "ìë£Œ ë¶„ì„ ì‹œì‘ (RAG Indexing)",
        "rag_tab": "RAG ì§€ì‹ ì±—ë´‡",
        "content_tab": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "lstm_tab": "LSTM ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "simulator_tab": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°", 
        "rag_header": "RAG ì§€ì‹ ì±—ë´‡ (ë¬¸ì„œ ê¸°ë°˜ Q&A)",
        "rag_desc": "ì—…ë¡œë“œëœ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ã€‚",
        "rag_input_placeholder": "í•™ìŠµ ìë£Œì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”",
        "llm_error_key": "âš ï¸ ê²½ê³ : GEMINI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì— 'GEMINI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”ã€‚",
        "llm_error_init": "LLM ì´ˆê¸°í™” ì˜¤ë¥˜: API í‚¤ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”ã€‚",
        "content_header": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "content_desc": "í•™ìŠµ ì£¼ì œì™€ ë‚œì´ë„ì— ë§ì¶° ì½˜í…ì¸  ìƒì„±",
        "topic_label": "í•™ìŠµ ì£¼ì œ",
        "level_label": "ë‚œì´ë„",
        "content_type_label": "ì½˜í…ì¸  í˜•ì‹",
        "level_options": ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"],
        "content_options": ["í•µì‹¬ ìš”ì•½ ë…¸íŠ¸", "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­", "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´"],
        "button_generate": "ì½˜í…ì¸  ìƒì„±",
        "warning_topic": "í•™ìŠµ ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚",
        "lstm_header": "LSTM ê¸°ë°˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "lstm_desc": "ê°€ìƒì˜ ê³¼ê±° í€´ì¦ˆ ì ìˆ˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ LSTM ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë¯¸ë˜ ì„±ì·¨ë„ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤ã€‚",
        "lstm_disabled_error": "The LSTM feature is temporarily disabled due to build environment issues. Please use the 'Custom Content Generation' feature first.",
        "lang_select": "ì–¸ì–´ ì„ íƒ",
        "embed_success": "ì´ {count}ê°œ ì²­í¬ë¡œ í•™ìŠµ DB êµ¬ì¶• ì™„ë£Œ!",
        "embed_fail": "ì„ë² ë”© ì‹¤íŒ¨: ë¬´ë£Œ í‹°ì–´ í•œë„ ì´ˆê³¼ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œã€‚",
        "warning_no_files": "ë¨¼ì € í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
        "warning_rag_not_ready": "RAGê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•˜ì„¸ìš”ã€‚",
        "quiz_fail_structure": "í€´ì¦ˆ ë°ì´í„° êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚",
        "select_answer": "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”",
        "check_answer": "ì •ë‹µ í™•ì¸",
        "next_question": "ë‹¤ìŒ ë¬¸í•­",
        "correct_answer": "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰",
        "incorrect_answer": "ì˜¤ë‹µì…ë‹ˆë‹¤. ğŸ˜",
        "correct_is": "ì •ë‹µ",
        "explanation": "í•´ì„¤",
        "quiz_complete": "í€´ì¦ˆ ì™„ë£Œ!",
        "score": "ì ìˆ˜",
        "retake_quiz": "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°",
        "quiz_error_llm": "í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: LLMì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ì‘ë‹µ ì›ë³¸ì„ í™•ì¸í•˜ì„¸ìš”ã€‚",
        "quiz_original_response": "LLM ì›ë³¸ ì‘ë‹µ",
        "firestore_loading": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...",
        
        # â­ ì‹œë®¬ë ˆì´í„° ê´€ë ¨ í…ìŠ¤íŠ¸
        "simulator_header": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°",
        "simulator_desc": "ê¹Œë‹¤ë¡œìš´ ê³ ê° ë¬¸ì˜ì— ëŒ€í•´ AIì˜ ì‘ëŒ€ ì´ˆì•ˆ ë° ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.",
        "customer_query_label": "ê³ ê° ë¬¸ì˜ ë‚´ìš© (ë§í¬ í¬í•¨ ê°€ëŠ¥)",
        "customer_type_label": "ê³ ê° ì„±í–¥",
        "customer_type_options": ["ì¼ë°˜ì ì¸ ë¬¸ì˜", "ê¹Œë‹¤ë¡œìš´ ê³ ê°", "ë§¤ìš° ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ìš´ ê³ ê°"],
        "button_simulate": "ì‘ëŒ€ ì¡°ì–¸ ìš”ì²­",
        "simulation_warning_query": "ê³ ê° ë¬¸ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”ã€‚",
        "simulation_no_key_warning": "âš ï¸ API Keyê°€ ì—†ëŠ” ê²½ìš°, ì‘ë‹µ ìƒì„±ì€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (UI êµ¬ì„±ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.)",
        "simulation_advice_ready": "AIì˜ ì‘ëŒ€ ì¡°ì–¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!",
        "simulation_advice_header": "AIì˜ ì‘ëŒ€ ê°€ì´ë“œë¼ì¸",
        "simulation_draft_header": "ì¶”ì²œ ì‘ëŒ€ ì´ˆì•ˆ",
        "button_listen_audio": "ìŒì„±ìœ¼ë¡œ ë“£ê¸°",
        "tts_status_ready": "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨",
        "tts_status_generating": "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...",
        "tts_status_success": "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!",
        "tts_status_fail": "âŒ TTS ìƒì„± ì‹¤íŒ¨ (ë°ì´í„° ì—†ìŒ)",
        "tts_status_error": "âŒ TTS ì˜¤ë¥˜ ë°œìƒ",
        
        # â­ ëŒ€í™”í˜•/ì¢…ë£Œ ë©”ì‹œì§€
        "button_mic_input": "ìŒì„± ì…ë ¥",
        "prompt_customer_end": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ ì±„íŒ…ì„ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤.",
        "prompt_survey": "ê³ ê° ë¬¸ì˜ ì„¼í„°ì— ì—°ë½ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦¬ë©°, ì¶”ê°€ë¡œ ì €í¬ ì‘ëŒ€ ì†”ë£¨ì…˜ì— ëŒ€í•œ ì„¤ë¬¸ ì¡°ì‚¬ì— ì‘í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹­ì‹œì˜¤.",
        "customer_closing_confirm": "ë˜ ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹ ê°€ìš”?",
        "customer_positive_response": "ì¢‹ì€ ë§ì”€/ì¹œì ˆí•œ ìƒë‹´ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.",
        "button_end_chat": "ì‘ëŒ€ ì¢…ë£Œ (ì„¤ë¬¸ ì¡°ì‚¬ ìš”ì²­)"
    },
    "en": {
        "title": "Personalized AI Study Coach",
        "sidebar_title": "ğŸ“š AI Study Coach Settings",
        "file_uploader": "Upload Study Materials (PDF, TXT, HTML)",
        "button_start_analysis": "Start Analysis (RAG Indexing)",
        "rag_tab": "RAG Knowledge Chatbot",
        "content_tab": "Custom Content Generation",
        "lstm_tab": "LSTM Achievement Prediction",
        "simulator_tab": "AI Customer Response Simulator", 
        "rag_header": "RAG Knowledge Chatbot (Document Q&A)",
        "rag_desc": "Answers questions based on the uploaded documents.",
        "rag_input_placeholder": "Ask a question about your study materials",
        "llm_error_key": "âš ï¸ Warning: GEMINI API Key is not set. Please set 'GEMINI_API_KEY' in Streamlit Secrets.",
        "llm_error_init": "LLM initialization error: Please check your API key.",
        "content_header": "Custom Learning Content Generation",
        "content_desc": "Generate content tailored to your topic and difficulty.",
        "topic_label": "Learning Topic",
        "level_label": "Difficulty",
        "content_type_label": "Content Type",
        "level_options": ["Beginner", "Intermediate", "Advanced"],
        "content_options": ["Key Summary Note", "10 Multiple-Choice Questions", "Practical Example Idea"],
        "button_generate": "Generate Content",
        "warning_topic": "Please enter a learning topic.",
        "lstm_header": "LSTM Based Achievement Prediction",
        "lstm_desc": "Trains an LSTM model on hypothetical past quiz scores to predict future achievement.",
        "lstm_disabled_error": "The LSTM feature is temporarily disabled due to build environment issues. Please use the 'Custom Content Generation' feature first.",
        "lang_select": "Select Language",
        "embed_success": "Learning DB built with {count} chunks!",
        "embed_fail": "Embedding failed: Free tier quota exceeded or network issue.",
        "warning_no_files": "Please upload study materials first.",
        "warning_rag_not_ready": "RAG is not ready. Upload materials and click Start Analysis.",
        "quiz_fail_structure": "Quiz data structure is incorrect.",
        "select_answer": "Select answer",
        "check_answer": "Confirm answer",
        "next_question": "Next Question",
        "correct_answer": "Correct! ğŸ‰",
        "incorrect_answer": "Incorrect. ğŸ˜",
        "correct_is": "Correct answer",
        "explanation": "Explanation",
        "quiz_complete": "Quiz completed!",
        "score": "Score",
        "retake_quiz": "Retake Quiz",
        "quiz_error_llm": "Quiz generation failed: LLM did not return a valid JSON format. Check the original LLM response.",
        "quiz_original_response": "Original LLM Response",
        "firestore_loading": "Loading RAG index from database...",
        
        # â­ ì‹œë®¬ë ˆì´í„° ê´€ë ¨ í…ìŠ¤íŠ¸
        "simulator_header": "AI Customer Response Simulator",
        "simulator_desc": "Provides AI-generated response drafts and guidelines for handling challenging customer inquiries.",
        "customer_query_label": "Customer Query (Link optional)",
        "customer_type_label": "Customer Sentiment",
        "customer_type_options": ["General Inquiry", "Challenging Customer", "Highly Dissatisfied Customer"],
        "button_simulate": "Request Response Advice",
        "simulation_warning_query": "Please enter the customer's query.",
        "simulation_no_key_warning": "âš ï¸ API Key is missing. Response generation cannot proceed. (UI configuration is complete.)",
        "simulation_advice_ready": "AI's response advice is ready!",
        "simulation_advice_header": "AI Response Guidelines",
        "simulation_draft_header": "Recommended Response Draft",
        "button_listen_audio": "Listen to Audio",
        "tts_status_ready": "Ready to listen",
        "tts_status_generating": "Generating audio...",
        "tts_status_success": "âœ… Audio playback complete!",
        "tts_status_fail": "âŒ TTS generation failed (No data)",
        "tts_status_error": "âŒ TTS API error occurred",

        # â­ ëŒ€í™”í˜•/ì¢…ë£Œ ë©”ì‹œì§€
        "button_mic_input": "Voice Input",
        "prompt_customer_end": "As there are no further inquiries, we will now end this chat session.",
        "prompt_survey": "Thank you for contacting our Customer Support Center. We would be grateful if you could participate in a short survey about our service solution. Please feel free to contact us anytime if you have any additional questions.",
        "customer_closing_confirm": "Is there anything else we can assist you with today?",
        "customer_positive_response": "Thank you for your kind understanding/friendly advice.",
        "button_end_chat": "End Chat (Request Survey)"
    },
    "ja": {
        "title": "ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºAIå­¦ç¿’ã‚³ãƒ¼ãƒ",
        "sidebar_title": "ğŸ“š AIå­¦ç¿’ã‚³ãƒ¼ãƒè¨­å®š",
        "file_uploader": "å­¦ç¿’è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PDF, TXT, HTML)",
        "button_start_analysis": "è³‡æ–™åˆ†æé–‹å§‹ (RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ)",
        "rag_tab": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
        "content_tab": "ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "lstm_tab": "LSTMé”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "simulator_tab": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼", 
        "rag_header": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆQ&A)",
        "rag_desc": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚",
        "rag_input_placeholder": "å­¦ç¿’è³‡æ–™ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
        "llm_error_key": "âš ï¸ è­¦å‘Š: GEMINI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlit Secretsã«'GEMINI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”ã€‚",
        "llm_error_init": "LLMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ï¼šAPIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        "content_header": "ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "content_desc": "å­¦ç¿’ãƒ†ãƒ¼ãƒã¨é›£æ˜“åº¦ã«åˆã‚ã›ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "topic_label": "å­¦ç¿’ãƒ†ãƒ¼ãƒ",
        "level_label": "é›£æ˜“åº¦",
        "content_type_label": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å½¢å¼",
        "level_options": ["åˆç´š", "ä¸­ç´š", "ä¸Šç´š"],
        "content_options": ["æ ¸å¿ƒè¦ç´„ãƒãƒ¼ãƒˆ", "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•", "å®Ÿè·µä¾‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢"],
        "button_generate": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "warning_topic": "å­¦ç¿’ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "lstm_header": "LSTMãƒ™ãƒ¼ã‚¹é”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "lstm_desc": "ä»®æƒ³ã®éå»ã‚¯ã‚¤ã‚ºã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€LSTMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦å°†æ¥ã®é”æˆåº¦ã‚’äºˆæ¸¬ã—è¡¨ç¤ºã—ã¾ã™ã€‚",
        "lstm_disabled_error": "ç¾åœ¨ã€ãƒ“ãƒ«ãƒ‰ç’°å¢ƒã®å•é¡Œã«ã‚ˆã‚ŠLSTMæ©Ÿèƒ½ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆã€æ©Ÿèƒ½ã‚’å…ˆã«ã”åˆ©ç”¨ãã ã•ã„ã€‚ã€",
        "lang_select": "è¨€èªé¸æŠ",
        "embed_success": "å…¨{count}ãƒãƒ£ãƒ³ã‚¯ã§å­¦ç¿’DBæ§‹ç¯‰å®Œäº†!",
        "embed_fail": "åŸ‹ã‚è¾¼ã¿å¤±æ•—: ãƒ•ãƒªãƒ¼ãƒ†ã‚£ã‚¢ã®ã‚¯ã‚©ãƒ¼ã‚¿è¶…éã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å•é¡Œã€‚",
        "warning_no_files": "ã¾ãšå­¦ç¿’è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
        "warning_rag_not_ready": "RAGãŒæº–å‚™ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ†æé–‹å§‹ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚",
        "quiz_fail_structure": "ã‚¯ã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚",
        "select_answer": "æ­£è§£ã‚’é¸æŠã—ã¦ãã ã•ã„",
        "check_answer": "æ­£è§£ã‚’ç¢ºèª",
        "next_question": "æ¬¡ã®è³ªå•",
        "correct_answer": "æ­£è§£ã§ã™! ğŸ‰",
        "incorrect_answer": "ä¸æ­£è§£ã§ã™ã€‚ğŸ˜",
        "correct_is": "æ­£è§£",
        "explanation": "è§£èª¬",
        "quiz_complete": "ã‚¯ã‚¤ã‚ºå®Œäº†!",
        "score": "ã‚¹ã‚³ã‚¢",
        "retake_quiz": "ã‚¯ã‚¤ã‚ºã‚’å†æŒ‘æˆ¦",
        "quiz_error_llm": "LLMãŒæ­£ã—ã„JSONã®å½¢å¼ã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸã®ã§ã€ã‚¯ã‚¤ã‚ºã®ç”ŸæˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚",
        "quiz_original_response": "LLM åŸæœ¬å¿œç­”",
        "firestore_loading": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...",
        
        # â­ ì‹œë®¬ë ˆì´í„° ê´€ë ¨ í…ìŠ¤íŠ¸
        "simulator_header": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
        "simulator_desc": "é›£ã—ã„é¡§å®¢ã®å•ã„åˆã‚ã›ã«å¯¾ã—ã¦ã€AIã«ã‚ˆã‚‹å¯¾å¿œæ¡ˆã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚",
        "customer_query_label": "é¡§å®¢ã®å•ã„åˆã‚ã›å†…å®¹ï¼ˆãƒªãƒ³ã‚¯ä»»æ„ï¼‰",
        "customer_type_label": "é¡§å®¢ã®å‚¾å‘",
        "customer_type_options": ["ä¸€èˆ¬çš„ãªå•ã„åˆã‚ã›", "æ‰‹ã”ã‚ã„é¡§å®¢", "éå¸¸ã«ä¸æº€ãªé¡§å®¢"],
        "button_simulate": "å¯¾å¿œã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¦æ±‚",
        "simulation_warning_query": "é¡§å®¢ã®å•ã„åˆã‚ã›å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "simulation_no_key_warning": "âš ï¸ APIã‚­ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å¿œç­”ã®ç”Ÿæˆã¯ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚ï¼ˆUIè¨­å®šã¯å®Œäº†ã—ã¦ã„ã¾ã™ã€‚ï¼‰",
        "simulation_advice_ready": "AIã®å¯¾å¿œã‚¢ãƒ‰ãƒã‚¤ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼",
        "simulation_advice_header": "AIå¯¾å¿œã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
        "simulation_draft_header": "æ¨å¥¨ã•ã‚Œã‚‹å¯¾å¿œè‰æ¡ˆ",
        "button_listen_audio": "éŸ³å£°ã§èã",
        "tts_status_ready": "éŸ³å£°å†ç”Ÿã®æº–å‚™ãŒã§ãã¾ã—ãŸ",
        "tts_status_generating": "éŸ³å£°ç”Ÿæˆä¸­...",
        "tts_status_success": "âœ… éŸ³å£°å†ç”Ÿå®Œäº†!",
        "tts_status_fail": "âŒ TTSç”Ÿæˆå¤±æ•—ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰",
        "tts_status_error": "âŒ TTS APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",

        # â­ ëŒ€í™”í˜•/ì¢…ë£Œ ë©”ì‹œì§€
        "button_mic_input": "éŸ³å£°å…¥åŠ›",
        "prompt_customer_end": "ãŠå®¢æ§˜ã‹ã‚‰ã®è¿½åŠ ã®ãŠå•ã„åˆã‚ã›ãŒãªã„ãŸã‚ã€æœ¬ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆã‚’çµ‚äº†ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚",
        "prompt_survey": "ãŠå•ã„åˆã‚ã›ã„ãŸã ãã€èª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚å¼Šç¤¾ã®å¯¾å¿œã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ç°¡å˜ãªã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã«ã”å”åŠ›ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚è¿½åŠ ã®ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã„ã¤ã§ã‚‚ã”é€£çµ¡ãã ã•ã„ã€‚",
        "customer_closing_confirm": "ã¾ãŸã€ãŠå®¢æ§˜ã«ãŠæ‰‹ä¼ã„ã•ã›ã¦é ‚ã‘ã‚‹ãŠå•ã„åˆã‚ã›ã¯å¾¡åº§ã„ã¾ã›ã‚“ã‹ï¼Ÿ",
        "customer_positive_response": "è¦ªåˆ‡ãªã”å¯¾å¿œã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
        "button_end_chat": "å¯¾å¿œçµ‚äº† (ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆã‚’ä¾é ¼)"
    }
}


# ================================
# 4. Streamlit í•µì‹¬ Config ì„¤ì • ë° Session State ì´ˆê¸°í™” (CRITICAL ZONE)
# ================================

if 'language' not in st.session_state: st.session_state.language = 'ko'
if 'uploaded_files_state' not in st.session_state: st.session_state.uploaded_files_state = None
if 'is_llm_ready' not in st.session_state: st.session_state.is_llm_ready = False
if 'is_rag_ready' not in st.session_state: st.session_state.is_rag_ready = False
if 'firestore_db' not in st.session_state: st.session_state.firestore_db = None
if 'llm_init_error_msg' not in st.session_state: st.session_state.llm_init_error_msg = None
if 'firestore_load_success' not in st.session_state: st.session_state.firestore_load_success = False

# â­ ì‹œë®¬ë ˆì´í„° ì „ìš© ìƒíƒœ ì´ˆê¸°í™” ì¶”ê°€
if "simulator_memory" not in st.session_state:
    # ConversationChainì—ì„œ ì‚¬ìš©í•  ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
    st.session_state.simulator_memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
if "simulator_messages" not in st.session_state:
    st.session_state.simulator_messages = []
if "initial_advice_provided" not in st.session_state:
    st.session_state.initial_advice_provided = False
if "simulator_chain" not in st.session_state:
    st.session_state.simulator_chain = None
# â­ ì‹œë®¬ë ˆì´í„° ì§„í–‰ ìƒíƒœ ì¶”ê°€
if "is_chat_ended" not in st.session_state:
    st.session_state.is_chat_ended = False

# ì–¸ì–´ ì„¤ì • ë¡œë“œ (UI ì¶œë ¥ ì „ í•„ìˆ˜)
L = LANG[st.session_state.language] 
API_KEY = os.environ.get("GEMINI_API_KEY")

# =======================================================
# 5. Streamlit UI í˜ì´ì§€ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ ë‚´ ì²« ë²ˆì§¸ ST ëª…ë ¹)
# =======================================================
st.set_page_config(page_title=L["title"], layout="wide")

# =======================================================
# 6. ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° LLM/DB ë¡œì§ (í˜ì´ì§€ ì„¤ì • í›„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰)
# =======================================================

if 'llm' not in st.session_state: 
    llm_init_error = None # â­ safety initialization
    if not API_KEY:
        llm_init_error = L["llm_error_key"]
    else:
        try:
            # LLM ë° Embeddings ì´ˆê¸°í™”
            st.session_state.llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.7, google_api_key=API_KEY)
            st.session_state.embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=API_KEY)
            st.session_state.is_llm_ready = True
            
            # Admin SDK í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” 
            sa_info, error_message = _get_admin_credentials()
            
            if error_message:
                llm_init_error = f"{L['llm_error_init']} (DB Auth Error: {error_message})" 
            elif sa_info:
                db = initialize_firestore_admin() 
                st.session_state.firestore_db = db
                
                if not db:
                    llm_init_error = f"{L['llm_init_error']} (DB Client Error: Firebase Admin Init Failed)" 

            # DB ë¡œë”© ë¡œì§ (RAG ì±—ë´‡ìš©)
            if st.session_state.firestore_db and 'conversation_chain' not in st.session_state:
                # DB ë¡œë”© ì‹œë„
                loaded_index = load_index_from_firestore(st.session_state.firestore_db, st.session_state.embeddings)
                
                if loaded_index:
                    st.session_state.conversation_chain = get_rag_chain(loaded_index)
                    st.session_state.is_rag_ready = True
                    st.session_state.firestore_load_success = True
                else:
                    st.session_state.firestore_load_success = False
            
            # â­ ì‹œë®¬ë ˆì´í„° ì²´ì¸ ì´ˆê¸°í™” (LangChain Prompt Variable Error í•´ê²°)
            
            # 1. ì‹œë®¬ë ˆì´í„° ì „ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (PromptTemplate ìƒì„±ì ì‚¬ìš©)
            SIMULATOR_PROMPT = PromptTemplate(
                template="The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n\n{chat_history}\nHuman: {input}\nAI:",
                input_variables=["input", "chat_history"]
            )
            
            # 2. ConversationChain ì´ˆê¸°í™”
            st.session_state.simulator_chain = ConversationChain(
                llm=st.session_state.llm,
                memory=st.session_state.simulator_memory,
                prompt=SIMULATOR_PROMPT,
                input_key="input", 
            )


        except Exception as e:
            # LLM ì´ˆê¸°í™” ì˜¤ë¥˜ ì²˜ë¦¬ 
            llm_init_error = f"{L['llm_init_error']} {e}" 
            st.session_state.is_llm_ready = False
    
    if llm_init_error:
        st.session_state.is_llm_ready = False
        st.session_state.llm_init_error_msg = llm_init_error 

# ë‚˜ë¨¸ì§€ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "memory" not in st.session_state:
    # RAG ì²´ì¸ìš© ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
    st.session_state.memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

if "embedding_cache" not in st.session_state:
    st.session_state.embedding_cache = {}

# ================================
# 7. ì´ˆê¸°í™” ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥ ë° DB ìƒíƒœ ì•Œë¦¼
# ================================

if st.session_state.llm_init_error_msg:
    st.error(st.session_state.llm_init_error_msg)
    
if st.session_state.get('firestore_db'):
    if st.session_state.get('firestore_load_success', False):
        st.success("âœ… RAG ì¸ë±ìŠ¤ê°€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif not st.session_state.get('is_rag_ready', False):
        st.info("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ RAG ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìƒˆë¡œ ë§Œë“œì„¸ìš”.")


# ================================
# 8. Streamlit UI ì‹œì‘
# ================================

with st.sidebar:
    selected_lang_key = st.selectbox(
        L["lang_select"],
        options=['ko', 'en', 'ja'],
        index=['ko', 'en', 'ja'].index(st.session_state.language),
        format_func=lambda x: {"ko": "í•œêµ­ì–´", "en": "English", "ja": "æ—¥æœ¬èª"}[x],
    )
    
    if selected_lang_key != st.session_state.language:
        st.session_state.language = selected_lang_key
        st.rerun() 
    
    L = LANG[st.session_state.language] 
    
    st.title(L["sidebar_title"])
    
    st.markdown("---")
    
    uploaded_files_widget = st.file_uploader(
        L["file_uploader"],
        type=["pdf","txt","html"],
        accept_multiple_files=True
    )
    
    if uploaded_files_widget:
        st.session_state.uploaded_files_state = uploaded_files_widget
    elif 'uploaded_files_state' not in st.session_state:
        st.session_state.uploaded_files_state = None
    
    files_to_process = st.session_state.uploaded_files_state if st.session_state.uploaded_files_state else []
    
    if files_to_process and st.session_state.is_llm_ready:
        if st.button(L["button_start_analysis"], key="start_analysis"):
            with st.spinner(f"ìë£Œ ë¶„ì„ ë° í•™ìŠµ DB êµ¬ì¶• ì¤‘..."):
                text_chunks = get_document_chunks(files_to_process)
                vector_store = get_vector_store(text_chunks)
                
                if vector_store:
                    # RAG ì¸ë±ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ë©´ Firestoreì— ì €ì¥ ì‹œë„
                    db = st.session_state.firestore_db
                    save_success = False
                    if db:
                        save_success = save_index_to_firestore(db, vector_store)
                    
                    if save_success:
                        st.success(L["embed_success"].format(count=len(text_chunks)) + " (DB ì €ì¥ ì™„ë£Œ)")
                    else:
                        st.success(L["embed_success"].format(count=len(text_chunks)) + " (DB ì €ì¥ ì‹¤íŒ¨)")

                    st.session_state.conversation_chain = get_rag_chain(vector_store)
                    st.session_state.is_rag_ready = True
                else:
                    st.session_state.is_rag_ready = False
                    st.error(L["embed_fail"])

    else:
        st.session_state.is_rag_ready = False
        st.warning(L.get("warning_no_files", "ë¨¼ì € í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")) 

    st.markdown("---")
    # â­ ìƒˆë¡œìš´ íƒ­(ì‹œë®¬ë ˆì´í„°)ì„ í¬í•¨í•˜ì—¬ ë¼ë””ì˜¤ ë²„íŠ¼ ì—…ë°ì´íŠ¸
    feature_selection = st.radio(
        L["content_tab"], 
        [L["rag_tab"], L["content_tab"], L["lstm_tab"], L["simulator_tab"]]
    )

st.title(L["title"])

# ================================
# 9. ê¸°ëŠ¥ë³„ í˜ì´ì§€ êµ¬í˜„
# ================================

if feature_selection == L["simulator_tab"]: 
    st.header(L["simulator_header"])
    st.markdown(L["simulator_desc"])
    
    # 1. TTS ìœ í‹¸ë¦¬í‹° (ìƒíƒœ í‘œì‹œê¸° ë° JS í•¨ìˆ˜)ë¥¼ í˜ì´ì§€ ìƒë‹¨ì— ì‚½ì…
    st.markdown(f'<div id="tts_status" style="padding: 5px; text-align: center; border-radius: 5px; background-color: #f0f0f0; margin-bottom: 10px;">{L["tts_status_ready"]}</div>', unsafe_allow_html=True)
    
    # TTS JS ìœ í‹¸ë¦¬í‹°ë¥¼ í˜ì´ì§€ ë¡œë“œ ì‹œ ë‹¨ í•œ ë²ˆë§Œ ì‚½ì… (TTS í•¨ìˆ˜ê°€ ê¸€ë¡œë²Œë¡œ ì •ì˜ë˜ë„ë¡)
    # â­ TTSëŠ” API Key ì—†ì´ ì‘ë™
    if "tts_js_loaded" not in st.session_state:
         synthesize_and_play_audio(st.session_state.language) 
         st.session_state.tts_js_loaded = True

    # â­ Firebase ìƒë‹´ ì´ë ¥ ë¡œë“œ ë° ì„ íƒ ì„¹ì…˜
    db = st.session_state.get('firestore_db')
    if db:
        with st.expander("ğŸ“ ì´ì „ ìƒë‹´ ì´ë ¥ ë¡œë“œ (ìµœê·¼ 10ê°œ)"):
            histories = load_simulation_histories(db)
            if histories:
                history_options = {
                    f"[{h['timestamp'].strftime('%m-%d %H:%M')}] {h['customer_type']} - {h['initial_query'][:30]}...": h
                    for h in histories
                }
                
                selected_key = st.selectbox(
                    "ë¡œë“œí•  ì´ë ¥ì„ ì„ íƒí•˜ì„¸ìš”:",
                    options=list(history_options.keys())
                )
                
                if st.button("ì„ íƒëœ ì´ë ¥ ë¡œë“œ"):
                    selected_history = history_options[selected_key]
                    
                    # ìƒíƒœ ë³µì›
                    st.session_state.customer_query_text_area = selected_history['initial_query']
                    st.session_state.initial_advice_provided = True
                    st.session_state.simulator_messages = selected_history['messages']
                    st.session_state.is_chat_ended = selected_history.get('is_chat_ended', False)
                    
                    # ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ë° ë©”ì‹œì§€ ì¬êµ¬ì„± (LangChain í˜¸í™˜ì„±ì„ ìœ„í•´)
                    st.session_state.simulator_memory.clear()
                    
                    # LLM ë©”ëª¨ë¦¬ì— ëŒ€í™” ì´ë ¥ ì¬ì£¼ì… (ì‹¤ì œ LLMì´ ì‘ëŒ€í•  ìˆ˜ ìˆë„ë¡)
                    for i, msg in enumerate(selected_history['messages']):
                         if msg['role'] == 'agent_response':
                             st.session_state.simulator_memory.chat_memory.add_user_message(msg['content'])
                         elif msg['role'] in ['supervisor', 'customer_rebuttal', 'customer_end']:
                             # supervisorì˜ adviceì™€ customerì˜ ë°˜ë°•ì€ LLM ì‘ë‹µìœ¼ë¡œ ê°„ì£¼
                             if i > 0 and selected_history['messages'][i-1]['role'] == 'customer': continue # ì´ˆê¸° ì¡°ì–¸ì€ ê³ ê° ë©”ì‹œì§€ ì´í›„ì—ë§Œ ì¶”ê°€
                             st.session_state.simulator_memory.chat_memory.add_ai_message(msg['content'])
                    
                    st.rerun()

    # â­ LLM ì´ˆê¸°í™”ê°€ ë˜ì–´ìˆì§€ ì•Šì•„ë„ (API Keyê°€ ì—†ì–´ë„) UIê°€ ì‘ë™í•´ì•¼ í•¨
    if st.session_state.is_llm_ready or not API_KEY:
        if st.session_state.is_chat_ended:
            st.success(L["prompt_customer_end"] + " " + L["prompt_survey"])
            
            if st.button("ìƒˆ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘", key="new_simulation"):
                 st.session_state.is_chat_ended = False
                 st.session_state.initial_advice_provided = False
                 st.session_state.simulator_messages = []
                 st.session_state.simulator_memory.clear()
                 st.rerun()
            st.stop()
        
        # 1. ê³ ê° ë¬¸ì˜ ì…ë ¥ í•„ë“œ
        if 'customer_query_text_area' not in st.session_state:
            st.session_state.customer_query_text_area = ""

        customer_query = st.text_area(
            L["customer_query_label"],
            key="customer_query_text_area",
            height=150,
            placeholder=L["customer_query_label"] + "...",
            disabled=st.session_state.initial_advice_provided
        )

        # 2. ê³ ê° ì„±í–¥ ì„ íƒ
        customer_type_display = st.selectbox(
            L["customer_type_label"],
            L["customer_type_options"],
            disabled=st.session_state.initial_advice_provided
        )
        
        # ì„ íƒëœ ì–¸ì–´ í‚¤
        current_lang_key = st.session_state.language 

        # 4. 'ì‘ëŒ€ ì¡°ì–¸ ìš”ì²­' ë²„íŠ¼: ì´ˆê¸° ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ë° ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        if st.button(L["button_simulate"], key="start_simulation", disabled=st.session_state.initial_advice_provided):
            if not customer_query:
                st.warning(L["simulation_warning_query"])
                st.stop()
            
            # ì´ˆê¸°í™”
            st.session_state.simulator_memory.clear()
            st.session_state.simulator_messages = []
            st.session_state.is_chat_ended = False
            
            st.session_state.simulator_messages.append({"role": "customer", "content": customer_query})
            
            initial_prompt = f"""
            You are an AI Customer Support Supervisor. Your task is to provide expert guidance to a customer support agent.
            The customer sentiment is: {customer_type_display}.
            The customer's initial inquiry is: "{customer_query}"
            
            Based on this, provide:
            1. Crucial advice on the tone and strategy for dealing with this specific sentiment. 
            2. A concise and compassionate recommended response draft.
            
            The response must be strictly in {LANG[current_lang_key]['lang_select']} and include the required initial contact information check.
            """
            
            if not API_KEY:
                # API Keyê°€ ì—†ì„ ê²½ìš° ëª¨ì˜(Mock) ë°ì´í„° ì‚¬ìš©
                mock_data = get_mock_response_data(current_lang_key, customer_type_display)
                ai_advice_text = f"### {mock_data['advice_header']}\n\n{mock_data['advice']}\n\n### {mock_data['draft_header']}\n\n{mock_data['draft']}"
                st.session_state.simulator_messages.append({"role": "supervisor", "content": ai_advice_text})
                
                st.session_state.initial_advice_provided = True
                
                # â­ Firebase ì´ë ¥ ì €ì¥ (API Key ì—†ì´ë„ UIëŠ” ì‹œì‘ ê°€ëŠ¥)
                save_simulation_history(db, customer_query, customer_type_display, st.session_state.simulator_messages)
                
                st.rerun() 
            
            if API_KEY:
                # API Keyê°€ ìˆì„ ê²½ìš° LLM í˜¸ì¶œ
                with st.spinner("AI ìŠˆí¼ë°”ì´ì € ì¡°ì–¸ ìƒì„± ì¤‘..."):
                    try:
                        # simulator_chainì´ Noneì´ ì•„ë‹Œì§€ í™•ì¸ (AttributeError ë°©ì§€)
                        if st.session_state.simulator_chain is None:
                            st.error(L['llm_error_init'] + " (ì‹œë®¬ë ˆì´í„° ì²´ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨)")
                            st.stop()

                        # ConversationChainì˜ predictëŠ” 'input'ë§Œ ë°›ìœ¼ë©°, ê²°ê³¼ëŠ” ë¬¸ìì—´ì…ë‹ˆë‹¤.
                        response_text = st.session_state.simulator_chain.predict(input=initial_prompt)
                        ai_advice_text = response_text
                        
                        st.session_state.simulator_messages.append({"role": "supervisor", "content": ai_advice_text})
                        st.session_state.initial_advice_provided = True
                        
                        # â­ Firebase ì´ë ¥ ì €ì¥ (API Key ìˆì„ ë•Œ)
                        save_simulation_history(db, customer_query, customer_type_display, st.session_state.simulator_messages)
                        
                        st.rerun() 
                    except Exception as e:
                        st.error(f"AI ì¡°ì–¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # 5. ì‹œë®¬ë ˆì´ì…˜ ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        st.markdown("---")
        
        # ì±„íŒ… ê¸°ë¡ ë Œë”ë§
        for message in st.session_state.simulator_messages:
            if message["role"] == "customer":
                with st.chat_message("user", avatar="ğŸ™‹"):
                    st.markdown(message["content"])
            elif message["role"] == "supervisor":
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    st.markdown(message["content"])
                    # TTS ë²„íŠ¼ì€ API Key ì—†ì´ ì‘ë™í•˜ë„ë¡ ìˆ˜ì •ë¨
                    render_tts_button(message["content"], st.session_state.language) 
            elif message["role"] == "agent_response":
                 with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
                    st.markdown(message["content"])
            elif message["role"] == "customer_rebuttal":
                 with st.chat_message("assistant", avatar="ğŸ˜ "):
                    st.markdown(message["content"])
            elif message["role"] == "customer_end":
                 with st.chat_message("assistant", avatar="ğŸ˜Š"):
                    st.markdown(message["content"])
            elif message["role"] == "system_end":
                 with st.chat_message("assistant", avatar="âœ¨"):
                    st.markdown(message["content"])

        # 6. ëŒ€í™”í˜• ì‹œë®¬ë ˆì´ì…˜ ì§„í–‰ (ì¶”ê°€ ì±„íŒ…)
        if st.session_state.initial_advice_provided and not st.session_state.is_chat_ended:
            
            last_role = st.session_state.simulator_messages[-1]['role'] if st.session_state.simulator_messages else None
            
            # --- ê³ ê°ì˜ ë‹¤ìŒ ë°˜ì‘ ìš”ì²­ ë²„íŠ¼ ---
            if last_role in ["agent_response", "customer", "customer_end", "supervisor"]: # ëª¨ë“  ë©”ì‹œì§€ í›„ ë‹¤ìŒ ë²„íŠ¼ì„ ëˆ„ë¥¼ ìˆ˜ ìˆë„ë¡ ìˆ˜ì •
                
                col_end, col_next = st.columns([1, 2])
                
                # A) ì‘ëŒ€ ì¢…ë£Œ ë²„íŠ¼ (ë§¤ë„ˆ ì¢…ë£Œ)
                if col_end.button(L["button_end_chat"], key="end_chat"):
                    closing_messages = get_closing_messages(current_lang_key)
                    
                    st.session_state.simulator_messages.append({"role": "supervisor", "content": closing_messages["additional_query"]}) # ë§¤ë„ˆ ì§ˆë¬¸
                    st.session_state.simulator_messages.append({"role": "system_end", "content": closing_messages["chat_closing"]}) # ìµœì¢… ì¢…ë£Œ ì¸ì‚¬
                    st.session_state.is_chat_ended = True
                    
                    # â­ Firebase ì´ë ¥ ì—…ë°ì´íŠ¸: ìµœì¢… ì¢…ë£Œ ìƒíƒœ ì €ì¥
                    # save_simulation_history(db, customer_query, customer_type_display, st.session_state.simulator_messages) # ì´ ë¶€ë¶„ì€ ë‹¤ìŒ ì‘ëŒ€ ì‹œ ì €ì¥ë˜ë„ë¡ ì„¤ê³„
                    
                    st.rerun()

                # B) ê³ ê°ì˜ ë‹¤ìŒ ë°˜ì‘ ìš”ì²­ (LLM í˜¸ì¶œ)
                if col_next.button("ê³ ê°ì˜ ë‹¤ìŒ ë°˜ì‘ ìš”ì²­ (LLM í˜¸ì¶œ)", key="request_rebuttal"):
                    if not API_KEY:
                        st.warning("API Keyê°€ ì—†ê¸° ë•Œë¬¸ì— LLMì„ í†µí•œ ëŒ€í™”í˜• ì‹œë®¬ë ˆì´ì…˜ì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                        st.stop()
                    
                    # LLM í˜¸ì¶œ ì‹œ simulator_chainì´ Noneì´ ì•„ë‹Œì§€ ë‹¤ì‹œ í™•ì¸
                    if st.session_state.simulator_chain is None:
                        st.error(L['llm_error_init'] + " (ì‹œë®¬ë ˆì´í„° ì²´ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨)")
                        st.stop()
                        
                    next_reaction_prompt = f"""
                    Analyze the entire chat history. Roleplay as the customer ({customer_type_display}). 
                    Based on the agent's last message, generate ONE of the following responses in the customer's voice:
                    1. A short, challenging rebuttal (still unsatisfied).
                    2. A new, follow-up question related to the previous interaction.
                    3. A positive closing remark (e.g., "{L['customer_positive_response']}").
                    
                    Do not provide any resolution yourself. Just the customer's message.
                    The response must be strictly in {LANG[current_lang_key]['lang_select']}.
                    """
                    
                    with st.spinner("ê³ ê°ì˜ ë°˜ì‘ ìƒì„± ì¤‘..."):
                        # ConversationChainì˜ predictëŠ” 'input' í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                        # LangChainì€ historyì™€ inputì„ ìë™ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
                        customer_reaction = st.session_state.simulator_chain.predict(input=next_reaction_prompt)
                        
                        # ê¸ì •ì  ì¢…ë£Œ í‚¤ì›Œë“œ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
                        positive_keywords = ["ê°ì‚¬", "thank you", "ã‚ã‚ŠãŒã¨ã†", L['customer_positive_response'].lower().split('/')[-1].strip()]
                        is_positive_close = any(keyword in customer_reaction.lower() for keyword in positive_keywords)
                        
                        if is_positive_close:
                            role = "customer_end" # ê¸ì •ì  ì¢…ë£Œ
                            st.session_state.simulator_messages.append({"role": role, "content": customer_reaction})
                            st.session_state.simulator_memory.chat_memory.add_ai_message(customer_reaction)
                            st.session_state.simulator_messages.append({"role": "supervisor", "content": L["customer_closing_confirm"]})
                            st.session_state.simulator_memory.chat_memory.add_ai_message(L["customer_closing_confirm"])
                        else:
                            role = "customer_rebuttal" # ì¬ë°˜ë°• ë˜ëŠ” ì¶”ê°€ ì§ˆë¬¸
                            st.session_state.simulator_messages.append({"role": role, "content": customer_reaction})
                            st.session_state.simulator_memory.chat_memory.add_ai_message(customer_reaction)
                             
                        st.rerun()
            
            # ì—ì´ì „íŠ¸(ì‚¬ìš©ì)ê°€ ê³ ê°ì—ê²Œ ì‘ë‹µí•  ì°¨ë¡€ (ì¬ë°˜ë°•, ì¶”ê°€ ì§ˆë¬¸ í›„)
            # ê³ ê°ì˜ ë§ˆì§€ë§‰ ë°˜ì‘ì´ 'rebuttal' ë˜ëŠ” 'end'ì˜€ê±°ë‚˜, 'supervisor'(ë§¤ë„ˆ ì§ˆë¬¸)ì¸ ê²½ìš°
            # --- ìŒì„± ì…ë ¥(ì„ íƒ) + í…ìŠ¤íŠ¸ ì…ë ¥ í¼ (agent ì‘ë‹µ) ---
import tempfile
import speech_recognition as sr  # ì„¤ì¹˜ í•„ìš”: pip install SpeechRecognition
from pydub import AudioSegment      # ì„¤ì¹˜ í•„ìš”: pip install pydub (ffmpeg í•„ìš”)

# ì—ì´ì „íŠ¸ê°€ ì‘ë‹µí•  ì°¨ë¡€ë¼ë©´, ìŒì„± ì…ë ¥ ìœ„ì ¯ + í…ìŠ¤íŠ¸ ì…ë ¥ì„ ëª¨ë‘ í‘œì‹œ
if last_role in ["customer_rebuttal", "customer_end", "supervisor"]:
    st.markdown("### ğŸ¤ ì—ì´ì „íŠ¸ ì‘ë‹µ (ìŒì„± ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥)")
    col_audio, col_text = st.columns([1, 3])

    # 1ï¸âƒ£ ìŒì„± ë…¹ìŒ ìœ„ì ¯
    with col_audio:
        st.markdown("**ğŸ”Š ìŒì„±ìœ¼ë¡œ ì‘ë‹µ (ì„ íƒ)**")
        audio_value = st.audio_input(L["button_mic_input"], key="simulator_audio_input")
        st.caption("ë…¹ìŒ í›„ ì „ì‚¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , í•„ìš”í•˜ë©´ í¸ì§‘í•œ ë’¤ ì „ì†¡í•˜ì„¸ìš”.")

    transcript = ""
    # 2ï¸âƒ£ ì˜¤ë””ì˜¤ê°€ ë“¤ì–´ì˜¤ë©´ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ì „ì‚¬ ì‹œë„
    if audio_value:
        tmp_dir = tempfile.mkdtemp()
        tmp_path = f"{tmp_dir}/sim_audio.wav"
        with open(tmp_path, "wb") as f:
            f.write(audio_value.getvalue())

        try:
            r = sr.Recognizer()
            # WAV íŒŒì¼ì„ í‘œì¤€í™”(16kHz, ëª¨ë…¸)ë¡œ ë³€í™˜
            audio_seg = AudioSegment.from_file(tmp_path)
            audio_seg = audio_seg.set_frame_rate(16000).set_channels(1)
            converted_path = f"{tmp_dir}/sim_audio_conv.wav"
            audio_seg.export(converted_path, format="wav")

            with sr.AudioFile(converted_path) as source:
                audio_data = r.record(source)
                lang = (
                    "ko-KR" if st.session_state.language == "ko"
                    else "ja-JP" if st.session_state.language == "ja"
                    else "en-US"
                )
                transcript = r.recognize_google(audio_data, language=lang)
                st.success("ğŸ™ï¸ ì „ì‚¬ ì„±ê³µ! í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"âš ï¸ ìŒì„± ì „ì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            transcript = ""

    # 3ï¸âƒ£ ì „ì‚¬ëœ í…ìŠ¤íŠ¸(ìˆìœ¼ë©´) ë³´ì—¬ì£¼ê³ , ì‚¬ìš©ìê°€ í¸ì§‘í•´ì„œ ë³´ë‚¼ ìˆ˜ ìˆê²Œ ì…ë ¥ë€ ì œê³µ
    with col_text:
        st.markdown("**âœï¸ ì—ì´ì „íŠ¸ ì‘ë‹µ (ìŒì„± ì „ì‚¬ ë˜ëŠ” ì§ì ‘ ì…ë ¥)**")
        agent_response = st.text_area(
            "ì—ì´ì „íŠ¸ë¡œì„œ ê³ ê°ì—ê²Œ ì‘ë‹µí•˜ì„¸ìš” (ì¬ë°˜ë°• ëŒ€ì‘)",
            value=transcript,
            key="agent_response_area",
            height=150
        )

        if st.button("ì‘ë‹µ ì „ì†¡", key="send_agent_response"):
            if agent_response.strip():
                st.session_state.simulator_messages.append(
                    {"role": "agent_response", "content": agent_response}
                )
                st.session_state.simulator_memory.chat_memory.add_user_message(agent_response)
                st.experimental_rerun()
            else:
                st.warning("ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")


    else:
        # LLM ì´ˆê¸°í™” ìì²´ì— ë¬¸ì œê°€ ìˆì„ ê²½ìš°ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ (ë‹¤êµ­ì–´)
        st.error(L["llm_error_init"])

elif feature_selection == L["rag_tab"]:
    st.header(L["rag_header"])
    st.markdown(L["rag_desc"])
    if st.session_state.get('is_rag_ready', False) and st.session_state.get('conversation_chain'):
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input(L["rag_input_placeholder"]):
            st.session_state.messages.append({"role":"user","content":prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                with st.spinner(f"ë‹µë³€ ìƒì„± ì¤‘..." if st.session_state.language == 'ko' else "Generating response..."):
                    try:
                        response = st.session_state.conversation_chain.invoke({"question":prompt})
                        answer = response.get('answer','ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' if st.session_state.language == 'ko' else 'Could not generate response.')
                        st.markdown(answer)
                        st.session_state.messages.append({"role":"assistant","content":answer})
                    except Exception as e:
                        st.error(f"ì±—ë´‡ ì˜¤ë¥˜: {e}")
                        st.session_state.messages.append({"role":"assistant","content":"ì˜¤ë¥˜ ë°œìƒ" if st.session_state.language == 'ko' else "An error occurred"})
    else:
        st.warning(L["warning_rag_not_ready"])

elif feature_selection == L["content_tab"]:
    st.header(L["content_header"])
    st.markdown(L["content_desc"])

    if st.session_state.is_llm_ready:
        topic = st.text_input(L["topic_label"])
        
        level_map = dict(zip(L["level_options"], ["Beginner", "Intermediate", "Advanced"]))
        content_map = dict(zip(L["content_options"], ["summary", "quiz", "example"]))
        
        level_display = st.selectbox(L["level_label"], L["level_options"])
        content_type_display = st.selectbox(L["content_type_label"], L["content_options"])

        level = level_map[level_display]
        content_type = content_map[content_type_display]

        if st.button(L["button_generate"]):
            if topic:
                target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]
                
                if content_type == 'quiz':
                    # 10ë¬¸í•­ìœ¼ë¡œ ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸
                    full_prompt = f"""You are a professional AI coach at the {level} level.
Please generate exactly 10 multiple-choice questions about the topic in {target_lang}.
Your entire response MUST be a valid JSON object wrapped in ```json tags.
The JSON must have a single key named 'quiz_questions', which is an array of objects.
Each question object must contain: 'question' (string), 'options' (array of objects with 'option' (A,B,C,D) and 'text' (string)), 'correct_answer' (A,B,C, or D), and 'explanation' (string).

Topic: {topic}"""
                else:
                    display_type_text = L["content_options"][L["content_options"].index(content_type_display)]
                    full_prompt = f"""You are a professional AI coach at the {level} level.
Please generate clear and educational content in the requested {display_type_text} format based on the topic.
The response MUST be strictly in {target_lang}.

Topic: {topic}
Requested Format: {display_type_text}"""
                
                
                with st.spinner(f"Generating {content_type_display} for {topic}..."):
                    
                    quiz_data_raw = None
                    try:
                        response = st.session_state.llm.invoke(full_prompt)
                        quiz_data_raw = response.content
                        st.session_state.quiz_data_raw = quiz_data_raw # ë””ë²„ê¹…ì„ ìœ„í•´ raw data ì €ì¥
                        
                        if content_type == 'quiz':
                            quiz_data = clean_and_load_json(quiz_data_raw)
                            
                            if quiz_data and 'quiz_questions' in quiz_data:
                                st.session_state.quiz_data = quiz_data
                                st.session_state.current_question = 0
                                st.session_state.quiz_submitted = False
                                st.session_state.quiz_results = [None] * len(quiz_data.get('quiz_questions',[]))
                                
                                st.success(f"**{topic}** - **{content_type_display}** Result:")
                            else:
                                st.error(L["quiz_error_llm"])
                                st.markdown(f"**{L['quiz_original_response']}**:")
                                st.code(quiz_data_raw, language="json")

                        else: # ì¼ë°˜ ì½˜í…ì¸  (ìš”ì•½, ì˜ˆì œ)
                            st.success(f"**{topic}** - **{content_type_display}** Result:")
                            st.markdown(response.content)

                    except Exception as e:
                        st.error(f"Content Generation Error: {e}")
                        if quiz_data_raw:
                            st.markdown(f"**{L['quiz_original_response']}**: {quiz_data_raw}")

            else:
                st.warning(L["warning_topic"])
    else:
        st.error(L["llm_error_init"])
        
    # í€´ì¦ˆ í’€ì´ ë Œë”ë§ì„ ë©”ì¸ ë£¨í”„ì—ì„œ ì¡°ê±´ë¶€ë¡œ ë‹¨ í•œ ë²ˆ í˜¸ì¶œ
    is_quiz_ready = content_type == 'quiz' and 'quiz_data' in st.session_state and st.session_state.quiz_data
    if is_quiz_ready and st.session_state.get('current_question', 0) < len(st.session_state.quiz_data.get('quiz_questions', [])):
        render_interactive_quiz(st.session_state.quiz_data, st.session_state.language)
