# ========================================
# streamlit_app_last_correction.py
# ë¡œì»¬ ì „ìš©: RAG + ì‹œë®¬ë ˆì´í„° + ìŒì„± ê¸°ë¡ + LSTM + ì½˜í…ì¸ 
# Firebase/GCS ì œê±°, local_db(JSON/íŒŒì¼)ë§Œ ì‚¬ìš©
# Python 3.9 / langchain>=1.0 / streamlit-mic-recorder 0.0.8 ê¸°ì¤€
# ========================================

import os
import io
import json
import time
import uuid
import base64
import tempfile
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any
import google.generativeai as genai
import numpy as np
import streamlit as st
from matplotlib import pyplot as plt

from openai import OpenAI
from anthropic import Anthropic  # Claude ì„í¬íŠ¸ ì¶”ê°€

# mic_recorder (0.0.8) - returns dict with key "bytes"
from streamlit_mic_recorder import mic_recorder

# LangChain / RAG ê´€ë ¨
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_community.embeddings import HuggingFaceEmbeddings  # NVIDIA/Claude/Groq fallbackìš©
try:
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    IS_GEMINI_EMBEDDING_AVAILABLE = True
except ImportError:
    IS_GEMINI_EMBEDDING_AVAILABLE = False
    
try:
    from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings
    IS_NVIDIA_EMBEDDING_AVAILABLE = True
except ImportError:
    IS_NVIDIA_EMBEDDING_AVAILABLE = False

# ========================================
# 0. ê¸°ë³¸ ê²½ë¡œ/ë¡œì»¬ DB ì„¤ì •
# ========================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "local_db")
AUDIO_DIR = os.path.join(DATA_DIR, "audio")
RAG_INDEX_DIR = os.path.join(DATA_DIR, "rag_index")

VOICE_META_FILE = os.path.join(DATA_DIR, "voice_records.json")
SIM_META_FILE = os.path.join(DATA_DIR, "simulation_histories.json")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(RAG_INDEX_DIR, exist_ok=True)


# ----------------------------------------
# JSON Helper
# ----------------------------------------
def _load_json(path: str, default: Any):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return default


def _save_json(path: str, data: Any):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# ========================================
# 1. ë‹¤êµ­ì–´ ì„¤ì •
# ========================================
# ========================================
# 1. ë‹¤êµ­ì–´ ì„¤ì •
# ========================================
DEFAULT_LANG = "ko"

LANG: Dict[str, Dict[str, str]] = {
    "ko": {
        "title": "ê°œì¸ ë§ì¶¤í˜• AI í•™ìŠµ ì½”ì¹˜ (ìŒì„± ë° DB í†µí•©)",
        "sidebar_title": "ğŸ“š AI Study Coach ì„¤ì •",
        "file_uploader": "í•™ìŠµ ìë£Œ ì—…ë¡œë“œ (PDF, TXT, HTML)",
        "button_start_analysis": "ìë£Œ ë¶„ì„ ì‹œì‘ (RAG Indexing)",
        "rag_tab": "RAG ì§€ì‹ ì±—ë´‡",
        "content_tab": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "lstm_tab": "LSTM ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "simulator_tab": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°",
        "rag_header": "RAG ì§€ì‹ ì±—ë´‡ (ë¬¸ì„œ ê¸°ë°˜ Q&A)",
        "rag_desc": "ì—…ë¡œë“œëœ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ã€‚",
        "rag_input_placeholder": "í•™ìŠµ ìë£Œì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”",
        "llm_error_key": "âš ï¸ ê²½ê³ : GEMINI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì— 'GEMINI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”ã€‚",
        "llm_error_init": "LLM ì´ˆê¸°í™” ì˜¤ë¥˜: API í‚¤ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”ã€‚",
        "content_header": "ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìƒì„±",
        "content_desc": "í•™ìŠµ ì£¼ì œì™€ ë‚œì´ë„ì— ë§ì¶° ì½˜í…ì¸  ìƒì„±",
        "topic_label": "í•™ìŠµ ì£¼ì œ",
        "level_label": "ë‚œì´ë„",
        "content_type_label": "ì½˜í…ì¸  í˜•ì‹",
        "level_options": ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"],
        "content_options": ["í•µì‹¬ ìš”ì•½ ë…¸íŠ¸", "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­", "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´"],
        "button_generate": "ì½˜í…ì¸  ìƒì„±",
        "warning_topic": "í•™ìŠµ ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚",
        "lstm_header": "LSTM ê¸°ë°˜ í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
        "lstm_desc": "ê°€ìƒì˜ ê³¼ê±° í€´ì¦ˆ ì ìˆ˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ LSTM ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë¯¸ë˜ ì„±ì·¨ë„ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤ã€‚",
        "lang_select": "ì–¸ì–´ ì„ íƒ",
        "embed_success": "ì´ {count}ê°œ ì²­í¬ë¡œ í•™ìŠµ DB êµ¬ì¶• ì™„ë£Œ!",
        "embed_fail": "ì„ë² ë”© ì‹¤íŒ¨: ë¬´ë£Œ í‹°ì–´ í•œë„ ì´ˆê³¼ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œã€‚",
        "warning_no_files": "ë¨¼ì € í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
        "warning_rag_not_ready": "RAGê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•™ìŠµ ìë£Œë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•˜ì„¸ìš”ã€‚",
        "quiz_fail_structure": "í€´ì¦ˆ ë°ì´í„° êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚",
        "select_answer": "ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”",
        "check_answer": "ì •ë‹µ í™•ì¸",
        "next_question": "ë‹¤ìŒ ë¬¸í•­",
        "correct_answer": "ì •ë‹µì…ë‹ˆë‹¤! ğŸ‰",
        "incorrect_answer": "ì˜¤ë‹µì…ë‹ˆë‹¤ã€‚ğŸ˜",
        "correct_is": "ì •ë‹µ",
        "explanation": "í•´ì„¤",
        "quiz_complete": "í€´ì¦ˆ ì™„ë£Œ!",
        "score": "ì ìˆ˜",
        "retake_quiz": "í€´ì¦ˆ ë‹¤ì‹œ í’€ê¸°",
        "quiz_error_llm": "í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: LLMì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ã€‚",
        "quiz_original_response": "LLM ì›ë³¸ ì‘ë‹µ",
        "firestore_loading": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...",
        "firestore_no_index": "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ RAG ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìƒˆë¡œ ë§Œë“œì„¸ìš”ã€‚",
        "db_save_complete": "(DB ì €ì¥ ì™„ë£Œ)",
        "data_analysis_progress": "ìë£Œ ë¶„ì„ ë° í•™ìŠµ DB êµ¬ì¶• ì¤‘...",
        "response_generating": "ë‹µë³€ ìƒì„± ì¤‘...",
        "lstm_result_header": "í•™ìŠµ ì„±ì·¨ë„ ì˜ˆì¸¡ ê²°ê³¼",
        "lstm_score_metric": "í˜„ì¬ ì˜ˆì¸¡ ì„±ì·¨ë„",
        "lstm_score_info": "ë‹¤ìŒ í€´ì¦ˆ ì˜ˆìƒ ì ìˆ˜ëŠ” ì•½ **{predicted_score:.1f}ì **ì…ë‹ˆë‹¤. í•™ìŠµ ì„±ê³¼ë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ê°œì„ í•˜ì„¸ìš”!",
        "lstm_rerun_button": "ìƒˆë¡œìš´ ê°€ìƒ ë°ì´í„°ë¡œ ì˜ˆì¸¡",

        # --- ì‹œë®¬ë ˆì´í„° ---
        "simulator_header": "AI ê³ ê° ì‘ëŒ€ ì‹œë®¬ë ˆì´í„°",
        "simulator_desc": "ê¹Œë‹¤ë¡œìš´ ê³ ê° ë¬¸ì˜ì— AIì˜ ì‘ëŒ€ ì´ˆì•ˆ ë° ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤ã€‚",
        "customer_query_label": "ê³ ê° ë¬¸ì˜ ë‚´ìš© (ë§í¬ í¬í•¨ ê°€ëŠ¥)",
        "customer_type_label": "ê³ ê° ì„±í–¥",
        "customer_type_options": ["ì¼ë°˜ì ì¸ ë¬¸ì˜", "ê¹Œë‹¤ë¡œìš´ ê³ ê°", "ë§¤ìš° ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ìš´ ê³ ê°"],
        "button_simulate": "ì‘ëŒ€ ì¡°ì–¸ ìš”ì²­",
        "customer_generate_response_button": "ê³ ê° ë°˜ì‘ ìƒì„±",
        "send_closing_confirm_button": "ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸°",
        "simulation_warning_query": "ê³ ê° ë¬¸ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”ã€‚",
        "simulation_no_key_warning": "âš ï¸ API Keyê°€ ì—†ê¸° ë•Œë¬¸ì— ì‘ë‹µ ìƒì„±ì€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ã€‚",
        "simulation_advice_header": "AIì˜ ì‘ëŒ€ ê°€ì´ë“œë¼ì¸",
        "simulation_draft_header": "ì¶”ì²œ ì‘ëŒ€ ì´ˆì•ˆ",
        "button_listen_audio": "ìŒì„±ìœ¼ë¡œ ë“£ê¸°",
        "tts_status_ready": "ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì¤€ë¹„ë¨",
        "tts_status_generating": "ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...",
        "tts_status_success": "âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ!",
        "tts_status_error": "âŒ TTS ì˜¤ë¥˜ ë°œìƒ",
        "history_expander_title": "ğŸ“ ì´ì „ ìƒë‹´ ì´ë ¥ ë¡œë“œ (ìµœê·¼ 10ê°œ)",
        "initial_query_sample": "í”„ë‘ìŠ¤ íŒŒë¦¬ì— ë„ì°©í–ˆëŠ”ë°, í´ë£©ì—ì„œ êµ¬ë§¤í•œ eSIMì´ í™œì„±í™”ê°€ ì•ˆ ë©ë‹ˆë‹¤...",
        "button_mic_input": "ğŸ™ ìŒì„± ì…ë ¥",
        "prompt_customer_end": "ê³ ê°ë‹˜ì˜ ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ì—†ì–´, ì´ ìƒë‹´ì„ ì¢…ë£Œí•©ë‹ˆë‹¤ã€‚",
        "prompt_survey": "ì§€ê¸ˆê¹Œì§€ ìƒë‹´ì› 000ì˜€ìŠµë‹ˆë‹¤. ì¦ê±°ìš´ í•˜ë£¨ ë˜ì‹œê¸° ë°”ëë‹ˆë‹¤. [ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬]",
        "customer_closing_confirm": "ë‹¤ë¥¸ ë¬¸ì˜ ì‚¬í•­ì€ ì—†ìœ¼ì‹­ë‹ˆê¹Œ?",
        "customer_positive_response": "ì•Œê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤ã€‚",
        "button_end_chat": "ì‘ëŒ€ ì¢…ë£Œ (ì„¤ë¬¸ ìš”ì²­)",
        "survey_sent_confirm": "ğŸ“¨ ì„¤ë¬¸ì¡°ì‚¬ ë§í¬ê°€ ì „ì†¡ë˜ì—ˆìœ¼ë©°, ì´ ìƒë‹´ì€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ã€‚",
        "new_simulation_ready": "ìƒˆ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ã€‚",
        "agent_response_header": "âœï¸ ì—ì´ì „íŠ¸ ì‘ë‹µ",
        "agent_response_placeholder": "ê³ ê°ì—ê²Œ ì‘ë‹µí•˜ì„¸ìš”...",
        "send_response_button": "ì‘ë‹µ ì „ì†¡",
        "request_rebuttal_button": "ê³ ê°ì˜ ë‹¤ìŒ ë°˜ì‘ ìš”ì²­",
        "new_simulation_button": "ìƒˆ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘",
        "history_selectbox_label": "ë¡œë“œí•  ì´ë ¥ì„ ì„ íƒí•˜ì„¸ìš”:",
        "history_load_button": "ì„ íƒëœ ì´ë ¥ ë¡œë“œ",
        "delete_history_button": "âŒ ëª¨ë“  ì´ë ¥ ì‚­ì œ",
        "delete_confirm_message": "ì •ë§ë¡œ ëª¨ë“  ìƒë‹´ ì´ë ¥ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "delete_confirm_yes": "ì˜ˆ, ì‚­ì œí•©ë‹ˆë‹¤",
        "delete_confirm_no": "ì•„ë‹ˆì˜¤, ìœ ì§€í•©ë‹ˆë‹¤",
        "delete_success": "âœ… ì‚­ì œ ì™„ë£Œ!",
        "deleting_history_progress": "ì´ë ¥ ì‚­ì œ ì¤‘...",
        "search_history_label": "ì´ë ¥ ê²€ìƒ‰",
        "date_range_label": "ë‚ ì§œ ë²”ìœ„ í•„í„°",
        "no_history_found": "ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "customer_email_label": "ê³ ê° ì´ë©”ì¼ (ì„ íƒ)",
        "customer_phone_label": "ê³ ê° ì—°ë½ì²˜ / ì „í™”ë²ˆí˜¸ (ì„ íƒ)",
        "transfer_header": "ì–¸ì–´ ì´ê´€ ìš”ì²­ (ë‹¤ë¥¸ íŒ€)",
        "transfer_to_en": "ğŸ‡ºğŸ‡¸ ì˜ì–´ íŒ€ìœ¼ë¡œ ì´ê´€",
        "transfer_to_ja": "ğŸ‡¯ğŸ‡µ ì¼ë³¸ì–´ íŒ€ìœ¼ë¡œ ì´ê´€",
        "transfer_to_ko": "ğŸ‡°ğŸ‡· í•œêµ­ì–´ íŒ€ìœ¼ë¡œ ì´ê´€",
        "transfer_system_msg": "ğŸ“Œ ì‹œìŠ¤í…œ ë©”ì‹œì§€: ê³ ê° ìš”ì²­ì— ë”°ë¼ ìƒë‹´ ì–¸ì–´ê°€ {target_lang} íŒ€ìœ¼ë¡œ ì´ê´€ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ìƒë‹´ì›(AI)ì´ ì‘ëŒ€í•©ë‹ˆë‹¤ã€‚",
        "transfer_loading": "ì´ê´€ ì²˜ë¦¬ ì¤‘: ì´ì „ ëŒ€í™” ì´ë ¥ ë²ˆì—­ ë° ê²€í†  (ê³ ê°ë‹˜ê»˜ 3~10ë¶„ ì–‘í•´ ìš”ì²­)",
        "transfer_summary_header": "ğŸ” ì´ê´€ëœ ìƒë‹´ì›ì„ ìœ„í•œ ìš”ì•½ (ë²ˆì—­ë¨)",
        "transfer_summary_intro": "ê³ ê°ë‹˜ê³¼ì˜ ì´ì „ ëŒ€í™” ì´ë ¥ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ëŒ€ë¥¼ ì´ì–´ë‚˜ê°€ì„¸ìš”ã€‚",
        "llm_translation_error": "âŒ ë²ˆì—­ ì‹¤íŒ¨: LLM ì‘ë‹µ ì˜¤ë¥˜",
        "timer_metric": "ìƒë‹´ ê²½ê³¼ ì‹œê°„",
        "timer_info_ok": "AHT (15ë¶„ ê¸°ì¤€)",
        "timer_info_warn": "AHT (10ë¶„ ì´ˆê³¼)",
        "timer_info_risk": "ğŸš¨ 15ë¶„ ì´ˆê³¼: ë†’ì€ ë¦¬ìŠ¤í¬",
        "solution_check_label": "âœ… ì´ ì‘ë‹µì— ì†”ë£¨ì…˜/í•´ê²°ì±…ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤ã€‚",

        # --- ìŒì„± ê¸°ë¡ ---
        "voice_rec_header": "ìŒì„± ê¸°ë¡ & ê´€ë¦¬",
        "record_help": "ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒí•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”ã€‚",
        "uploaded_file": "ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ",
        "rec_list_title": "ì €ì¥ëœ ìŒì„± ê¸°ë¡",
        "transcribe_btn": "ì „ì‚¬(Whisper)",
        "save_btn": "ìŒì„± ê¸°ë¡ ì €ì¥",
        "transcribing": "ìŒì„± ì „ì‚¬ ì¤‘...",
        "transcript_result": "ì „ì‚¬ ê²°ê³¼:",
        "transcript_text": "ì „ì‚¬ í…ìŠ¤íŠ¸",
        "openai_missing": "OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "whisper_client_error": "âŒ Whisper API Client ì´ˆê¸°í™” ì‹¤íŒ¨",
        "whisper_auth_error": "âŒ Whisper API ì¸ì¦ ì‹¤íŒ¨",
        "whisper_format_error": "âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤ã€‚",
        "whisper_success": "âœ… ìŒì„± ì „ì‚¬ ì™„ë£Œ!",
        "playback": "ë…¹ìŒ ì¬ìƒ",
        "retranscribe": "ì¬ì „ì‚¬",
        "delete": "ì‚­ì œ",
        "no_records": "ì €ì¥ëœ ìŒì„± ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤ã€‚",
        "saved_success": "ì €ì¥ ì™„ë£Œ!",
        "delete_confirm_rec": "ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "gcs_not_conf": "GCS ë¯¸ì„¤ì •",
        "gcs_playback_fail": "ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨",
        "gcs_no_audio": "ì˜¤ë””ì˜¤ ì—†ìŒ",
        "error": "ì˜¤ë¥˜:",
        "firestore_no_db_connect": "DB ì—°ê²° ì‹¤íŒ¨",
        "save_history_success": "ìƒë‹´ ì´ë ¥ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ã€‚",
        "save_history_fail": "ìƒë‹´ ì´ë ¥ ì €ì¥ ì‹¤íŒ¨",
        "delete_fail": "ì‚­ì œ ì‹¤íŒ¨",
        "rec_header": "ìŒì„± ì…ë ¥ ë° ì „ì‚¬",
        "whisper_processing": "ìŒì„± ì „ì‚¬ ì²˜ë¦¬ ì¤‘",
        "empty_response_warning": "ì‘ë‹µì„ ì…ë ¥í•˜ì„¸ìš”ã€‚",
        "customer_no_more_inquiries": "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤ã€‚",
        "customer_has_additional_inquiries": "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ë„ ìˆìŠµë‹ˆë‹¤ã€‚",
        "sim_end_chat_button": "ì„¤ë¬¸ ì¡°ì‚¬ ë§í¬ ì „ì†¡ ë° ì±„íŒ… ì¢…ë£Œ",

        # --- ì²¨ë¶€ íŒŒì¼ ê¸°ëŠ¥ ì¶”ê°€ ---
        "attachment_label": "ê³ ê° ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë“œ (ìŠ¤í¬ë¦°ìƒ· ë“±)",
        "attachment_placeholder": "íŒŒì¼ì„ ì²¨ë¶€í•˜ì—¬ ìƒí™©ì„ ì„¤ëª…í•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­)",
        "attachment_status_llm": "ê³ ê°ì´ **{filename}** íŒŒì¼ì„ ì²¨ë¶€í–ˆìŠµë‹ˆë‹¤. ì´ íŒŒì¼ì„ ìŠ¤í¬ë¦°ìƒ·ì´ë¼ê³  ê°€ì •í•˜ê³  ì‘ëŒ€ ì´ˆì•ˆ ë° ê°€ì´ë“œë¼ì¸ì— ë°˜ì˜í•˜ì„¸ìš”. (íŒŒì¼ íƒ€ì…: {filetype})",
        "agent_attachment_label": "ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ (ìŠ¤í¬ë¦°ìƒ· ë“±)",
        "agent_attachment_placeholder": "ì‘ë‹µì— ì²¨ë¶€í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­)",
        "agent_attachment_status": "ğŸ“ ì—ì´ì „íŠ¸ê°€ **{filename}** íŒŒì¼ì„ ì‘ë‹µì— ì²¨ë¶€í–ˆìŠµë‹ˆë‹¤. (íŒŒì¼ íƒ€ì…: {filetype})",

        # --- RAG ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ê°€ ---
        "rag_embed_error_openai": "RAG ì„ë² ë”© ì‹¤íŒ¨: OpenAI API Keyê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        "rag_embed_error_gemini": "RAG ì„ë² ë”© ì‹¤íŒ¨: Gemini API Keyê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        "rag_embed_error_nvidia": "RAG ì„ë² ë”© ì‹¤íŒ¨: NVIDIA API Keyê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ã€‚",
        "rag_embed_error_none": "RAG ì„ë² ë”©ì— í•„ìš”í•œ ëª¨ë“  í‚¤(OpenAI, Gemini, NVIDIA)ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‚¤ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”ã€‚",
    },

    # --- â­ ì˜ì–´ ë²„ì „ (í•œêµ­ì–´ 100% ë§¤ì¹­) ---
    "en": {
        "title": "Personalized AI Study Coach (Voice & Local DB)",
        "sidebar_title": "ğŸ“š AI Study Coach Settings",
        "file_uploader": "Upload Study Materials (PDF, TXT, HTML)",
        "button_start_analysis": "Start Analysis (RAG Indexing)",
        "rag_tab": "RAG Knowledge Chatbot",
        "content_tab": "Custom Content Generation",
        "lstm_tab": "LSTM Achievement Prediction Dashboard",
        "simulator_tab": "AI Customer Support Simulator",
        "rag_header": "RAG Knowledge Chatbot (Document Q&A)",
        "rag_desc": "Answer questions based on uploaded documents.",
        "rag_input_placeholder": "Ask a question about your study materials",
        "llm_error_key": "âš ï¸ Warning: GEMINI_API_KEY is not set.",
        "llm_error_init": "LLM initialization error. Please check your API key.",
        "content_header": "Custom Learning Content Generation",
        "content_desc": "Generate content based on the topic and difficulty.",
        "topic_label": "Learning Topic",
        "level_label": "Difficulty",
        "content_type_label": "Content Type",
        "level_options": ["Beginner", "Intermediate", "Advanced"],
        "content_options": ["Key Summary Note", "10 MCQ Questions", "Practical Example Idea"],
        "button_generate": "Generate Content",
        "warning_topic": "Please enter a learning topic.",
        "lstm_header": "LSTM Achievement Prediction Dashboard",
        "lstm_desc": "Train an LSTM model on hypothetical quiz scores and predict performance.",
        "lang_select": "Select Language",
        "embed_success": "Learning DB built with {count} chunks!",
        "embed_fail": "Embedding failed: quota exceeded or network issue.",
        "warning_no_files": "Please upload study materials first.",
        "warning_rag_not_ready": "RAG is not ready. Upload materials and analyze.",
        "quiz_fail_structure": "Quiz data structure is invalid.",
        "select_answer": "Select answer",
        "check_answer": "Check answer",
        "next_question": "Next question",
        "correct_answer": "Correct! ğŸ‰",
        "incorrect_answer": "Incorrect ğŸ˜",
        "correct_is": "Correct answer",
        "explanation": "Explanation",
        "quiz_complete": "Quiz Complete!",
        "score": "Score",
        "retake_quiz": "Retake Quiz",
        "quiz_error_llm": "Quiz generation failed: invalid JSON.",
        "quiz_original_response": "Original LLM Response",
        "firestore_loading": "Loading RAG index...",
        "firestore_no_index": "No existing RAG index found.",
        "db_save_complete": "(DB Save Complete)",
        "data_analysis_progress": "Analyzing materials and building DB...",
        "response_generating": "Generating response...",
        "lstm_result_header": "Achievement Prediction",
        "lstm_score_metric": "Predicted Achievement",
        "lstm_score_info": "Estimated next quiz score: **{predicted_score:.1f}**.",
        "lstm_rerun_button": "Predict with New Data",

        # Simulator
        "simulator_header": "AI Customer Response Simulator",
        "simulator_desc": "AI generates draft responses and guidelines for customer inquiries.",
        "customer_query_label": "Customer Message (links allowed)",
        "customer_type_label": "Customer Type",
        "customer_type_options": ["General Inquiry", "Difficult Customer", "Highly Dissatisfied Customer"],
        "button_simulate": "Generate Response",
        "customer_generate_response_button": "Generate Customer Response",
        "send_closing_confirm_button": "Send Closing Confirmation",
        "simulation_warning_query": "Please enter the customerâ€™s message.",
        "simulation_no_key_warning": "âš ï¸ API Key missing. Simulation cannot proceed.",
        "simulation_advice_header": "AI Response Guidelines",
        "simulation_draft_header": "Recommended Response Draft",
        "button_listen_audio": "Play as Audio",
        "tts_status_ready": "Ready to generate audio",
        "tts_status_generating": "Generating audio...",
        "tts_status_success": "Audio ready!",
        "tts_status_error": "TTS error occurred",
        "history_expander_title": "ğŸ“ Load Previous Sessions (Last 10)",
        "initial_query_sample": "I arrived in Paris but my Klook eSIM won't activateâ€¦",
        "button_mic_input": "ğŸ™ Voice Input",
        "prompt_customer_end": "No further inquiries. Ending chat.",
        "prompt_survey": "This was Agent 000. Have a nice day. [Survey Link]",
        "customer_closing_confirm": "Is there anything else we can assist you with?",
        "customer_positive_response": "Noted with thanks.",
        "button_end_chat": "End Chat (Survey Request)",
        "survey_sent_confirm": "ğŸ“¨ The survey link has been sent. This chat session is now closed.",
        "new_simulation_ready": "You can now start a new simulation.",
        "agent_response_header": "âœï¸ Agent Response",
        "agent_response_placeholder": "Write a response...",
        "send_response_button": "Send Response",
        "request_rebuttal_button": "Request Customer Reaction",
        "new_simulation_button": "Start New Simulation",
        "history_selectbox_label": "Choose a record to load:",
        "history_load_button": "Load Selected Record",
        "delete_history_button": "âŒ Delete All History",
        "delete_confirm_message": "Are you sure you want to delete all records?",
        "delete_confirm_yes": "Yes, Delete",
        "delete_confirm_no": "Cancel",
        "delete_success": "Deleted successfully!",
        "deleting_history_progress": "Deleting history...",
        "search_history_label": "Search History",
        "date_range_label": "Date Filter",
        "no_history_found": "No matching history found.",
        "customer_email_label": "Customer Email (optional)",
        "customer_phone_label": "Customer Phone / WhatsApp (optional)",
        "transfer_header": "Language Transfer Request (To Other Teams)",
        "transfer_to_en": "ğŸ‡°ğŸ‡· Korean Team Transfer",
        "transfer_to_ja": "ğŸ‡¯ğŸ‡µ Japanese Team Transfer",
        "transfer_to_ko": "ğŸ‡ºğŸ‡¸ English Team Transfer",
        "transfer_system_msg": "ğŸ“Œ System Message: The session language has been transferred to the {target_lang} team per customer request. A new agent (AI) will now respond.",
        "transfer_loading": "Transferring: Translating and reviewing chat history (3-10 minute wait requested from customer)",
        "transfer_summary_header": "ğŸ” Summary for Transferred Agent (Translated)",
        "transfer_summary_intro": "This is the previous chat history. Please continue the support based on this summary.",
        "llm_translation_error": "âŒ Translation failed: LLM response error",
        "timer_metric": "Elapsed Time",
        "timer_info_ok": "AHT (15 min standard)",
        "timer_info_warn": "AHT (Over 10 min)",
        "timer_info_risk": "ğŸš¨ Over 15 min: High Risk",
        "solution_check_label": "âœ… This response includes a solution/fix.",

        # Voice
        "voice_rec_header": "Voice Record & Management",
        "record_help": "Record using the microphone or upload a file.",
        "uploaded_file": "Upload Audio File",
        "rec_list_title": "Saved Voice Records",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Record",
        "transcribing": "Transcribing...",
        "transcript_result": "Transcription:",
        "transcript_text": "Transcribed Text",
        "openai_missing": "Missing OPENAI_API_KEY",
        "whisper_client_error": "Whisper client initialization failed.",
        "whisper_auth_error": "Whisper authentication failed.",
        "whisper_format_error": "Unsupported audio format.",
        "whisper_success": "Transcription complete!",
        "playback": "Play Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "transcribe_btn": "Transcribe (Whisper)",
        "save_btn": "Save Voice Record",
        "transcribing": "Transcribing voice...",
        "transcript_result": "Transcription Result:",
        "transcript_text": "Transcribed Text",
        "whisper_processing": "Processing voice transcription...",
        "whisper_success": "âœ… Transcription complete! Please check the text below.",
        "openai_missing": "OpenAI API Key is missing. Please set OPENAI_API_KEY.",
        "whisper_client_error": "âŒ Error: Whisper API client not initialized.",
        "whisper_auth_error": "âŒ Whisper API authentication failed. Check your API Key.",
        "whisper_format_error": "âŒ Error: Unsupported audio format.",
        "playback": "Playback Recording",
        "retranscribe": "Re-transcribe",
        "delete": "Delete",
        "no_records": "No saved voice records.",
        "saved_success": "Saved successfully!",
        "delete_confirm_rec": "Are you sure you want to delete this voice record?",
        "gcs_not_conf": "GCS not configured or no audio available",
        "gcs_playback_fail": "Failed to play audio",
        "gcs_no_audio": "No audio file found",
        "error": "Error:",
        "firestore_no_db_connect": "DB connection failed",
        "save_history_success": "Saved successfully.",
        "save_history_fail": "Save failed.",
        "delete_fail": "Delete failed",
        "rec_header": "Voice Input & Transcription",
        "whisper_processing": "Processing...",
        "empty_response_warning": "Please enter a response.",
        "customer_no_more_inquiries": "No, that will be all, thank you.",
        "customer_has_additional_inquiries": "Yes, I have an additional question.",
        "sim_end_chat_button": "Send Survey Link and End Chat",

        # --- ì²¨ë¶€ íŒŒì¼ ê¸°ëŠ¥ ì¶”ê°€ ---
        "attachment_label": "Customer Attachment Upload (Screenshot, etc.)",
        "attachment_placeholder": "Attach a file to explain the situation (optional)",
        "attachment_status_llm": "The customer has attached the file **{filename}** files. Assume these files are screenshots and incorporate them into the draft response and guidelines. (Total files: {count})",
        "agent_attachment_label": "Agent Attachment (Screenshot, etc.)",
        "agent_attachment_placeholder": "Select a file to attach to the response (optional)",
        "agent_attachment_status": "ğŸ“ Agent attached **{filename}** files. (Total files: {count})",

        # --- RAG ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ê°€ ---
        "rag_embed_error_openai": "RAG embedding failed: OpenAI API Key is invalid or not set.",
        "rag_embed_error_gemini": "RAG embedding failed: Gemini API Key is invalid or not set.",
        "rag_embed_error_nvidia": "RAG embedding failed: NVIDIA API Key is invalid or not set.",
        "rag_embed_error_none": "RAG embedding failed: All required keys (OpenAI, Gemini, NVIDIA) are invalid or not set. Please configure a key.",
    },

    # --- â­ ì¼ë³¸ì–´ ë²„ì „ (í•œêµ­ì–´ 100% ë§¤ì¹­) ---
    "ja": {
        "title": "ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºAIå­¦ç¿’ã‚³ãƒ¼ãƒ (éŸ³å£°ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«DB)",
        "sidebar_title": "ğŸ“š AIå­¦ç¿’ã‚³ãƒ¼ãƒè¨­å®š",
        "file_uploader": "å­¦ç¿’è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PDF, TXT, HTML)",
        "button_start_analysis": "è³‡æ–™åˆ†æé–‹å§‹ (RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ)",
        "rag_tab": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
        "content_tab": "ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "lstm_tab": "LSTMé”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "simulator_tab": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
        "rag_header": "RAGçŸ¥è­˜ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆQ&A)",
        "rag_desc": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè³‡æ–™ã«åŸºã¥ã„ã¦è³ªå•ã«å›ç­”ã—ã¾ã™ã€‚",
        "rag_input_placeholder": "è³‡æ–™ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„",
        "llm_error_key": "âš ï¸ æ³¨æ„: GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "llm_error_init": "LLM åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ï¼šAPIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        "content_header": "ã‚«ã‚¹ã‚¿ãƒ å­¦ç¿’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ",
        "content_desc": "å­¦ç¿’ãƒ†ãƒ¼ãƒã¨é›£æ˜“åº¦ã«å¿œã˜ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "topic_label": "å­¦ç¿’ãƒ†ãƒ¼ãƒ",
        "level_label": "é›£æ˜“åº¦",
        "content_type_label": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç¨®é¡",
        "level_options": ["åˆç´š", "ä¸­ç´š", "ä¸Šç´š"],
        "content_options": ["è¦ç‚¹ã‚µãƒãƒªãƒ¼", "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•", "å®Ÿè·µä¾‹ã‚¢ã‚¤ãƒ‡ã‚¢"],
        "button_generate": "ç”Ÿæˆã™ã‚‹",
        "warning_topic": "å­¦ç¿’ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "lstm_header": "LSTMé”æˆåº¦äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
        "lstm_desc": "ä»®æƒ³ã‚¯ã‚¤ã‚ºã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã—ã¦é”æˆåº¦ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚",
        "lang_select": "è¨€èªé¸æŠ",
        "embed_success": "{count}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã§DBæ§‹ç¯‰å®Œäº†!",
        "embed_fail": "åŸ‹ã‚è¾¼ã¿å¤±æ•—ï¼šã‚¯ã‚©ãƒ¼ã‚¿è¶…éã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã€‚",
        "warning_no_files": "è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
        "warning_rag_not_ready": "RAGãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“ã€‚",
        "quiz_fail_structure": "ã‚¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚",
        "select_answer": "å›ç­”ã‚’é¸æŠã—ã¦ãã ã•ã„",
        "check_answer": "å›ç­”ã‚’ç¢ºèª",
        "next_question": "æ¬¡ã®è³ªå•",
        "correct_answer": "æ­£è§£ï¼ ğŸ‰",
        "incorrect_answer": "ä¸æ­£è§£ ğŸ˜",
        "correct_is": "æ­£è§£",
        "explanation": "è§£èª¬",
        "quiz_complete": "ã‚¯ã‚¤ã‚ºå®Œäº†!",
        "score": "ã‚¹ã‚³ã‚¢",
        "retake_quiz": "å†æŒ‘æˆ¦",
        "quiz_error_llm": "í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨ï¼šJSONå½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚",
        "quiz_original_response": "LLM åŸæœ¬å›ç­”",
        "firestore_loading": "RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ä¸­...",
        "firestore_no_index": "ä¿å­˜ã•ã‚ŒãŸRAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
        "db_save_complete": "(DBä¿å­˜å®Œäº†)",
        "data_analysis_progress": "è³‡æ–™åˆ†æä¸­...",
        "response_generating": "å¿œç­”ç”Ÿæˆä¸­...",
        "lstm_result_header": "é”æˆåº¦äºˆæ¸¬çµæœ",
        "lstm_score_metric": "äºˆæ¸¬é”æˆåº¦",
        "lstm_score_info": "æ¬¡ã®ã‚¹ã‚³ã‚¢äºˆæ¸¬: **{predicted_score:.1f}ç‚¹**",
        "lstm_rerun_button": "æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§å†äºˆæ¸¬",

        # --- Simulator ---
        "simulator_header": "AIé¡§å®¢å¯¾å¿œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
        "simulator_desc": "é›£ã—ã„é¡§å®¢å•ã„åˆã‚ã›ã«å¯¾ã™ã‚‹AIã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¨è‰æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "customer_query_label": "é¡§å®¢ã‹ã‚‰ã®å•ã„åˆã‚ã›å†…å®¹ (ãƒªãƒ³ã‚¯å¯)",
        "customer_type_label": "é¡§å®¢ã‚¿ã‚¤ãƒ—",
        "customer_type_options": ["ä¸€èˆ¬çš„ãªå•ã„åˆã‚ã›", "é›£ã—ã„é¡§å®¢", "éå¸¸ã«ä¸æº€ãªé¡§å®¢"],
        "button_simulate": "å¿œå¯¾ã‚¬ã‚¤ãƒ‰ç”Ÿæˆ",
        "customer_generate_response_button": "é¡§å®¢ã®è¿”ä¿¡ã‚’ç”Ÿæˆ",
        "send_closing_confirm_button": "è¿½åŠ ã®ã”è³ªå•æœ‰ç„¡ã‚’ç¢ºèªã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡",
        "simulation_warning_query": "ãŠå•ã„åˆã‚ã›å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "simulation_no_key_warning": "âš ï¸ APIã‚­ãƒ¼ä¸è¶³ã®ãŸã‚å¿œå¯¾ç”Ÿæˆä¸å¯ã€‚",
        "simulation_advice_header": "AIå¯¾å¿œã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
        "simulation_draft_header": "æ¨å¥¨å¿œå¯¾è‰æ¡ˆ",
        "button_listen_audio": "éŸ³å£°ã§èã",
        "tts_status_ready": "éŸ³å£°ç”Ÿæˆæº–å‚™å®Œäº†",
        "tts_status_generating": "éŸ³å£°ç”Ÿæˆä¸­...",
        "tts_status_success": "éŸ³å£°æº–å‚™å®Œäº†ï¼",
        "tts_status_error": "TTS ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
        "history_expander_title": "ğŸ“ éå»ã®å¯¾å¿œå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ (æœ€æ–°10ä»¶)",
        "initial_query_sample": "ãƒ‘ãƒªã«åˆ°ç€ã—ã¾ã—ãŸãŒã€Klookã®eSIMãŒä½¿ãˆã¾ã›ã‚“â€¦",
        "button_mic_input": "ğŸ™ éŸ³å£°å…¥åŠ›",
        "prompt_customer_end": "è¿½åŠ ã®è³ªå•ãŒãªã„ãŸã‚ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚",
        "prompt_survey": "æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ000ã§ã—ãŸã€‚è‰¯ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ã€‚ [ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒªãƒ³ã‚¯]",
        "customer_closing_confirm": "ä»–ã®ãŠå•åˆã›ã¯ã”ã–ã„ã¾ã›ã‚“ã§ã—ã‚‡ã†ã‹ã€‚",
        "customer_positive_response": "ã¯ã„ã€æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",
        "button_end_chat": "ãƒãƒ£ãƒƒãƒˆçµ‚äº†ï¼ˆã‚¢ãƒ³ã‚±ãƒ¼ãƒˆï¼‰",
        "new_simulation_ready": "æ–°ã—ã„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã§ãã¾ã™ã€‚",
        "survey_sent_confirm": "ğŸ“¨ ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒªãƒ³ã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚ã“ã®ãƒãƒ£ãƒƒãƒˆã¯çµ‚äº†ã—ã¾ã—ãŸã€‚",
        "agent_response_header": "âœï¸ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”",
        "agent_response_placeholder": "é¡§å®¢ã¸è¿”ä¿¡å†…å®¹ã‚’å…¥åŠ›â€¦",
        "send_response_button": "è¿”ä¿¡é€ä¿¡",
        "request_rebuttal_button": "é¡§å®¢ã®åå¿œã‚’ç”Ÿæˆ",
        "new_simulation_button": "æ–°è¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
        "history_selectbox_label": "å±¥æ­´ã‚’é¸æŠ:",
        "history_load_button": "å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€",
        "delete_history_button": "âŒ å…¨å±¥æ­´å‰Šé™¤",
        "delete_confirm_message": "ã™ã¹ã¦ã®å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ",
        "delete_confirm_yes": "ã¯ã„ã€å‰Šé™¤ã—ã¾ã™ã€‚",
        "delete_confirm_no": "ã„ã„ãˆã€ç¶­æŒã—ã¾ã™ã€‚",
        "delete_success": "å‰Šé™¤å®Œäº†ï¼",
        "deleting_history_progress": "å‰Šé™¤ä¸­...",
        "search_history_label": "å±¥æ­´æ¤œç´¢",
        "date_range_label": "æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
        "no_history_found": "è©²å½“ã™ã‚‹å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        "customer_email_label": "é¡§å®¢ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆä»»æ„ï¼‰",
        "customer_phone_label": "é¡§å®¢é€£çµ¡å…ˆ / é›»è©±ç•ªå·ï¼ˆä»»æ„ï¼‰",
        "transfer_header": "è¨€èªåˆ‡ã‚Šæ›¿ãˆè¦è«‹ï¼ˆä»–ãƒãƒ¼ãƒ ã¸ï¼‰",
        "transfer_to_en": "ğŸ‡ºğŸ‡¸ è‹±èªãƒãƒ¼ãƒ ã¸è»¢é€",
        "transfer_to_ko": "ğŸ‡°ğŸ‡· éŸ“å›½èªãƒãƒ¼ãƒ ã¸è»¢é€",
        "transfer_system_msg": "ğŸ“Œ ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: é¡§å®¢ã®è¦è«‹ã«ã‚ˆã‚Šã€å¯¾å¿œè¨€èªãŒ {target_lang} ãƒãƒ¼ãƒ ã¸åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¾ã—ãŸã€‚æ–°ã—ã„æ‹…å½“è€…(AI)ãŒå¯¾å¿œã—ã¾ã™ã€‚",
        "transfer_loading": "è»¢é€ä¸­: éå»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ç¿»è¨³ãŠã‚ˆã³ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã„ã¾ã™ (ãŠå®¢æ§˜ã«ã¯3ã€œ10åˆ†ã®ãŠæ™‚é–“ã‚’ã„ãŸã ã„ã¦ã„ã¾ã™)",
        "transfer_summary_header": "ğŸ” è»¢é€ã•ã‚ŒãŸæ‹…å½“è€…å‘ã‘ã®è¦ç´„ (ç¿»è¨³æ¸ˆã¿)",
        "transfer_summary_intro": "ã“ã‚ŒãŒé¡§å®¢ã¨ã®éå»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã§ã™ã€‚ã“ã®è¦ç´„ã«åŸºã¥ã„ã¦ã‚µãƒãƒ¼ãƒˆã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚",
        "llm_translation_error": "âŒ ç¿»è¨³å¤±æ•—: LLMå¿œç­”ã‚¨ãƒ©ãƒ¼",
        "timer_metric": "çµŒéæ™‚é–“",
        "timer_info_ok": "AHT (15ë¶„ ê¸°ì¤€)",
        "timer_info_warn": "AHT (10ë¶„ ì´ˆê³¼)",
        "timer_info_risk": "ğŸš¨ 15ë¶„ ì´ˆê³¼: é«˜ã„ãƒªã‚¹ã‚¯",
        "solution_check_label": "âœ… ã“ã®å¿œç­”ã«è§£æ±ºç­–/å¯¾å¿œç­–ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚",

        # --- Voice ---
        "voice_rec_header": "éŸ³å£°è¨˜éŒ²ï¼†ç®¡ç†",
        "record_help": "éŒ²éŸ³ã™ã‚‹ã‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚",
        "uploaded_file": "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "rec_list_title": "ä¿å­˜ã•ã‚ŒãŸéŸ³å£°è¨˜éŒ²",
        "transcribe_btn": "è»¢å†™ (Whisper)",
        "save_btn": "éŸ³å£°è¨˜éŒ²ã‚’ä¿å­˜",
        "transcribing": "éŸ³å£°ã‚’è»¢å†™ä¸­...",
        "transcript_result": "è»¢å†™çµæœ:",
        "transcript_text": "è»¢å†™ãƒ†ã‚­ã‚¹ãƒˆ",
        "whisper_processing": "éŸ³å£°è»¢å†™ã‚’å‡¦ç†ä¸­...",
        "whisper_success": "âœ… è»¢å†™ãŒå®Œäº†ã—ã¾ã—ãŸï¼ ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
        "openai_missing": "OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚",
        "whisper_client_error": "âŒ ã‚¨ãƒ©ãƒ¼: Whisper APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "whisper_auth_error": "âŒ Whisper APIèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
        "whisper_format_error": "âŒ ã‚¨ãƒ©ãƒ¼: ã“ã®éŸ³å£°å½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "playback": "éŒ²éŸ³å†ç”Ÿ",
        "retranscribe": "å†è»¢å†™",
        "delete": "å‰Šé™¤",
        "no_records": "ä¿å­˜ã•ã‚ŒãŸéŸ³å£°è¨˜éŒ²ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        "saved_success": "ä¿å­˜ã—ã¾ã—ãŸï¼",
        "delete_confirm_rec": "ã“ã®éŸ³å£°è¨˜éŒ²ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ",
        "gcs_not_conf": "GCSãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€éŸ³å£°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "gcs_playback_fail": "éŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
        "gcs_no_audio": "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "error": "ã‚¨ãƒ©ãƒ¼:",
        "firestore_no_db_connect": "DBæ¥ç¶šå¤±æ•—",
        "save_history_success": "ä¿å­˜å®Œäº†ã€‚",
        "save_history_fail": "ä¿å­˜å¤±æ•—ã€‚",
        "delete_fail": "å‰Šé™¤å¤±æ•—",
        "rec_header": "éŸ³å£°å…¥åŠ›ï¼†è»¢å†™",
        "whisper_processing": "å‡¦ç†ä¸­...",
        "empty_response_warning": "å¿œç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "customer_no_more_inquiries": "ã„ã„ãˆã€çµæ§‹ã§ã™ã€‚å¤§ä¸ˆå¤«ã§ã™ã€‚æœ‰é›£ã†å¾¡åº§ã„ã¾ã—ãŸã€‚",
        "customer_has_additional_inquiries": "ã¯ã„ã€è¿½åŠ ã®å•ã„åˆã‚ã›ãŒã‚ã‚Šã¾ã™ã€‚",
        "sim_end_chat_button": "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒªãƒ³ã‚¯ã‚’é€ä¿¡ã—ã¦ãƒãƒ£ãƒƒãƒˆçµ‚äº†",

        # --- ì²¨ë¶€ íŒŒì¼ ê¸°ëŠ¥ ì¶”ê°€ ---
        "attachment_label": "é¡§å®¢ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãªã©)",
        "attachment_placeholder": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¦çŠ¶æ³ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
        "attachment_status_llm": "é¡§å®¢ãŒ **{filename}** ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¾ã—ãŸã€‚ã“ã‚Œã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã¨ä»®å®šã—ã€å¿œå¯¾è‰æ¡ˆã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚(ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—: {filetype})",
        "agent_attachment_label": "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãªã©)",
        "agent_attachment_placeholder": "å¿œç­”ã«æ·»ä»˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
        "agent_attachment_status": "ğŸ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ **{filename}** ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¿œç­”ã«æ·»ä»˜ã—ã¾ã—ãŸã€‚(ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—: {filetype})",

        # --- RAG ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ê°€ ---
        "rag_embed_error_openai": "RAG embedding failed: OpenAI API Key is invalid or not set.",
        "rag_embed_error_gemini": "RAG embedding failed: Gemini API Key is invalid or not set.",
        "rag_embed_error_nvidia": "RAG embedding failed: NVIDIA API Key is invalid or not set.",
        "rag_embed_error_none": "RAG embedding failed: All required keys (OpenAI, Gemini, NVIDIA) are invalid or not set. Please configure a key.",
    }
}

# ========================================
# 1-1. Session State ì´ˆê¸°í™” (ëˆ„ë½ëœ AHT/ì†”ë£¨ì…˜/ì´ê´€ ìƒíƒœ ì¶”ê°€)
# ========================================

if "language" not in st.session_state:
    st.session_state.language = DEFAULT_LANG
if "is_llm_ready" not in st.session_state:
    st.session_state.is_llm_ready = False
if "llm_init_error_msg" not in st.session_state:
    st.session_state.llm_init_error_msg = ""
if "uploaded_files_state" not in st.session_state:
    st.session_state.uploaded_files_state = None
if "is_rag_ready" not in st.session_state:
    st.session_state.is_rag_ready = False
if "rag_vectorstore" not in st.session_state:
    st.session_state.rag_vectorstore = None
if "rag_messages" not in st.session_state:
    st.session_state.rag_messages = []
if "agent_input" not in st.session_state:
    st.session_state.agent_input = ""
if "last_audio" not in st.session_state:
    st.session_state.last_audio = None
if "simulator_messages" not in st.session_state:
    st.session_state.simulator_messages = []
if "simulator_memory" not in st.session_state:
    st.session_state.simulator_memory = ConversationBufferMemory(memory_key="chat_history")
if "simulator_chain" not in st.session_state:
    st.session_state.simulator_chain = None
if "initial_advice_provided" not in st.session_state:
    st.session_state.initial_advice_provided = False
if "is_chat_ended" not in st.session_state:
    st.session_state.is_chat_ended = False
if "show_delete_confirm" not in st.session_state:
    st.session_state.show_delete_confirm = False
if "customer_query_text_area" not in st.session_state:
    st.session_state.customer_query_text_area = ""
if "agent_response_area_text" not in st.session_state:
    st.session_state.agent_response_area_text = ""
if "last_transcript" not in st.session_state:
    st.session_state.last_transcript = ""
if "sim_audio_bytes" not in st.session_state:
    st.session_state.sim_audio_bytes = None
if "chat_state" not in st.session_state:
    st.session_state.chat_state = "idle"
    # idle â†’ initial_customer â†’ supervisor_advice â†’ agent_turn â†’ customer_turn â†’ closing
if "openai_client" not in st.session_state:
    st.session_state.openai_client = None
if "openai_init_msg" not in st.session_state:
    st.session_state.openai_init_msg = ""
if "sim_stage" not in st.session_state:
    st.session_state.sim_stage = "WAIT_FIRST_QUERY"
    # WAIT_FIRST_QUERY (ì´ˆê¸° ë¬¸ì˜ ì…ë ¥)
    # AGENT_TURN (ì—ì´ì „íŠ¸ ì‘ë‹µ ì…ë ¥)
    # CUSTOMER_TURN (ê³ ê° ë°˜ì‘ ìƒì„± ìš”ì²­)
    # WAIT_CLOSING_CONFIRMATION_FROM_AGENT (ê³ ê°ì´ ê°ì‚¬, ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ë³´ë‚´ê¸° ëŒ€ê¸°)
    # WAIT_CUSTOMER_CLOSING_RESPONSE (ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ë³´ëƒ„, ê³ ê°ì˜ ë§ˆì§€ë§‰ ì‘ë‹µ ëŒ€ê¸°)
    # FINAL_CLOSING_ACTION (ìµœì¢… ì¢…ë£Œ ë²„íŠ¼ ëŒ€ê¸°)
    # CLOSING (ì±„íŒ… ì¢…ë£Œ)
if "start_time" not in st.session_state:  # AHT íƒ€ì´ë¨¸ ì‹œì‘ ì‹œê°„
    st.session_state.start_time = None
if "is_solution_provided" not in st.session_state:  # ì†”ë£¨ì…˜ ì œê³µ ì—¬ë¶€ í”Œë˜ê·¸
    st.session_state.is_solution_provided = False
if "transfer_summary_text" not in st.session_state:  # ì´ê´€ ì‹œ ë²ˆì—­ëœ ìš”ì•½
    st.session_state.transfer_summary_text = ""
if "language_transfer_requested" not in st.session_state:  # ê³ ê°ì˜ ì–¸ì–´ ì´ê´€ ìš”ì²­ ì—¬ë¶€
    st.session_state.language_transfer_requested = False
if "customer_attachment_file" not in st.session_state:  # ê³ ê° ì²¨ë¶€ íŒŒì¼ ì •ë³´
    # â­ ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ë„ë¡ ì´ˆê¸°í™”: None ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None ì‚¬ìš©
    st.session_state.customer_attachment_file = None
if "sim_attachment_context_for_llm" not in st.session_state:  # LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ì²¨ë¶€ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸
    st.session_state.sim_attachment_context_for_llm = ""
if "agent_attachment_file" not in st.session_state:  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì •ë³´
    # â­ ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ë„ë¡ ì´ˆê¸°í™”: None ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None ì‚¬ìš©
    st.session_state.agent_attachment_file = None

# â­ 2-A. Gemini í‚¤ ì´ˆê¸°í™” (ì˜ëª»ëœ í‚¤ ì”ì¡´ ë°©ì§€)
# Streamlitì´ ì‹œì‘ë  ë•Œë§ˆë‹¤ ì‚¬ì´ë“œë°”ì— ë‚¨ì€ ìœ íš¨í•˜ì§€ ì•Šì€ í‚¤ë¥¼ ê°•ì œë¡œ ë¹„ì›Œ, RAG ì´ˆê¸°í™” ì‹œë„ë¥¼ ë§‰ìŠµë‹ˆë‹¤.
if "user_gemini_key" in st.session_state and st.session_state["user_gemini_key"].startswith("AIza"):
    # í‚¤ê°€ ìœ íš¨í•œì§€ ì—¬ë¶€ë¥¼ ì•± ë‚´ë¶€ì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì‚¬ìš©ìì—ê²Œ ìœ íš¨í•œ í‚¤ë¥¼ ì…ë ¥í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ë„ìš°ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ì•ˆì „ì„ ìœ„í•´ í‚¤ ì…ë ¥ì´ ëª…ì‹œì ìœ¼ë¡œ ì—†ìœ¼ë©´ None ì²˜ë¦¬í•˜ë„ë¡ ë¡œì§ì„ ìœ ì§€í•˜ê³ ,
    # í‚¤ ì…ë ¥ ì‹œ ì„¸ì…˜ì— ì €ì¥ë˜ë„ë¡ í•©ë‹ˆë‹¤.
    pass  # í‚¤ ì´ˆê¸°í™” ë¡œì§ì€ ì‚­ì œí•˜ê³ , ì‚¬ìš©ì ì…ë ¥ì— ì˜ì¡´í•˜ë„ë¡ í•©ë‹ˆë‹¤. (ì˜¤íˆë ¤ ê°•ì œ ì´ˆê¸°í™”ê°€ í™˜ê²½ ë³€ìˆ˜ ì˜¤ë²„ë¼ì´ë”© ë¬¸ì œ ì•¼ê¸° ê°€ëŠ¥)

L = LANG[st.session_state.language]

# ========================================
# 0. ë©€í‹° ëª¨ë¸ API Key ì•ˆì „ êµ¬ì¡° (Secrets + User Input)
# ========================================

# 1) ì§€ì›í•˜ëŠ” API ëª©ë¡ ì •ì˜
SUPPORTED_APIS = {
    "openai": {
        "label": "OpenAI API Key",
        "secret_key": "OPENAI_API_KEY",
        "session_key": "user_openai_key",
        "placeholder": "sk-proj-**************************",  # ì—…ë°ì´íŠ¸
    },
    "gemini": {
        "label": "Google Gemini API Key",
        "secret_key": "GEMINI_API_KEY",
        "session_key": "user_gemini_key",
        "placeholder": "AIza***********************************",  # ì—…ë°ì´íŠ¸
    },
    "nvidia": {
        "label": "NVIDIA NIM API Key",
        "secret_key": "NVIDIA_API_KEY",
        "session_key": "user_nvidia_key",
        "placeholder": "nvapi-**************************",  # ì—…ë°ì´íŠ¸
    },
    "claude": {
        "label": "Anthropic Claude API Key",
        "secret_key": "CLAUDE_API_KEY",
        "session_key": "user_claude_key",
        "placeholder": "sk-ant-api-**************************",  # ì—…ë°ì´íŠ¸
    },
    "groq": {
        "label": "Groq API Key",
        "secret_key": "GROQ_API_KEY",
        "session_key": "user_groq_key",
        "placeholder": "gsk_**************************",  # ì—…ë°ì´íŠ¸
    },
}

# 2) ì„¸ì…˜ ì´ˆê¸°í™”
for api, cfg in SUPPORTED_APIS.items():
    if cfg["session_key"] not in st.session_state:
        st.session_state[cfg["session_key"]] = ""

if "selected_llm" not in st.session_state:
    st.session_state.selected_llm = "openai_gpt4"  # ê¸°ë³¸ê°’


def get_api_key(api):
    cfg = SUPPORTED_APIS[api]

    # 1. Streamlit Secrets (.streamlit/secrets.toml)
    try:
        if hasattr(st, "secrets") and cfg["secret_key"] in st.secrets:
            return st.secrets[cfg["secret_key"]]
    except Exception:
        pass

    # 2. Environment Variable (os.environ) - ë¡œì»¬ .env ë˜ëŠ” í„°ë¯¸ë„ exportë¥¼ ìœ„í•´ ì¶”ê°€
    env_key = os.environ.get(cfg["secret_key"])
    if env_key:
        return env_key

    # 3. User Input (Streamlit sidebar session state)
    return st.session_state.get(cfg["session_key"], "")


# ========================================
# 1. Sidebar UI: ë©€í‹° API Key ì…ë ¥ + ëª¨ë¸ ì„ íƒ
# ========================================
with st.sidebar:
    st.markdown("### ğŸ” API Keys ì„¤ì •")

    for api, cfg in SUPPORTED_APIS.items():
        st.markdown(f"**{cfg['label']}**")
        key_input = st.text_input(
            cfg["label"],
            value=st.session_state.get(cfg["session_key"], ""),  # ì´ë¯¸ ì €ì¥ëœ ê°’ ë³´ì—¬ì£¼ê¸°
            type="password",
            key=f"input_{api}",
            placeholder=cfg["placeholder"],  # <-- placeholder ì„¤ì • ì—…ë°ì´íŠ¸
        )

        if st.button(f"{cfg['label']} ì ìš©", key=f"apply_{api}"):
            if key_input.strip():
                st.session_state[cfg["session_key"]] = key_input.strip()
                st.success(f"{cfg['label']} ì €ì¥ë¨")
                st.rerun()  # í‚¤ ë³€ê²½ ì‹œ ì¬ì‹¤í–‰
            else:
                st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    st.divider()
    st.markdown("### ğŸ¤– ì‚¬ìš©í•  LLM ëª¨ë¸ ì„ íƒ")

    MODEL_CHOICES = {
        "openai_gpt4": "OpenAI GPT-4o",
        "openai_gpt35": "OpenAI GPT-3.5 Turbo",
        "gemini_flash": "Gemini 2.0 Flash",
        "gemini_pro": "Gemini 2.0 Pro",
        "claude_sonnet": "Claude 3.5 Sonnet",
        "groq_llama3": "Groq Llama-3-70B",
    }

    # ê¸°ë³¸ê°’ ì„¤ì •: "openai_gpt4"ê°€ ë¦¬ìŠ¤íŠ¸ì— ìˆë‹¤ë©´ í•´ë‹¹ ì¸ë±ìŠ¤, ì—†ë‹¤ë©´ 0
    default_index = list(MODEL_CHOICES.keys()).index(st.session_state.selected_llm) \
        if st.session_state.selected_llm in MODEL_CHOICES else 0

    st.session_state.selected_llm = st.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ",
        options=list(MODEL_CHOICES.keys()),
        format_func=lambda x: MODEL_CHOICES[x],
        key="selected_llm_box",
        index=default_index,
    )


# ========================================
# 2. LLM í´ë¼ì´ì–¸íŠ¸ ë¼ìš°íŒ… & ì‹¤í–‰
# ========================================
def get_llm_client():
    """ì„ íƒëœ ëª¨ë¸ì— ë§ëŠ” í´ë¼ì´ì–¸íŠ¸ + ëª¨ë¸ì½”ë“œ ë°˜í™˜"""
    model_key = st.session_state.get("selected_llm", "openai_gpt4")

    # --- OpenAI ---
    if model_key.startswith("openai"):
        key = get_api_key("openai")
        if not key: return None, None
        try:
            client = OpenAI(api_key=key)
            model_name = "gpt-4o" if model_key == "openai_gpt4" else "gpt-3.5-turbo"
            return client, ("openai", model_name)
        except Exception:
            return None, None

    # --- Gemini ---
    if model_key.startswith("gemini"):
        key = get_api_key("gemini")
        if not key: return None, None
        try:
            genai.configure(api_key=key)
            model_name = "gemini-2.5-pro" if model_key == "gemini_pro" else "gemini-2.5-flash"
            return genai, ("gemini", model_name)
        except Exception:
            return None, None

    # --- Claude ---
    if model_key.startswith("claude"):
        key = get_api_key("claude")
        if not key: return None, None
        try:
            client = Anthropic(api_key=key)
            model_name = "claude-3-5-sonnet-latest"
            return client, ("claude", model_name)
        except Exception:
            return None, None

    # --- Groq ---
    if model_key.startswith("groq"):
        from groq import Groq
        key = get_api_key("groq")
        if not key: return None, None
        try:
            client = Groq(api_key=key)
            model_name = (
                "llama3-70b-8192"
                if "llama3" in model_key
                else "mixtral-8x7b-32768"
            )
            return client, ("groq", model_name)
        except Exception:
            return None, None

    return None, None


def run_llm(prompt: str) -> str:
    """ì„ íƒëœ LLMìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰"""
    client, info = get_llm_client()

    if client is None or info is None:
        return "âŒ No API key for selected model."

    provider, model_name = info

    # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    messages = [{"role": "user", "content": prompt}]

    # --- OpenAI Chat ---
    if provider == "openai":
        resp = client.chat.completions.create(
            model=model_name,
            messages=messages,
        )
        return resp.choices[0].message.content

    # --- Gemini ---
    if provider == "gemini":
        gen_model = client.GenerativeModel(model_name)
        resp = gen_model.generate_content(prompt)
        return resp.text

    # --- Claude ---
    if provider == "claude":
        resp = client.messages.create(
            model=model_name,
            messages=messages,
        )
        return resp.content[0].text

    # --- Groq ---
    if provider == "groq":
        resp = client.chat.completions.create(
            model=model_name,
            messages=messages,
        )
        return resp.choices[0].message.content

    return "âŒ Unsupported provider."


# ========================================
# 2-A. Whisper / TTS ìš© OpenAI Client ë³„ë„ë¡œ ì´ˆê¸°í™”
#      (ì„ íƒ ëª¨ë¸ê³¼ ë¬´ê´€í•˜ê²Œ, OpenAI Keyë§Œ ìˆìœ¼ë©´ ì‚¬ìš©)
# ========================================

def init_openai_audio_client():
    key = get_api_key("openai")
    if not key:
        return None
    try:
        return OpenAI(api_key=key)
    except:
        return None


# LLM í´ë¼ì´ì–¸íŠ¸ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
st.session_state.openai_client = init_openai_audio_client()
probe_client, _ = get_llm_client()
st.session_state.is_llm_ready = probe_client is not None

if st.session_state.openai_client:
    # í‚¤ë¥¼ ì°¾ì•˜ê³  í´ë¼ì´ì–¸íŠ¸ ê°ì²´ëŠ” ìƒì„±ë˜ì—ˆìœ¼ë‚˜, ì‹¤ì œ ì¸ì¦ì€ API í˜¸ì¶œ ì‹œ ì´ë£¨ì–´ì§ (401 ì˜¤ë¥˜ëŠ” ì—¬ê¸°ì„œ ë°œìƒ)
    st.session_state.openai_init_msg = "âœ… OpenAI TTS/Whisper í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ (Key í™•ì¸ë¨)"
else:
    # í‚¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
    st.session_state.openai_init_msg = L["openai_missing"]

if not st.session_state.is_llm_ready:
    st.session_state.llm_init_error_msg = L["simulation_no_key_warning"]
else:
    st.session_state.llm_init_error_msg = ""


# ----------------------------------------
# LLM ë²ˆì—­ í•¨ìˆ˜ (Gemini í´ë¼ì´ì–¸íŠ¸ ì˜ì¡´ì„± ì œê±° ë° ê°•í™”)
# ----------------------------------------
def translate_text_with_llm(text_content: str, target_lang_code: str, source_lang_code: str) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ LLM Fallbackì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ìƒ ì–¸ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
    """
    target_lang = LANG.get(target_lang_code, {})
    target_lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(target_lang_code, "English")
    source_lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(source_lang_code, "English")

    # ë²ˆì—­ì„ ì‹œë„í•  LLM ê³µê¸‰ì ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ (í˜„ì¬ ì‘ë™ ì¤‘ì¸ OpenAIë¥¼ ìµœìš°ì„ )
    TRANSLATION_FALLBACKS = [
        ("openai", "gpt-3.5-turbo"),
        ("gemini", "gemini-2.5-flash"),
        ("claude", "claude-3-5-sonnet-latest"),
    ]

    system_prompt = (
        f"You are a professional translation AI. Translate the following customer support chat history "
        f"from '{source_lang_name}' to '{target_lang_name}'. Preserve the original format, marking "
        f"each speaker (e.g., 'Customer:', 'Agent:'). Do not add any introductory or concluding remarks. "
        f"Translate the content accurately and neutrally."
    )
    prompt = f"Original Chat History:\n\n{text_content}"

    for provider, model_name in TRANSLATION_FALLBACKS:
        key = get_api_key(provider)
        if not key:
            continue  # í‚¤ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ì œê³µìë¡œ ë„˜ì–´ê°

        try:
            # 3. LLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë° ì‹¤í–‰
            if provider == "openai":
                client = OpenAI(api_key=key)
                resp = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}],
                    temperature=0.1
                )
                return resp.choices[0].message.content.strip()

            elif provider == "gemini":
                genai.configure(api_key=key)
                gen_model = genai.GenerativeModel(model_name)
                resp = gen_model.generate_content(
                    contents=prompt,
                    config=genai.types.GenerateContentConfig(system_instruction=system_prompt, temperature=0.1)
                )
                return resp.text.strip()

            elif provider == "claude":
                client = Anthropic(api_key=key)
                resp = client.messages.create(
                    model=model_name,
                    system=system_prompt,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1
                )
                return resp.content[0].text.strip()

        except Exception as e:
            # í•´ë‹¹ APIë¡œ ë²ˆì—­ ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (401, ë„¤íŠ¸ì›Œí¬ ë“±) -> ë‹¤ìŒ ì œê³µìë¡œ ë„˜ì–´ê°
            st.error(f"âŒ Translation failed with {provider.upper()} ({model_name}): {e}")
            continue

    # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í–ˆì„ ê²½ìš° (í‚¤ê°€ ì—†ê±°ë‚˜ ëª¨ë“  API í˜¸ì¶œ ì‹¤íŒ¨)
    st.error(f"âŒ {target_lang.get('llm_translation_error', 'Translation failed')}: ëª¨ë“  API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ API í˜¸ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    return ""


# ========================================
# 3. Whisper / TTS Helper
# ========================================

def transcribe_bytes_with_whisper(audio_bytes: bytes, mime_type: str = "audio/webm", lang_code: str = "ko") -> str:
    L = LANG[st.session_state.language]
    client = st.session_state.openai_client
    if client is None:
        return f"âŒ {L['openai_missing']}"

    whisper_lang = {"ko": "ko", "en": "en", "ja": "ja"}.get(lang_code, "en")

    # ì„ì‹œ íŒŒì¼ ì €ì¥ (Whisper API í˜¸í™˜ì„±)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp.write(audio_bytes)
    tmp.flush()
    tmp.close()

    try:
        with open(tmp.name, "rb") as f:
            res = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                response_format="text",
                language=whisper_lang,
            )
        # res.text ì†ì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ res ìì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        return res.text.strip() if hasattr(res, 'text') else str(res).strip()
    except Exception as e:
        # íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜ ë“± ìƒì„¸ ì˜¤ë¥˜ ì²˜ë¦¬
        return f"âŒ {L['error']} Whisper: {e}"
    finally:
        try:
            os.remove(tmp.name)
        except OSError:
            pass


# ì—­í• ë³„ TTS ìŒì„± ìŠ¤íƒ€ì¼ ì„¤ì •
TTS_VOICES = {
    "customer": {
        "gender": "male",
        "voice": "alloy"  # Distinct Male, Generic/Customer
    },
    "agent": {
        "gender": "female",
        "voice": "shimmer"  # Distinct Female, Professional/Agent
    },
    "supervisor": {
        "gender": "female",
        "voice": "nova"  # Another Distinct Female, Informative/Supervisor
    }
}


def synthesize_tts(text: str, lang_key: str, role: str = "agent"):
    L = LANG[lang_key]
    client = st.session_state.openai_client
    if client is None:
        return None, L["openai_missing"]

    if role not in TTS_VOICES:
        role = "agent"

    voice_name = TTS_VOICES[role]["voice"]

    try:
        # tts-1 ëª¨ë¸ ì‚¬ìš© (ì•ˆì •ì„±)
        resp = client.audio.speech.create(
            model="tts-1",
            voice=voice_name,
            input=text
            # format="mp3"ì€ ê¸°ë³¸ê°’ì…ë‹ˆë‹¤.
        )
        return resp.read(), L["tts_status_success"]

    except Exception as e:
        return None, f"{L['tts_status_error']}: {e}"


def render_tts_button(text, lang_key, role="customer", prefix="", index: int = -1):
    """
    TTS ì¬ìƒ ë²„íŠ¼ì„ ë Œë”ë§í•˜ê³ , ê³ ìœ í•œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    index: ëŒ€í™” ë‚´ì—­ì—ì„œì˜ ê³ ìœ  ì¸ë±ìŠ¤ (DuplicateWidgetID ë°©ì§€ìš©)
    """
    L = LANG[lang_key]

    # í…ìŠ¤íŠ¸ì˜ í•´ì‹œê°’ê³¼ ê³ ìœ  ì¸ë±ìŠ¤ë¥¼ ê²°í•©í•˜ì—¬ í‚¤ ìƒì„±
    # ì¸ë±ìŠ¤(-1ì€ í‚¤ê°€ ì¤‘ìš”í•˜ì§€ ì•Šì€ ê²½ìš°, ì˜ˆ: ìŒì„± ê¸°ë¡ ëª©ë¡)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
    content_hash = hashlib.md5(text[:100].encode()).hexdigest()
    safe_key = f"{prefix}_{index}_{content_hash}"

    # ì¬ìƒ ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œë§Œ TTS ìš”ì²­
    if st.button(L["button_listen_audio"], key=safe_key):
        with st.spinner(L["tts_status_generating"]):
            # ê°ì • ë¶„ì„ (í˜„ì¬ ë¯¸ì‚¬ìš©) ëŒ€ì‹  ë‹¨ìˆœ í…ìŠ¤íŠ¸ë§Œ ì „ë‹¬
            audio_bytes, msg = synthesize_tts(text, lang_key, role=role)
            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3")
                st.success(msg)
            else:
                st.error(msg)


# ========================================
# 4. ë¡œì»¬ ìŒì„± ê¸°ë¡ Helper
# (RAG ë° ìŒì„± ê¸°ë¡ ê´€ë¦¬ìš© í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)
# ========================================

def load_voice_records() -> List[Dict[str, Any]]:
    return _load_json(VOICE_META_FILE, [])


def save_voice_records(records: List[Dict[str, Any]]):
    _save_json(VOICE_META_FILE, records)


def save_audio_record_local(
        audio_bytes: bytes,
        filename: str,
        transcript_text: str,
        mime_type: str = "audio/webm",
        meta: Dict[str, Any] = None,
) -> str:
    records = load_voice_records()
    rec_id = str(uuid.uuid4())
    ts = datetime.utcnow().isoformat()

    ext = filename.split(".")[-1] if "." in filename else "webm"
    audio_filename = f"{rec_id}.{ext}"
    audio_path = os.path.join(AUDIO_DIR, audio_filename)
    with open(audio_path, "wb") as f:
        f.write(audio_bytes)

    rec = {
        "id": rec_id,
        "created_at": ts,
        "filename": filename,
        "audio_filename": audio_filename,
        "size": len(audio_bytes),
        "transcript": transcript_text,
        "mime_type": mime_type,
        "language": st.session_state.language,
        "meta": meta or {},
    }
    records.insert(0, rec)
    save_voice_records(records)
    return rec_id


def delete_audio_record_local(rec_id: str) -> bool:
    records = load_voice_records()
    idx = next((i for i, r in enumerate(records) if r.get("id") == rec_id), None)
    if idx is None:
        return False
    rec = records.pop(idx)
    audio_filename = rec.get("audio_filename")
    if audio_filename:
        audio_path = os.path.join(AUDIO_DIR, audio_filename)
        try:
            os.remove(audio_path)
        except FileNotFoundError:
            pass
    save_voice_records(records)
    return True


def get_audio_bytes_local(rec_id: str):
    records = load_voice_records()
    rec = next((r for r in records if r.get("id") == rec_id), None)
    if not rec:
        raise FileNotFoundError("record not found")
    audio_filename = rec["audio_filename"]
    audio_path = os.path.join(AUDIO_DIR, audio_filename)
    with open(audio_path, "rb") as f:
        b = f.read()
    return b, rec


# ========================================
# 5. ë¡œì»¬ ì‹œë®¬ë ˆì´ì…˜ ì´ë ¥ Helper
# ========================================

def load_simulation_histories_local(lang_key: str) -> List[Dict[str, Any]]:
    histories = _load_json(SIM_META_FILE, [])
    # í˜„ì¬ ì–¸ì–´ì™€ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ê°€ ìœ íš¨í•œ ì´ë ¥ë§Œ í•„í„°ë§
    return [
        h for h in histories
        if h.get("language_key") == lang_key and isinstance(h.get("messages"), list)
    ]


def save_simulation_history_local(initial_query: str, customer_type: str, messages: List[Dict[str, Any]],
                                  is_chat_ended: bool, attachment_context: str):
    histories = _load_json(SIM_META_FILE, [])
    doc_id = str(uuid.uuid4())
    ts = datetime.utcnow().isoformat()
    data = {
        "id": doc_id,
        "initial_query": initial_query,
        "customer_type": customer_type,
        "messages": messages,
        "language_key": st.session_state.language,
        "timestamp": ts,
        "is_chat_ended": is_chat_ended,
        "attachment_context": attachment_context,  # ì²¨ë¶€ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ë„ ì €ì¥
    }
    # ê¸°ì¡´ ì´ë ¥ì— ì¶”ê°€ (ìµœì‹ ìˆœ)
    histories.insert(0, data)
    # ë„ˆë¬´ ë§ì€ ì´ë ¥ ë°©ì§€ (ì˜ˆ: 50ê°œ)
    _save_json(SIM_META_FILE, histories[:50])
    return doc_id


def delete_all_history_local():
    _save_json(SIM_META_FILE, [])


# ========================================
# 6. RAG Helper (FAISS)
# ========================================
# RAG ê´€ë ¨ í•¨ìˆ˜ëŠ” ì‹œë®¬ë ˆì´í„°ì™€ ë¬´ê´€í•˜ë¯€ë¡œ ê¸°ì¡´ ì½”ë“œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

def load_documents(files) -> List[Document]:
    docs: List[Document] = []
    for f in files:
        name = f.name
        lower = name.lower()
        if lower.endswith(".pdf"):
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
            tmp.write(f.read())
            tmp.flush()
            tmp.close()
            loader = PyPDFLoader(tmp.name)
            file_docs = loader.load()
            for d in file_docs:
                d.metadata["source"] = name
            docs.extend(file_docs)
            try:
                os.remove(tmp.name)
            except OSError:
                pass
        elif lower.endswith(".txt"):
            text = f.read().decode("utf-8", errors="ignore")
            docs.append(Document(page_content=text, metadata={"source": name}))
        elif lower.endswith(".html") or lower.endswith(".htm"):
            text = f.read().decode("utf-8", errors="ignore")
            docs.append(Document(page_content=text, metadata={"source": name}))
    return docs


def split_documents(docs: List[Document]) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=["\n\n", "\n", ".", " ", ""],
    )
    return splitter.split_documents(docs)


def get_embedding_function():
    """
    RAG ì„ë² ë”©ì— ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ì„ ê²°ì •í•©ë‹ˆë‹¤.
    API í‚¤ ìœ íš¨ì„± ìˆœì„œ: Gemini -> OpenAI -> NVIDIA
    API ì¸ì¦ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ì´ë™í•˜ë„ë¡ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """

    # 1. Gemini ì„ë² ë”© ì‹œë„ (ìµœìš°ì„  ìˆœìœ„)
    gemini_key = get_api_key("gemini")
    if IS_GEMINI_EMBEDDING_AVAILABLE and gemini_key:
        try:
            # GoogleGenerativeAIEmbeddings ì´ˆê¸°í™” ì‹œ API Key ìœ íš¨ì„± ê²€ì‚¬ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            return GoogleGenerativeAIEmbeddings(google_api_key=gemini_key, model="text-embedding-004")
        except Exception as e:
            # print(f"Gemini ì„ë² ë”© ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ìŠ¤í‚µ): {e}")
            pass

    # 2. OpenAI ì„ë² ë”© ì‹œë„
    openai_key = get_api_key("openai")
    if openai_key:
        try:
            # OpenAIEmbeddings ì´ˆê¸°í™” ì‹œ API Key ìœ íš¨ì„± ê²€ì‚¬ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            return OpenAIEmbeddings(openai_api_key=openai_key)
        except Exception as e:
            # print(f"OpenAI ì„ë² ë”© ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ìŠ¤í‚µ): {e}")
            pass

    # 3. NVIDIA NIM ì„ë² ë”© ì‹œë„
    nvidia_key = get_api_key("nvidia")
    if IS_NVIDIA_EMBEDDING_AVAILABLE and nvidia_key:
        try:
            # NVIDIAEmbeddings ì´ˆê¸°í™” ì‹œ API Key ìœ íš¨ì„± ê²€ì‚¬ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # RAG ì„ë² ë”©ì— NVIDIA Embeddingsë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ë ¤ë©´
            # NVIDIA API Keyê°€ ìœ íš¨í•˜ê³ , í•´ë‹¹ ëª¨ë¸ì„ ì§€ì›í•˜ëŠ” LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
            return NVIDIAEmbeddings(api_key=nvidia_key, model="ai-embed-qa-4")
        except Exception as e:
            # print(f"NVIDIA ì„ë² ë”© ì‹œë„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ìŠ¤í‚µ): {e}")
            pass

    return None  # ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© í•¨ìˆ˜ê°€ ì—†ìŒ


def build_rag_index(files):
    L = LANG[st.session_state.language]
    if not files: return None, 0

    # ì„ë² ë”© í•¨ìˆ˜ë¥¼ ì‹œë„í•˜ëŠ” ê³¼ì •ì—ì„œ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ try-exceptë¡œ ê°ìŒ‰ë‹ˆë‹¤.
    try:
        embeddings = get_embedding_function()
    except Exception as e:
        st.error(f"RAG ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™” ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, 0

    if embeddings is None:
        # ì–´ë–¤ ì„ë² ë”© ëª¨ë¸ë„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŒì„ ì•Œë¦¼
        error_msg = L["rag_embed_error_none"]

        # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ êµ¬ì„± (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°)
        if not get_api_key("openai"):
            error_msg += f"\n- {L['rag_embed_error_openai']}"
        if not get_api_key("gemini"):
            error_msg += f"\n- {L['rag_embed_error_gemini']}"
        if not get_api_key("nvidia"):
            error_msg += f"\n- {L['rag_embed_error_nvidia']}"

        st.error(error_msg)
        return None, 0

    # ì„ë² ë”© ê°ì²´ ì´ˆê¸°í™” ì„±ê³µ í›„, ë°ì´í„° ë¡œë“œ ë° ë¶„í• 
    docs = load_documents(files)
    if not docs: return None, 0

    chunks = split_documents(docs)
    if not chunks: return None, 0

    try:
        vectorstore = FAISS.from_documents(chunks, embeddings)
        # ì €ì¥
        vectorstore.save_local(RAG_INDEX_DIR)
    except Exception as e:
        # API ì¸ì¦ ì‹¤íŒ¨ ë“± ì‹¤ì œ API í˜¸ì¶œ ì˜¤ë¥˜ ì²˜ë¦¬
        st.error(f"RAG ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None, 0

    return vectorstore, len(chunks)


def load_rag_index():
    # RAG ì¸ë±ìŠ¤ ë¡œë“œ ì‹œì—ë„ ìœ íš¨í•œ ì„ë² ë”© í•¨ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    try:
        embeddings = get_embedding_function()
    except Exception:
        # get_embedding_function ë‚´ì—ì„œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê±°ë‚˜ ìŠ¤í‚µí•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¡°ìš©íˆ ì²˜ë¦¬
        return None

    if embeddings is None:
        return None

    try:
        # allow_dangerous_deserialization=TrueëŠ” í•„ìˆ˜
        vs = FAISS.load_local(RAG_INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
        return vs
    except Exception:
        return None


def rag_answer(question: str, vectorstore: FAISS, lang_key: str) -> str:
    # RAG AnswerëŠ” LLM í´ë¼ì´ì–¸íŠ¸ ë¼ìš°íŒ…ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
    llm_client, info = get_llm_client()
    if llm_client is None:
        return LANG[lang_key]["simulation_no_key_warning"]

    # Langchain ChatOpenAI ëŒ€ì‹  run_llmì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ promptë¥¼ ì§ì ‘ êµ¬ì„±
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
    docs = retriever.get_relevant_documents(question)
    context = "\n\n".join(d.page_content[:1500] for d in docs)

    prompt = (
            "You are a helpful AI tutor. Answer the question using ONLY the provided context.\n"
            "If you cannot find the answer in the context, say you don't know.\n"
            "Answer in the language of the question.\n\n"
            "Question:\n" + question + "\n\n"
                                       "Context:\n" + context + "\n\n"
                                                                "Answer:"
    )
    return run_llm(prompt)


# ========================================
# 7. LSTM Helper (ê°„ë‹¨ Mock + ì‹œê°í™”)
# ========================================

def load_or_train_lstm():
    # ì‹¤ì œ LSTM ëŒ€ì‹  ëœë¤ + sin íŒŒí˜• ê¸°ë°˜ Mock
    np.random.seed(42)
    n_points = 50
    ts = 60 + 20 * np.sin(np.linspace(0, 4 * np.pi, n_points)) + np.random.normal(0, 5, n_points)
    ts = np.clip(ts, 50, 100).astype(np.float32)
    return ts


# ========================================
# 8. LLM (ChatOpenAI) for Simulator / Content
# (RAGì™€ ë™ì¼í•˜ê²Œ run_llmìœ¼ë¡œ í†µí•©)
# ========================================

# ConversationChain ëŒ€ì‹  run_llmì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„
# st.session_state.simulator_memoryëŠ” ìœ ì§€í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

def get_chat_history_for_prompt():
    """ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ì¶”ì¶œí•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ë¬¸ìì—´ í˜•íƒœë¡œ ë°˜í™˜"""
    history_str = ""
    for msg in st.session_state.simulator_messages:
        role = msg["role"]
        content = msg["content"]
        if role == "customer" or role == "customer_rebuttal":
            history_str += f"Customer: {content}\n"
        elif role == "agent_response":
            history_str += f"Agent: {content}\n"
        # supervisor ë©”ì‹œì§€ëŠ” LLMì— ì „ë‹¬í•˜ì§€ ì•Šì•„ ì—­í•  í˜¼ë™ ë°©ì§€
    return history_str


def generate_customer_reaction(current_lang_key: str) -> str:
    """ê³ ê°ì˜ ë‹¤ìŒ ë°˜ì‘ì„ ìƒì„±í•˜ëŠ” LLM í˜¸ì¶œ"""
    history_text = get_chat_history_for_prompt()
    lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}[current_lang_key]

    # ì²¨ë¶€ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    attachment_context = st.session_state.sim_attachment_context_for_llm
    if attachment_context:
        # LLMì—ê²Œ ì²¨ë¶€ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ë˜, ì—ì´ì „íŠ¸ì—ê²Œ ë°˜ë³µí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜
        attachment_context = f"[INITIAL ATTACHMENT CONTEXT (for customer reference only, do not repeat to agent)]\n{attachment_context}\n\n"
    else:
        attachment_context = ""

    next_prompt = f"""
{attachment_context}
You are now ROLEPLAYING as the CUSTOMER.

Read the following conversation and respond naturally in {lang_name}.

Conversation so far:
{history_text}

RULES:
1. You are only the customer. Do not write as the agent.
2. **[Crucial Rule for Repetition/New Inquiry]** After the agent has provided a solution:
    - If you are still confused or the problem is not fully solved, you MUST state the remaining confusion/problem clearly and briefly. DO NOT REPEAT THE INITIAL QUERY. Focus only on the unresolved aspect or the new inquiry.
3. If the agent requested information â†’ provide EXACTLY ONE missing detail.
4. If the agent provided a clear solution, or if you have no further questions,
   you MUST respond with appreciation or satisfaction, like "{L['customer_positive_response']}".
5. If the agent's LAST message was the closing confirmation: "{L['customer_closing_confirm']}"
    - If you have NO additional questions: You MUST reply with "{L['customer_no_more_inquiries']}".
    - If you DO have additional questions: You MUST reply with "{L['customer_has_additional_inquiries']}" AND MUST FOLLOW UP WITH THE NEW INQUIRY DETAILS IMMEDIATELY. DO NOT just repeat that you have an additional question.
6. Do NOT repeat your initial message or previous responses unless necessary.
7. Output ONLY the customer's next message.
"""
    try:
        reaction = run_llm(next_prompt)
        return reaction.strip()
    except Exception as e:
        return f"âŒ ê³ ê° ë°˜ì‘ ìƒì„± ì˜¤ë¥˜: {e}"


def generate_customer_closing_response(current_lang_key: str) -> str:
    """ì—ì´ì „íŠ¸ì˜ ë§ˆì§€ë§‰ í™•ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ê³ ê°ì˜ ìµœì¢… ë‹µë³€ ìƒì„±"""
    history_text = get_chat_history_for_prompt()
    lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}[current_lang_key]

    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì—ì´ì „íŠ¸ì˜ ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ì¸ì§€ í™•ì¸ (í”„ë¡¬í”„íŠ¸ì— í¬í•¨)
    closing_msg = L['customer_closing_confirm']

    # ì²¨ë¶€ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    attachment_context = st.session_state.sim_attachment_context_for_llm
    if attachment_context:
        attachment_context = f"[INITIAL ATTACHMENT CONTEXT (for customer reference only, do not repeat to agent)]\n{attachment_context}\n\n"
    else:
        attachment_context = ""

    final_prompt = f"""
{attachment_context}
You are now ROLEPLAYING as the CUSTOMER.

The agent's final message was the closing confirmation: "{closing_msg}".
You MUST respond to this confirmation based on the overall conversation.

Conversation history:
{history_text}

RULES:
1. If the conversation seems resolved and you have NO additional questions:
    - You MUST reply with "{L['customer_no_more_inquiries']}".
2. If the conversation is NOT fully resolved and you DO have additional questions (or the agent provided a cancellation denial that you want to appeal):
    - You MUST reply with "{L['customer_has_additional_inquiries']}" AND MUST FOLLOW UP WITH THE NEW INQUIRY DETAILS. DO NOT just repeat that you have an additional question.
3. Your reply MUST be ONLY one of the two options above, in {lang_name}.
4. Output ONLY the customer's next message (must be one of the two rule options).
"""
    try:
        reaction = run_llm(final_prompt)
        # LLMì˜ ì¶œë ¥ì´ ê·œì¹™ì„ ë”°ë¥´ì§€ ì•Šì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ê°•ì œ ì ìš©
        reaction_text = reaction.strip()
        # "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ë„ ìˆìŠµë‹ˆë‹¤"ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ìƒì„¸ ë‚´ìš© í¬í•¨ ê°€ì •)
        if L['customer_no_more_inquiries'] in reaction_text:
            return L['customer_no_more_inquiries']
        elif L['customer_has_additional_inquiries'] in reaction_text:
            return reaction_text
        else:
            # LLMì´ ê·œì¹™ì„ ì–´ê²¼ì„ ê²½ìš°, "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ì´ ìˆë‹¤"ê³  ê°€ì •í•˜ê³  ì—ì´ì „íŠ¸ í„´ìœ¼ë¡œ ë„˜ê¹€
            return L['customer_has_additional_inquiries']
    except Exception as e:
        st.error(f"ê³ ê° ìµœì¢… ë°˜ì‘ ìƒì„± ì˜¤ë¥˜: {e}")
        return L['customer_has_additional_inquiries']  # ì˜¤ë¥˜ ì‹œ ì—ì´ì „íŠ¸ í„´ìœ¼ë¡œ ìœ ë„


# ========================================
# 9. ì‚¬ì´ë“œë°”
# ========================================

with st.sidebar:
    selected_lang_key = st.selectbox(
        L["lang_select"],
        options=["ko", "en", "ja"],
        index=["ko", "en", "ja"].index(st.session_state.language),
        format_func=lambda x: {"ko": "í•œêµ­ì–´", "en": "English", "ja": "æ—¥æœ¬èª"}[x],
    )

    # ğŸ”¹ ì–¸ì–´ ë³€ê²½ ê°ì§€
    if selected_lang_key != st.session_state.language:
        st.session_state.language = selected_lang_key
        st.session_state.simulator_messages = []
        st.session_state.simulator_memory.clear()
        st.session_state.initial_advice_provided = False
        st.session_state.is_chat_ended = False
        st.session_state.agent_response_area_text = ""
        st.session_state.customer_query_text_area = ""
        st.session_state.last_transcript = ""
        st.session_state.sim_audio_bytes = None
        st.session_state.sim_stage = "WAIT_FIRST_QUERY"
        st.session_state.customer_attachment_file = None  # ì–¸ì–´ ë³€ê²½ ì‹œ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
        st.session_state.sim_attachment_context_for_llm = ""  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        st.session_state.agent_attachment_file = None  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
        st.rerun()

    L = LANG[st.session_state.language]

    st.title(L["sidebar_title"])
    st.markdown("---")

    st.subheader("í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ìƒíƒœ")
    if st.session_state.llm_init_error_msg:
        st.error(st.session_state.llm_init_error_msg)
    elif st.session_state.is_llm_ready:
        st.success("âœ… LLM í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ")

    if st.session_state.openai_client:
        st.success("âœ… OpenAI TTS/Whisper í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ")
    else:
        st.warning(L["openai_missing"])

    st.markdown("---")

    uploaded_files_widget = st.file_uploader(
        L["file_uploader"], type=["pdf", "txt", "html"], accept_multiple_files=True
    )
    if uploaded_files_widget:
        st.session_state.uploaded_files_state = uploaded_files_widget

    files_to_process = st.session_state.uploaded_files_state or []

    # â­ RAG ì¸ë±ì‹± ë²„íŠ¼ ë¡œì§ ìˆ˜ì • (get_embedding_functionì— ì˜¤ë¥˜ ë©”ì‹œì§€ í†µí•©)
    if files_to_process and st.session_state.is_llm_ready:
        if st.button(L["button_start_analysis"]):
            with st.spinner(L["data_analysis_progress"]):
                vs, count = build_rag_index(files_to_process)
                if vs is not None:
                    st.session_state.rag_vectorstore = vs
                    st.session_state.is_rag_ready = True
                    st.success(L["embed_success"].format(count=count))
                else:
                    # ì˜¤ë¥˜ëŠ” build_rag_index ë‚´ë¶€ì—ì„œ ì´ë¯¸ st.errorë¡œ ì¶œë ¥ë¨
                    st.session_state.is_rag_ready = False
    elif not files_to_process:
        st.info(L["warning_no_files"])

    st.markdown("---")

    feature_selection = st.radio(
        "ê¸°ëŠ¥ ì„ íƒ",
        [L["rag_tab"], L["content_tab"], L["lstm_tab"], L["simulator_tab"], L["voice_rec_header"]],
    )

# ë©”ì¸ íƒ€ì´í‹€
st.title(L["title"])

# ========================================
# 10. ê¸°ëŠ¥ë³„ í˜ì´ì§€
# ========================================

# -------------------- Voice Record Tab --------------------
if feature_selection == L["voice_rec_header"]:
    st.header(L["voice_rec_header"])
    st.caption(L["record_help"])

    col_rec, col_list = st.columns([1, 1])

    # ë…¹ìŒ/ì—…ë¡œë“œ + ì „ì‚¬ + ì €ì¥
    with col_rec:
        st.subheader(L["rec_header"])
        audio_file = st.file_uploader(
            L["uploaded_file"],
            type=["wav", "mp3", "m4a", "webm", "ogg"],
            key="voice_rec_uploader",
        )
        audio_bytes = None
        audio_mime = "audio/webm"

        if audio_file is not None:
            audio_bytes = audio_file.getvalue()
            audio_mime = audio_file.type or "audio/webm"

        # ì¬ìƒ
        if audio_bytes:
            st.audio(audio_bytes, format=audio_mime)

        # ì „ì‚¬ ë²„íŠ¼
        if audio_bytes and st.button(L["transcribe_btn"]):
            if st.session_state.openai_client is None:
                st.error(L["openai_missing"])
            else:
                with st.spinner(L["transcribing"]):
                    text = transcribe_bytes_with_whisper(
                        audio_bytes, audio_mime, lang_code=st.session_state.language
                    )
                    st.session_state.last_transcript = text
                    snippet = text[:50].replace("\n", " ")
                    if len(text) > 50:
                        snippet += "..."
                    if text.startswith("âŒ"):
                        st.error(text)
                    else:
                        st.success(f"{L['transcript_result']} **{snippet}**")

        st.text_area(
            L["transcript_text"],
            value=st.session_state.last_transcript,
            height=150,
            key="voice_rec_transcript_area",
        )

        if audio_bytes and st.button(L["save_btn"]):
            try:
                ext = audio_mime.split("/")[-1] if "/" in audio_mime else "webm"
                filename = f"record_{int(time.time())}.{ext}"
                save_audio_record_local(
                    audio_bytes,
                    filename,
                    st.session_state.last_transcript,
                    mime_type=audio_mime,
                )
                st.success(L["saved_success"])
                st.session_state.last_transcript = ""
                st.rerun()
            except Exception as e:
                st.error(f"{L['error']} {e}")

    # ì €ì¥ëœ ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
    with col_list:
        st.subheader(L["rec_list_title"])
        try:
            records = load_voice_records()
        except Exception as e:
            st.error(f"read error: {e}")
            records = []

        if not records:
            st.info(L["no_records"])
        else:
            for rec in records:
                rec_id = rec["id"]
                created_at = rec.get("created_at")
                try:
                    dt = datetime.fromisoformat(created_at)
                    created_str = dt.strftime("%Y-%m-%d %H:%M")
                except Exception:
                    created_str = str(created_at)

                transcript_snippet = (rec.get("transcript") or "")[:50].replace("\n", " ")
                if len(rec.get("transcript") or "") > 50:
                    transcript_snippet += "..."

                with st.expander(f"[{created_str}] {transcript_snippet}"):
                    st.write(f"**{L['transcript_text']}:** {rec.get('transcript') or 'N/A'}")
                    st.caption(
                        f"**Size:** {rec.get('size')} bytes | **File:** {rec.get('audio_filename')}"
                    )

                    col_p, col_r, col_d = st.columns([2, 1, 1])

                    if col_p.button(L["playback"], key=f"play_{rec_id}"):
                        try:
                            b, info = get_audio_bytes_local(rec_id)
                            mime = info.get("mime_type", "audio/webm")
                            st.audio(b, format=mime)
                        except Exception as e:
                            st.error(f"{L['gcs_playback_fail']}: {e}")

                    if col_r.button(L["retranscribe"], key=f"re_{rec_id}"):
                        if st.session_state.openai_client is None:
                            st.error(L["openai_missing"])
                        else:
                            with st.spinner(L["transcribing"]):
                                try:
                                    b, info = get_audio_bytes_local(rec_id)
                                    mime = info.get("mime_type", "audio/webm")
                                    new_text = transcribe_bytes_with_whisper(
                                        b, mime, lang_code=st.session_state.language
                                    )
                                    records = load_voice_records()
                                    for r in records:
                                        if r["id"] == rec_id:
                                            r["transcript"] = new_text
                                            break
                                    save_voice_records(records)
                                    st.success(L["retranscribe"] + " " + L["saved_success"])
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"{L['error']} {e}")

                    if col_d.button(L["delete"], key=f"del_{rec_id}"):
                        if st.session_state.get(f"confirm_del_{rec_id}", False):
                            ok = delete_audio_record_local(rec_id)
                            if ok:
                                st.success(L["delete_success"])
                            else:
                                st.error(L["delete_fail"])
                            st.session_state[f"confirm_del_{rec_id}"] = False
                            st.rerun()
                        else:
                            st.session_state[f"confirm_del_{rec_id}"] = True
                            st.warning(L["delete_confirm_rec"])

# -------------------- Simulator Tab --------------------
elif feature_selection == L["simulator_tab"]:
    st.header(L["simulator_header"])
    st.markdown(L["simulator_desc"])

    current_lang = st.session_state.language
    L = LANG[current_lang]  # ë‹¤ì‹œ L ì—…ë°ì´íŠ¸

    # =========================
    # 0. ì „ì²´ ì´ë ¥ ì‚­ì œ
    # =========================
    col_del, _ = st.columns([1, 4])
    with col_del:
        if st.button(L["delete_history_button"], key="trigger_delete_hist"):
            st.session_state.show_delete_confirm = True

    if st.session_state.show_delete_confirm:
        with st.container():
            st.warning(L["delete_confirm_message"])
            c_yes, c_no = st.columns(2)
            if c_yes.button(L["delete_confirm_yes"], key="confirm_del_yes"):
                with st.spinner(L["deleting_history_progress"]):
                    delete_all_history_local()
                    st.session_state.simulator_messages = []
                    st.session_state.simulator_memory.clear()
                    st.session_state.show_delete_confirm = False
                    st.session_state.is_chat_ended = False
                    st.session_state.sim_stage = "WAIT_FIRST_QUERY"
                    st.session_state.customer_attachment_file = None  # ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
                    st.session_state.sim_attachment_context_for_llm = ""  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                    st.session_state.agent_attachment_file = None  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
                    st.success(L["delete_success"])
                st.rerun()
            if c_no.button(L["delete_confirm_no"], key="confirm_del_no"):
                st.session_state.show_delete_confirm = False

    # =========================
    # 1. ì´ì „ ì´ë ¥ ë¡œë“œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    # =========================
    with st.expander(L["history_expander_title"]):
        histories = load_simulation_histories_local(current_lang)
        search_query = st.text_input(L["search_history_label"], key="sim_hist_search")

        today = datetime.now().date()
        dr = st.date_input(
            L["date_range_label"],
            value=[today - timedelta(days=7), today],
            key="sim_hist_date_range",
        )

        filtered = []
        if histories:
            if isinstance(dr, list) and len(dr) == 2:
                start_date = min(dr)
                end_date = max(dr)
            else:
                start_date = datetime.min.date()
                end_date = datetime.max.date()

            for h in histories:
                ok_search = True
                if search_query:
                    q = search_query.lower()
                    text = (h["initial_query"] + " " + h["customer_type"]).lower()
                    if q not in text:
                        ok_search = False

                ok_date = True
                ts = h.get("timestamp")
                if ts:
                    try:
                        d = datetime.fromisoformat(ts).date()
                        if not (start_date <= d <= end_date):
                            ok_date = False
                    except Exception:
                        pass

                if ok_search and ok_date:
                    filtered.append(h)

        if filtered:
            def _label(h):
                try:
                    t = datetime.fromisoformat(h["timestamp"])
                    t_str = t.strftime("%m-%d %H:%M")
                except Exception:
                    t_str = h.get("timestamp", "")
                q = h["initial_query"][:30].replace("\n", " ")
                # ì²¨ë¶€ íŒŒì¼ ì—¬ë¶€ í‘œì‹œ ì¶”ê°€
                attachment_icon = "ğŸ“" if h.get("attachment_context") else ""
                return f"[{t_str}] {attachment_icon} {h['customer_type']} - {q}..."


            options_map = {_label(h): h for h in filtered}
            sel_key = st.selectbox(L["history_selectbox_label"], options=list(options_map.keys()))
            if st.button(L["history_load_button"], key="load_hist_btn"):
                h = options_map[sel_key]
                st.session_state.customer_query_text_area = h["initial_query"]
                st.session_state.simulator_messages = h["messages"]
                st.session_state.initial_advice_provided = True
                st.session_state.is_chat_ended = h.get("is_chat_ended", False)
                st.session_state.sim_attachment_context_for_llm = h.get("attachment_context", "")  # ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
                st.session_state.customer_attachment_file = None  # ë¡œë“œëœ ì´ë ¥ì—ëŠ” íŒŒì¼ ê°ì²´ ëŒ€ì‹  ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë§Œ ì‚¬ìš©
                st.session_state.agent_attachment_file = None  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”

                # ìƒíƒœ ë³µì›
                if st.session_state.is_chat_ended:
                    st.session_state.sim_stage = "CLOSING"
                else:
                    last_role = h["messages"][-1]["role"] if h["messages"] else None
                    if last_role == "agent_response":
                        st.session_state.sim_stage = "CUSTOMER_TURN"
                    elif last_role == "customer_rebuttal":
                        st.session_state.sim_stage = "AGENT_TURN"
                    elif last_role == "supervisor" and h["messages"][-1]["content"] == L["customer_closing_confirm"]:
                        st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"
                    else:
                        st.session_state.sim_stage = "AGENT_TURN"

                st.session_state.simulator_memory.clear()  # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
                st.rerun()
        else:
            st.info(L["no_history_found"])

    if st.session_state.sim_stage not in ["WAIT_FIRST_QUERY", "CLOSING", "idle"]:
        elapsed_placeholder = st.empty()

        if st.session_state.start_time is not None:
            # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ í˜ì´ì§€ ë¡œë“œ ì‹œë§ˆë‹¤ í˜„ì¬ ì‹œê°„ ê³„ì‚°
            elapsed_time = datetime.now() - st.session_state.start_time
            total_seconds = elapsed_time.total_seconds()

            # ì‹œê°„ í˜•ì‹ í¬ë§·íŒ…
            minutes = int(total_seconds // 60)
            seconds = int(total_seconds % 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            # ê²½ê³  ê¸°ì¤€
            if total_seconds > 900:  # 15ë¶„
                delta_str = L["timer_info_risk"]
                delta_color = "inverse"
            elif total_seconds > 600:  # 10ë¶„
                delta_str = L["timer_info_warn"]
                delta_color = "off"
            else:
                delta_str = L["timer_info_ok"]
                delta_color = "normal"

            elapsed_placeholder.metric(
                L["timer_metric"],
                time_str,
                delta=delta_str,
                delta_color=delta_color
            )

            # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ê°•ì œ ì¬ì‹¤í–‰ (10ë¶„ë§ˆë‹¤)
            if seconds % 900 == 0 and total_seconds < 1000:
                time.sleep(1)
                st.rerun()  # ì‹œë®¬ë ˆì´í„°ê°€ ë©ˆì¶°ìˆì§€ ì•Šì„ ë•Œë§Œ ì¬ì‹¤í–‰ ìœ ë„

        st.markdown("---")

        # =========================
        # AHT íƒ€ì´ë¨¸ (í™”ë©´ ìµœìƒë‹¨)
        # =========================
        if st.session_state.sim_stage not in ["WAIT_FIRST_QUERY", "CLOSING", "idle"]:
            col_timer, _ = st.columns([1, 4])

            # start_timeì´ ìˆì„ ë•Œë§Œ ê³„ì‚° ë° í‘œì‹œ
            if st.session_state.start_time is not None:
                # í˜„ì¬ ì‹œê°„ ê³„ì‚°
                elapsed_time = datetime.now() - st.session_state.start_time
                total_seconds = elapsed_time.total_seconds()

                # ì‹œê°„ í˜•ì‹ í¬ë§·íŒ…
                minutes = int(total_seconds // 60)
                seconds = int(total_seconds % 60)
                time_str = f"{minutes:02d}:{seconds:02d}"

                # ê²½ê³  ê¸°ì¤€
                if total_seconds > 900:  # 15ë¶„
                    delta_str = L["timer_info_risk"]
                    delta_color = "inverse"
                elif total_seconds > 600:  # 10ë¶„
                    delta_str = L["timer_info_warn"]
                    delta_color = "off"
                else:
                    delta_str = L["timer_info_ok"]
                    delta_color = "normal"

                with col_timer:
                    st.metric(
                        L["timer_metric"],
                        time_str,
                        delta=delta_str,
                        delta_color=delta_color
                    )

            st.markdown("---")

    # =========================
    # 2. LLM ì¤€ë¹„ ì²´í¬ & ì±„íŒ… ì¢…ë£Œ ìƒíƒœ
    # =========================
    if not st.session_state.is_llm_ready:
        st.warning(L["simulation_no_key_warning"])

    if st.session_state.sim_stage == "CLOSING":
        st.success(L["survey_sent_confirm"])
        st.info(L["new_simulation_ready"])
        if st.button(L["new_simulation_button"], key="new_simulation_btn"):
            # ì´ˆê¸°í™” ë¡œì§
            st.session_state.simulator_messages = []
            st.session_state.simulator_memory.clear()
            st.session_state.initial_advice_provided = False
            st.session_state.is_chat_ended = False
            st.session_state.agent_response_area_text = ""
            st.session_state.customer_query_text_area = ""
            st.session_state.last_transcript = ""
            st.session_state.sim_audio_bytes = None
            st.session_state.sim_stage = "WAIT_FIRST_QUERY"
            st.session_state.customer_attachment_file = None  # ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            st.session_state.sim_attachment_context_for_llm = ""  # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
            st.session_state.agent_attachment_file = None  # ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            st.rerun()
        st.stop()

    # ========================================
    # 3. ì´ˆê¸° ë¬¸ì˜ ì…ë ¥ (WAIT_FIRST_QUERY)
    # ========================================
    if st.session_state.sim_stage == "WAIT_FIRST_QUERY":
        customer_query = st.text_area(
            L["customer_query_label"],
            key="customer_query_text_area",
            height=150,
            placeholder=L["initial_query_sample"],
        )

        # --- ê³ ê° ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë” ---
        # íŒŒì¼ ì—…ë¡œë”ëŠ” íŒŒì¼ ê°ì²´ë¥¼ ì§ì ‘ ë‹¤ë£¨ê¸° ë•Œë¬¸ì—, Streamlitì˜ ê¸°ë³¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        attachment_files = st.file_uploader(
            L["attachment_label"],
            type=["png", "jpg", "jpeg", "pdf"],  # ìŠ¤í¬ë¦°ìƒ· ë° ê´€ë ¨ ë¬¸ì„œ íƒ€ì…
            key="customer_attachment_file_uploader",
            help=L["attachment_placeholder"],
            # â­ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ í—ˆìš©
            accept_multiple_files=True
        )

        if attachment_files:
            # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥
            st.session_state.customer_attachment_file = [
                {
                    "name": f.name,
                    "type": f.type,
                    "size": f.size,
                }
                for f in attachment_files
            ]
        else:
            st.session_state.customer_attachment_file = None

        customer_email = st.text_input(
            L["customer_email_label"],
            key="customer_email",
        )
        customer_phone = st.text_input(
            L["customer_phone_label"],
            key="customer_phone",
        )

        customer_type_options = L["customer_type_options"]
        default_idx = 1 if len(customer_type_options) > 1 else 0
        customer_type_display = st.selectbox(
            L["customer_type_label"],
            customer_type_options,
            index=default_idx,
            key="customer_type_sim_select",
        )

        if st.button(L["button_simulate"], key="btn_simulate_initial"):
            if not customer_query.strip():
                st.warning(L["simulation_warning_query"])
                st.stop()

            # ì´ˆê¸° ìƒíƒœ ë¦¬ì…‹
            st.session_state.simulator_messages = []
            st.session_state.simulator_memory.clear()
            st.session_state.is_chat_ended = False
            st.session_state.initial_advice_provided = False
            st.session_state.is_solution_provided = False
            st.session_state.language_transfer_requested = False
            st.session_state.transfer_summary_text = ""
            st.session_state.start_time = None
            st.session_state.sim_attachment_context_for_llm = ""
            st.session_state.agent_attachment_file = None

            # 1) ê³ ê° ì²« ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.simulator_messages.append(
                {"role": "customer", "content": customer_query}
            )

            contact_info_block = ""
            if customer_email or customer_phone:
                contact_info_block = (
                    f"\n\n[Customer contact info for reference (DO NOT use these in your reply draft!)]"
                    f"\n- Email: {customer_email or 'N/A'}"
                    f"\n- Phone: {customer_phone or 'N/A'}"
                )

            # --- ì²¨ë¶€ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬) ---
            attachment_block = ""
            if st.session_state.customer_attachment_file and len(st.session_state.customer_attachment_file) > 0:
                file_count = len(st.session_state.customer_attachment_file)
                # LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  íŒŒì¼ ëª©ë¡ ë¬¸ìì—´ ìƒì„±
                file_names = ", ".join([f['name'] for f in st.session_state.customer_attachment_file])

                attachment_status_msg = L["attachment_status_llm"].format(
                    filename=file_names, count=file_count
                )
                attachment_block = f"\n\n[ATTACHMENT STATUS]\n{attachment_status_msg}\n"
                st.session_state.sim_attachment_context_for_llm = attachment_block  # ì„¸ì…˜ì— ì €ì¥

                # ê³ ê° ë©”ì‹œì§€ì— ì²¨ë¶€ íŒŒì¼ ì •ë³´ ì¶”ê°€ (í™”ë©´ì— í‘œì‹œìš©)
                display_list = ", ".join([f['name'] for f in st.session_state.customer_attachment_file])
                st.session_state.simulator_messages[-1]["content"] += (
                    f"\n\nğŸ“ *ì´ {file_count}ê°œì˜ íŒŒì¼ ì²¨ë¶€ë¨: {display_list}*"
                )
            # ---------------------------

            current_lang_key = st.session_state.language
            lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}[current_lang_key]

            # 2) Supervisor ê°€ì´ë“œ + ì´ˆì•ˆ ìƒì„± (ì²¨ë¶€ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨)
            initial_prompt = f"""
{st.session_state.sim_attachment_context_for_llm}
You are an AI Customer Support Supervisor. Your role is to analyze the following customer inquiry
from a **{customer_type_display}** and provide:

1) A detailed **response guideline for the human agent** (step-by-step).
2) A **ready-to-send draft reply** in {lang_name}.

[FORMAT]
- Use the exact markdown headers:
  - "### {L['simulation_advice_header']}"
  - "### {L['simulation_draft_header']}"

[CRITICAL GUIDELINE RULES]
1. **Initial Information Collection (Req 3):** The first step in the guideline MUST be to request the necessary initial diagnostic information (e.g., device compatibility, local status/location, order number) BEFORE attempting to troubleshoot or solve the problem.
2. **Empathy for Difficult Customers (Req 5):** If the customer type is 'Difficult Customer' or 'Highly Dissatisfied Customer', the guideline MUST emphasize extreme politeness, empathy, and apologies, even if the policy (e.g., no refund) must be enforced.
3. **24-48 Hour Follow-up (Req 6):** If the issue cannot be solved immediately or requires confirmation from a local partner/supervisor, the guideline MUST state the procedure:
   - Acknowledge the issue.
   - Inform the customer they will receive a definite answer within 24 or 48 hours.
   - Request the customer's email or phone number for follow-up contact.

Customer Inquiry:
{customer_query}
{contact_info_block}
"""

            if not st.session_state.is_llm_ready:
                mock_text = (
                    f"### {L['simulation_advice_header']}\n\n"
                    f"- (Mock) {customer_type_display} ìœ í˜• ê³ ê° ì‘ëŒ€ ê°€ì´ë“œì…ë‹ˆë‹¤. (ìš”ì²­ 3, 5, 6 ë°˜ì˜)\n\n"
                    f"### {L['simulation_draft_header']}\n\n"
                    f"(Mock) ì—ì´ì „íŠ¸ ì‘ëŒ€ ì´ˆì•ˆì´ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤ã€‚\n\n"
                )
                if attachment_block:
                    # ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª¨í‚¹ í…ìŠ¤íŠ¸ì— í¬í•¨
                    mock_text = f"ì²¨ë¶€ íŒŒì¼ ì •ë³´:\n{attachment_block.replace('[ATTACHMENT STATUS]', '').strip()}\n\n" + mock_text
                st.session_state.simulator_messages.append(
                    {"role": "supervisor", "content": mock_text}
                )
            else:
                with st.spinner(L["response_generating"]):
                    try:
                        text = run_llm(initial_prompt)
                        st.session_state.simulator_messages.append(
                            {"role": "supervisor", "content": text}
                        )
                    except Exception as e:
                        st.error(f"AI ì¡°ì–¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            st.session_state.initial_advice_provided = True
            save_simulation_history_local(
                customer_query,
                customer_type_display,
                st.session_state.simulator_messages,
                is_chat_ended=False,
                attachment_context=st.session_state.sim_attachment_context_for_llm,  # ì»¨í…ìŠ¤íŠ¸ ì €ì¥
            )
            st.session_state.sim_stage = "AGENT_TURN"
            st.rerun()

    # =========================
    # 4. ëŒ€í™” ë¡œê·¸ í‘œì‹œ (ê³µí†µ)
    # =========================
    for idx, msg in enumerate(st.session_state.simulator_messages):
        role = msg["role"]
        content = msg["content"]
        avatar = {"customer": "ğŸ™‹", "supervisor": "ğŸ¤–", "agent_response": "ğŸ§‘â€ğŸ’»", "customer_rebuttal": "âœ¨",
                  "system_end": "ğŸ“Œ"}.get(role, "ğŸ’¬")
        tts_role = "customer" if role.startswith("customer") or role == "customer_rebuttal" else (
            "agent" if role == "agent_response" else "supervisor")

        with st.chat_message(role, avatar=avatar):
            st.markdown(content)
            # ì¸ë±ìŠ¤ë¥¼ render_tts_buttonì— ì „ë‹¬í•˜ì—¬ ê³ ìœ  í‚¤ ìƒì„±ì— ì‚¬ìš©
            render_tts_button(content, st.session_state.language, role=tts_role, prefix=f"{role}_", index=idx)

        # ì´ê´€ ìš”ì•½ í‘œì‹œ (ì´ê´€ í›„ì—ë§Œ)
        if st.session_state.transfer_summary_text:
            st.markdown("---")
            st.markdown(f"**{L['transfer_summary_header']}**")
            st.info(L["transfer_summary_intro"])
            st.markdown(st.session_state.transfer_summary_text)
            st.markdown("---")

    # =========================
    # 5. ì—ì´ì „íŠ¸ ì…ë ¥ ë‹¨ê³„ (AGENT_TURN)
    # =========================
    if st.session_state.sim_stage == "AGENT_TURN":
        st.markdown(f"### {L['agent_response_header']}")

        if st.session_state.language_transfer_requested:
            st.error("ğŸš¨ ê³ ê°ì´ ì–¸ì–´ ì „í™˜(ì´ê´€)ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì‘ëŒ€í•˜ê±°ë‚˜ ì´ê´€ì„ ì§„í–‰í•˜ì„¸ìš”.")

        # --- ê³ ê° ì²¨ë¶€ íŒŒì¼ ì •ë³´ ì¬í‘œì‹œ ---
        if st.session_state.sim_attachment_context_for_llm:
            st.info(
                f"ğŸ“ ìµœì´ˆ ë¬¸ì˜ ì‹œ ì²¨ë¶€ëœ íŒŒì¼ ì •ë³´:\n\n{st.session_state.sim_attachment_context_for_llm.replace('[ATTACHMENT STATUS]', '').strip()}")

        # --- ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë” (ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬) ---
        agent_attachment_files = st.file_uploader(
            L["agent_attachment_label"],
            type=["png", "jpg", "jpeg", "pdf"],
            key="agent_attachment_file_uploader",
            help=L["agent_attachment_placeholder"],
            # â­ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ í—ˆìš©
            accept_multiple_files=True
        )

        if agent_attachment_files:
            # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥
            st.session_state.agent_attachment_file = [
                {
                    "name": f.name,
                    "type": f.type,
                    "size": f.size,
                }
                for f in agent_attachment_files
            ]
        else:
            st.session_state.agent_attachment_file = None

        col_mic, col_text = st.columns([1, 2])

        # --- ë§ˆì´í¬ ë…¹ìŒ ---
        with col_mic:
            mic_audio = mic_recorder(
                start_prompt=L["button_mic_input"],
                stop_prompt="â¹ï¸ ë…¹ìŒ ì¢…ë£Œ",
                just_once=False,
                format="wav",
                use_container_width=True,
                key="sim_mic_recorder",
            )

        if mic_audio and mic_audio.get("bytes"):
            st.session_state.sim_audio_bytes = mic_audio["bytes"]
            st.info("âœ… ë…¹ìŒ ì™„ë£Œ! ì•„ë˜ ì „ì‚¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”.")

        if st.session_state.sim_audio_bytes:
            st.audio(st.session_state.sim_audio_bytes, format="audio/wav")

        col_tr, _ = st.columns([1, 2])
        if col_tr.button(L["transcribe_btn"], key="sim_transcribe_btn"):
            if st.session_state.sim_audio_bytes is None:
                st.warning("ë¨¼ì € ë§ˆì´í¬ë¡œ ë…¹ìŒì„ ì™„ë£Œí•˜ì„¸ìš”.")
            elif st.session_state.openai_client is None:
                st.error(L["whisper_client_error"])
            else:
                with st.spinner(L["whisper_processing"]):
                    transcribed_text = transcribe_bytes_with_whisper(
                        st.session_state.sim_audio_bytes,
                        "audio/wav",
                        lang_code=st.session_state.language,
                    )
                    if transcribed_text.startswith("âŒ"):
                        st.error(transcribed_text)
                        st.session_state.last_transcript = ""
                    else:
                        st.session_state.last_transcript = transcribed_text.strip()
                        # ì „ì‚¬ëœ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ì°½ì— ë°˜ì˜
                        st.session_state.agent_response_area_text = transcribed_text.strip()
                        snippet = transcribed_text[:50].replace("\n", " ")
                        if len(transcribed_text) > 50:
                            snippet += "..."
                        st.success(L["whisper_success"] + f"\n\n**ì¸ì‹ ë‚´ìš©:** *{snippet}*")
                        st.rerun()  # í…ìŠ¤íŠ¸ ë°˜ì˜ì„ ìœ„í•´ UI ì¬ì‹¤í–‰


        def update_agent_response():
            st.session_state.agent_response_area_text = st.session_state.agent_response_input_box_widget


        col_text, col_button = st.columns([4, 1])

        with col_text:
            st.text_area(
                L["agent_response_placeholder"],
                value=st.session_state.agent_response_area_text,
                key="agent_response_input_box_widget",
                on_change=update_agent_response,
            )

            # ì†”ë£¨ì…˜ ì œê³µ ì²´í¬ë°•ìŠ¤
            st.session_state.is_solution_provided = st.checkbox(
                L["solution_check_label"],
                value=st.session_state.is_solution_provided,
                key="solution_checkbox_widget",
            )

        with col_button:
            send_clicked = st.button(L["send_response_button"], key="send_agent_response_btn")

        if send_clicked:
            agent_response = st.session_state.agent_response_input_box_widget.strip()

            if not agent_response:
                st.warning(L["empty_response_warning"])
                st.stop()

            # --- ì—ì´ì „íŠ¸ ì²¨ë¶€ íŒŒì¼ ì²˜ë¦¬ (ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬) ---
            final_response_content = agent_response
            if st.session_state.agent_attachment_file and len(st.session_state.agent_attachment_file) > 0:
                file_count = len(st.session_state.agent_attachment_file)
                file_names = ", ".join([f['name'] for f in st.session_state.agent_attachment_file])

                attachment_msg = L["agent_attachment_status"].format(
                    filename=file_names, count=file_count
                )
                final_response_content = f"{agent_response}\n\n---\n{attachment_msg}"

            st.session_state.agent_response_area_text = final_response_content  # ìµœì¢…ê°’ ë°˜ì˜

            # ë¡œê·¸ ì—…ë°ì´íŠ¸
            st.session_state.simulator_messages.append(
                {"role": "agent_response", "content": final_response_content}
            )

            # ì…ë ¥ì°½/ì˜¤ë””ì˜¤/ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            st.session_state.agent_response_area_text = ""
            st.session_state.sim_audio_bytes = None
            st.session_state.agent_attachment_file = None  # ì²¨ë¶€ íŒŒì¼ ì´ˆê¸°í™”
            st.session_state.language_transfer_requested = False

            # ë‹¤ìŒ ë‹¨ê³„: ê³ ê° ë°˜ì‘ ìƒì„± ìš”ì²­
            st.session_state.sim_stage = "CUSTOMER_TURN"
            st.rerun()

        # --- ì–¸ì–´ ì´ê´€ ë²„íŠ¼ ---
        st.markdown("---")
        st.markdown(f"**{L['transfer_header']}**")
        transfer_cols = st.columns(len(LANG) - 1)

        languages = list(LANG.keys())
        languages.remove(current_lang)


        def transfer_session(target_lang: str, current_messages: List[Dict[str, str]]):
            """ì–¸ì–´ ì´ê´€ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ê³  ì„¸ì…˜ ì–¸ì–´ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤."""

            # API í‚¤ ì²´í¬ëŠ” run_llm ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ Gemini í‚¤ë¥¼ ìš”êµ¬í•¨
            if not get_api_key("gemini"):
                st.error(LANG[current_lang]["simulation_no_key_warning"].replace('API Key', 'Gemini API Key'))
                st.stop()
                return

            # AHT íƒ€ì´ë¨¸ ì¤‘ì§€
            st.session_state.start_time = None

            # 1. ë¡œë”© ì‹œì‘ (ì‹œê°„ ì–‘í•´ ë©”ì‹œì§€ ì‹œë®¬ë ˆì´ì…˜)
            with st.spinner(L["transfer_loading"]):
                # ì‹¤ì œ ëŒ€ê¸° ì‹œê°„ 5~10ì´ˆ (3~10ë¶„ ì‹œë®¬ë ˆì´ì…˜)
                time.sleep(np.random.uniform(5, 10))

                # 2. ëŒ€í™” ê¸°ë¡ì„ ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¡œ ê°€ê³µ
                history_text = ""
                for msg in current_messages:
                    role = "Customer" if msg["role"].startswith("customer") or msg[
                        "role"] == "initial_query" else "Agent"
                    if msg["role"] in ["initial_query", "customer_rebuttal", "agent_response",
                                       "customer_closing_response"]:
                        history_text += f"{role}: {msg['content']}\n"

                # 3. LLM ë²ˆì—­ ì‹¤í–‰ (ìˆ˜ì •ëœ ë²ˆì—­ í•¨ìˆ˜ ì‚¬ìš©)
                translated_summary = translate_text_with_llm(history_text, target_lang, st.session_state.language)

                if translated_summary.startswith("âŒ"):
                    st.session_state.transfer_summary_text = translated_summary
                    st.rerun()
                    return

                # 4. ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.transfer_summary_text = translated_summary

                # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€ (ì´ê´€ ì•Œë¦¼)
                target_lang_name = {"ko": "í•œêµ­ì–´", "en": "English", "ja": "Japanese"}.get(target_lang,
                                                                                        target_lang.capitalize())
                system_msg = L["transfer_system_msg"].format(target_lang=target_lang_name)
                st.session_state.simulator_messages.append(
                    {"role": "system_end", "content": system_msg}
                )

                # ê¸°ì¡´ ì–¸ì–´ ì €ì¥
                old_lang = st.session_state.language
                st.session_state.language = target_lang  # ì–¸ì–´ ë³€ê²½
                st.session_state.is_solution_provided = False  # ìƒˆë¡œìš´ ì‘ëŒ€ë¥¼ ìœ„í•´ í”Œë˜ê·¸ ë¦¬ì…‹
                st.session_state.language_transfer_requested = False  # í”Œë˜ê·¸ ë¦¬ì…‹
                st.session_state.sim_stage = "AGENT_TURN"

                # 5. ì´ë ¥ ì €ì¥
                customer_type_display = st.session_state.get("customer_type_sim_select", "")
                save_simulation_history_local(
                    st.session_state.customer_query_text_area,
                    customer_type_display + f" (Transferred from {old_lang} to {target_lang})",
                    st.session_state.simulator_messages,
                    is_chat_ended=False,
                    attachment_context=st.session_state.sim_attachment_context_for_llm,  # ì»¨í…ìŠ¤íŠ¸ ì €ì¥
                )

            # 6. UI ì¬ì‹¤í–‰ (ì–¸ì–´ ë³€ê²½ ì ìš©)
            st.success(f"âœ… {LANG[target_lang]['transfer_summary_header']}ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì‘ëŒ€ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
            st.rerun()


        for i, target_lang in enumerate(languages):
            button_label_key = f"transfer_to_{target_lang}"
            button_label = L.get(button_label_key, f"Transfer to {target_lang.capitalize()} Team")

            if transfer_cols[i].button(button_label, key=f"btn_transfer_{target_lang}"):
                transfer_session(target_lang, st.session_state.simulator_messages)

        st.markdown("---")

    # --- Language Transfer Buttons End ---

    # =========================
    # 6. ê³ ê° ë°˜ì‘ ìƒì„± ë‹¨ê³„ (CUSTOMER_TURN)
    #    - ê³ ê° ë°˜ì‘ ìƒì„± í›„: ê°ì‚¬ í‘œí˜„ ì‹œ -> WAIT_CLOSING_CONFIRMATION_FROM_AGENTë¡œ, ì•„ë‹ˆë©´ -> AGENT_TURNìœ¼ë¡œ
    # =========================
    if st.session_state.sim_stage == "CUSTOMER_TURN":
        st.info("ì—ì´ì „íŠ¸ ì‘ë‹µ ì „ì†¡ ì™„ë£Œ. ê³ ê° ë°˜ì‘ ìƒì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # AHT íƒ€ì´ë¨¸ ì‹œì‘
        if st.session_state.start_time is None and len(st.session_state.simulator_messages) >= 2:
            st.session_state.start_time = datetime.now()

        if st.button(L["customer_generate_response_button"], key="sim_next_rebuttal_btn"):
            if not st.session_state.is_llm_ready:
                st.warning(L["simulation_no_key_warning"])
                st.stop()

            with st.spinner(L["response_generating"]):  # ë¡œë”© í‘œì‹œ
                reaction = generate_customer_reaction(st.session_state.language)

            if reaction.startswith("âŒ"):
                st.error(reaction)
                st.stop()

            st.session_state.simulator_messages.append(
                {"role": "customer_rebuttal", "content": reaction}
            )

            # ì–¸ì–´ ì´ê´€ ìš”ì²­ í‚¤ì›Œë“œ í™•ì¸
            lang_request_keywords = ["english", "japanese", "í•œêµ­ì–´", "è‹±èª", "æ—¥æœ¬èª", "korean"]
            if any(k in reaction.lower() for k in lang_request_keywords):
                st.session_state.language_transfer_requested = True

            # ì¢…ë£Œ ì˜ì‚¬ íŒë³„
            reaction_lower = reaction.lower()
            appreciation_signals = ["ê°ì‚¬", "thank", "ã‚ã‚ŠãŒã¨ã†", "noted"]
            has_appreciation = any(k in reaction_lower for k in appreciation_signals)

            is_additional_inquiry_signal = L['customer_has_additional_inquiries'] in reaction

            customer_type_display = st.session_state.get("customer_type_sim_select", "")

            # --- í•µì‹¬ ë¡œì§ ìˆ˜ì • ---
            # 1. ì†”ë£¨ì…˜ ì œê³µ O, ê³ ê° ê°ì‚¬ O -> ì¢…ë£Œ í™•ì¸ ë‹¨ê³„ë¡œ (WAIT_CLOSING_CONFIRMATION_FROM_AGENT)
            if st.session_state.is_solution_provided and has_appreciation and not is_additional_inquiry_signal:
                st.session_state.sim_stage = "WAIT_CLOSING_CONFIRMATION_FROM_AGENT"
                st.session_state.is_solution_provided = False  # ì¢…ë£Œ ë‹¨ê³„ ì§„ì… í›„ í”Œë˜ê·¸ ë¦¬ì…‹
                save_simulation_history_local(
                    st.session_state.customer_query_text_area, customer_type_display,
                    st.session_state.simulator_messages, is_chat_ended=False,
                    attachment_context=st.session_state.sim_attachment_context_for_llm,
                )
            # 2. ì†”ë£¨ì…˜ ì œê³µ X, ê³ ê° ë°˜ì‘ O (ë˜ëŠ” ì¶”ê°€ ë¬¸ì˜ O) -> ì—ì´ì „íŠ¸ í„´ ìœ ì§€ (AGENT_TURN)
            else:
                st.session_state.sim_stage = "AGENT_TURN"
                save_simulation_history_local(
                    st.session_state.customer_query_text_area, customer_type_display,
                    st.session_state.simulator_messages, is_chat_ended=False,
                    attachment_context=st.session_state.sim_attachment_context_for_llm,
                )

            st.rerun()

    # =========================
    # 7. ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ ëŒ€ê¸° (WAIT_CLOSING_CONFIRMATION_FROM_AGENT)
    #    - ê³ ê°ì´ ê°ì‚¬ ì¸ì‚¬ë¥¼ í–ˆìœ¼ë¯€ë¡œ, ì—ì´ì „íŠ¸ê°€ ì¢…ë£Œ í™•ì¸ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì•¼ í•¨
    # =========================
    if st.session_state.sim_stage == "WAIT_CLOSING_CONFIRMATION_FROM_AGENT":
        st.success("ê³ ê°ì´ ì†”ë£¨ì…˜ì— ê¸ì •ì ìœ¼ë¡œ ë°˜ì‘í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

        # ì—ì´ì „íŠ¸ê°€ "ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ í™•ì¸ ë©”ì‹œì§€"ë¥¼ ë³´ë‚´ëŠ” ë²„íŠ¼
        if st.button(L["send_closing_confirm_button"], key="btn_send_closing_confirm"):
            closing_msg = L["customer_closing_confirm"]

            # ì—ì´ì „íŠ¸ ì‘ë‹µìœ¼ë¡œ ë¡œê·¸ ê¸°ë¡
            st.session_state.simulator_messages.append(
                {"role": "agent_response", "content": closing_msg}
            )

            # ë‹¤ìŒ ë‹¨ê³„: ê³ ê°ì˜ ìµœì¢… ë‹µë³€ ëŒ€ê¸°
            st.session_state.sim_stage = "WAIT_CUSTOMER_CLOSING_RESPONSE"

            customer_type_display = st.session_state.get("customer_type_sim_select", "")
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=False,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )
            st.rerun()

    # =========================
    # 8. ê³ ê° ìµœì¢… ì‘ë‹µ ìƒì„± ë° ì²˜ë¦¬ (WAIT_CUSTOMER_CLOSING_RESPONSE)
    #    - ê³ ê° ë‹µë³€ì— ë”°ë¼ 8A(ì¢…ë£Œ) ë˜ëŠ” 8B(ì¶”ê°€ ë¬¸ì˜) ì²˜ë¦¬
    # =========================
    if st.session_state.sim_stage == "WAIT_CUSTOMER_CLOSING_RESPONSE":
        st.info("ì—ì´ì „íŠ¸ê°€ ì¶”ê°€ ë¬¸ì˜ ì—¬ë¶€ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³ ê°ì˜ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")

        # ê³ ê° ë‹µë³€ ìë™ ìƒì„±
        if st.button(L["customer_generate_response_button"], key="btn_generate_final_response"):
            if not st.session_state.is_llm_ready:
                st.warning(L["simulation_no_key_warning"])
                st.stop()

            with st.spinner(L["response_generating"]):
                # ê³ ê°ì˜ ìµœì¢… ë‹µë³€ ìƒì„±
                final_customer_reaction = generate_customer_closing_response(st.session_state.language)

            customer_type_display = st.session_state.get("customer_type_sim_select", "")

            # ë¡œê·¸ ê¸°ë¡
            st.session_state.simulator_messages.append(
                {"role": "customer_rebuttal", "content": final_customer_reaction}
            )

            # (A) "ì—†ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤" ê²½ë¡œ
            if L['customer_no_more_inquiries'] in final_customer_reaction:
                st.session_state.sim_stage = "FINAL_CLOSING_ACTION"
                save_simulation_history_local(
                    st.session_state.customer_query_text_area, customer_type_display,
                    st.session_state.simulator_messages, is_chat_ended=False,
                    attachment_context=st.session_state.sim_attachment_context_for_llm,
                )
            # (B) "ì¶”ê°€ ë¬¸ì˜ ì‚¬í•­ë„ ìˆìŠµë‹ˆë‹¤" ê²½ë¡œ
            elif L['customer_has_additional_inquiries'] in final_customer_reaction:
                st.session_state.sim_stage = "AGENT_TURN"  # ë‹¤ì‹œ ì—ì´ì „íŠ¸ ì‘ë‹µ ë‹¨ê³„ë¡œ
                save_simulation_history_local(
                    st.session_state.customer_query_text_area, customer_type_display,
                    st.session_state.simulator_messages, is_chat_ended=False,
                    attachment_context=st.session_state.sim_attachment_context_for_llm,
                )

            st.rerun()

    # =========================
    # 9. ìµœì¢… ì¢…ë£Œ í–‰ë™ (FINAL_CLOSING_ACTION)
    # =========================
    if st.session_state.sim_stage == "FINAL_CLOSING_ACTION":
        st.success("ê³ ê°ì´ ë” ì´ìƒ ë¬¸ì˜í•  ì‚¬í•­ì´ ì—†ë‹¤ê³  í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

        if st.button(L["sim_end_chat_button"], key="btn_final_end_chat"):
            # AHT íƒ€ì´ë¨¸ ì •ì§€
            st.session_state.start_time = None

            end_msg = L["prompt_survey"]
            st.session_state.simulator_messages.append(
                {"role": "system_end", "content": end_msg}
            )
            st.session_state.is_chat_ended = True
            st.session_state.sim_stage = "CLOSING"

            customer_type_display = st.session_state.get("customer_type_sim_select", "")
            save_simulation_history_local(
                st.session_state.customer_query_text_area, customer_type_display,
                st.session_state.simulator_messages, is_chat_ended=True,
                attachment_context=st.session_state.sim_attachment_context_for_llm,
            )

            st.rerun()

# -------------------- RAG Tab --------------------
elif feature_selection == L["rag_tab"]:
    st.header(L["rag_header"])
    st.markdown(L["rag_desc"])

    if not st.session_state.is_rag_ready or st.session_state.rag_vectorstore is None:
        if st.session_state.is_llm_ready:
            with st.spinner(L["firestore_loading"]):
                # RAG ì¸ë±ìŠ¤ ë¡œë“œ ì‹œì—ë„ ì„ë² ë”© í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, í‚¤ ìœ íš¨ì„± ì²´í¬ í•„ìš”
                vs = load_rag_index()
                if vs is not None:
                    st.session_state.rag_vectorstore = vs
                    st.session_state.is_rag_ready = True
                else:
                    st.info(L["firestore_no_index"])
        else:
            st.warning(L["warning_rag_not_ready"])

    if st.session_state.is_rag_ready and st.session_state.rag_vectorstore is not None:
        # ê¸°ì¡´ ëŒ€í™” ë¡œê·¸ í‘œì‹œ
        for m in st.session_state.rag_messages:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        user_q = st.chat_input(L["rag_input_placeholder"])
        if user_q:
            st.session_state.rag_messages.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)
            with st.chat_message("assistant"):
                with st.spinner(L["response_generating"]):
                    try:
                        ans = rag_answer(user_q, st.session_state.rag_vectorstore, st.session_state.language)
                        st.markdown(ans)
                        st.session_state.rag_messages.append({"role": "assistant", "content": ans})
                    except Exception as e:
                        st.error(f"ì±—ë´‡ ì˜¤ë¥˜: {e}")
                        msg = "ì˜¤ë¥˜ ë°œìƒ" if st.session_state.language == "ko" else "An error occurred"
                        st.session_state.rag_messages.append({"role": "assistant", "content": msg})
    else:
        st.warning(L["warning_rag_not_ready"])

# -------------------- Content Tab --------------------
elif feature_selection == L["content_tab"]:
    st.header(L["content_header"])
    st.markdown(L["content_desc"])

    if not st.session_state.is_llm_ready:
        st.error(L["llm_error_init"])
    else:
        topic = st.text_input(L["topic_label"])
        level_display = st.selectbox(L["level_label"], L["level_options"])
        content_display = st.selectbox(L["content_type_label"], L["content_options"])

        level_map = {
            "ì´ˆê¸‰": "Beginner",
            "ì¤‘ê¸‰": "Intermediate",
            "ê³ ê¸‰": "Advanced",
            "Beginner": "Beginner",
            "Intermediate": "Intermediate",
            "Advanced": "Advanced",
            "åˆç´š": "Beginner",
            "ä¸­ç´š": "Intermediate",
            "ä¸Šç´š": "Advanced",
        }
        content_map = {
            "í•µì‹¬ ìš”ì•½ ë…¸íŠ¸": "summary",
            "ê°ê´€ì‹ í€´ì¦ˆ 10ë¬¸í•­": "quiz",
            "ì‹¤ìŠµ ì˜ˆì œ ì•„ì´ë””ì–´": "example",
            "Key Summary Note": "summary",
            "10 MCQ Questions": "quiz",
            "Practical Example Idea": "example",
            "æ ¸å¿ƒè¦ç´„ãƒãƒ¼ãƒˆ": "summary",
            "é¸æŠå¼ã‚¯ã‚¤ã‚º10å•": "quiz",
            "å®Ÿè·µä¾‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢": "example",
        }

        level = level_map.get(level_display, "Beginner")
        content_type = content_map.get(content_display, "summary")

        if st.button(L["button_generate"]):
            if not topic.strip():
                st.warning(L["warning_topic"])
            else:
                target_lang = {"ko": "Korean", "en": "English", "ja": "Japanese"}[st.session_state.language]

                if content_type == "quiz":
                    system_prompt = (
                        "You are an expert quiz creator.\n"
                        "Generate EXACTLY 10 multiple-choice questions.\n"
                        "Return ONLY valid JSON wrapped inside ```json ... ```.\n"
                        "JSON structure:\n"
                        "{\n"
                        '  \"quiz_questions\": [\n'
                        "    {\n"
                        '      \"question\": \"...\",\n'
                        '      \"options\": [\"A\", \"B\", \"C\", \"D\"],\n'
                        '      \"correct_index\": 0,\n'
                        '      \"explanation\": \"...\"\n'
                        "    }\n"
                        "  ]\n"
                        "}\n"
                        f"The language of questions MUST be {target_lang}.\n"
                    )
                    user_msg = f"Topic: {topic} (level: {level})"
                    with st.spinner("í€´ì¦ˆ ìƒì„± ì¤‘..."):
                        try:
                            resp = run_llm(system_prompt + "\n\n" + user_msg)
                            # ë‹¨ìˆœ ì¶œë ¥
                            st.success(f"**{topic}** - {content_display}")
                            st.code(resp, language="json")
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")
                else:
                    content_prompt = (
                        f"You are a professional AI coach at the {level} level.\n"
                        f"Generate clear and educational content in {target_lang}.\n"
                        f"Content type: {content_type}.\n"
                        f"Topic: {topic}\n"
                    )
                    with st.spinner("ì½˜í…ì¸  ìƒì„± ì¤‘..."):
                        try:
                            resp = run_llm(content_prompt)
                            st.success(f"**{topic}** - {content_display}")
                            st.markdown(resp)
                        except Exception as e:
                            st.error(f"Content Generation Error: {e}")

# -------------------- LSTM Tab --------------------
elif feature_selection == L["lstm_tab"]:
    st.header(L["lstm_header"])
    st.markdown(L["lstm_desc"])

    if st.button(L["lstm_rerun_button"]):
        st.rerun()

    try:
        data = load_or_train_lstm()
        predicted_score = float(np.clip(data[-1] + np.random.uniform(-3, 5), 50, 100))

        st.markdown("---")
        st.subheader(L["lstm_result_header"])

        col_score, col_chart = st.columns([1, 2])

        with col_score:
            suffix = "ì " if st.session_state.language == "ko" else ""
            st.metric(L["lstm_score_metric"], f"{predicted_score:.1f}{suffix}")
            st.info(L["lstm_score_info"].format(predicted_score=predicted_score))

        with col_chart:
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(data, label="Past Scores", marker="o")
            ax.plot(len(data), predicted_score, marker="*", markersize=10)
            ax.set_title(L["lstm_header"])
            ax.set_xlabel("Time (attempts)")
            ax.set_ylabel("Score (0-100)")
            ax.legend()
            st.pyplot(fig)
    except Exception as e:
        st.info(f"LSTM ê¸°ëŠ¥ ì—ëŸ¬: {e}")
