# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
RAG ì²˜ë¦¬ ëª¨ë“ˆ
ë¬¸ì„œ ë¡œë“œ, ì„ë² ë”©, ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ë° ì§ˆë¬¸ ë‹µë³€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import io
import tempfile
import numpy as np
import streamlit as st
from typing import List
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_community.embeddings import HuggingFaceEmbeddings

from config import RAG_INDEX_DIR
from llm_client import get_api_key, get_llm_client, run_llm
from lang_pack import LANG

# ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    IS_GEMINI_EMBEDDING_AVAILABLE = True
except ImportError:
    IS_GEMINI_EMBEDDING_AVAILABLE = False

try:
    from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings
    IS_NVIDIA_EMBEDDING_AVAILABLE = True
except ImportError:
    IS_NVIDIA_EMBEDDING_AVAILABLE = False

def load_documents(files) -> List[Document]:
    docs: List[Document] = []
    for f in files:
        # â­ ìˆ˜ì •: íŒŒì¼ ê°ì²´ê°€ ì´ë¯¸ ë‹«í˜”ê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        try:
            # íŒŒì¼ì´ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            if isinstance(f, str):
                file_path = f
                name = os.path.basename(file_path)
                lower = name.lower()
                if lower.endswith(".pdf"):
                    # â­ ìˆ˜ì •: pypdf íŒ¨í‚¤ì§€ ì—†ì„ ë•Œ ì²˜ë¦¬
                    try:
                        loader = PyPDFLoader(file_path)
                        file_docs = loader.load()
                        for d in file_docs:
                            d.metadata["source"] = name
                        docs.extend(file_docs)
                    except ImportError as e:
                        error_msg = f"pypdf package not found, please install it with pip install pypdf"
                        st.warning(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({name}): {error_msg}")
                        continue
                    except Exception as e:
                        error_msg = f"PDF ë¡œë“œ ì˜¤ë¥˜: {e}"
                        st.warning(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({name}): {error_msg}")
                        continue
                elif lower.endswith(".txt") or lower.endswith(".html") or lower.endswith(".htm"):
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as file:
                        text = file.read()
                    docs.append(Document(page_content=text, metadata={"source": name}))
            else:
                # íŒŒì¼ ê°ì²´ì¸ ê²½ìš°
                name = getattr(f, 'name', 'unknown')
                lower = name.lower()
                
                # íŒŒì¼ì´ ì´ë¯¸ ì½í˜”ëŠ”ì§€ í™•ì¸í•˜ê³ , ì½ê¸° ê°€ëŠ¥í•œì§€ í™•ì¸
                try:
                    # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ë™ ì‹œë„
                    if hasattr(f, 'seek'):
                        f.seek(0)
                    # íŒŒì¼ì´ ì½ê¸° ëª¨ë“œì¸ì§€ í™•ì¸
                    if hasattr(f, 'read'):
                        file_content = f.read()
                    else:
                        # ì½ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° íŒŒì¼ ê²½ë¡œë¡œ ì²˜ë¦¬
                        if hasattr(f, 'name') and os.path.exists(f.name):
                            with open(f.name, "r", encoding="utf-8", errors="ignore") as file:
                                file_content = file.read()
                        else:
                            continue
                except (io.UnsupportedOperation, AttributeError, OSError) as e:
                    # íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° íŒŒì¼ ê²½ë¡œë¡œ ì²˜ë¦¬ ì‹œë„
                    if hasattr(f, 'name') and os.path.exists(f.name):
                        try:
                            with open(f.name, "r", encoding="utf-8", errors="ignore") as file:
                                file_content = file.read()
                        except Exception:
                            continue
                    else:
                        continue
                
                if lower.endswith(".pdf"):
                    # â­ ìˆ˜ì •: pypdf íŒ¨í‚¤ì§€ ì—†ì„ ë•Œ ì²˜ë¦¬
                    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
                    try:
                        if isinstance(file_content, bytes):
                            tmp.write(file_content)
                        else:
                            tmp.write(file_content.encode('utf-8'))
                        tmp.flush()
                        tmp.close()
                        try:
                            loader = PyPDFLoader(tmp.name)
                            file_docs = loader.load()
                            for d in file_docs:
                                d.metadata["source"] = name
                            docs.extend(file_docs)
                        except ImportError as e:
                            error_msg = f"pypdf package not found, please install it with pip install pypdf"
                            st.warning(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({name}): {error_msg}")
                    except Exception as e:
                        error_msg = f"PDF ë¡œë“œ ì˜¤ë¥˜: {e}"
                        st.warning(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({name}): {error_msg}")
                    finally:
                        try:
                            os.remove(tmp.name)
                        except OSError:
                            pass
                elif lower.endswith(".txt"):
                    if isinstance(file_content, bytes):
                        text = file_content.decode("utf-8", errors="ignore")
                    else:
                        text = file_content
                    docs.append(Document(page_content=text, metadata={"source": name}))
                elif lower.endswith(".html") or lower.endswith(".htm"):
                    if isinstance(file_content, bytes):
                        text = file_content.decode("utf-8", errors="ignore")
                    else:
                        text = file_content
                    docs.append(Document(page_content=text, metadata={"source": name}))
        except Exception as e:
            # ê°œë³„ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            import traceback
            st.warning(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({name if 'name' in locals() else 'unknown'}): {e}")
            continue
    return docs



def split_documents(docs: List[Document]) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=["\n\n", "\n", ".", " ", ""],
    )
    return splitter.split_documents(docs)



def get_embedding_model():
    if get_api_key("openai"):
        try:
            return OpenAIEmbeddings(model="text-embedding-3-small")
        except:
            pass
    if get_api_key("gemini"):
        try:
            return GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
        except:
            pass
    return None



def get_embedding_function():
    """
    RAG ì„ë² ë”©ì— ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ì„ ê²°ì •í•©ë‹ˆë‹¤.
    API í‚¤ ìœ íš¨ì„± ìˆœì„œ: OpenAI (ì‚¬ìš©ì ì„¤ì • ì‹œ) -> Gemini -> NVIDIA -> HuggingFace (fallback)
    API ì¸ì¦ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ì´ë™í•˜ë„ë¡ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """

    # 1. OpenAI ì„ë² ë”© ì‹œë„ (ì‚¬ìš©ìê°€ ìœ íš¨í•œ í‚¤ë¥¼ ì„¤ì •í–ˆì„ ê²½ìš°)
    openai_key = get_api_key("openai")
    if openai_key:
        try:
            st.info("ğŸ”¹ RAG: OpenAI Embedding ì‚¬ìš© ì¤‘")
            return OpenAIEmbeddings(openai_api_key=openai_key)
        except Exception as e:
            error_msg = str(e).lower()
            # â­ ìˆ˜ì •: quota exceeded, network issue ë“± êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ì²˜ë¦¬
            if "quota" in error_msg or "rate limit" in error_msg:
                st.warning(f"OpenAI ì„ë² ë”© ì‹¤íŒ¨ (í• ë‹¹ëŸ‰ ì´ˆê³¼) â†’ Geminië¡œ Fallback: {e}")
            elif "network" in error_msg or "connection" in error_msg or "timeout" in error_msg:
                st.warning(f"OpenAI ì„ë² ë”© ì‹¤íŒ¨ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜) â†’ Geminië¡œ Fallback: {e}")
            else:
                st.warning(f"OpenAI ì„ë² ë”© ì‹¤íŒ¨ â†’ Geminië¡œ Fallback: {e}")

    # 2. Gemini ì„ë² ë”© ì‹œë„
    gemini_key = get_api_key("gemini")
    if IS_GEMINI_EMBEDDING_AVAILABLE and gemini_key:
        try:
            st.info("ğŸ”¹ RAG: Gemini Embedding ì‚¬ìš© ì¤‘")
            # â­ ìˆ˜ì •: ëª¨ë¸ ì´ë¦„ í˜•ì‹ì„ 'models/model-name'ìœ¼ë¡œ ìˆ˜ì •
            return GoogleGenerativeAIEmbeddings(google_api_key=gemini_key, model="models/text-embedding-004")
        except Exception as e:
            st.warning(f"Gemini ì„ë² ë”© ì‹¤íŒ¨ â†’ NVIDIAë¡œ Fallback: {e}")

    # 3. NVIDIA ì„ë² ë”© ì‹œë„
    nvidia_key = get_api_key("nvidia")
    if IS_NVIDIA_EMBEDDING_AVAILABLE and nvidia_key:
        try:
            st.info("ğŸ”¹ RAG: NVIDIA Embedding ì‚¬ìš© ì¤‘")
            # NIM ëª¨ë¸ ì‚¬ìš© (ì‹¤ì œ í‚¤ê°€ ìœ íš¨í•´ì•¼ í•¨)
            return NVIDIAEmbeddings(api_key=nvidia_key, model="ai-embed-qa-4")
        except Exception as e:
            st.warning(f"NVIDIA ì„ë² ë”© ì‹¤íŒ¨ â†’ HuggingFace Fallback: {e}")

    # 4. HuggingFace Embeddings (Local Fallback)
    try:
        st.info("ğŸ”¹ RAG: Local HuggingFace Embedding ì‚¬ìš© ì¤‘")
        # ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš©
        return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    except Exception as e:
        st.warning(f"ìµœì¢… Fallback ì„ë² ë”© ì‹¤íŒ¨: {e}")

    st.error("âŒ RAG ì„ë² ë”© ì‹¤íŒ¨: ì‚¬ìš© ê°€ëŠ¥í•œ API Keyê°€ ì—†ìŠµë‹ˆë‹¤.")
    return None



def build_rag_index(files):
    # ì–¸ì–´ í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
    current_lang = st.session_state.get("language", "ko")
    if current_lang not in ["ko", "en", "ja"]:
        current_lang = "ko"
    L = LANG.get(current_lang, LANG["ko"])
    if not files: return None, 0

    # ì„ë² ë”© í•¨ìˆ˜ë¥¼ ì‹œë„í•˜ëŠ” ê³¼ì •ì—ì„œ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ try-exceptë¡œ ê°ìŒ‰ë‹ˆë‹¤.
    try:
        embeddings = get_embedding_function()
    except Exception as e:
        st.error(f"RAG ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™” ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, 0

    if embeddings is None:
        # ì–´ë–¤ ì„ë² ë”© ëª¨ë¸ë„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŒì„ ì•Œë¦¼
        error_msg = L["rag_embed_error_none"]

        # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ êµ¬ì„± (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°)
        if not get_api_key("openai"):
            error_msg += f"\n- {L['rag_embed_error_openai']}"
        if not get_api_key("gemini"):
            error_msg += f"\n- {L['rag_embed_error_gemini']}"
        if not get_api_key("nvidia"):
            error_msg += f"\n- {L['rag_embed_error_nvidia']}"

        st.error(error_msg)
        return None, 0

    # ì„ë² ë”© ê°ì²´ ì´ˆê¸°í™” ì„±ê³µ í›„, ë°ì´í„° ë¡œë“œ ë° ë¶„í• 
    docs = load_documents(files)
    if not docs: return None, 0

    chunks = split_documents(docs)
    if not chunks: return None, 0

    try:
        vectorstore = FAISS.from_documents(chunks, embeddings)
        # ì €ì¥
        vectorstore.save_local(RAG_INDEX_DIR)
    except Exception as e:
        # â­ ìˆ˜ì •: quota exceeded, network issue ë“± êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ì²˜ë¦¬
        error_msg = str(e).lower()
        if "quota" in error_msg or "rate limit" in error_msg:
            st.error(f"RAG ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ (í• ë‹¹ëŸ‰ ì´ˆê³¼): {e}")
        elif "network" in error_msg or "connection" in error_msg or "timeout" in error_msg:
            st.error(f"RAG ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ (ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ): {e}")
        else:
            st.error(f"RAG ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None, 0

    return vectorstore, len(chunks)



def load_rag_index():
    # RAG ì¸ë±ìŠ¤ ë¡œë“œ ì‹œì—ë„ ìœ íš¨í•œ ì„ë² ë”© í•¨ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    try:
        embeddings = get_embedding_function()
    except Exception:
        # get_embedding_function ë‚´ì—ì„œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê±°ë‚˜ ìŠ¤í‚µí•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¡°ìš©íˆ ì²˜ë¦¬
        return None

    if embeddings is None:
        return None

    try:
        # allow_dangerous_deserialization=TrueëŠ” í•„ìˆ˜
        vs = FAISS.load_local(RAG_INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
        return vs
    except Exception:
        return None



def rag_answer(question: str, vectorstore: FAISS, lang_key: str) -> str:
    # RAG AnswerëŠ” LLM í´ë¼ì´ì–¸íŠ¸ ë¼ìš°íŒ…ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
    llm_client, info = get_llm_client()
    if llm_client is None:
        # ì–¸ì–´ í‚¤ ê²€ì¦
        if lang_key not in ["ko", "en", "ja"]:
            lang_key = "ko"
        return LANG.get(lang_key, LANG["ko"]).get("simulation_no_key_warning", "API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # Langchain ChatOpenAI ëŒ€ì‹  run_llmì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ promptë¥¼ ì§ì ‘ êµ¬ì„±
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
    docs = retriever.get_relevant_documents(question)
    context = "\n\n".join(d.page_content[:1500] for d in docs)

    # â­ RAG ë‹¤êµ­ì–´ ì¸ì‹ ì˜¤ë¥˜ í•´ê²°: ë‹µë³€ ìƒì„± ëª¨ë¸ì—ê²Œ ì§ˆë¬¸ ì–¸ì–´ë¡œ ì¼ê´€ë˜ê²Œ ë‹µí•˜ë„ë¡ ê°•ë ¥íˆ ì§€ì‹œ
    lang_name = {"ko": "Korean", "en": "English", "ja": "Japanese"}.get(lang_key, "English")

    prompt = (
            f"You are a helpful AI tutor. Answer the question using ONLY the provided context.\n"
            f"The answer MUST be STRICTLY in {lang_name}, which is the language of the question.\n"
            f"If you cannot find the answer in the context, say you don't know in {lang_name}.\n"
            f"Note: The context may be in a different language, but you must still answer in {lang_name}.\n\n"
            "Question:\n" + question + "\n\n"
                                       "Context:\n" + context + "\n\n"
                                                                f"Answer (in {lang_name}):"
    )
    return run_llm(prompt)


# ========================================
# 7. LSTM Helper (ê°„ë‹¨ Mock + ì‹œê°í™”)
# ========================================


def load_or_train_lstm():
    # ì‹¤ì œ LSTM ëŒ€ì‹  ëœë¤ + sin íŒŒí˜• ê¸°ë°˜ Mock
    np.random.seed(42)
    n_points = 50
    ts = 60 + 20 * np.sin(np.linspace(0, 4 * np.pi, n_points)) + np.random.normal(0, 5, n_points)
    ts = np.clip(ts, 50, 100).astype(np.float32)
    return ts






